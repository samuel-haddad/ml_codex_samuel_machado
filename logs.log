2024-05-25 11:23:25,355:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-25 11:23:25,356:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-25 11:23:25,356:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-25 11:23:25,356:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-25 14:12:02,199:INFO:PyCaret ClassificationExperiment
2024-05-25 14:12:02,199:INFO:Logging name: ml_codex
2024-05-25 14:12:02,199:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-25 14:12:02,200:INFO:version 3.3.2
2024-05-25 14:12:02,200:INFO:Initializing setup()
2024-05-25 14:12:02,200:INFO:self.USI: 0a6e
2024-05-25 14:12:02,200:INFO:self._variable_keys: {'fold_generator', 'is_multiclass', 'y_train', 'html_param', 'log_plots_param', '_ml_usecase', 'fix_imbalance', 'y_test', 'exp_name_log', 'data', 'pipeline', 'y', 'USI', 'gpu_param', '_available_plots', 'n_jobs_param', 'target_param', 'exp_id', 'seed', 'X_test', 'X', 'logging_param', 'idx', 'fold_shuffle_param', 'memory', 'fold_groups_param', 'gpu_n_jobs_param', 'X_train'}
2024-05-25 14:12:02,200:INFO:Checking environment
2024-05-25 14:12:02,200:INFO:python_version: 3.10.13
2024-05-25 14:12:02,200:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-25 14:12:02,201:INFO:machine: AMD64
2024-05-25 14:12:02,201:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-25 14:12:02,201:INFO:Memory: svmem(total=34267656192, available=12831289344, percent=62.6, used=21436366848, free=12831289344)
2024-05-25 14:12:02,201:INFO:Physical Core: 8
2024-05-25 14:12:02,201:INFO:Logical Core: 16
2024-05-25 14:12:02,201:INFO:Checking libraries
2024-05-25 14:12:02,201:INFO:System:
2024-05-25 14:12:02,201:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-25 14:12:02,201:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-25 14:12:02,201:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-25 14:12:02,202:INFO:PyCaret required dependencies:
2024-05-25 14:12:02,281:INFO:                 pip: 23.3
2024-05-25 14:12:02,281:INFO:          setuptools: 68.0.0
2024-05-25 14:12:02,281:INFO:             pycaret: 3.3.2
2024-05-25 14:12:02,281:INFO:             IPython: 8.24.0
2024-05-25 14:12:02,281:INFO:          ipywidgets: 8.1.2
2024-05-25 14:12:02,281:INFO:                tqdm: 4.66.4
2024-05-25 14:12:02,282:INFO:               numpy: 1.26.4
2024-05-25 14:12:02,282:INFO:              pandas: 2.1.4
2024-05-25 14:12:02,282:INFO:              jinja2: 3.1.4
2024-05-25 14:12:02,282:INFO:               scipy: 1.11.4
2024-05-25 14:12:02,282:INFO:              joblib: 1.3.2
2024-05-25 14:12:02,282:INFO:             sklearn: 1.4.2
2024-05-25 14:12:02,283:INFO:                pyod: 1.1.3
2024-05-25 14:12:02,283:INFO:            imblearn: 0.12.2
2024-05-25 14:12:02,283:INFO:   category_encoders: 2.6.3
2024-05-25 14:12:02,283:INFO:            lightgbm: 4.3.0
2024-05-25 14:12:02,283:INFO:               numba: 0.59.1
2024-05-25 14:12:02,283:INFO:            requests: 2.32.2
2024-05-25 14:12:02,283:INFO:          matplotlib: 3.7.5
2024-05-25 14:12:02,283:INFO:          scikitplot: 0.3.7
2024-05-25 14:12:02,283:INFO:         yellowbrick: 1.5
2024-05-25 14:12:02,283:INFO:              plotly: 5.22.0
2024-05-25 14:12:02,283:INFO:    plotly-resampler: Not installed
2024-05-25 14:12:02,284:INFO:             kaleido: 0.2.1
2024-05-25 14:12:02,284:INFO:           schemdraw: 0.15
2024-05-25 14:12:02,284:INFO:         statsmodels: 0.14.2
2024-05-25 14:12:02,284:INFO:              sktime: 0.26.0
2024-05-25 14:12:02,284:INFO:               tbats: 1.1.3
2024-05-25 14:12:02,284:INFO:            pmdarima: 2.0.4
2024-05-25 14:12:02,284:INFO:              psutil: 5.9.0
2024-05-25 14:12:02,284:INFO:          markupsafe: 2.1.5
2024-05-25 14:12:02,284:INFO:             pickle5: Not installed
2024-05-25 14:12:02,284:INFO:         cloudpickle: 3.0.0
2024-05-25 14:12:02,284:INFO:         deprecation: 2.1.0
2024-05-25 14:12:02,285:INFO:              xxhash: 3.4.1
2024-05-25 14:12:02,285:INFO:           wurlitzer: Not installed
2024-05-25 14:12:02,285:INFO:PyCaret optional dependencies:
2024-05-25 14:12:02,312:INFO:                shap: Not installed
2024-05-25 14:12:02,313:INFO:           interpret: Not installed
2024-05-25 14:12:02,313:INFO:                umap: Not installed
2024-05-25 14:12:02,313:INFO:     ydata_profiling: Not installed
2024-05-25 14:12:02,313:INFO:  explainerdashboard: Not installed
2024-05-25 14:12:02,313:INFO:             autoviz: Not installed
2024-05-25 14:12:02,313:INFO:           fairlearn: Not installed
2024-05-25 14:12:02,313:INFO:          deepchecks: Not installed
2024-05-25 14:12:02,313:INFO:             xgboost: Not installed
2024-05-25 14:12:02,313:INFO:            catboost: Not installed
2024-05-25 14:12:02,314:INFO:              kmodes: Not installed
2024-05-25 14:12:02,314:INFO:             mlxtend: Not installed
2024-05-25 14:12:02,314:INFO:       statsforecast: Not installed
2024-05-25 14:12:02,314:INFO:        tune_sklearn: Not installed
2024-05-25 14:12:02,314:INFO:                 ray: Not installed
2024-05-25 14:12:02,314:INFO:            hyperopt: Not installed
2024-05-25 14:12:02,314:INFO:              optuna: Not installed
2024-05-25 14:12:02,314:INFO:               skopt: Not installed
2024-05-25 14:12:02,315:INFO:              mlflow: 2.13.0
2024-05-25 14:12:02,315:INFO:              gradio: Not installed
2024-05-25 14:12:02,315:INFO:             fastapi: Not installed
2024-05-25 14:12:02,315:INFO:             uvicorn: Not installed
2024-05-25 14:12:02,315:INFO:              m2cgen: Not installed
2024-05-25 14:12:02,315:INFO:           evidently: Not installed
2024-05-25 14:12:02,315:INFO:               fugue: Not installed
2024-05-25 14:12:02,315:INFO:           streamlit: Not installed
2024-05-25 14:12:02,315:INFO:             prophet: Not installed
2024-05-25 14:12:02,315:INFO:None
2024-05-25 14:12:02,316:INFO:Set up data.
2024-05-25 14:12:22,394:INFO:PyCaret ClassificationExperiment
2024-05-25 14:12:22,394:INFO:Logging name: ml_codex
2024-05-25 14:12:22,394:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-25 14:12:22,395:INFO:version 3.3.2
2024-05-25 14:12:22,395:INFO:Initializing setup()
2024-05-25 14:12:22,395:INFO:self.USI: cdba
2024-05-25 14:12:22,395:INFO:self._variable_keys: {'fold_generator', 'is_multiclass', 'y_train', 'html_param', 'log_plots_param', '_ml_usecase', 'fix_imbalance', 'y_test', 'exp_name_log', 'data', 'pipeline', 'y', 'USI', 'gpu_param', '_available_plots', 'n_jobs_param', 'target_param', 'exp_id', 'seed', 'X_test', 'X', 'logging_param', 'idx', 'fold_shuffle_param', 'memory', 'fold_groups_param', 'gpu_n_jobs_param', 'X_train'}
2024-05-25 14:12:22,395:INFO:Checking environment
2024-05-25 14:12:22,395:INFO:python_version: 3.10.13
2024-05-25 14:12:22,395:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-25 14:12:22,395:INFO:machine: AMD64
2024-05-25 14:12:22,395:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-25 14:12:22,396:INFO:Memory: svmem(total=34267656192, available=12840947712, percent=62.5, used=21426708480, free=12840947712)
2024-05-25 14:12:22,396:INFO:Physical Core: 8
2024-05-25 14:12:22,396:INFO:Logical Core: 16
2024-05-25 14:12:22,396:INFO:Checking libraries
2024-05-25 14:12:22,396:INFO:System:
2024-05-25 14:12:22,396:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-25 14:12:22,396:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-25 14:12:22,396:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-25 14:12:22,396:INFO:PyCaret required dependencies:
2024-05-25 14:12:22,397:INFO:                 pip: 23.3
2024-05-25 14:12:22,397:INFO:          setuptools: 68.0.0
2024-05-25 14:12:22,397:INFO:             pycaret: 3.3.2
2024-05-25 14:12:22,397:INFO:             IPython: 8.24.0
2024-05-25 14:12:22,397:INFO:          ipywidgets: 8.1.2
2024-05-25 14:12:22,397:INFO:                tqdm: 4.66.4
2024-05-25 14:12:22,397:INFO:               numpy: 1.26.4
2024-05-25 14:12:22,397:INFO:              pandas: 2.1.4
2024-05-25 14:12:22,397:INFO:              jinja2: 3.1.4
2024-05-25 14:12:22,398:INFO:               scipy: 1.11.4
2024-05-25 14:12:22,398:INFO:              joblib: 1.3.2
2024-05-25 14:12:22,398:INFO:             sklearn: 1.4.2
2024-05-25 14:12:22,398:INFO:                pyod: 1.1.3
2024-05-25 14:12:22,398:INFO:            imblearn: 0.12.2
2024-05-25 14:12:22,398:INFO:   category_encoders: 2.6.3
2024-05-25 14:12:22,398:INFO:            lightgbm: 4.3.0
2024-05-25 14:12:22,398:INFO:               numba: 0.59.1
2024-05-25 14:12:22,398:INFO:            requests: 2.32.2
2024-05-25 14:12:22,398:INFO:          matplotlib: 3.7.5
2024-05-25 14:12:22,398:INFO:          scikitplot: 0.3.7
2024-05-25 14:12:22,399:INFO:         yellowbrick: 1.5
2024-05-25 14:12:22,399:INFO:              plotly: 5.22.0
2024-05-25 14:12:22,399:INFO:    plotly-resampler: Not installed
2024-05-25 14:12:22,399:INFO:             kaleido: 0.2.1
2024-05-25 14:12:22,399:INFO:           schemdraw: 0.15
2024-05-25 14:12:22,399:INFO:         statsmodels: 0.14.2
2024-05-25 14:12:22,399:INFO:              sktime: 0.26.0
2024-05-25 14:12:22,399:INFO:               tbats: 1.1.3
2024-05-25 14:12:22,399:INFO:            pmdarima: 2.0.4
2024-05-25 14:12:22,399:INFO:              psutil: 5.9.0
2024-05-25 14:12:22,399:INFO:          markupsafe: 2.1.5
2024-05-25 14:12:22,400:INFO:             pickle5: Not installed
2024-05-25 14:12:22,400:INFO:         cloudpickle: 3.0.0
2024-05-25 14:12:22,400:INFO:         deprecation: 2.1.0
2024-05-25 14:12:22,400:INFO:              xxhash: 3.4.1
2024-05-25 14:12:22,400:INFO:           wurlitzer: Not installed
2024-05-25 14:12:22,400:INFO:PyCaret optional dependencies:
2024-05-25 14:12:22,400:INFO:                shap: Not installed
2024-05-25 14:12:22,400:INFO:           interpret: Not installed
2024-05-25 14:12:22,400:INFO:                umap: Not installed
2024-05-25 14:12:22,400:INFO:     ydata_profiling: Not installed
2024-05-25 14:12:22,400:INFO:  explainerdashboard: Not installed
2024-05-25 14:12:22,401:INFO:             autoviz: Not installed
2024-05-25 14:12:22,401:INFO:           fairlearn: Not installed
2024-05-25 14:12:22,401:INFO:          deepchecks: Not installed
2024-05-25 14:12:22,401:INFO:             xgboost: Not installed
2024-05-25 14:12:22,401:INFO:            catboost: Not installed
2024-05-25 14:12:22,401:INFO:              kmodes: Not installed
2024-05-25 14:12:22,401:INFO:             mlxtend: Not installed
2024-05-25 14:12:22,401:INFO:       statsforecast: Not installed
2024-05-25 14:12:22,401:INFO:        tune_sklearn: Not installed
2024-05-25 14:12:22,401:INFO:                 ray: Not installed
2024-05-25 14:12:22,401:INFO:            hyperopt: Not installed
2024-05-25 14:12:22,402:INFO:              optuna: Not installed
2024-05-25 14:12:22,402:INFO:               skopt: Not installed
2024-05-25 14:12:22,402:INFO:              mlflow: 2.13.0
2024-05-25 14:12:22,402:INFO:              gradio: Not installed
2024-05-25 14:12:22,402:INFO:             fastapi: Not installed
2024-05-25 14:12:22,402:INFO:             uvicorn: Not installed
2024-05-25 14:12:22,402:INFO:              m2cgen: Not installed
2024-05-25 14:12:22,403:INFO:           evidently: Not installed
2024-05-25 14:12:22,403:INFO:               fugue: Not installed
2024-05-25 14:12:22,403:INFO:           streamlit: Not installed
2024-05-25 14:12:22,403:INFO:             prophet: Not installed
2024-05-25 14:12:22,403:INFO:None
2024-05-25 14:12:22,403:INFO:Set up data.
2024-05-25 14:12:22,699:INFO:Set up folding strategy.
2024-05-25 14:12:22,699:INFO:Set up train/test split.
2024-05-25 14:12:22,755:INFO:Set up index.
2024-05-25 14:12:22,757:INFO:Assigning column types.
2024-05-25 14:12:22,778:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-25 14:12:22,850:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-25 14:12:22,857:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-25 14:12:22,922:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 14:12:22,922:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 14:12:22,994:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-25 14:12:22,996:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-25 14:12:23,041:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 14:12:23,041:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 14:12:23,042:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-25 14:12:23,114:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-25 14:12:23,159:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 14:12:23,159:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 14:12:23,234:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-25 14:12:23,278:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 14:12:23,279:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 14:12:23,279:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-25 14:12:23,397:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 14:12:23,397:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 14:12:23,515:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 14:12:23,515:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 14:12:23,521:INFO:Preparing preprocessing pipeline...
2024-05-25 14:12:23,525:INFO:Set up simple imputation.
2024-05-25 14:12:23,544:INFO:Set up encoding of ordinal features.
2024-05-25 14:12:23,551:INFO:Set up encoding of categorical features.
2024-05-25 14:12:23,554:INFO:Set up column name cleaning.
2024-05-25 14:12:24,834:INFO:Finished creating preprocessing pipeline.
2024-05-25 14:12:24,860:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=OneHotEncoder(cols=['listing_type_id',
                                                                    'buying_mode',
                                                                    'status',
                                                                    'seller_address.state.name',
                                                                    'shipping.mode'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-05-25 14:12:24,860:INFO:Creating final display dataframe.
2024-05-25 14:12:26,085:INFO:Setup _display_container:                     Description            Value
0                    Session id             2150
1                        Target           target
2                   Target type           Binary
3           Original data shape     (100000, 16)
4        Transformed data shape     (100000, 54)
5   Transformed train set shape      (70000, 54)
6    Transformed test set shape      (30000, 54)
7              Numeric features                5
8          Categorical features                6
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Fold Generator  StratifiedKFold
16                  Fold Number               10
17                     CPU Jobs               -1
18                      Use GPU            False
19               Log Experiment     MlflowLogger
20              Experiment Name         ml_codex
21                          USI             cdba
2024-05-25 14:12:26,212:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 14:12:26,213:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 14:12:26,331:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 14:12:26,332:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 14:12:26,333:INFO:Logging experiment in loggers
2024-05-25 14:12:26,834:INFO:SubProcess save_model() called ==================================
2024-05-25 14:12:26,883:INFO:Initializing save_model()
2024-05-25 14:12:26,883:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=OneHotEncoder(cols=['listing_type_id',
                                                                    'buying_mode',
                                                                    'status',
                                                                    'seller_address.state.name',
                                                                    'shipping.mode'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\Adm\AppData\Local\Temp\tmpuzvkw2lz\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=OneHotEncoder(cols=['listing_type_id',
                                                                    'buying_mode',
                                                                    'status',
                                                                    'seller_address.state.name',
                                                                    'shipping.mode'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-25 14:12:26,884:INFO:Adding model into prep_pipe
2024-05-25 14:12:26,884:WARNING:Only Model saved as it was a pipeline.
2024-05-25 14:12:26,909:INFO:C:\Users\Adm\AppData\Local\Temp\tmpuzvkw2lz\Transformation Pipeline.pkl saved in current working directory
2024-05-25 14:12:26,934:INFO:Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=OneHotEncoder(cols=['listing_type_id',
                                                                    'buying_mode',
                                                                    'status',
                                                                    'seller_address.state.name',
                                                                    'shipping.mode'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-05-25 14:12:26,934:INFO:save_model() successfully completed......................................
2024-05-25 14:12:27,868:INFO:SubProcess save_model() end ==================================
2024-05-25 14:12:27,895:INFO:setup() successfully completed in 3.94s...............
2024-05-25 14:12:27,895:INFO:Initializing compare_models()
2024-05-25 14:12:27,895:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276DA906200>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000276DA906200>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-25 14:12:27,895:INFO:Checking exceptions
2024-05-25 14:12:27,915:INFO:Preparing display monitor
2024-05-25 14:12:27,946:INFO:Initializing Logistic Regression
2024-05-25 14:12:27,946:INFO:Total runtime is 0.0 minutes
2024-05-25 14:12:27,951:INFO:SubProcess create_model() called ==================================
2024-05-25 14:12:27,951:INFO:Initializing create_model()
2024-05-25 14:12:27,951:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276DA906200>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276DAA79090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 14:12:27,952:INFO:Checking exceptions
2024-05-25 14:12:27,952:INFO:Importing libraries
2024-05-25 14:12:27,952:INFO:Copying training dataset
2024-05-25 14:12:27,990:INFO:Defining folds
2024-05-25 14:12:27,990:INFO:Declaring metric variables
2024-05-25 14:12:27,996:INFO:Importing untrained model
2024-05-25 14:12:28,001:INFO:Logistic Regression Imported successfully
2024-05-25 14:12:28,011:INFO:Starting cross validation
2024-05-25 14:12:28,015:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 14:12:54,790:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-25 14:12:54,917:INFO:Calculating mean and std
2024-05-25 14:12:54,919:INFO:Creating metrics dataframe
2024-05-25 14:12:54,922:INFO:Uploading results into container
2024-05-25 14:12:54,922:INFO:Uploading model into container now
2024-05-25 14:12:54,923:INFO:_master_model_container: 1
2024-05-25 14:12:54,923:INFO:_display_container: 2
2024-05-25 14:12:54,924:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2150, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-25 14:12:54,924:INFO:create_model() successfully completed......................................
2024-05-25 14:12:55,829:INFO:SubProcess create_model() end ==================================
2024-05-25 14:12:55,830:INFO:Creating metrics dataframe
2024-05-25 14:12:55,838:INFO:Initializing K Neighbors Classifier
2024-05-25 14:12:55,839:INFO:Total runtime is 0.4648832480112712 minutes
2024-05-25 14:12:55,843:INFO:SubProcess create_model() called ==================================
2024-05-25 14:12:55,844:INFO:Initializing create_model()
2024-05-25 14:12:55,844:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276DA906200>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276DAA79090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 14:12:55,844:INFO:Checking exceptions
2024-05-25 14:12:55,844:INFO:Importing libraries
2024-05-25 14:12:55,844:INFO:Copying training dataset
2024-05-25 14:12:55,879:INFO:Defining folds
2024-05-25 14:12:55,879:INFO:Declaring metric variables
2024-05-25 14:12:55,884:INFO:Importing untrained model
2024-05-25 14:12:55,889:INFO:K Neighbors Classifier Imported successfully
2024-05-25 14:12:55,899:INFO:Starting cross validation
2024-05-25 14:12:55,903:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 14:13:13,167:INFO:Calculating mean and std
2024-05-25 14:13:13,169:INFO:Creating metrics dataframe
2024-05-25 14:13:13,172:INFO:Uploading results into container
2024-05-25 14:13:13,173:INFO:Uploading model into container now
2024-05-25 14:13:13,173:INFO:_master_model_container: 2
2024-05-25 14:13:13,173:INFO:_display_container: 2
2024-05-25 14:13:13,174:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-25 14:13:13,175:INFO:create_model() successfully completed......................................
2024-05-25 14:13:14,129:INFO:SubProcess create_model() end ==================================
2024-05-25 14:13:14,129:INFO:Creating metrics dataframe
2024-05-25 14:13:14,139:INFO:Initializing Naive Bayes
2024-05-25 14:13:14,139:INFO:Total runtime is 0.7698832472165426 minutes
2024-05-25 14:13:14,144:INFO:SubProcess create_model() called ==================================
2024-05-25 14:13:14,144:INFO:Initializing create_model()
2024-05-25 14:13:14,145:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276DA906200>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276DAA79090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 14:13:14,145:INFO:Checking exceptions
2024-05-25 14:13:14,145:INFO:Importing libraries
2024-05-25 14:13:14,145:INFO:Copying training dataset
2024-05-25 14:13:14,181:INFO:Defining folds
2024-05-25 14:13:14,181:INFO:Declaring metric variables
2024-05-25 14:13:14,186:INFO:Importing untrained model
2024-05-25 14:13:14,191:INFO:Naive Bayes Imported successfully
2024-05-25 14:13:14,203:INFO:Starting cross validation
2024-05-25 14:13:14,209:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 14:13:16,659:INFO:Calculating mean and std
2024-05-25 14:13:16,661:INFO:Creating metrics dataframe
2024-05-25 14:13:16,664:INFO:Uploading results into container
2024-05-25 14:13:16,665:INFO:Uploading model into container now
2024-05-25 14:13:16,665:INFO:_master_model_container: 3
2024-05-25 14:13:16,666:INFO:_display_container: 2
2024-05-25 14:13:16,666:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-25 14:13:16,666:INFO:create_model() successfully completed......................................
2024-05-25 14:13:17,585:INFO:SubProcess create_model() end ==================================
2024-05-25 14:13:17,585:INFO:Creating metrics dataframe
2024-05-25 14:13:17,596:INFO:Initializing Decision Tree Classifier
2024-05-25 14:13:17,597:INFO:Total runtime is 0.8275166074434916 minutes
2024-05-25 14:13:17,601:INFO:SubProcess create_model() called ==================================
2024-05-25 14:13:17,601:INFO:Initializing create_model()
2024-05-25 14:13:17,602:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276DA906200>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276DAA79090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 14:13:17,602:INFO:Checking exceptions
2024-05-25 14:13:17,602:INFO:Importing libraries
2024-05-25 14:13:17,602:INFO:Copying training dataset
2024-05-25 14:13:17,638:INFO:Defining folds
2024-05-25 14:13:17,638:INFO:Declaring metric variables
2024-05-25 14:13:17,643:INFO:Importing untrained model
2024-05-25 14:13:17,649:INFO:Decision Tree Classifier Imported successfully
2024-05-25 14:13:17,658:INFO:Starting cross validation
2024-05-25 14:13:17,663:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 14:13:20,267:INFO:Calculating mean and std
2024-05-25 14:13:20,269:INFO:Creating metrics dataframe
2024-05-25 14:13:20,272:INFO:Uploading results into container
2024-05-25 14:13:20,272:INFO:Uploading model into container now
2024-05-25 14:13:20,273:INFO:_master_model_container: 4
2024-05-25 14:13:20,273:INFO:_display_container: 2
2024-05-25 14:13:20,274:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2150, splitter='best')
2024-05-25 14:13:20,274:INFO:create_model() successfully completed......................................
2024-05-25 14:13:21,181:INFO:SubProcess create_model() end ==================================
2024-05-25 14:13:21,181:INFO:Creating metrics dataframe
2024-05-25 14:13:21,191:INFO:Initializing SVM - Linear Kernel
2024-05-25 14:13:21,192:INFO:Total runtime is 0.8874332547187805 minutes
2024-05-25 14:13:21,197:INFO:SubProcess create_model() called ==================================
2024-05-25 14:13:21,197:INFO:Initializing create_model()
2024-05-25 14:13:21,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276DA906200>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276DAA79090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 14:13:21,197:INFO:Checking exceptions
2024-05-25 14:13:21,198:INFO:Importing libraries
2024-05-25 14:13:21,198:INFO:Copying training dataset
2024-05-25 14:13:21,234:INFO:Defining folds
2024-05-25 14:13:21,234:INFO:Declaring metric variables
2024-05-25 14:13:21,238:INFO:Importing untrained model
2024-05-25 14:13:21,244:INFO:SVM - Linear Kernel Imported successfully
2024-05-25 14:13:21,253:INFO:Starting cross validation
2024-05-25 14:13:21,258:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 14:13:23,724:INFO:Calculating mean and std
2024-05-25 14:13:23,726:INFO:Creating metrics dataframe
2024-05-25 14:13:23,728:INFO:Uploading results into container
2024-05-25 14:13:23,729:INFO:Uploading model into container now
2024-05-25 14:13:23,729:INFO:_master_model_container: 5
2024-05-25 14:13:23,730:INFO:_display_container: 2
2024-05-25 14:13:23,730:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2150, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-25 14:13:23,731:INFO:create_model() successfully completed......................................
2024-05-25 14:13:24,637:INFO:SubProcess create_model() end ==================================
2024-05-25 14:13:24,638:INFO:Creating metrics dataframe
2024-05-25 14:13:24,649:INFO:Initializing Ridge Classifier
2024-05-25 14:13:24,649:INFO:Total runtime is 0.9450499097506205 minutes
2024-05-25 14:13:24,655:INFO:SubProcess create_model() called ==================================
2024-05-25 14:13:24,656:INFO:Initializing create_model()
2024-05-25 14:13:24,656:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276DA906200>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276DAA79090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 14:13:24,656:INFO:Checking exceptions
2024-05-25 14:13:24,656:INFO:Importing libraries
2024-05-25 14:13:24,656:INFO:Copying training dataset
2024-05-25 14:13:24,694:INFO:Defining folds
2024-05-25 14:13:24,694:INFO:Declaring metric variables
2024-05-25 14:13:24,700:INFO:Importing untrained model
2024-05-25 14:13:24,705:INFO:Ridge Classifier Imported successfully
2024-05-25 14:13:24,715:INFO:Starting cross validation
2024-05-25 14:13:24,719:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 14:13:26,551:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=7.22458e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 14:13:26,597:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=7.22412e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 14:13:26,628:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=7.22469e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 14:13:26,644:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=7.22451e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 14:13:26,650:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=7.22426e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 14:13:26,731:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=7.2252e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 14:13:26,767:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=7.22454e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 14:13:26,775:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=7.22416e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 14:13:26,784:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=7.22444e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 14:13:26,977:INFO:Calculating mean and std
2024-05-25 14:13:26,979:INFO:Creating metrics dataframe
2024-05-25 14:13:26,982:INFO:Uploading results into container
2024-05-25 14:13:26,983:INFO:Uploading model into container now
2024-05-25 14:13:26,983:INFO:_master_model_container: 6
2024-05-25 14:13:26,984:INFO:_display_container: 2
2024-05-25 14:13:26,984:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2150, solver='auto',
                tol=0.0001)
2024-05-25 14:13:26,984:INFO:create_model() successfully completed......................................
2024-05-25 14:13:27,886:INFO:SubProcess create_model() end ==================================
2024-05-25 14:13:27,887:INFO:Creating metrics dataframe
2024-05-25 14:13:27,900:INFO:Initializing Random Forest Classifier
2024-05-25 14:13:27,900:INFO:Total runtime is 0.9992332418759664 minutes
2024-05-25 14:13:27,905:INFO:SubProcess create_model() called ==================================
2024-05-25 14:13:27,905:INFO:Initializing create_model()
2024-05-25 14:13:27,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276DA906200>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276DAA79090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 14:13:27,905:INFO:Checking exceptions
2024-05-25 14:13:27,906:INFO:Importing libraries
2024-05-25 14:13:27,906:INFO:Copying training dataset
2024-05-25 14:13:27,942:INFO:Defining folds
2024-05-25 14:13:27,943:INFO:Declaring metric variables
2024-05-25 14:13:27,949:INFO:Importing untrained model
2024-05-25 14:13:27,954:INFO:Random Forest Classifier Imported successfully
2024-05-25 14:13:27,964:INFO:Starting cross validation
2024-05-25 14:13:27,969:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 14:13:40,333:INFO:Calculating mean and std
2024-05-25 14:13:40,335:INFO:Creating metrics dataframe
2024-05-25 14:13:40,337:INFO:Uploading results into container
2024-05-25 14:13:40,338:INFO:Uploading model into container now
2024-05-25 14:13:40,339:INFO:_master_model_container: 7
2024-05-25 14:13:40,339:INFO:_display_container: 2
2024-05-25 14:13:40,339:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2150, verbose=0,
                       warm_start=False)
2024-05-25 14:13:40,340:INFO:create_model() successfully completed......................................
2024-05-25 14:13:41,242:INFO:SubProcess create_model() end ==================================
2024-05-25 14:13:41,242:INFO:Creating metrics dataframe
2024-05-25 14:13:41,255:INFO:Initializing Quadratic Discriminant Analysis
2024-05-25 14:13:41,255:INFO:Total runtime is 1.2218165834744772 minutes
2024-05-25 14:13:41,260:INFO:SubProcess create_model() called ==================================
2024-05-25 14:13:41,260:INFO:Initializing create_model()
2024-05-25 14:13:41,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276DA906200>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276DAA79090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 14:13:41,261:INFO:Checking exceptions
2024-05-25 14:13:41,261:INFO:Importing libraries
2024-05-25 14:13:41,261:INFO:Copying training dataset
2024-05-25 14:13:41,296:INFO:Defining folds
2024-05-25 14:13:41,296:INFO:Declaring metric variables
2024-05-25 14:13:41,302:INFO:Importing untrained model
2024-05-25 14:13:41,307:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-25 14:13:41,318:INFO:Starting cross validation
2024-05-25 14:13:41,323:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 14:13:43,386:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 14:13:43,646:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 14:13:43,742:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 14:13:43,889:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 14:13:43,893:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 14:13:43,934:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 14:13:43,942:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 14:13:44,011:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 14:13:44,024:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 14:13:44,088:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 14:13:45,067:INFO:Calculating mean and std
2024-05-25 14:13:45,069:INFO:Creating metrics dataframe
2024-05-25 14:13:45,072:INFO:Uploading results into container
2024-05-25 14:13:45,072:INFO:Uploading model into container now
2024-05-25 14:13:45,073:INFO:_master_model_container: 8
2024-05-25 14:13:45,073:INFO:_display_container: 2
2024-05-25 14:13:45,074:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-25 14:13:45,074:INFO:create_model() successfully completed......................................
2024-05-25 14:13:45,971:INFO:SubProcess create_model() end ==================================
2024-05-25 14:13:45,971:INFO:Creating metrics dataframe
2024-05-25 14:13:45,984:INFO:Initializing Ada Boost Classifier
2024-05-25 14:13:45,985:INFO:Total runtime is 1.3006332437197368 minutes
2024-05-25 14:13:45,989:INFO:SubProcess create_model() called ==================================
2024-05-25 14:13:45,989:INFO:Initializing create_model()
2024-05-25 14:13:45,990:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276DA906200>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276DAA79090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 14:13:45,990:INFO:Checking exceptions
2024-05-25 14:13:45,990:INFO:Importing libraries
2024-05-25 14:13:45,990:INFO:Copying training dataset
2024-05-25 14:13:46,026:INFO:Defining folds
2024-05-25 14:13:46,026:INFO:Declaring metric variables
2024-05-25 14:13:46,032:INFO:Importing untrained model
2024-05-25 14:13:46,037:INFO:Ada Boost Classifier Imported successfully
2024-05-25 14:13:46,047:INFO:Starting cross validation
2024-05-25 14:13:46,051:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 14:13:47,670:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 14:13:47,681:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 14:13:47,764:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 14:13:47,794:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 14:13:47,812:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 14:13:47,866:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 14:13:47,900:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 14:13:47,917:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 14:13:47,942:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 14:13:47,953:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 14:13:53,849:INFO:Calculating mean and std
2024-05-25 14:13:53,851:INFO:Creating metrics dataframe
2024-05-25 14:13:53,853:INFO:Uploading results into container
2024-05-25 14:13:53,854:INFO:Uploading model into container now
2024-05-25 14:13:53,855:INFO:_master_model_container: 9
2024-05-25 14:13:53,855:INFO:_display_container: 2
2024-05-25 14:13:53,855:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2150)
2024-05-25 14:13:53,856:INFO:create_model() successfully completed......................................
2024-05-25 14:13:54,755:INFO:SubProcess create_model() end ==================================
2024-05-25 14:13:54,755:INFO:Creating metrics dataframe
2024-05-25 14:13:54,769:INFO:Initializing Gradient Boosting Classifier
2024-05-25 14:13:54,769:INFO:Total runtime is 1.447049911816915 minutes
2024-05-25 14:13:54,773:INFO:SubProcess create_model() called ==================================
2024-05-25 14:13:54,774:INFO:Initializing create_model()
2024-05-25 14:13:54,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276DA906200>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276DAA79090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 14:13:54,774:INFO:Checking exceptions
2024-05-25 14:13:54,774:INFO:Importing libraries
2024-05-25 14:13:54,774:INFO:Copying training dataset
2024-05-25 14:13:54,809:INFO:Defining folds
2024-05-25 14:13:54,809:INFO:Declaring metric variables
2024-05-25 14:13:54,815:INFO:Importing untrained model
2024-05-25 14:13:54,820:INFO:Gradient Boosting Classifier Imported successfully
2024-05-25 14:13:54,830:INFO:Starting cross validation
2024-05-25 14:13:54,835:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 14:14:09,802:INFO:Calculating mean and std
2024-05-25 14:14:09,804:INFO:Creating metrics dataframe
2024-05-25 14:14:09,806:INFO:Uploading results into container
2024-05-25 14:14:09,807:INFO:Uploading model into container now
2024-05-25 14:14:09,807:INFO:_master_model_container: 10
2024-05-25 14:14:09,807:INFO:_display_container: 2
2024-05-25 14:14:09,808:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2150, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-25 14:14:09,809:INFO:create_model() successfully completed......................................
2024-05-25 14:14:10,720:INFO:SubProcess create_model() end ==================================
2024-05-25 14:14:10,721:INFO:Creating metrics dataframe
2024-05-25 14:14:10,735:INFO:Initializing Linear Discriminant Analysis
2024-05-25 14:14:10,735:INFO:Total runtime is 1.713149909178416 minutes
2024-05-25 14:14:10,740:INFO:SubProcess create_model() called ==================================
2024-05-25 14:14:10,740:INFO:Initializing create_model()
2024-05-25 14:14:10,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276DA906200>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276DAA79090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 14:14:10,741:INFO:Checking exceptions
2024-05-25 14:14:10,741:INFO:Importing libraries
2024-05-25 14:14:10,741:INFO:Copying training dataset
2024-05-25 14:14:10,776:INFO:Defining folds
2024-05-25 14:14:10,777:INFO:Declaring metric variables
2024-05-25 14:14:10,781:INFO:Importing untrained model
2024-05-25 14:14:10,787:INFO:Linear Discriminant Analysis Imported successfully
2024-05-25 14:14:10,797:INFO:Starting cross validation
2024-05-25 14:14:10,801:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 14:14:14,716:INFO:Calculating mean and std
2024-05-25 14:14:14,718:INFO:Creating metrics dataframe
2024-05-25 14:14:14,720:INFO:Uploading results into container
2024-05-25 14:14:14,721:INFO:Uploading model into container now
2024-05-25 14:14:14,722:INFO:_master_model_container: 11
2024-05-25 14:14:14,722:INFO:_display_container: 2
2024-05-25 14:14:14,722:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-25 14:14:14,722:INFO:create_model() successfully completed......................................
2024-05-25 14:14:15,641:INFO:SubProcess create_model() end ==================================
2024-05-25 14:14:15,641:INFO:Creating metrics dataframe
2024-05-25 14:14:15,655:INFO:Initializing Extra Trees Classifier
2024-05-25 14:14:15,656:INFO:Total runtime is 1.7951499621073406 minutes
2024-05-25 14:14:15,660:INFO:SubProcess create_model() called ==================================
2024-05-25 14:14:15,660:INFO:Initializing create_model()
2024-05-25 14:14:15,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276DA906200>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276DAA79090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 14:14:15,661:INFO:Checking exceptions
2024-05-25 14:14:15,661:INFO:Importing libraries
2024-05-25 14:14:15,661:INFO:Copying training dataset
2024-05-25 14:14:15,697:INFO:Defining folds
2024-05-25 14:14:15,697:INFO:Declaring metric variables
2024-05-25 14:14:15,703:INFO:Importing untrained model
2024-05-25 14:14:15,708:INFO:Extra Trees Classifier Imported successfully
2024-05-25 14:14:15,719:INFO:Starting cross validation
2024-05-25 14:14:15,724:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 14:14:32,236:INFO:Calculating mean and std
2024-05-25 14:14:32,238:INFO:Creating metrics dataframe
2024-05-25 14:14:32,240:INFO:Uploading results into container
2024-05-25 14:14:32,241:INFO:Uploading model into container now
2024-05-25 14:14:32,242:INFO:_master_model_container: 12
2024-05-25 14:14:32,242:INFO:_display_container: 2
2024-05-25 14:14:32,243:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2150, verbose=0,
                     warm_start=False)
2024-05-25 14:14:32,243:INFO:create_model() successfully completed......................................
2024-05-25 14:14:33,165:INFO:SubProcess create_model() end ==================================
2024-05-25 14:14:33,165:INFO:Creating metrics dataframe
2024-05-25 14:14:33,180:INFO:Initializing Light Gradient Boosting Machine
2024-05-25 14:14:33,180:INFO:Total runtime is 2.0872332652409873 minutes
2024-05-25 14:14:33,184:INFO:SubProcess create_model() called ==================================
2024-05-25 14:14:33,185:INFO:Initializing create_model()
2024-05-25 14:14:33,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276DA906200>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276DAA79090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 14:14:33,185:INFO:Checking exceptions
2024-05-25 14:14:33,185:INFO:Importing libraries
2024-05-25 14:14:33,185:INFO:Copying training dataset
2024-05-25 14:14:33,220:INFO:Defining folds
2024-05-25 14:14:33,221:INFO:Declaring metric variables
2024-05-25 14:14:33,226:INFO:Importing untrained model
2024-05-25 14:14:33,233:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 14:14:33,243:INFO:Starting cross validation
2024-05-25 14:14:33,248:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 14:14:36,915:INFO:Calculating mean and std
2024-05-25 14:14:36,917:INFO:Creating metrics dataframe
2024-05-25 14:14:36,922:INFO:Uploading results into container
2024-05-25 14:14:36,923:INFO:Uploading model into container now
2024-05-25 14:14:36,924:INFO:_master_model_container: 13
2024-05-25 14:14:36,925:INFO:_display_container: 2
2024-05-25 14:14:36,926:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2150, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-25 14:14:36,926:INFO:create_model() successfully completed......................................
2024-05-25 14:14:37,868:INFO:SubProcess create_model() end ==================================
2024-05-25 14:14:37,868:INFO:Creating metrics dataframe
2024-05-25 14:14:37,884:INFO:Initializing Dummy Classifier
2024-05-25 14:14:37,884:INFO:Total runtime is 2.165633300940196 minutes
2024-05-25 14:14:37,889:INFO:SubProcess create_model() called ==================================
2024-05-25 14:14:37,890:INFO:Initializing create_model()
2024-05-25 14:14:37,890:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276DA906200>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276DAA79090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 14:14:37,890:INFO:Checking exceptions
2024-05-25 14:14:37,890:INFO:Importing libraries
2024-05-25 14:14:37,891:INFO:Copying training dataset
2024-05-25 14:14:37,929:INFO:Defining folds
2024-05-25 14:14:37,929:INFO:Declaring metric variables
2024-05-25 14:14:37,934:INFO:Importing untrained model
2024-05-25 14:14:37,939:INFO:Dummy Classifier Imported successfully
2024-05-25 14:14:37,949:INFO:Starting cross validation
2024-05-25 14:14:37,954:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 14:14:39,888:INFO:Calculating mean and std
2024-05-25 14:14:39,890:INFO:Creating metrics dataframe
2024-05-25 14:14:39,892:INFO:Uploading results into container
2024-05-25 14:14:39,893:INFO:Uploading model into container now
2024-05-25 14:14:39,894:INFO:_master_model_container: 14
2024-05-25 14:14:39,894:INFO:_display_container: 2
2024-05-25 14:14:39,894:INFO:DummyClassifier(constant=None, random_state=2150, strategy='prior')
2024-05-25 14:14:39,895:INFO:create_model() successfully completed......................................
2024-05-25 14:14:40,806:INFO:SubProcess create_model() end ==================================
2024-05-25 14:14:40,806:INFO:Creating metrics dataframe
2024-05-25 14:14:40,825:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-25 14:14:40,837:INFO:Initializing create_model()
2024-05-25 14:14:40,837:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276DA906200>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2150, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 14:14:40,838:INFO:Checking exceptions
2024-05-25 14:14:40,840:INFO:Importing libraries
2024-05-25 14:14:40,840:INFO:Copying training dataset
2024-05-25 14:14:40,874:INFO:Defining folds
2024-05-25 14:14:40,874:INFO:Declaring metric variables
2024-05-25 14:14:40,874:INFO:Importing untrained model
2024-05-25 14:14:40,874:INFO:Declaring custom model
2024-05-25 14:14:40,875:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 14:14:40,879:INFO:Cross validation set to False
2024-05-25 14:14:40,879:INFO:Fitting Model
2024-05-25 14:14:41,608:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:14:41,611:INFO:[LightGBM] [Info] Number of positive: 37631, number of negative: 32369
2024-05-25 14:14:41,621:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003344 seconds.
2024-05-25 14:14:41,621:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:14:41,621:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:14:41,621:INFO:[LightGBM] [Info] Total Bins 1223
2024-05-25 14:14:41,621:INFO:[LightGBM] [Info] Number of data points in the train set: 70000, number of used features: 46
2024-05-25 14:14:41,622:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537586 -> initscore=0.150627
2024-05-25 14:14:41,622:INFO:[LightGBM] [Info] Start training from score 0.150627
2024-05-25 14:14:41,860:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2150, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-25 14:14:41,860:INFO:create_model() successfully completed......................................
2024-05-25 14:14:42,785:INFO:Creating Dashboard logs
2024-05-25 14:14:42,791:INFO:Model: Light Gradient Boosting Machine
2024-05-25 14:14:42,861:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 2150, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-05-25 14:14:43,069:INFO:Initializing predict_model()
2024-05-25 14:14:43,069:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276DA906200>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2150, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000276CF2DEDD0>)
2024-05-25 14:14:43,069:INFO:Checking exceptions
2024-05-25 14:14:43,069:INFO:Preloading libraries
2024-05-25 14:14:44,333:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2024-05-25 14:14:47,497:INFO:Creating Dashboard logs
2024-05-25 14:14:47,502:INFO:Model: Random Forest Classifier
2024-05-25 14:14:47,568:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 2150, 'verbose': 0, 'warm_start': False}
2024-05-25 14:14:48,879:INFO:Creating Dashboard logs
2024-05-25 14:14:48,884:INFO:Model: Gradient Boosting Classifier
2024-05-25 14:14:48,951:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 2150, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-25 14:14:50,175:INFO:Creating Dashboard logs
2024-05-25 14:14:50,180:INFO:Model: Extra Trees Classifier
2024-05-25 14:14:50,248:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 2150, 'verbose': 0, 'warm_start': False}
2024-05-25 14:14:51,471:INFO:Creating Dashboard logs
2024-05-25 14:14:51,476:INFO:Model: Ada Boost Classifier
2024-05-25 14:14:51,619:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 2150}
2024-05-25 14:14:52,802:INFO:Creating Dashboard logs
2024-05-25 14:14:52,807:INFO:Model: Decision Tree Classifier
2024-05-25 14:14:52,874:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 2150, 'splitter': 'best'}
2024-05-25 14:14:54,110:INFO:Creating Dashboard logs
2024-05-25 14:14:54,114:INFO:Model: K Neighbors Classifier
2024-05-25 14:14:54,180:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2024-05-25 14:14:55,450:INFO:Creating Dashboard logs
2024-05-25 14:14:55,454:INFO:Model: Logistic Regression
2024-05-25 14:14:55,520:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 2150, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-05-25 14:14:56,738:INFO:Creating Dashboard logs
2024-05-25 14:14:56,742:INFO:Model: Ridge Classifier
2024-05-25 14:14:56,809:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 2150, 'solver': 'auto', 'tol': 0.0001}
2024-05-25 14:14:57,999:INFO:Creating Dashboard logs
2024-05-25 14:14:58,003:INFO:Model: Linear Discriminant Analysis
2024-05-25 14:14:58,072:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-05-25 14:14:59,346:INFO:Creating Dashboard logs
2024-05-25 14:14:59,351:INFO:Model: Quadratic Discriminant Analysis
2024-05-25 14:14:59,418:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2024-05-25 14:15:00,626:INFO:Creating Dashboard logs
2024-05-25 14:15:00,631:INFO:Model: SVM - Linear Kernel
2024-05-25 14:15:00,705:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 2150, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-25 14:15:02,068:INFO:Creating Dashboard logs
2024-05-25 14:15:02,072:INFO:Model: Dummy Classifier
2024-05-25 14:15:02,139:INFO:Logged params: {'constant': None, 'random_state': 2150, 'strategy': 'prior'}
2024-05-25 14:15:03,453:INFO:Creating Dashboard logs
2024-05-25 14:15:03,457:INFO:Model: Naive Bayes
2024-05-25 14:15:03,525:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-05-25 14:15:04,733:INFO:_master_model_container: 14
2024-05-25 14:15:04,733:INFO:_display_container: 2
2024-05-25 14:15:04,734:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2150, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-25 14:15:04,734:INFO:compare_models() successfully completed......................................
2024-05-25 14:24:38,040:INFO:Initializing create_model()
2024-05-25 14:24:38,040:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276DA906200>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 14:24:38,041:INFO:Checking exceptions
2024-05-25 14:24:38,061:INFO:Importing libraries
2024-05-25 14:24:38,061:INFO:Copying training dataset
2024-05-25 14:24:38,098:INFO:Defining folds
2024-05-25 14:24:38,098:INFO:Declaring metric variables
2024-05-25 14:24:38,103:INFO:Importing untrained model
2024-05-25 14:24:38,108:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 14:24:38,118:INFO:Starting cross validation
2024-05-25 14:24:38,122:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 14:24:47,179:INFO:Calculating mean and std
2024-05-25 14:24:47,182:INFO:Creating metrics dataframe
2024-05-25 14:24:47,192:INFO:Finalizing model
2024-05-25 14:24:47,977:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:24:47,980:INFO:[LightGBM] [Info] Number of positive: 37631, number of negative: 32369
2024-05-25 14:24:47,989:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003199 seconds.
2024-05-25 14:24:47,989:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:24:47,989:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:24:47,990:INFO:[LightGBM] [Info] Total Bins 1223
2024-05-25 14:24:47,990:INFO:[LightGBM] [Info] Number of data points in the train set: 70000, number of used features: 46
2024-05-25 14:24:47,991:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537586 -> initscore=0.150627
2024-05-25 14:24:47,991:INFO:[LightGBM] [Info] Start training from score 0.150627
2024-05-25 14:24:48,252:INFO:Creating Dashboard logs
2024-05-25 14:24:48,258:INFO:Model: Light Gradient Boosting Machine
2024-05-25 14:24:48,343:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 2150, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-05-25 14:24:48,565:INFO:Initializing predict_model()
2024-05-25 14:24:48,565:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276DA906200>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2150, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000276CF64FE20>)
2024-05-25 14:24:48,565:INFO:Checking exceptions
2024-05-25 14:24:48,565:INFO:Preloading libraries
2024-05-25 14:24:50,978:INFO:Uploading results into container
2024-05-25 14:24:50,979:INFO:Uploading model into container now
2024-05-25 14:24:50,994:INFO:_master_model_container: 15
2024-05-25 14:24:50,995:INFO:_display_container: 3
2024-05-25 14:24:50,995:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2150, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-25 14:24:50,996:INFO:create_model() successfully completed......................................
2024-05-25 14:24:51,912:INFO:Initializing plot_model()
2024-05-25 14:24:51,912:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2150, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276DA906200>, system=True)
2024-05-25 14:24:51,913:INFO:Checking exceptions
2024-05-25 14:24:51,927:INFO:Preloading libraries
2024-05-25 14:24:51,934:INFO:Copying training dataset
2024-05-25 14:24:51,935:INFO:Plot type: auc
2024-05-25 14:24:52,269:INFO:Fitting Model
2024-05-25 14:24:52,272:INFO:Scoring test/hold-out set
2024-05-25 14:24:52,677:INFO:Visual Rendered Successfully
2024-05-25 14:24:53,601:INFO:plot_model() successfully completed......................................
2024-05-25 14:27:25,050:INFO:Initializing plot_model()
2024-05-25 14:27:25,050:INFO:plot_model(plot=threshold, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2150, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276DA906200>, system=True)
2024-05-25 14:27:25,050:INFO:Checking exceptions
2024-05-25 14:27:25,066:INFO:Preloading libraries
2024-05-25 14:27:25,074:INFO:Copying training dataset
2024-05-25 14:27:25,074:INFO:Plot type: threshold
2024-05-25 14:27:25,404:INFO:Fitting Model
2024-05-25 14:27:25,556:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:25,558:INFO:[LightGBM] [Info] Number of positive: 33822, number of negative: 29178
2024-05-25 14:27:25,567:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003274 seconds.
2024-05-25 14:27:25,567:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:25,567:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:25,568:INFO:[LightGBM] [Info] Total Bins 1216
2024-05-25 14:27:25,568:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:25,568:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.536857 -> initscore=0.147696
2024-05-25 14:27:25,569:INFO:[LightGBM] [Info] Start training from score 0.147696
2024-05-25 14:27:26,173:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:26,176:INFO:[LightGBM] [Info] Number of positive: 33887, number of negative: 29113
2024-05-25 14:27:26,195:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010866 seconds.
2024-05-25 14:27:26,195:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:26,195:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:26,195:INFO:[LightGBM] [Info] Total Bins 1134
2024-05-25 14:27:26,195:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:26,196:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537889 -> initscore=0.151847
2024-05-25 14:27:26,197:INFO:[LightGBM] [Info] Start training from score 0.151847
2024-05-25 14:27:26,785:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:26,788:INFO:[LightGBM] [Info] Number of positive: 33909, number of negative: 29091
2024-05-25 14:27:26,795:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002503 seconds.
2024-05-25 14:27:26,795:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:26,795:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:26,795:INFO:[LightGBM] [Info] Total Bins 1125
2024-05-25 14:27:26,796:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:26,796:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.538238 -> initscore=0.153252
2024-05-25 14:27:26,796:INFO:[LightGBM] [Info] Start training from score 0.153252
2024-05-25 14:27:27,333:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:27,335:INFO:[LightGBM] [Info] Number of positive: 33828, number of negative: 29172
2024-05-25 14:27:27,342:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002850 seconds.
2024-05-25 14:27:27,343:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:27,343:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:27,343:INFO:[LightGBM] [Info] Total Bins 1133
2024-05-25 14:27:27,343:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:27,344:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.536952 -> initscore=0.148080
2024-05-25 14:27:27,344:INFO:[LightGBM] [Info] Start training from score 0.148080
2024-05-25 14:27:27,879:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:27,882:INFO:[LightGBM] [Info] Number of positive: 33884, number of negative: 29116
2024-05-25 14:27:27,889:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003429 seconds.
2024-05-25 14:27:27,889:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:27,889:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:27,890:INFO:[LightGBM] [Info] Total Bins 1132
2024-05-25 14:27:27,890:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:27,891:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537841 -> initscore=0.151655
2024-05-25 14:27:27,891:INFO:[LightGBM] [Info] Start training from score 0.151655
2024-05-25 14:27:28,427:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:28,430:INFO:[LightGBM] [Info] Number of positive: 33809, number of negative: 29191
2024-05-25 14:27:28,438:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003032 seconds.
2024-05-25 14:27:28,438:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:28,438:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:28,439:INFO:[LightGBM] [Info] Total Bins 1204
2024-05-25 14:27:28,439:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 43
2024-05-25 14:27:28,440:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.536651 -> initscore=0.146867
2024-05-25 14:27:28,440:INFO:[LightGBM] [Info] Start training from score 0.146867
2024-05-25 14:27:28,971:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:28,973:INFO:[LightGBM] [Info] Number of positive: 33858, number of negative: 29142
2024-05-25 14:27:28,979:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002585 seconds.
2024-05-25 14:27:28,980:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:28,980:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:28,980:INFO:[LightGBM] [Info] Total Bins 1209
2024-05-25 14:27:28,980:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:28,981:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537429 -> initscore=0.149995
2024-05-25 14:27:28,981:INFO:[LightGBM] [Info] Start training from score 0.149995
2024-05-25 14:27:29,512:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:29,514:INFO:[LightGBM] [Info] Number of positive: 33830, number of negative: 29170
2024-05-25 14:27:29,522:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002993 seconds.
2024-05-25 14:27:29,523:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:29,523:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:29,523:INFO:[LightGBM] [Info] Total Bins 1125
2024-05-25 14:27:29,523:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 46
2024-05-25 14:27:29,524:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.536984 -> initscore=0.148207
2024-05-25 14:27:29,524:INFO:[LightGBM] [Info] Start training from score 0.148207
2024-05-25 14:27:30,073:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:30,076:INFO:[LightGBM] [Info] Number of positive: 33928, number of negative: 29072
2024-05-25 14:27:30,085:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003093 seconds.
2024-05-25 14:27:30,085:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:30,085:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:30,086:INFO:[LightGBM] [Info] Total Bins 1210
2024-05-25 14:27:30,086:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:30,087:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.538540 -> initscore=0.154465
2024-05-25 14:27:30,087:INFO:[LightGBM] [Info] Start training from score 0.154465
2024-05-25 14:27:30,633:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:30,635:INFO:[LightGBM] [Info] Number of positive: 33840, number of negative: 29160
2024-05-25 14:27:30,642:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002656 seconds.
2024-05-25 14:27:30,642:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:30,642:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:30,642:INFO:[LightGBM] [Info] Total Bins 1129
2024-05-25 14:27:30,642:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 43
2024-05-25 14:27:30,643:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537143 -> initscore=0.148846
2024-05-25 14:27:30,643:INFO:[LightGBM] [Info] Start training from score 0.148846
2024-05-25 14:27:31,177:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:31,179:INFO:[LightGBM] [Info] Number of positive: 33883, number of negative: 29117
2024-05-25 14:27:31,188:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002750 seconds.
2024-05-25 14:27:31,188:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:31,188:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:31,188:INFO:[LightGBM] [Info] Total Bins 1137
2024-05-25 14:27:31,188:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 46
2024-05-25 14:27:31,189:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537825 -> initscore=0.151591
2024-05-25 14:27:31,189:INFO:[LightGBM] [Info] Start training from score 0.151591
2024-05-25 14:27:31,718:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:31,721:INFO:[LightGBM] [Info] Number of positive: 33887, number of negative: 29113
2024-05-25 14:27:31,727:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002289 seconds.
2024-05-25 14:27:31,727:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:31,727:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:31,727:INFO:[LightGBM] [Info] Total Bins 1209
2024-05-25 14:27:31,727:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 44
2024-05-25 14:27:31,728:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537889 -> initscore=0.151847
2024-05-25 14:27:31,728:INFO:[LightGBM] [Info] Start training from score 0.151847
2024-05-25 14:27:32,287:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:32,289:INFO:[LightGBM] [Info] Number of positive: 33871, number of negative: 29129
2024-05-25 14:27:32,296:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002795 seconds.
2024-05-25 14:27:32,296:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:32,296:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:32,296:INFO:[LightGBM] [Info] Total Bins 1209
2024-05-25 14:27:32,296:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:32,297:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537635 -> initscore=0.150825
2024-05-25 14:27:32,297:INFO:[LightGBM] [Info] Start training from score 0.150825
2024-05-25 14:27:32,837:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:32,840:INFO:[LightGBM] [Info] Number of positive: 33828, number of negative: 29172
2024-05-25 14:27:32,847:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002749 seconds.
2024-05-25 14:27:32,847:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:32,847:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:32,848:INFO:[LightGBM] [Info] Total Bins 1124
2024-05-25 14:27:32,848:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 44
2024-05-25 14:27:32,849:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.536952 -> initscore=0.148080
2024-05-25 14:27:32,849:INFO:[LightGBM] [Info] Start training from score 0.148080
2024-05-25 14:27:33,395:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:33,397:INFO:[LightGBM] [Info] Number of positive: 33884, number of negative: 29116
2024-05-25 14:27:33,406:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002993 seconds.
2024-05-25 14:27:33,406:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:33,407:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:33,407:INFO:[LightGBM] [Info] Total Bins 1140
2024-05-25 14:27:33,407:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:33,408:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537841 -> initscore=0.151655
2024-05-25 14:27:33,408:INFO:[LightGBM] [Info] Start training from score 0.151655
2024-05-25 14:27:33,944:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:33,946:INFO:[LightGBM] [Info] Number of positive: 33840, number of negative: 29160
2024-05-25 14:27:33,954:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003293 seconds.
2024-05-25 14:27:33,955:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:33,955:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:33,955:INFO:[LightGBM] [Info] Total Bins 1209
2024-05-25 14:27:33,955:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:33,956:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537143 -> initscore=0.148846
2024-05-25 14:27:33,956:INFO:[LightGBM] [Info] Start training from score 0.148846
2024-05-25 14:27:34,492:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:34,495:INFO:[LightGBM] [Info] Number of positive: 33780, number of negative: 29220
2024-05-25 14:27:34,502:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002782 seconds.
2024-05-25 14:27:34,502:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:34,502:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:34,502:INFO:[LightGBM] [Info] Total Bins 1138
2024-05-25 14:27:34,502:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 46
2024-05-25 14:27:34,503:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.536190 -> initscore=0.145016
2024-05-25 14:27:34,503:INFO:[LightGBM] [Info] Start training from score 0.145016
2024-05-25 14:27:35,051:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:35,054:INFO:[LightGBM] [Info] Number of positive: 33856, number of negative: 29144
2024-05-25 14:27:35,061:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002930 seconds.
2024-05-25 14:27:35,061:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:35,061:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:35,062:INFO:[LightGBM] [Info] Total Bins 1130
2024-05-25 14:27:35,062:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 44
2024-05-25 14:27:35,062:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537397 -> initscore=0.149867
2024-05-25 14:27:35,063:INFO:[LightGBM] [Info] Start training from score 0.149867
2024-05-25 14:27:35,609:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:35,611:INFO:[LightGBM] [Info] Number of positive: 33822, number of negative: 29178
2024-05-25 14:27:35,618:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002711 seconds.
2024-05-25 14:27:35,618:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:35,618:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:35,618:INFO:[LightGBM] [Info] Total Bins 1215
2024-05-25 14:27:35,619:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:35,619:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.536857 -> initscore=0.147696
2024-05-25 14:27:35,620:INFO:[LightGBM] [Info] Start training from score 0.147696
2024-05-25 14:27:36,160:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:36,162:INFO:[LightGBM] [Info] Number of positive: 33905, number of negative: 29095
2024-05-25 14:27:36,170:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003174 seconds.
2024-05-25 14:27:36,170:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:36,170:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:36,170:INFO:[LightGBM] [Info] Total Bins 1129
2024-05-25 14:27:36,171:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 44
2024-05-25 14:27:36,171:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.538175 -> initscore=0.152996
2024-05-25 14:27:36,171:INFO:[LightGBM] [Info] Start training from score 0.152996
2024-05-25 14:27:36,706:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:36,708:INFO:[LightGBM] [Info] Number of positive: 33891, number of negative: 29109
2024-05-25 14:27:36,715:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002489 seconds.
2024-05-25 14:27:36,715:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:36,715:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:36,715:INFO:[LightGBM] [Info] Total Bins 1208
2024-05-25 14:27:36,715:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:36,716:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537952 -> initscore=0.152102
2024-05-25 14:27:36,716:INFO:[LightGBM] [Info] Start training from score 0.152102
2024-05-25 14:27:37,252:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:37,254:INFO:[LightGBM] [Info] Number of positive: 33889, number of negative: 29111
2024-05-25 14:27:37,261:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002537 seconds.
2024-05-25 14:27:37,261:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:37,261:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:37,262:INFO:[LightGBM] [Info] Total Bins 1128
2024-05-25 14:27:37,262:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 46
2024-05-25 14:27:37,263:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537921 -> initscore=0.151974
2024-05-25 14:27:37,263:INFO:[LightGBM] [Info] Start training from score 0.151974
2024-05-25 14:27:37,788:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:37,790:INFO:[LightGBM] [Info] Number of positive: 33889, number of negative: 29111
2024-05-25 14:27:37,798:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002492 seconds.
2024-05-25 14:27:37,798:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:37,798:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:37,799:INFO:[LightGBM] [Info] Total Bins 1210
2024-05-25 14:27:37,799:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:37,799:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537921 -> initscore=0.151974
2024-05-25 14:27:37,799:INFO:[LightGBM] [Info] Start training from score 0.151974
2024-05-25 14:27:38,347:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:38,349:INFO:[LightGBM] [Info] Number of positive: 33782, number of negative: 29218
2024-05-25 14:27:38,356:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002630 seconds.
2024-05-25 14:27:38,356:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:38,356:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:38,356:INFO:[LightGBM] [Info] Total Bins 1125
2024-05-25 14:27:38,357:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 44
2024-05-25 14:27:38,357:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.536222 -> initscore=0.145143
2024-05-25 14:27:38,357:INFO:[LightGBM] [Info] Start training from score 0.145143
2024-05-25 14:27:38,927:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:38,929:INFO:[LightGBM] [Info] Number of positive: 33844, number of negative: 29156
2024-05-25 14:27:38,936:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002612 seconds.
2024-05-25 14:27:38,936:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:38,936:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:38,937:INFO:[LightGBM] [Info] Total Bins 1129
2024-05-25 14:27:38,937:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:38,937:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537206 -> initscore=0.149101
2024-05-25 14:27:38,938:INFO:[LightGBM] [Info] Start training from score 0.149101
2024-05-25 14:27:39,490:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:39,492:INFO:[LightGBM] [Info] Number of positive: 33836, number of negative: 29164
2024-05-25 14:27:39,501:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002811 seconds.
2024-05-25 14:27:39,501:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:39,501:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:39,501:INFO:[LightGBM] [Info] Total Bins 1124
2024-05-25 14:27:39,501:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 44
2024-05-25 14:27:39,502:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537079 -> initscore=0.148590
2024-05-25 14:27:39,502:INFO:[LightGBM] [Info] Start training from score 0.148590
2024-05-25 14:27:40,043:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:40,045:INFO:[LightGBM] [Info] Number of positive: 33890, number of negative: 29110
2024-05-25 14:27:40,052:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002756 seconds.
2024-05-25 14:27:40,052:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:40,052:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:40,052:INFO:[LightGBM] [Info] Total Bins 1209
2024-05-25 14:27:40,052:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:40,053:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537937 -> initscore=0.152038
2024-05-25 14:27:40,053:INFO:[LightGBM] [Info] Start training from score 0.152038
2024-05-25 14:27:40,535:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:40,537:INFO:[LightGBM] [Info] Number of positive: 33849, number of negative: 29151
2024-05-25 14:27:40,546:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003402 seconds.
2024-05-25 14:27:40,546:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:40,546:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:40,546:INFO:[LightGBM] [Info] Total Bins 1128
2024-05-25 14:27:40,546:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 43
2024-05-25 14:27:40,547:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537286 -> initscore=0.149420
2024-05-25 14:27:40,547:INFO:[LightGBM] [Info] Start training from score 0.149420
2024-05-25 14:27:41,018:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:41,020:INFO:[LightGBM] [Info] Number of positive: 33834, number of negative: 29166
2024-05-25 14:27:41,028:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003129 seconds.
2024-05-25 14:27:41,028:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:41,028:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:41,028:INFO:[LightGBM] [Info] Total Bins 1132
2024-05-25 14:27:41,028:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 44
2024-05-25 14:27:41,029:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537048 -> initscore=0.148463
2024-05-25 14:27:41,029:INFO:[LightGBM] [Info] Start training from score 0.148463
2024-05-25 14:27:41,501:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:41,504:INFO:[LightGBM] [Info] Number of positive: 33835, number of negative: 29165
2024-05-25 14:27:41,512:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002768 seconds.
2024-05-25 14:27:41,512:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:41,512:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:41,512:INFO:[LightGBM] [Info] Total Bins 1213
2024-05-25 14:27:41,513:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:41,513:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537063 -> initscore=0.148526
2024-05-25 14:27:41,513:INFO:[LightGBM] [Info] Start training from score 0.148526
2024-05-25 14:27:41,990:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:41,992:INFO:[LightGBM] [Info] Number of positive: 33897, number of negative: 29103
2024-05-25 14:27:42,001:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002900 seconds.
2024-05-25 14:27:42,001:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:42,001:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:42,001:INFO:[LightGBM] [Info] Total Bins 1210
2024-05-25 14:27:42,001:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 44
2024-05-25 14:27:42,002:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.538048 -> initscore=0.152485
2024-05-25 14:27:42,002:INFO:[LightGBM] [Info] Start training from score 0.152485
2024-05-25 14:27:42,475:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:42,478:INFO:[LightGBM] [Info] Number of positive: 33855, number of negative: 29145
2024-05-25 14:27:42,485:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003321 seconds.
2024-05-25 14:27:42,485:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:42,485:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:42,486:INFO:[LightGBM] [Info] Total Bins 1204
2024-05-25 14:27:42,486:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 44
2024-05-25 14:27:42,486:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537381 -> initscore=0.149803
2024-05-25 14:27:42,487:INFO:[LightGBM] [Info] Start training from score 0.149803
2024-05-25 14:27:42,962:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:42,965:INFO:[LightGBM] [Info] Number of positive: 33858, number of negative: 29142
2024-05-25 14:27:42,973:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003473 seconds.
2024-05-25 14:27:42,973:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:42,973:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:42,973:INFO:[LightGBM] [Info] Total Bins 1214
2024-05-25 14:27:42,973:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:42,974:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537429 -> initscore=0.149995
2024-05-25 14:27:42,974:INFO:[LightGBM] [Info] Start training from score 0.149995
2024-05-25 14:27:43,450:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:43,453:INFO:[LightGBM] [Info] Number of positive: 33870, number of negative: 29130
2024-05-25 14:27:43,460:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002505 seconds.
2024-05-25 14:27:43,461:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:43,461:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:43,461:INFO:[LightGBM] [Info] Total Bins 1210
2024-05-25 14:27:43,461:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:43,462:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537619 -> initscore=0.150761
2024-05-25 14:27:43,462:INFO:[LightGBM] [Info] Start training from score 0.150761
2024-05-25 14:27:43,941:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:43,944:INFO:[LightGBM] [Info] Number of positive: 33867, number of negative: 29133
2024-05-25 14:27:43,952:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002564 seconds.
2024-05-25 14:27:43,953:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:43,953:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:43,953:INFO:[LightGBM] [Info] Total Bins 1129
2024-05-25 14:27:43,953:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 44
2024-05-25 14:27:43,954:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537571 -> initscore=0.150570
2024-05-25 14:27:43,954:INFO:[LightGBM] [Info] Start training from score 0.150570
2024-05-25 14:27:44,422:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:44,424:INFO:[LightGBM] [Info] Number of positive: 33817, number of negative: 29183
2024-05-25 14:27:44,432:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002714 seconds.
2024-05-25 14:27:44,432:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:44,433:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:44,433:INFO:[LightGBM] [Info] Total Bins 1129
2024-05-25 14:27:44,433:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 43
2024-05-25 14:27:44,434:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.536778 -> initscore=0.147377
2024-05-25 14:27:44,434:INFO:[LightGBM] [Info] Start training from score 0.147377
2024-05-25 14:27:44,924:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:44,927:INFO:[LightGBM] [Info] Number of positive: 33816, number of negative: 29184
2024-05-25 14:27:44,933:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002550 seconds.
2024-05-25 14:27:44,934:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:44,934:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:44,934:INFO:[LightGBM] [Info] Total Bins 1207
2024-05-25 14:27:44,934:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:44,935:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.536762 -> initscore=0.147313
2024-05-25 14:27:44,935:INFO:[LightGBM] [Info] Start training from score 0.147313
2024-05-25 14:27:45,407:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:45,409:INFO:[LightGBM] [Info] Number of positive: 33849, number of negative: 29151
2024-05-25 14:27:45,418:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002747 seconds.
2024-05-25 14:27:45,418:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:45,418:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:45,418:INFO:[LightGBM] [Info] Total Bins 1122
2024-05-25 14:27:45,419:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 44
2024-05-25 14:27:45,419:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537286 -> initscore=0.149420
2024-05-25 14:27:45,420:INFO:[LightGBM] [Info] Start training from score 0.149420
2024-05-25 14:27:45,899:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:45,902:INFO:[LightGBM] [Info] Number of positive: 33799, number of negative: 29201
2024-05-25 14:27:45,911:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003169 seconds.
2024-05-25 14:27:45,911:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:45,911:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:45,911:INFO:[LightGBM] [Info] Total Bins 1130
2024-05-25 14:27:45,911:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:45,912:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.536492 -> initscore=0.146228
2024-05-25 14:27:45,912:INFO:[LightGBM] [Info] Start training from score 0.146228
2024-05-25 14:27:46,400:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:46,402:INFO:[LightGBM] [Info] Number of positive: 33851, number of negative: 29149
2024-05-25 14:27:46,409:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003112 seconds.
2024-05-25 14:27:46,409:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:46,409:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:46,410:INFO:[LightGBM] [Info] Total Bins 1128
2024-05-25 14:27:46,410:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 44
2024-05-25 14:27:46,410:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537317 -> initscore=0.149548
2024-05-25 14:27:46,410:INFO:[LightGBM] [Info] Start training from score 0.149548
2024-05-25 14:27:46,897:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:46,899:INFO:[LightGBM] [Info] Number of positive: 33869, number of negative: 29131
2024-05-25 14:27:46,906:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003152 seconds.
2024-05-25 14:27:46,906:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:46,906:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:46,907:INFO:[LightGBM] [Info] Total Bins 1129
2024-05-25 14:27:46,907:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:46,907:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537603 -> initscore=0.150697
2024-05-25 14:27:46,907:INFO:[LightGBM] [Info] Start training from score 0.150697
2024-05-25 14:27:47,383:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:47,386:INFO:[LightGBM] [Info] Number of positive: 33855, number of negative: 29145
2024-05-25 14:27:47,393:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002848 seconds.
2024-05-25 14:27:47,393:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:47,393:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:47,393:INFO:[LightGBM] [Info] Total Bins 1207
2024-05-25 14:27:47,393:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:47,394:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537381 -> initscore=0.149803
2024-05-25 14:27:47,394:INFO:[LightGBM] [Info] Start training from score 0.149803
2024-05-25 14:27:47,900:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:47,903:INFO:[LightGBM] [Info] Number of positive: 33930, number of negative: 29070
2024-05-25 14:27:47,910:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002477 seconds.
2024-05-25 14:27:47,910:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:47,910:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:47,910:INFO:[LightGBM] [Info] Total Bins 1130
2024-05-25 14:27:47,910:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:47,911:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.538571 -> initscore=0.154593
2024-05-25 14:27:47,911:INFO:[LightGBM] [Info] Start training from score 0.154593
2024-05-25 14:27:48,381:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:48,383:INFO:[LightGBM] [Info] Number of positive: 33889, number of negative: 29111
2024-05-25 14:27:48,392:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003078 seconds.
2024-05-25 14:27:48,392:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:48,392:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:48,392:INFO:[LightGBM] [Info] Total Bins 1211
2024-05-25 14:27:48,392:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 46
2024-05-25 14:27:48,393:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537921 -> initscore=0.151974
2024-05-25 14:27:48,393:INFO:[LightGBM] [Info] Start training from score 0.151974
2024-05-25 14:27:48,883:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:48,885:INFO:[LightGBM] [Info] Number of positive: 33890, number of negative: 29110
2024-05-25 14:27:48,892:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003124 seconds.
2024-05-25 14:27:48,893:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:48,893:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:48,893:INFO:[LightGBM] [Info] Total Bins 1134
2024-05-25 14:27:48,893:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 43
2024-05-25 14:27:48,894:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537937 -> initscore=0.152038
2024-05-25 14:27:48,894:INFO:[LightGBM] [Info] Start training from score 0.152038
2024-05-25 14:27:49,369:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:49,372:INFO:[LightGBM] [Info] Number of positive: 33871, number of negative: 29129
2024-05-25 14:27:49,379:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002583 seconds.
2024-05-25 14:27:49,380:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:49,380:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:49,380:INFO:[LightGBM] [Info] Total Bins 1133
2024-05-25 14:27:49,380:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 44
2024-05-25 14:27:49,381:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537635 -> initscore=0.150825
2024-05-25 14:27:49,381:INFO:[LightGBM] [Info] Start training from score 0.150825
2024-05-25 14:27:49,853:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:49,855:INFO:[LightGBM] [Info] Number of positive: 33855, number of negative: 29145
2024-05-25 14:27:49,864:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002750 seconds.
2024-05-25 14:27:49,864:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:49,864:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:49,864:INFO:[LightGBM] [Info] Total Bins 1131
2024-05-25 14:27:49,864:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:49,865:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537381 -> initscore=0.149803
2024-05-25 14:27:49,865:INFO:[LightGBM] [Info] Start training from score 0.149803
2024-05-25 14:27:50,343:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:50,346:INFO:[LightGBM] [Info] Number of positive: 33885, number of negative: 29115
2024-05-25 14:27:50,353:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002499 seconds.
2024-05-25 14:27:50,353:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:50,353:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:50,353:INFO:[LightGBM] [Info] Total Bins 1209
2024-05-25 14:27:50,354:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:50,354:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537857 -> initscore=0.151719
2024-05-25 14:27:50,354:INFO:[LightGBM] [Info] Start training from score 0.151719
2024-05-25 14:27:50,831:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:50,834:INFO:[LightGBM] [Info] Number of positive: 33924, number of negative: 29076
2024-05-25 14:27:50,841:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003275 seconds.
2024-05-25 14:27:50,841:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:50,842:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:50,842:INFO:[LightGBM] [Info] Total Bins 1133
2024-05-25 14:27:50,842:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:50,843:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.538476 -> initscore=0.154210
2024-05-25 14:27:50,843:INFO:[LightGBM] [Info] Start training from score 0.154210
2024-05-25 14:27:51,328:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 14:27:51,331:INFO:[LightGBM] [Info] Number of positive: 33878, number of negative: 29122
2024-05-25 14:27:51,338:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003088 seconds.
2024-05-25 14:27:51,338:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 14:27:51,338:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 14:27:51,338:INFO:[LightGBM] [Info] Total Bins 1208
2024-05-25 14:27:51,339:INFO:[LightGBM] [Info] Number of data points in the train set: 63000, number of used features: 45
2024-05-25 14:27:51,339:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537746 -> initscore=0.151272
2024-05-25 14:27:51,339:INFO:[LightGBM] [Info] Start training from score 0.151272
2024-05-25 14:27:53,838:INFO:Scoring test/hold-out set
2024-05-25 14:27:54,478:INFO:Visual Rendered Successfully
2024-05-25 14:27:55,417:INFO:plot_model() successfully completed......................................
2024-05-25 15:37:28,999:INFO:PyCaret ClassificationExperiment
2024-05-25 15:37:29,000:INFO:Logging name: ml_codex
2024-05-25 15:37:29,000:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-25 15:37:29,000:INFO:version 3.3.2
2024-05-25 15:37:29,000:INFO:Initializing setup()
2024-05-25 15:37:29,001:INFO:self.USI: 371e
2024-05-25 15:37:29,001:INFO:self._variable_keys: {'fold_generator', 'is_multiclass', 'y_train', 'html_param', 'log_plots_param', '_ml_usecase', 'fix_imbalance', 'y_test', 'exp_name_log', 'data', 'pipeline', 'y', 'USI', 'gpu_param', '_available_plots', 'n_jobs_param', 'target_param', 'exp_id', 'seed', 'X_test', 'X', 'logging_param', 'idx', 'fold_shuffle_param', 'memory', 'fold_groups_param', 'gpu_n_jobs_param', 'X_train'}
2024-05-25 15:37:29,001:INFO:Checking environment
2024-05-25 15:37:29,001:INFO:python_version: 3.10.13
2024-05-25 15:37:29,001:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-25 15:37:29,001:INFO:machine: AMD64
2024-05-25 15:37:29,001:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-25 15:37:29,001:INFO:Memory: svmem(total=34267656192, available=13275086848, percent=61.3, used=20992569344, free=13275086848)
2024-05-25 15:37:29,001:INFO:Physical Core: 8
2024-05-25 15:37:29,001:INFO:Logical Core: 16
2024-05-25 15:37:29,001:INFO:Checking libraries
2024-05-25 15:37:29,001:INFO:System:
2024-05-25 15:37:29,002:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-25 15:37:29,002:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-25 15:37:29,002:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-25 15:37:29,002:INFO:PyCaret required dependencies:
2024-05-25 15:37:29,002:INFO:                 pip: 23.3
2024-05-25 15:37:29,002:INFO:          setuptools: 68.0.0
2024-05-25 15:37:29,002:INFO:             pycaret: 3.3.2
2024-05-25 15:37:29,002:INFO:             IPython: 8.24.0
2024-05-25 15:37:29,002:INFO:          ipywidgets: 8.1.2
2024-05-25 15:37:29,002:INFO:                tqdm: 4.66.4
2024-05-25 15:37:29,003:INFO:               numpy: 1.26.4
2024-05-25 15:37:29,003:INFO:              pandas: 2.1.4
2024-05-25 15:37:29,003:INFO:              jinja2: 3.1.4
2024-05-25 15:37:29,003:INFO:               scipy: 1.11.4
2024-05-25 15:37:29,003:INFO:              joblib: 1.3.2
2024-05-25 15:37:29,003:INFO:             sklearn: 1.4.2
2024-05-25 15:37:29,003:INFO:                pyod: 1.1.3
2024-05-25 15:37:29,003:INFO:            imblearn: 0.12.2
2024-05-25 15:37:29,003:INFO:   category_encoders: 2.6.3
2024-05-25 15:37:29,003:INFO:            lightgbm: 4.3.0
2024-05-25 15:37:29,003:INFO:               numba: 0.59.1
2024-05-25 15:37:29,004:INFO:            requests: 2.32.2
2024-05-25 15:37:29,004:INFO:          matplotlib: 3.7.5
2024-05-25 15:37:29,004:INFO:          scikitplot: 0.3.7
2024-05-25 15:37:29,004:INFO:         yellowbrick: 1.5
2024-05-25 15:37:29,004:INFO:              plotly: 5.22.0
2024-05-25 15:37:29,004:INFO:    plotly-resampler: Not installed
2024-05-25 15:37:29,004:INFO:             kaleido: 0.2.1
2024-05-25 15:37:29,004:INFO:           schemdraw: 0.15
2024-05-25 15:37:29,004:INFO:         statsmodels: 0.14.2
2024-05-25 15:37:29,004:INFO:              sktime: 0.26.0
2024-05-25 15:37:29,005:INFO:               tbats: 1.1.3
2024-05-25 15:37:29,005:INFO:            pmdarima: 2.0.4
2024-05-25 15:37:29,005:INFO:              psutil: 5.9.0
2024-05-25 15:37:29,005:INFO:          markupsafe: 2.1.5
2024-05-25 15:37:29,005:INFO:             pickle5: Not installed
2024-05-25 15:37:29,005:INFO:         cloudpickle: 3.0.0
2024-05-25 15:37:29,005:INFO:         deprecation: 2.1.0
2024-05-25 15:37:29,005:INFO:              xxhash: 3.4.1
2024-05-25 15:37:29,005:INFO:           wurlitzer: Not installed
2024-05-25 15:37:29,005:INFO:PyCaret optional dependencies:
2024-05-25 15:37:29,006:INFO:                shap: Not installed
2024-05-25 15:37:29,006:INFO:           interpret: Not installed
2024-05-25 15:37:29,006:INFO:                umap: Not installed
2024-05-25 15:37:29,006:INFO:     ydata_profiling: Not installed
2024-05-25 15:37:29,006:INFO:  explainerdashboard: Not installed
2024-05-25 15:37:29,006:INFO:             autoviz: Not installed
2024-05-25 15:37:29,006:INFO:           fairlearn: Not installed
2024-05-25 15:37:29,006:INFO:          deepchecks: Not installed
2024-05-25 15:37:29,007:INFO:             xgboost: Not installed
2024-05-25 15:37:29,007:INFO:            catboost: Not installed
2024-05-25 15:37:29,007:INFO:              kmodes: Not installed
2024-05-25 15:37:29,007:INFO:             mlxtend: Not installed
2024-05-25 15:37:29,007:INFO:       statsforecast: Not installed
2024-05-25 15:37:29,007:INFO:        tune_sklearn: Not installed
2024-05-25 15:37:29,007:INFO:                 ray: Not installed
2024-05-25 15:37:29,007:INFO:            hyperopt: Not installed
2024-05-25 15:37:29,007:INFO:              optuna: Not installed
2024-05-25 15:37:29,007:INFO:               skopt: Not installed
2024-05-25 15:37:29,007:INFO:              mlflow: 2.13.0
2024-05-25 15:37:29,008:INFO:              gradio: Not installed
2024-05-25 15:37:29,008:INFO:             fastapi: Not installed
2024-05-25 15:37:29,008:INFO:             uvicorn: Not installed
2024-05-25 15:37:29,008:INFO:              m2cgen: Not installed
2024-05-25 15:37:29,008:INFO:           evidently: Not installed
2024-05-25 15:37:29,008:INFO:               fugue: Not installed
2024-05-25 15:37:29,008:INFO:           streamlit: Not installed
2024-05-25 15:37:29,008:INFO:             prophet: Not installed
2024-05-25 15:37:29,008:INFO:None
2024-05-25 15:37:29,009:INFO:Set up data.
2024-05-25 15:37:29,302:INFO:Set up folding strategy.
2024-05-25 15:38:47,154:INFO:PyCaret ClassificationExperiment
2024-05-25 15:38:47,154:INFO:Logging name: ml_codex
2024-05-25 15:38:47,154:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-25 15:38:47,155:INFO:version 3.3.2
2024-05-25 15:38:47,155:INFO:Initializing setup()
2024-05-25 15:38:47,155:INFO:self.USI: 2410
2024-05-25 15:38:47,155:INFO:self._variable_keys: {'fold_generator', 'is_multiclass', 'y_train', 'html_param', 'log_plots_param', '_ml_usecase', 'fix_imbalance', 'y_test', 'exp_name_log', 'data', 'pipeline', 'y', 'USI', 'gpu_param', '_available_plots', 'n_jobs_param', 'target_param', 'exp_id', 'seed', 'X_test', 'X', 'logging_param', 'idx', 'fold_shuffle_param', 'memory', 'fold_groups_param', 'gpu_n_jobs_param', 'X_train'}
2024-05-25 15:38:47,155:INFO:Checking environment
2024-05-25 15:38:47,155:INFO:python_version: 3.10.13
2024-05-25 15:38:47,155:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-25 15:38:47,156:INFO:machine: AMD64
2024-05-25 15:38:47,156:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-25 15:38:47,156:INFO:Memory: svmem(total=34267656192, available=13134114816, percent=61.7, used=21133541376, free=13134114816)
2024-05-25 15:38:47,156:INFO:Physical Core: 8
2024-05-25 15:38:47,156:INFO:Logical Core: 16
2024-05-25 15:38:47,156:INFO:Checking libraries
2024-05-25 15:38:47,157:INFO:System:
2024-05-25 15:38:47,157:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-25 15:38:47,157:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-25 15:38:47,157:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-25 15:38:47,157:INFO:PyCaret required dependencies:
2024-05-25 15:38:47,157:INFO:                 pip: 23.3
2024-05-25 15:38:47,157:INFO:          setuptools: 68.0.0
2024-05-25 15:38:47,158:INFO:             pycaret: 3.3.2
2024-05-25 15:38:47,158:INFO:             IPython: 8.24.0
2024-05-25 15:38:47,158:INFO:          ipywidgets: 8.1.2
2024-05-25 15:38:47,158:INFO:                tqdm: 4.66.4
2024-05-25 15:38:47,158:INFO:               numpy: 1.26.4
2024-05-25 15:38:47,158:INFO:              pandas: 2.1.4
2024-05-25 15:38:47,158:INFO:              jinja2: 3.1.4
2024-05-25 15:38:47,158:INFO:               scipy: 1.11.4
2024-05-25 15:38:47,159:INFO:              joblib: 1.3.2
2024-05-25 15:38:47,159:INFO:             sklearn: 1.4.2
2024-05-25 15:38:47,159:INFO:                pyod: 1.1.3
2024-05-25 15:38:47,159:INFO:            imblearn: 0.12.2
2024-05-25 15:38:47,159:INFO:   category_encoders: 2.6.3
2024-05-25 15:38:47,160:INFO:            lightgbm: 4.3.0
2024-05-25 15:38:47,160:INFO:               numba: 0.59.1
2024-05-25 15:38:47,160:INFO:            requests: 2.32.2
2024-05-25 15:38:47,160:INFO:          matplotlib: 3.7.5
2024-05-25 15:38:47,160:INFO:          scikitplot: 0.3.7
2024-05-25 15:38:47,160:INFO:         yellowbrick: 1.5
2024-05-25 15:38:47,160:INFO:              plotly: 5.22.0
2024-05-25 15:38:47,161:INFO:    plotly-resampler: Not installed
2024-05-25 15:38:47,161:INFO:             kaleido: 0.2.1
2024-05-25 15:38:47,161:INFO:           schemdraw: 0.15
2024-05-25 15:38:47,161:INFO:         statsmodels: 0.14.2
2024-05-25 15:38:47,161:INFO:              sktime: 0.26.0
2024-05-25 15:38:47,161:INFO:               tbats: 1.1.3
2024-05-25 15:38:47,161:INFO:            pmdarima: 2.0.4
2024-05-25 15:38:47,161:INFO:              psutil: 5.9.0
2024-05-25 15:38:47,162:INFO:          markupsafe: 2.1.5
2024-05-25 15:38:47,162:INFO:             pickle5: Not installed
2024-05-25 15:38:47,162:INFO:         cloudpickle: 3.0.0
2024-05-25 15:38:47,162:INFO:         deprecation: 2.1.0
2024-05-25 15:38:47,162:INFO:              xxhash: 3.4.1
2024-05-25 15:38:47,162:INFO:           wurlitzer: Not installed
2024-05-25 15:38:47,163:INFO:PyCaret optional dependencies:
2024-05-25 15:38:47,163:INFO:                shap: Not installed
2024-05-25 15:38:47,163:INFO:           interpret: Not installed
2024-05-25 15:38:47,163:INFO:                umap: Not installed
2024-05-25 15:38:47,163:INFO:     ydata_profiling: Not installed
2024-05-25 15:38:47,163:INFO:  explainerdashboard: Not installed
2024-05-25 15:38:47,164:INFO:             autoviz: Not installed
2024-05-25 15:38:47,164:INFO:           fairlearn: Not installed
2024-05-25 15:38:47,164:INFO:          deepchecks: Not installed
2024-05-25 15:38:47,164:INFO:             xgboost: Not installed
2024-05-25 15:38:47,164:INFO:            catboost: Not installed
2024-05-25 15:38:47,164:INFO:              kmodes: Not installed
2024-05-25 15:38:47,164:INFO:             mlxtend: Not installed
2024-05-25 15:38:47,164:INFO:       statsforecast: Not installed
2024-05-25 15:38:47,164:INFO:        tune_sklearn: Not installed
2024-05-25 15:38:47,164:INFO:                 ray: Not installed
2024-05-25 15:38:47,164:INFO:            hyperopt: Not installed
2024-05-25 15:38:47,164:INFO:              optuna: Not installed
2024-05-25 15:38:47,165:INFO:               skopt: Not installed
2024-05-25 15:38:47,165:INFO:              mlflow: 2.13.0
2024-05-25 15:38:47,165:INFO:              gradio: Not installed
2024-05-25 15:38:47,165:INFO:             fastapi: Not installed
2024-05-25 15:38:47,165:INFO:             uvicorn: Not installed
2024-05-25 15:38:47,165:INFO:              m2cgen: Not installed
2024-05-25 15:38:47,165:INFO:           evidently: Not installed
2024-05-25 15:38:47,165:INFO:               fugue: Not installed
2024-05-25 15:38:47,165:INFO:           streamlit: Not installed
2024-05-25 15:38:47,165:INFO:             prophet: Not installed
2024-05-25 15:38:47,165:INFO:None
2024-05-25 15:38:47,166:INFO:Set up data.
2024-05-25 15:38:47,495:INFO:Set up folding strategy.
2024-05-25 15:38:47,495:INFO:Set up train/test split.
2024-05-25 15:38:47,547:INFO:Set up index.
2024-05-25 15:38:47,549:INFO:Assigning column types.
2024-05-25 15:38:47,570:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-25 15:38:47,643:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-25 15:38:47,644:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-25 15:38:47,689:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 15:38:47,690:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 15:38:47,763:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-25 15:38:47,764:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-25 15:38:47,809:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 15:38:47,810:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 15:38:47,810:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-25 15:38:47,883:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-25 15:38:47,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 15:38:47,930:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 15:38:48,003:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-25 15:38:48,048:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 15:38:48,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 15:38:48,049:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-25 15:38:48,168:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 15:38:48,168:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 15:38:48,291:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 15:38:48,291:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 15:38:48,293:INFO:Preparing preprocessing pipeline...
2024-05-25 15:38:48,300:INFO:Set up simple imputation.
2024-05-25 15:38:48,322:INFO:Set up encoding of ordinal features.
2024-05-25 15:38:48,330:INFO:Set up encoding of categorical features.
2024-05-25 15:38:48,333:INFO:Set up column name cleaning.
2024-05-25 15:38:49,629:INFO:Finished creating preprocessing pipeline.
2024-05-25 15:38:49,656:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=OneHotEncoder(cols=['listing_type_id',
                                                                    'buying_mode',
                                                                    'status',
                                                                    'seller_address.state.name',
                                                                    'shipping.mode'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-05-25 15:38:49,656:INFO:Creating final display dataframe.
2024-05-25 15:38:50,619:INFO:Setup _display_container:                     Description            Value
0                    Session id              933
1                        Target           target
2                   Target type           Binary
3           Original data shape     (100000, 16)
4        Transformed data shape     (100000, 53)
5   Transformed train set shape      (90000, 53)
6    Transformed test set shape      (10000, 53)
7              Numeric features                5
8          Categorical features                6
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Fold Generator  StratifiedKFold
16                  Fold Number               10
17                     CPU Jobs               -1
18                      Use GPU            False
19               Log Experiment     MlflowLogger
20              Experiment Name         ml_codex
21                          USI             2410
2024-05-25 15:38:50,750:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 15:38:50,750:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 15:38:50,870:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 15:38:50,870:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 15:38:50,872:INFO:Logging experiment in loggers
2024-05-25 15:38:51,007:INFO:SubProcess save_model() called ==================================
2024-05-25 15:38:51,057:INFO:Initializing save_model()
2024-05-25 15:38:51,057:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=OneHotEncoder(cols=['listing_type_id',
                                                                    'buying_mode',
                                                                    'status',
                                                                    'seller_address.state.name',
                                                                    'shipping.mode'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\Adm\AppData\Local\Temp\tmpw5qtwf17\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=OneHotEncoder(cols=['listing_type_id',
                                                                    'buying_mode',
                                                                    'status',
                                                                    'seller_address.state.name',
                                                                    'shipping.mode'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-25 15:38:51,057:INFO:Adding model into prep_pipe
2024-05-25 15:38:51,057:WARNING:Only Model saved as it was a pipeline.
2024-05-25 15:38:51,083:INFO:C:\Users\Adm\AppData\Local\Temp\tmpw5qtwf17\Transformation Pipeline.pkl saved in current working directory
2024-05-25 15:38:51,108:INFO:Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=OneHotEncoder(cols=['listing_type_id',
                                                                    'buying_mode',
                                                                    'status',
                                                                    'seller_address.state.name',
                                                                    'shipping.mode'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-05-25 15:38:51,108:INFO:save_model() successfully completed......................................
2024-05-25 15:38:52,061:INFO:SubProcess save_model() end ==================================
2024-05-25 15:38:52,089:INFO:setup() successfully completed in 3.73s...............
2024-05-25 15:38:52,104:INFO:Initializing compare_models()
2024-05-25 15:38:52,104:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-25 15:38:52,104:INFO:Checking exceptions
2024-05-25 15:38:52,127:INFO:Preparing display monitor
2024-05-25 15:38:52,156:INFO:Initializing Logistic Regression
2024-05-25 15:38:52,157:INFO:Total runtime is 1.666545867919922e-05 minutes
2024-05-25 15:38:52,161:INFO:SubProcess create_model() called ==================================
2024-05-25 15:38:52,162:INFO:Initializing create_model()
2024-05-25 15:38:52,162:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276E4236830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:38:52,162:INFO:Checking exceptions
2024-05-25 15:38:52,162:INFO:Importing libraries
2024-05-25 15:38:52,162:INFO:Copying training dataset
2024-05-25 15:38:52,204:INFO:Defining folds
2024-05-25 15:38:52,205:INFO:Declaring metric variables
2024-05-25 15:38:52,209:INFO:Importing untrained model
2024-05-25 15:38:52,215:INFO:Logistic Regression Imported successfully
2024-05-25 15:38:52,225:INFO:Starting cross validation
2024-05-25 15:38:52,229:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:39:13,037:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-25 15:39:13,169:INFO:Calculating mean and std
2024-05-25 15:39:13,171:INFO:Creating metrics dataframe
2024-05-25 15:39:13,175:INFO:Uploading results into container
2024-05-25 15:39:13,176:INFO:Uploading model into container now
2024-05-25 15:39:13,177:INFO:_master_model_container: 1
2024-05-25 15:39:13,177:INFO:_display_container: 2
2024-05-25 15:39:13,178:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=933, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-25 15:39:13,178:INFO:create_model() successfully completed......................................
2024-05-25 15:39:14,106:INFO:SubProcess create_model() end ==================================
2024-05-25 15:39:14,107:INFO:Creating metrics dataframe
2024-05-25 15:39:14,115:INFO:Initializing K Neighbors Classifier
2024-05-25 15:39:14,116:INFO:Total runtime is 0.3659959554672241 minutes
2024-05-25 15:39:14,120:INFO:SubProcess create_model() called ==================================
2024-05-25 15:39:14,120:INFO:Initializing create_model()
2024-05-25 15:39:14,121:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276E4236830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:39:14,121:INFO:Checking exceptions
2024-05-25 15:39:14,121:INFO:Importing libraries
2024-05-25 15:39:14,122:INFO:Copying training dataset
2024-05-25 15:39:14,164:INFO:Defining folds
2024-05-25 15:39:14,164:INFO:Declaring metric variables
2024-05-25 15:39:14,170:INFO:Importing untrained model
2024-05-25 15:39:14,176:INFO:K Neighbors Classifier Imported successfully
2024-05-25 15:39:14,185:INFO:Starting cross validation
2024-05-25 15:39:14,189:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:39:39,143:INFO:Calculating mean and std
2024-05-25 15:39:39,145:INFO:Creating metrics dataframe
2024-05-25 15:39:39,148:INFO:Uploading results into container
2024-05-25 15:39:39,149:INFO:Uploading model into container now
2024-05-25 15:39:39,149:INFO:_master_model_container: 2
2024-05-25 15:39:39,149:INFO:_display_container: 2
2024-05-25 15:39:39,150:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-25 15:39:39,150:INFO:create_model() successfully completed......................................
2024-05-25 15:39:40,065:INFO:SubProcess create_model() end ==================================
2024-05-25 15:39:40,065:INFO:Creating metrics dataframe
2024-05-25 15:39:40,075:INFO:Initializing Naive Bayes
2024-05-25 15:39:40,075:INFO:Total runtime is 0.798653213183085 minutes
2024-05-25 15:39:40,080:INFO:SubProcess create_model() called ==================================
2024-05-25 15:39:40,080:INFO:Initializing create_model()
2024-05-25 15:39:40,080:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276E4236830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:39:40,081:INFO:Checking exceptions
2024-05-25 15:39:40,081:INFO:Importing libraries
2024-05-25 15:39:40,081:INFO:Copying training dataset
2024-05-25 15:39:40,123:INFO:Defining folds
2024-05-25 15:39:40,123:INFO:Declaring metric variables
2024-05-25 15:39:40,128:INFO:Importing untrained model
2024-05-25 15:39:40,133:INFO:Naive Bayes Imported successfully
2024-05-25 15:39:40,143:INFO:Starting cross validation
2024-05-25 15:39:40,148:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:39:43,137:INFO:Calculating mean and std
2024-05-25 15:39:43,139:INFO:Creating metrics dataframe
2024-05-25 15:39:43,142:INFO:Uploading results into container
2024-05-25 15:39:43,143:INFO:Uploading model into container now
2024-05-25 15:39:43,144:INFO:_master_model_container: 3
2024-05-25 15:39:43,144:INFO:_display_container: 2
2024-05-25 15:39:43,144:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-25 15:39:43,145:INFO:create_model() successfully completed......................................
2024-05-25 15:39:44,062:INFO:SubProcess create_model() end ==================================
2024-05-25 15:39:44,063:INFO:Creating metrics dataframe
2024-05-25 15:39:44,073:INFO:Initializing Decision Tree Classifier
2024-05-25 15:39:44,073:INFO:Total runtime is 0.865279217561086 minutes
2024-05-25 15:39:44,078:INFO:SubProcess create_model() called ==================================
2024-05-25 15:39:44,078:INFO:Initializing create_model()
2024-05-25 15:39:44,078:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276E4236830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:39:44,079:INFO:Checking exceptions
2024-05-25 15:39:44,079:INFO:Importing libraries
2024-05-25 15:39:44,079:INFO:Copying training dataset
2024-05-25 15:39:44,120:INFO:Defining folds
2024-05-25 15:39:44,120:INFO:Declaring metric variables
2024-05-25 15:39:44,126:INFO:Importing untrained model
2024-05-25 15:39:44,131:INFO:Decision Tree Classifier Imported successfully
2024-05-25 15:39:44,141:INFO:Starting cross validation
2024-05-25 15:39:44,146:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:39:47,601:INFO:Calculating mean and std
2024-05-25 15:39:47,603:INFO:Creating metrics dataframe
2024-05-25 15:39:47,605:INFO:Uploading results into container
2024-05-25 15:39:47,606:INFO:Uploading model into container now
2024-05-25 15:39:47,607:INFO:_master_model_container: 4
2024-05-25 15:39:47,607:INFO:_display_container: 2
2024-05-25 15:39:47,607:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=933, splitter='best')
2024-05-25 15:39:47,608:INFO:create_model() successfully completed......................................
2024-05-25 15:39:48,525:INFO:SubProcess create_model() end ==================================
2024-05-25 15:39:48,525:INFO:Creating metrics dataframe
2024-05-25 15:39:48,537:INFO:Initializing SVM - Linear Kernel
2024-05-25 15:39:48,537:INFO:Total runtime is 0.9396864215532938 minutes
2024-05-25 15:39:48,542:INFO:SubProcess create_model() called ==================================
2024-05-25 15:39:48,542:INFO:Initializing create_model()
2024-05-25 15:39:48,543:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276E4236830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:39:48,543:INFO:Checking exceptions
2024-05-25 15:39:48,543:INFO:Importing libraries
2024-05-25 15:39:48,543:INFO:Copying training dataset
2024-05-25 15:39:48,587:INFO:Defining folds
2024-05-25 15:39:48,587:INFO:Declaring metric variables
2024-05-25 15:39:48,593:INFO:Importing untrained model
2024-05-25 15:39:48,598:INFO:SVM - Linear Kernel Imported successfully
2024-05-25 15:39:48,608:INFO:Starting cross validation
2024-05-25 15:39:48,612:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:39:51,815:INFO:Calculating mean and std
2024-05-25 15:39:51,817:INFO:Creating metrics dataframe
2024-05-25 15:39:51,819:INFO:Uploading results into container
2024-05-25 15:39:51,820:INFO:Uploading model into container now
2024-05-25 15:39:51,820:INFO:_master_model_container: 5
2024-05-25 15:39:51,821:INFO:_display_container: 2
2024-05-25 15:39:51,822:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=933, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-25 15:39:51,822:INFO:create_model() successfully completed......................................
2024-05-25 15:39:52,756:INFO:SubProcess create_model() end ==================================
2024-05-25 15:39:52,756:INFO:Creating metrics dataframe
2024-05-25 15:39:52,767:INFO:Initializing Ridge Classifier
2024-05-25 15:39:52,768:INFO:Total runtime is 1.0102020303408306 minutes
2024-05-25 15:39:52,773:INFO:SubProcess create_model() called ==================================
2024-05-25 15:39:52,773:INFO:Initializing create_model()
2024-05-25 15:39:52,773:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276E4236830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:39:52,773:INFO:Checking exceptions
2024-05-25 15:39:52,773:INFO:Importing libraries
2024-05-25 15:39:52,774:INFO:Copying training dataset
2024-05-25 15:39:52,816:INFO:Defining folds
2024-05-25 15:39:52,816:INFO:Declaring metric variables
2024-05-25 15:39:52,821:INFO:Importing untrained model
2024-05-25 15:39:52,826:INFO:Ridge Classifier Imported successfully
2024-05-25 15:39:52,836:INFO:Starting cross validation
2024-05-25 15:39:52,841:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:39:55,241:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.79993e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 15:39:55,274:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.42905e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 15:39:55,344:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.75543e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 15:39:55,348:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.79988e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 15:39:55,404:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.80961e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 15:39:55,426:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.79968e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 15:39:55,426:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.80005e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 15:39:55,440:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.79983e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 15:39:55,479:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.75531e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 15:39:55,505:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.8077e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 15:39:55,701:INFO:Calculating mean and std
2024-05-25 15:39:55,703:INFO:Creating metrics dataframe
2024-05-25 15:39:55,705:INFO:Uploading results into container
2024-05-25 15:39:55,706:INFO:Uploading model into container now
2024-05-25 15:39:55,707:INFO:_master_model_container: 6
2024-05-25 15:39:55,707:INFO:_display_container: 2
2024-05-25 15:39:55,708:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=933, solver='auto',
                tol=0.0001)
2024-05-25 15:39:55,708:INFO:create_model() successfully completed......................................
2024-05-25 15:39:56,615:INFO:SubProcess create_model() end ==================================
2024-05-25 15:39:56,615:INFO:Creating metrics dataframe
2024-05-25 15:39:56,627:INFO:Initializing Random Forest Classifier
2024-05-25 15:39:56,627:INFO:Total runtime is 1.0745132327079774 minutes
2024-05-25 15:39:56,632:INFO:SubProcess create_model() called ==================================
2024-05-25 15:39:56,632:INFO:Initializing create_model()
2024-05-25 15:39:56,633:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276E4236830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:39:56,633:INFO:Checking exceptions
2024-05-25 15:39:56,633:INFO:Importing libraries
2024-05-25 15:39:56,633:INFO:Copying training dataset
2024-05-25 15:39:56,677:INFO:Defining folds
2024-05-25 15:39:56,677:INFO:Declaring metric variables
2024-05-25 15:39:56,683:INFO:Importing untrained model
2024-05-25 15:39:56,689:INFO:Random Forest Classifier Imported successfully
2024-05-25 15:39:56,699:INFO:Starting cross validation
2024-05-25 15:39:56,703:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:40:14,142:INFO:Calculating mean and std
2024-05-25 15:40:14,143:INFO:Creating metrics dataframe
2024-05-25 15:40:14,146:INFO:Uploading results into container
2024-05-25 15:40:14,147:INFO:Uploading model into container now
2024-05-25 15:40:14,148:INFO:_master_model_container: 7
2024-05-25 15:40:14,148:INFO:_display_container: 2
2024-05-25 15:40:14,149:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=933, verbose=0,
                       warm_start=False)
2024-05-25 15:40:14,149:INFO:create_model() successfully completed......................................
2024-05-25 15:40:15,161:INFO:SubProcess create_model() end ==================================
2024-05-25 15:40:15,161:INFO:Creating metrics dataframe
2024-05-25 15:40:15,174:INFO:Initializing Quadratic Discriminant Analysis
2024-05-25 15:40:15,174:INFO:Total runtime is 1.3836278875668844 minutes
2024-05-25 15:40:15,179:INFO:SubProcess create_model() called ==================================
2024-05-25 15:40:15,180:INFO:Initializing create_model()
2024-05-25 15:40:15,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276E4236830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:40:15,180:INFO:Checking exceptions
2024-05-25 15:40:15,180:INFO:Importing libraries
2024-05-25 15:40:15,181:INFO:Copying training dataset
2024-05-25 15:40:15,221:INFO:Defining folds
2024-05-25 15:40:15,221:INFO:Declaring metric variables
2024-05-25 15:40:15,227:INFO:Importing untrained model
2024-05-25 15:40:15,233:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-25 15:40:15,242:INFO:Starting cross validation
2024-05-25 15:40:15,248:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:40:18,338:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 15:40:18,391:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 15:40:18,419:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 15:40:18,505:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 15:40:18,530:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 15:40:18,671:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 15:40:18,715:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 15:40:18,767:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 15:40:18,867:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 15:40:18,917:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 15:40:20,163:INFO:Calculating mean and std
2024-05-25 15:40:20,165:INFO:Creating metrics dataframe
2024-05-25 15:40:20,167:INFO:Uploading results into container
2024-05-25 15:40:20,168:INFO:Uploading model into container now
2024-05-25 15:40:20,169:INFO:_master_model_container: 8
2024-05-25 15:40:20,169:INFO:_display_container: 2
2024-05-25 15:40:20,169:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-25 15:40:20,170:INFO:create_model() successfully completed......................................
2024-05-25 15:40:21,098:INFO:SubProcess create_model() end ==================================
2024-05-25 15:40:21,098:INFO:Creating metrics dataframe
2024-05-25 15:40:21,111:INFO:Initializing Ada Boost Classifier
2024-05-25 15:40:21,112:INFO:Total runtime is 1.4825960954030355 minutes
2024-05-25 15:40:21,117:INFO:SubProcess create_model() called ==================================
2024-05-25 15:40:21,117:INFO:Initializing create_model()
2024-05-25 15:40:21,117:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276E4236830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:40:21,117:INFO:Checking exceptions
2024-05-25 15:40:21,118:INFO:Importing libraries
2024-05-25 15:40:21,118:INFO:Copying training dataset
2024-05-25 15:40:21,159:INFO:Defining folds
2024-05-25 15:40:21,159:INFO:Declaring metric variables
2024-05-25 15:40:21,165:INFO:Importing untrained model
2024-05-25 15:40:21,170:INFO:Ada Boost Classifier Imported successfully
2024-05-25 15:40:21,181:INFO:Starting cross validation
2024-05-25 15:40:21,185:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:40:23,217:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 15:40:23,305:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 15:40:23,326:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 15:40:23,357:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 15:40:23,499:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 15:40:23,500:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 15:40:23,526:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 15:40:23,542:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 15:40:23,562:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 15:40:23,589:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 15:40:31,649:INFO:Calculating mean and std
2024-05-25 15:40:31,651:INFO:Creating metrics dataframe
2024-05-25 15:40:31,653:INFO:Uploading results into container
2024-05-25 15:40:31,654:INFO:Uploading model into container now
2024-05-25 15:40:31,654:INFO:_master_model_container: 9
2024-05-25 15:40:31,655:INFO:_display_container: 2
2024-05-25 15:40:31,655:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=933)
2024-05-25 15:40:31,655:INFO:create_model() successfully completed......................................
2024-05-25 15:40:32,569:INFO:SubProcess create_model() end ==================================
2024-05-25 15:40:32,569:INFO:Creating metrics dataframe
2024-05-25 15:40:32,584:INFO:Initializing Gradient Boosting Classifier
2024-05-25 15:40:32,584:INFO:Total runtime is 1.6737969477971395 minutes
2024-05-25 15:40:32,588:INFO:SubProcess create_model() called ==================================
2024-05-25 15:40:32,589:INFO:Initializing create_model()
2024-05-25 15:40:32,589:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276E4236830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:40:32,589:INFO:Checking exceptions
2024-05-25 15:40:32,589:INFO:Importing libraries
2024-05-25 15:40:32,590:INFO:Copying training dataset
2024-05-25 15:40:32,630:INFO:Defining folds
2024-05-25 15:40:32,630:INFO:Declaring metric variables
2024-05-25 15:40:32,635:INFO:Importing untrained model
2024-05-25 15:40:32,641:INFO:Gradient Boosting Classifier Imported successfully
2024-05-25 15:40:32,652:INFO:Starting cross validation
2024-05-25 15:40:32,656:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:40:53,042:INFO:Calculating mean and std
2024-05-25 15:40:53,044:INFO:Creating metrics dataframe
2024-05-25 15:40:53,046:INFO:Uploading results into container
2024-05-25 15:40:53,047:INFO:Uploading model into container now
2024-05-25 15:40:53,048:INFO:_master_model_container: 10
2024-05-25 15:40:53,048:INFO:_display_container: 2
2024-05-25 15:40:53,049:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=933, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-25 15:40:53,049:INFO:create_model() successfully completed......................................
2024-05-25 15:40:53,970:INFO:SubProcess create_model() end ==================================
2024-05-25 15:40:53,970:INFO:Creating metrics dataframe
2024-05-25 15:40:53,984:INFO:Initializing Linear Discriminant Analysis
2024-05-25 15:40:53,984:INFO:Total runtime is 2.0304681022961937 minutes
2024-05-25 15:40:53,989:INFO:SubProcess create_model() called ==================================
2024-05-25 15:40:53,990:INFO:Initializing create_model()
2024-05-25 15:40:53,990:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276E4236830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:40:53,990:INFO:Checking exceptions
2024-05-25 15:40:53,990:INFO:Importing libraries
2024-05-25 15:40:53,990:INFO:Copying training dataset
2024-05-25 15:40:54,032:INFO:Defining folds
2024-05-25 15:40:54,032:INFO:Declaring metric variables
2024-05-25 15:40:54,037:INFO:Importing untrained model
2024-05-25 15:40:54,043:INFO:Linear Discriminant Analysis Imported successfully
2024-05-25 15:40:54,052:INFO:Starting cross validation
2024-05-25 15:40:54,056:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:40:58,825:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 32.1 MiB for an array with shape (81000, 52) and data type float64

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py", line 628, in fit
    self._solve_svd(X, y)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py", line 522, in _solve_svd
    U, S, Vt = svd(X, full_matrices=False)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\scipy\linalg\_decomp_svd.py", line 127, in svd
    u, s, v, info = gesXd(a1, compute_uv=compute_uv, lwork=lwork,
TypeError: _ArrayMemoryError.__init__() missing 1 required positional argument: 'dtype'

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 15:40:58,826:INFO:Calculating mean and std
2024-05-25 15:40:58,827:INFO:Creating metrics dataframe
2024-05-25 15:40:58,830:INFO:Uploading results into container
2024-05-25 15:40:58,830:INFO:Uploading model into container now
2024-05-25 15:40:58,831:INFO:_master_model_container: 11
2024-05-25 15:40:58,832:INFO:_display_container: 2
2024-05-25 15:40:58,833:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-25 15:40:58,833:INFO:create_model() successfully completed......................................
2024-05-25 15:40:59,737:INFO:SubProcess create_model() end ==================================
2024-05-25 15:40:59,737:INFO:Creating metrics dataframe
2024-05-25 15:40:59,751:INFO:Initializing Extra Trees Classifier
2024-05-25 15:40:59,752:INFO:Total runtime is 2.126600543657939 minutes
2024-05-25 15:40:59,756:INFO:SubProcess create_model() called ==================================
2024-05-25 15:40:59,757:INFO:Initializing create_model()
2024-05-25 15:40:59,757:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276E4236830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:40:59,757:INFO:Checking exceptions
2024-05-25 15:40:59,757:INFO:Importing libraries
2024-05-25 15:40:59,758:INFO:Copying training dataset
2024-05-25 15:40:59,799:INFO:Defining folds
2024-05-25 15:40:59,799:INFO:Declaring metric variables
2024-05-25 15:40:59,804:INFO:Importing untrained model
2024-05-25 15:40:59,810:INFO:Extra Trees Classifier Imported successfully
2024-05-25 15:40:59,821:INFO:Starting cross validation
2024-05-25 15:40:59,825:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:41:13,650:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 731, in _accumulate_prediction
    prediction = predict(X, check_input=False)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 1043, in predict_proba
    proba = self.tree_.predict(X)
  File "sklearn\\tree\\_tree.pyx", line 970, in sklearn.tree._tree.Tree.predict
  File "sklearn\\tree\\_tree.pyx", line 972, in sklearn.tree._tree.Tree.predict
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 141. KiB for an array with shape (9000, 1, 2) and data type float64
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 905, in predict
    proba = self.predict_proba(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 958, in predict_proba
    Parallel(n_jobs=n_jobs, verbose=self.verbose, require="sharedmem")(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 141. KiB for an array with shape (9000, 1, 2) and data type float64

  warnings.warn(

2024-05-25 15:41:13,658:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
9 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 1048576 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 1048576 bytes

--------------------------------------------------------------------------------
3 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 4194304 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 4194304 bytes

--------------------------------------------------------------------------------
4 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 2097152 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 2097152 bytes

--------------------------------------------------------------------------------
1 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 524288 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 524288 bytes

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 15:41:13,659:INFO:Calculating mean and std
2024-05-25 15:41:13,660:INFO:Creating metrics dataframe
2024-05-25 15:41:13,663:INFO:Uploading results into container
2024-05-25 15:41:13,664:INFO:Uploading model into container now
2024-05-25 15:41:13,665:INFO:_master_model_container: 12
2024-05-25 15:41:13,665:INFO:_display_container: 2
2024-05-25 15:41:13,666:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=933, verbose=0,
                     warm_start=False)
2024-05-25 15:41:13,667:INFO:create_model() successfully completed......................................
2024-05-25 15:41:14,701:INFO:SubProcess create_model() end ==================================
2024-05-25 15:41:14,701:INFO:Creating metrics dataframe
2024-05-25 15:41:14,716:INFO:Initializing Light Gradient Boosting Machine
2024-05-25 15:41:14,716:INFO:Total runtime is 2.376000277201335 minutes
2024-05-25 15:41:14,721:INFO:SubProcess create_model() called ==================================
2024-05-25 15:41:14,722:INFO:Initializing create_model()
2024-05-25 15:41:14,722:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276E4236830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:41:14,722:INFO:Checking exceptions
2024-05-25 15:41:14,722:INFO:Importing libraries
2024-05-25 15:41:14,722:INFO:Copying training dataset
2024-05-25 15:41:14,764:INFO:Defining folds
2024-05-25 15:41:14,765:INFO:Declaring metric variables
2024-05-25 15:41:14,770:INFO:Importing untrained model
2024-05-25 15:41:14,776:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:41:14,787:INFO:Starting cross validation
2024-05-25 15:41:14,791:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:41:19,517:INFO:Calculating mean and std
2024-05-25 15:41:19,519:INFO:Creating metrics dataframe
2024-05-25 15:41:19,524:INFO:Uploading results into container
2024-05-25 15:41:19,527:INFO:Uploading model into container now
2024-05-25 15:41:19,528:INFO:_master_model_container: 13
2024-05-25 15:41:19,529:INFO:_display_container: 2
2024-05-25 15:41:19,530:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-25 15:41:19,530:INFO:create_model() successfully completed......................................
2024-05-25 15:41:20,624:INFO:SubProcess create_model() end ==================================
2024-05-25 15:41:20,624:INFO:Creating metrics dataframe
2024-05-25 15:41:20,640:INFO:Initializing Dummy Classifier
2024-05-25 15:41:20,640:INFO:Total runtime is 2.4747356414794925 minutes
2024-05-25 15:41:20,645:INFO:SubProcess create_model() called ==================================
2024-05-25 15:41:20,645:INFO:Initializing create_model()
2024-05-25 15:41:20,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276E4236830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:41:20,646:INFO:Checking exceptions
2024-05-25 15:41:20,646:INFO:Importing libraries
2024-05-25 15:41:20,646:INFO:Copying training dataset
2024-05-25 15:41:20,690:INFO:Defining folds
2024-05-25 15:41:20,690:INFO:Declaring metric variables
2024-05-25 15:41:20,696:INFO:Importing untrained model
2024-05-25 15:41:20,703:INFO:Dummy Classifier Imported successfully
2024-05-25 15:41:20,714:INFO:Starting cross validation
2024-05-25 15:41:20,719:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:41:23,475:INFO:Calculating mean and std
2024-05-25 15:41:23,477:INFO:Creating metrics dataframe
2024-05-25 15:41:23,480:INFO:Uploading results into container
2024-05-25 15:41:23,481:INFO:Uploading model into container now
2024-05-25 15:41:23,482:INFO:_master_model_container: 14
2024-05-25 15:41:23,482:INFO:_display_container: 2
2024-05-25 15:41:23,483:INFO:DummyClassifier(constant=None, random_state=933, strategy='prior')
2024-05-25 15:41:23,483:INFO:create_model() successfully completed......................................
2024-05-25 15:41:24,498:INFO:SubProcess create_model() end ==================================
2024-05-25 15:41:24,498:INFO:Creating metrics dataframe
2024-05-25 15:41:24,515:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-25 15:41:24,528:INFO:Initializing create_model()
2024-05-25 15:41:24,528:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:41:24,528:INFO:Checking exceptions
2024-05-25 15:41:24,530:INFO:Importing libraries
2024-05-25 15:41:24,530:INFO:Copying training dataset
2024-05-25 15:41:24,572:INFO:Defining folds
2024-05-25 15:41:24,573:INFO:Declaring metric variables
2024-05-25 15:41:24,573:INFO:Importing untrained model
2024-05-25 15:41:24,573:INFO:Declaring custom model
2024-05-25 15:41:24,574:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:41:24,578:INFO:Cross validation set to False
2024-05-25 15:41:24,578:INFO:Fitting Model
2024-05-25 15:41:25,664:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:41:25,667:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:41:25,678:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004004 seconds.
2024-05-25 15:41:25,678:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:41:25,678:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:41:25,679:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:41:25,679:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:41:25,680:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:41:25,680:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:41:26,045:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-25 15:41:26,045:INFO:create_model() successfully completed......................................
2024-05-25 15:41:27,039:INFO:Creating Dashboard logs
2024-05-25 15:41:27,045:INFO:Model: Light Gradient Boosting Machine
2024-05-25 15:41:27,117:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 933, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-05-25 15:41:27,337:INFO:Initializing predict_model()
2024-05-25 15:41:27,338:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000276CED21630>)
2024-05-25 15:41:27,338:INFO:Checking exceptions
2024-05-25 15:41:27,338:INFO:Preloading libraries
2024-05-25 15:41:29,552:INFO:Creating Dashboard logs
2024-05-25 15:41:29,557:INFO:Model: Random Forest Classifier
2024-05-25 15:41:29,623:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 933, 'verbose': 0, 'warm_start': False}
2024-05-25 15:41:31,189:INFO:Creating Dashboard logs
2024-05-25 15:41:31,197:INFO:Model: Gradient Boosting Classifier
2024-05-25 15:41:31,303:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 933, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-25 15:41:32,923:INFO:Creating Dashboard logs
2024-05-25 15:41:32,929:INFO:Model: Ada Boost Classifier
2024-05-25 15:41:32,996:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 933}
2024-05-25 15:41:34,197:INFO:Creating Dashboard logs
2024-05-25 15:41:34,202:INFO:Model: Decision Tree Classifier
2024-05-25 15:41:34,269:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 933, 'splitter': 'best'}
2024-05-25 15:41:35,587:INFO:Creating Dashboard logs
2024-05-25 15:41:35,592:INFO:Model: K Neighbors Classifier
2024-05-25 15:41:35,661:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2024-05-25 15:41:36,873:INFO:Creating Dashboard logs
2024-05-25 15:41:36,878:INFO:Model: Ridge Classifier
2024-05-25 15:41:36,946:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 933, 'solver': 'auto', 'tol': 0.0001}
2024-05-25 15:41:38,321:INFO:Creating Dashboard logs
2024-05-25 15:41:38,326:INFO:Model: Logistic Regression
2024-05-25 15:41:38,395:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 933, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-05-25 15:41:39,707:INFO:Creating Dashboard logs
2024-05-25 15:41:39,712:INFO:Model: Linear Discriminant Analysis
2024-05-25 15:41:39,782:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-05-25 15:41:40,986:INFO:Creating Dashboard logs
2024-05-25 15:41:40,991:INFO:Model: Quadratic Discriminant Analysis
2024-05-25 15:41:41,058:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2024-05-25 15:41:42,363:INFO:Creating Dashboard logs
2024-05-25 15:41:42,367:INFO:Model: Dummy Classifier
2024-05-25 15:41:42,435:INFO:Logged params: {'constant': None, 'random_state': 933, 'strategy': 'prior'}
2024-05-25 15:41:43,629:INFO:Creating Dashboard logs
2024-05-25 15:41:43,634:INFO:Model: SVM - Linear Kernel
2024-05-25 15:41:43,702:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 933, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-25 15:41:44,943:INFO:Creating Dashboard logs
2024-05-25 15:41:44,947:INFO:Model: Naive Bayes
2024-05-25 15:41:45,015:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-05-25 15:41:46,294:INFO:Creating Dashboard logs
2024-05-25 15:41:46,299:INFO:Model: Extra Trees Classifier
2024-05-25 15:41:46,367:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 933, 'verbose': 0, 'warm_start': False}
2024-05-25 15:41:47,670:INFO:_master_model_container: 14
2024-05-25 15:41:47,670:INFO:_display_container: 2
2024-05-25 15:41:47,671:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-25 15:41:47,672:INFO:compare_models() successfully completed......................................
2024-05-25 15:42:23,281:INFO:Initializing create_model()
2024-05-25 15:42:23,282:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:42:23,282:INFO:Checking exceptions
2024-05-25 15:42:23,303:INFO:Importing libraries
2024-05-25 15:42:23,303:INFO:Copying training dataset
2024-05-25 15:42:23,349:INFO:Defining folds
2024-05-25 15:42:23,349:INFO:Declaring metric variables
2024-05-25 15:42:23,354:INFO:Importing untrained model
2024-05-25 15:42:23,360:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:42:23,370:INFO:Starting cross validation
2024-05-25 15:42:23,375:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:42:36,629:INFO:Initializing create_model()
2024-05-25 15:42:36,629:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:42:36,629:INFO:Checking exceptions
2024-05-25 15:42:36,650:INFO:Importing libraries
2024-05-25 15:42:36,651:INFO:Copying training dataset
2024-05-25 15:42:36,696:INFO:Defining folds
2024-05-25 15:42:36,696:INFO:Declaring metric variables
2024-05-25 15:42:36,701:INFO:Importing untrained model
2024-05-25 15:42:36,706:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:42:36,716:INFO:Starting cross validation
2024-05-25 15:42:36,720:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:42:46,465:INFO:Calculating mean and std
2024-05-25 15:42:46,468:INFO:Creating metrics dataframe
2024-05-25 15:42:46,483:INFO:Finalizing model
2024-05-25 15:42:47,447:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:42:47,450:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:42:47,462:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003808 seconds.
2024-05-25 15:42:47,462:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:42:47,462:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:42:47,462:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:42:47,463:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:42:47,463:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:42:47,463:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:42:47,737:INFO:Creating Dashboard logs
2024-05-25 15:42:47,743:INFO:Model: Light Gradient Boosting Machine
2024-05-25 15:42:47,827:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 933, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-05-25 15:42:48,048:INFO:Initializing predict_model()
2024-05-25 15:42:48,048:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000276A6B50AF0>)
2024-05-25 15:42:48,049:INFO:Checking exceptions
2024-05-25 15:42:48,049:INFO:Preloading libraries
2024-05-25 15:42:50,331:INFO:Uploading results into container
2024-05-25 15:42:50,332:INFO:Uploading model into container now
2024-05-25 15:42:50,347:INFO:_master_model_container: 15
2024-05-25 15:42:50,347:INFO:_display_container: 3
2024-05-25 15:42:50,348:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-25 15:42:50,348:INFO:create_model() successfully completed......................................
2024-05-25 15:42:51,290:INFO:Initializing optimize_threshold()
2024-05-25 15:42:51,290:INFO:optimize_threshold(return_data=False, plot_kwargs=None, shgo_kwargs={}, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), optimize=Accuracy, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, verbose=True)
2024-05-25 15:42:51,290:INFO:Importing libraries
2024-05-25 15:42:51,291:INFO:Checking exceptions
2024-05-25 15:42:51,291:INFO:defining variables
2024-05-25 15:42:51,291:INFO:starting optimization
2024-05-25 15:42:51,305:INFO:Initializing create_model()
2024-05-25 15:42:51,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:42:51,305:INFO:Checking exceptions
2024-05-25 15:42:51,307:INFO:Importing libraries
2024-05-25 15:42:51,307:INFO:Copying training dataset
2024-05-25 15:42:51,346:INFO:Defining folds
2024-05-25 15:42:51,346:INFO:Declaring metric variables
2024-05-25 15:42:51,347:INFO:Importing untrained model
2024-05-25 15:42:51,347:INFO:Declaring custom model
2024-05-25 15:42:51,348:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:42:51,348:INFO:Starting cross validation
2024-05-25 15:42:51,351:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:42:58,897:INFO:Calculating mean and std
2024-05-25 15:42:58,898:INFO:Creating metrics dataframe
2024-05-25 15:42:58,902:INFO:Finalizing model
2024-05-25 15:42:59,840:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:42:59,843:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:42:59,853:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004329 seconds.
2024-05-25 15:42:59,853:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:42:59,853:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:42:59,854:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:42:59,854:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:42:59,854:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:42:59,855:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:43:00,121:INFO:Uploading results into container
2024-05-25 15:43:00,122:INFO:Uploading model into container now
2024-05-25 15:43:00,123:INFO:_master_model_container: 16
2024-05-25 15:43:00,123:INFO:_display_container: 4
2024-05-25 15:43:00,126:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:43:00,126:INFO:create_model() successfully completed......................................
2024-05-25 15:43:01,045:INFO:Threshold: 0.375. Accuracy: 0.8258
2024-05-25 15:43:01,046:INFO:Initializing create_model()
2024-05-25 15:43:01,046:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:43:01,046:INFO:Checking exceptions
2024-05-25 15:43:01,048:INFO:Importing libraries
2024-05-25 15:43:01,048:INFO:Copying training dataset
2024-05-25 15:43:01,086:INFO:Defining folds
2024-05-25 15:43:01,086:INFO:Declaring metric variables
2024-05-25 15:43:01,087:INFO:Importing untrained model
2024-05-25 15:43:01,087:INFO:Declaring custom model
2024-05-25 15:43:01,088:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:43:01,088:INFO:Starting cross validation
2024-05-25 15:43:01,092:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:43:05,677:INFO:Calculating mean and std
2024-05-25 15:43:05,678:INFO:Creating metrics dataframe
2024-05-25 15:43:05,681:INFO:Finalizing model
2024-05-25 15:43:06,705:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:43:06,708:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:43:06,717:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003092 seconds.
2024-05-25 15:43:06,717:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:43:06,718:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:43:06,718:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:43:06,718:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:43:06,719:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:43:06,719:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:43:06,991:INFO:Uploading results into container
2024-05-25 15:43:06,992:INFO:Uploading model into container now
2024-05-25 15:43:06,992:INFO:_master_model_container: 17
2024-05-25 15:43:06,992:INFO:_display_container: 4
2024-05-25 15:43:06,996:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.125,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:43:06,996:INFO:create_model() successfully completed......................................
2024-05-25 15:43:07,937:INFO:Threshold: 0.125. Accuracy: 0.6998
2024-05-25 15:43:07,938:INFO:Initializing create_model()
2024-05-25 15:43:07,938:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.5, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:43:07,938:INFO:Checking exceptions
2024-05-25 15:43:07,940:INFO:Importing libraries
2024-05-25 15:43:07,940:INFO:Copying training dataset
2024-05-25 15:43:07,985:INFO:Defining folds
2024-05-25 15:43:07,985:INFO:Declaring metric variables
2024-05-25 15:43:07,985:INFO:Importing untrained model
2024-05-25 15:43:07,986:INFO:Declaring custom model
2024-05-25 15:43:07,987:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:43:07,987:INFO:Starting cross validation
2024-05-25 15:43:07,990:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:43:12,573:INFO:Calculating mean and std
2024-05-25 15:43:12,574:INFO:Creating metrics dataframe
2024-05-25 15:43:12,577:INFO:Finalizing model
2024-05-25 15:43:13,493:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:43:13,496:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:43:13,505:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003621 seconds.
2024-05-25 15:43:13,505:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:43:13,505:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:43:13,505:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:43:13,505:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:43:13,506:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:43:13,506:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:43:13,761:INFO:Uploading results into container
2024-05-25 15:43:13,762:INFO:Uploading model into container now
2024-05-25 15:43:13,763:INFO:_master_model_container: 18
2024-05-25 15:43:13,763:INFO:_display_container: 4
2024-05-25 15:43:13,766:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None, probability_threshold=0.5,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:43:13,767:INFO:create_model() successfully completed......................................
2024-05-25 15:43:14,704:INFO:Threshold: 0.5. Accuracy: 0.8365
2024-05-25 15:43:14,705:INFO:Initializing create_model()
2024-05-25 15:43:14,705:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.25, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:43:14,705:INFO:Checking exceptions
2024-05-25 15:43:14,707:INFO:Importing libraries
2024-05-25 15:43:14,707:INFO:Copying training dataset
2024-05-25 15:43:14,745:INFO:Defining folds
2024-05-25 15:43:14,745:INFO:Declaring metric variables
2024-05-25 15:43:14,746:INFO:Importing untrained model
2024-05-25 15:43:14,746:INFO:Declaring custom model
2024-05-25 15:43:14,747:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:43:14,747:INFO:Starting cross validation
2024-05-25 15:43:14,751:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:43:19,301:INFO:Calculating mean and std
2024-05-25 15:43:19,302:INFO:Creating metrics dataframe
2024-05-25 15:43:19,305:INFO:Finalizing model
2024-05-25 15:43:20,231:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:43:20,234:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:43:20,246:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008445 seconds.
2024-05-25 15:43:20,246:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-25 15:43:20,246:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:43:20,247:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:43:20,248:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:43:20,248:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:43:20,541:INFO:Uploading results into container
2024-05-25 15:43:20,542:INFO:Uploading model into container now
2024-05-25 15:43:20,543:INFO:_master_model_container: 19
2024-05-25 15:43:20,543:INFO:_display_container: 4
2024-05-25 15:43:20,546:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None, probability_threshold=0.25,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:43:20,546:INFO:create_model() successfully completed......................................
2024-05-25 15:43:21,486:INFO:Threshold: 0.25. Accuracy: 0.7971
2024-05-25 15:43:21,487:INFO:Initializing create_model()
2024-05-25 15:43:21,488:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:43:21,488:INFO:Checking exceptions
2024-05-25 15:43:21,490:INFO:Importing libraries
2024-05-25 15:43:21,491:INFO:Copying training dataset
2024-05-25 15:43:21,529:INFO:Defining folds
2024-05-25 15:43:21,530:INFO:Declaring metric variables
2024-05-25 15:43:21,530:INFO:Importing untrained model
2024-05-25 15:43:21,530:INFO:Declaring custom model
2024-05-25 15:43:21,531:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:43:21,531:INFO:Starting cross validation
2024-05-25 15:43:21,535:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:43:26,058:INFO:Calculating mean and std
2024-05-25 15:43:26,059:INFO:Creating metrics dataframe
2024-05-25 15:43:26,062:INFO:Finalizing model
2024-05-25 15:43:27,074:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:43:27,077:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:43:27,087:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004061 seconds.
2024-05-25 15:43:27,088:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:43:27,088:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:43:27,088:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:43:27,088:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:43:27,089:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:43:27,089:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:43:27,355:INFO:Uploading results into container
2024-05-25 15:43:27,356:INFO:Uploading model into container now
2024-05-25 15:43:27,356:INFO:_master_model_container: 20
2024-05-25 15:43:27,356:INFO:_display_container: 4
2024-05-25 15:43:27,359:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.625,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:43:27,360:INFO:create_model() successfully completed......................................
2024-05-25 15:43:28,297:INFO:Threshold: 0.625. Accuracy: 0.8206
2024-05-25 15:43:28,298:INFO:Initializing create_model()
2024-05-25 15:43:28,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.75, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:43:28,299:INFO:Checking exceptions
2024-05-25 15:43:28,302:INFO:Importing libraries
2024-05-25 15:43:28,302:INFO:Copying training dataset
2024-05-25 15:43:28,341:INFO:Defining folds
2024-05-25 15:43:28,341:INFO:Declaring metric variables
2024-05-25 15:43:28,341:INFO:Importing untrained model
2024-05-25 15:43:28,341:INFO:Declaring custom model
2024-05-25 15:43:28,342:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:43:28,343:INFO:Starting cross validation
2024-05-25 15:43:28,347:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:43:33,209:INFO:Calculating mean and std
2024-05-25 15:43:33,210:INFO:Creating metrics dataframe
2024-05-25 15:43:33,213:INFO:Finalizing model
2024-05-25 15:43:34,146:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:43:34,149:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:43:34,160:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003192 seconds.
2024-05-25 15:43:34,161:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:43:34,161:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:43:34,161:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:43:34,161:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:43:34,162:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:43:34,162:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:43:34,418:INFO:Uploading results into container
2024-05-25 15:43:34,418:INFO:Uploading model into container now
2024-05-25 15:43:34,419:INFO:_master_model_container: 21
2024-05-25 15:43:34,419:INFO:_display_container: 4
2024-05-25 15:43:34,422:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None, probability_threshold=0.75,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:43:34,422:INFO:create_model() successfully completed......................................
2024-05-25 15:43:35,367:INFO:Threshold: 0.75. Accuracy: 0.8022
2024-05-25 15:43:35,368:INFO:Initializing create_model()
2024-05-25 15:43:35,368:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:43:35,368:INFO:Checking exceptions
2024-05-25 15:43:35,370:INFO:Importing libraries
2024-05-25 15:43:35,370:INFO:Copying training dataset
2024-05-25 15:43:35,414:INFO:Defining folds
2024-05-25 15:43:35,414:INFO:Declaring metric variables
2024-05-25 15:43:35,415:INFO:Importing untrained model
2024-05-25 15:43:35,415:INFO:Declaring custom model
2024-05-25 15:43:35,416:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:43:35,416:INFO:Starting cross validation
2024-05-25 15:43:35,419:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:43:40,352:INFO:Calculating mean and std
2024-05-25 15:43:40,353:INFO:Creating metrics dataframe
2024-05-25 15:43:40,356:INFO:Finalizing model
2024-05-25 15:43:41,275:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:43:41,278:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:43:41,288:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003622 seconds.
2024-05-25 15:43:41,288:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:43:41,288:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:43:41,289:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:43:41,289:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:43:41,290:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:43:41,290:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:43:41,546:INFO:Uploading results into container
2024-05-25 15:43:41,547:INFO:Uploading model into container now
2024-05-25 15:43:41,548:INFO:_master_model_container: 22
2024-05-25 15:43:41,548:INFO:_display_container: 4
2024-05-25 15:43:41,551:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.875,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:43:41,552:INFO:create_model() successfully completed......................................
2024-05-25 15:43:42,489:INFO:Threshold: 0.875. Accuracy: 0.7702
2024-05-25 15:43:42,490:INFO:Initializing create_model()
2024-05-25 15:43:42,491:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.0, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:43:42,491:INFO:Checking exceptions
2024-05-25 15:43:42,493:INFO:Importing libraries
2024-05-25 15:43:42,493:INFO:Copying training dataset
2024-05-25 15:43:42,537:INFO:Defining folds
2024-05-25 15:43:42,537:INFO:Declaring metric variables
2024-05-25 15:43:42,537:INFO:Importing untrained model
2024-05-25 15:43:42,537:INFO:Declaring custom model
2024-05-25 15:43:42,539:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:43:42,539:INFO:Starting cross validation
2024-05-25 15:43:42,542:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:43:47,629:INFO:Calculating mean and std
2024-05-25 15:43:47,630:INFO:Creating metrics dataframe
2024-05-25 15:43:47,633:INFO:Finalizing model
2024-05-25 15:43:48,641:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:43:48,645:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:43:48,654:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003833 seconds.
2024-05-25 15:43:48,654:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:43:48,655:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:43:48,655:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:43:48,655:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:43:48,656:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:43:48,656:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:43:48,919:INFO:Uploading results into container
2024-05-25 15:43:48,920:INFO:Uploading model into container now
2024-05-25 15:43:48,921:INFO:_master_model_container: 23
2024-05-25 15:43:48,921:INFO:_display_container: 4
2024-05-25 15:43:48,924:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None, probability_threshold=0.0,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:43:48,924:INFO:create_model() successfully completed......................................
2024-05-25 15:43:49,870:INFO:Threshold: 0.0. Accuracy: 0.5376
2024-05-25 15:43:49,871:INFO:Initializing create_model()
2024-05-25 15:43:49,872:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.5, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:43:49,872:INFO:Checking exceptions
2024-05-25 15:43:49,874:INFO:Importing libraries
2024-05-25 15:43:49,874:INFO:Copying training dataset
2024-05-25 15:43:49,911:INFO:Defining folds
2024-05-25 15:43:49,912:INFO:Declaring metric variables
2024-05-25 15:43:49,912:INFO:Importing untrained model
2024-05-25 15:43:49,912:INFO:Declaring custom model
2024-05-25 15:43:49,913:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:43:49,914:INFO:Starting cross validation
2024-05-25 15:43:49,917:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:43:54,983:INFO:Calculating mean and std
2024-05-25 15:43:54,984:INFO:Creating metrics dataframe
2024-05-25 15:43:54,987:INFO:Finalizing model
2024-05-25 15:43:55,980:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:43:55,983:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:43:55,995:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003669 seconds.
2024-05-25 15:43:55,995:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:43:55,995:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:43:55,995:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:43:55,996:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:43:55,996:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:43:55,996:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:43:56,248:INFO:Uploading results into container
2024-05-25 15:43:56,249:INFO:Uploading model into container now
2024-05-25 15:43:56,250:INFO:_master_model_container: 24
2024-05-25 15:43:56,250:INFO:_display_container: 4
2024-05-25 15:43:56,253:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None, probability_threshold=0.5,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:43:56,253:INFO:create_model() successfully completed......................................
2024-05-25 15:43:57,190:INFO:Threshold: 0.5. Accuracy: 0.8365
2024-05-25 15:43:57,191:INFO:Initializing create_model()
2024-05-25 15:43:57,191:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.5000000149011612, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:43:57,192:INFO:Checking exceptions
2024-05-25 15:43:57,193:INFO:Importing libraries
2024-05-25 15:43:57,194:INFO:Copying training dataset
2024-05-25 15:43:57,232:INFO:Defining folds
2024-05-25 15:43:57,232:INFO:Declaring metric variables
2024-05-25 15:43:57,232:INFO:Importing untrained model
2024-05-25 15:43:57,232:INFO:Declaring custom model
2024-05-25 15:43:57,233:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:43:57,233:INFO:Starting cross validation
2024-05-25 15:43:57,236:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:44:02,350:INFO:Calculating mean and std
2024-05-25 15:44:02,351:INFO:Creating metrics dataframe
2024-05-25 15:44:02,354:INFO:Finalizing model
2024-05-25 15:44:03,355:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:44:03,358:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:44:03,370:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004215 seconds.
2024-05-25 15:44:03,370:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:44:03,370:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:44:03,370:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:44:03,371:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:44:03,371:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:44:03,372:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:44:03,670:INFO:Uploading results into container
2024-05-25 15:44:03,671:INFO:Uploading model into container now
2024-05-25 15:44:03,672:INFO:_master_model_container: 25
2024-05-25 15:44:03,672:INFO:_display_container: 4
2024-05-25 15:44:03,675:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.5000000149011612,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:44:03,675:INFO:create_model() successfully completed......................................
2024-05-25 15:44:04,615:INFO:Threshold: 0.5000000149011612. Accuracy: 0.8365
2024-05-25 15:44:04,617:INFO:Initializing create_model()
2024-05-25 15:44:04,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.21875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:44:04,617:INFO:Checking exceptions
2024-05-25 15:44:04,619:INFO:Importing libraries
2024-05-25 15:44:04,619:INFO:Copying training dataset
2024-05-25 15:44:04,657:INFO:Defining folds
2024-05-25 15:44:04,657:INFO:Declaring metric variables
2024-05-25 15:44:04,657:INFO:Importing untrained model
2024-05-25 15:44:04,657:INFO:Declaring custom model
2024-05-25 15:44:04,658:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:44:04,659:INFO:Starting cross validation
2024-05-25 15:44:04,662:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:44:09,862:INFO:Calculating mean and std
2024-05-25 15:44:09,863:INFO:Creating metrics dataframe
2024-05-25 15:44:09,866:INFO:Finalizing model
2024-05-25 15:44:10,779:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:44:10,782:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:44:10,791:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003247 seconds.
2024-05-25 15:44:10,792:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:44:10,792:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:44:10,792:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:44:10,792:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:44:10,793:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:44:10,793:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:44:11,052:INFO:Uploading results into container
2024-05-25 15:44:11,053:INFO:Uploading model into container now
2024-05-25 15:44:11,053:INFO:_master_model_container: 26
2024-05-25 15:44:11,054:INFO:_display_container: 4
2024-05-25 15:44:11,057:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.21875,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:44:11,057:INFO:create_model() successfully completed......................................
2024-05-25 15:44:11,992:INFO:Threshold: 0.21875. Accuracy: 0.7897
2024-05-25 15:44:11,993:INFO:Initializing create_model()
2024-05-25 15:44:11,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.09375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:44:11,993:INFO:Checking exceptions
2024-05-25 15:44:11,995:INFO:Importing libraries
2024-05-25 15:44:11,995:INFO:Copying training dataset
2024-05-25 15:44:12,034:INFO:Defining folds
2024-05-25 15:44:12,034:INFO:Declaring metric variables
2024-05-25 15:44:12,034:INFO:Importing untrained model
2024-05-25 15:44:12,034:INFO:Declaring custom model
2024-05-25 15:44:12,035:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:44:12,036:INFO:Starting cross validation
2024-05-25 15:44:12,039:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:44:17,135:INFO:Calculating mean and std
2024-05-25 15:44:17,136:INFO:Creating metrics dataframe
2024-05-25 15:44:17,139:INFO:Finalizing model
2024-05-25 15:44:18,156:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:44:18,159:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:44:18,169:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003427 seconds.
2024-05-25 15:44:18,169:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:44:18,169:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:44:18,169:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:44:18,170:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:44:18,170:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:44:18,170:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:44:18,423:INFO:Uploading results into container
2024-05-25 15:44:18,424:INFO:Uploading model into container now
2024-05-25 15:44:18,425:INFO:_master_model_container: 27
2024-05-25 15:44:18,425:INFO:_display_container: 4
2024-05-25 15:44:18,428:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.09375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:44:18,428:INFO:create_model() successfully completed......................................
2024-05-25 15:44:19,364:INFO:Threshold: 0.09375. Accuracy: 0.6776
2024-05-25 15:44:19,365:INFO:Initializing create_model()
2024-05-25 15:44:19,365:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.3125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:44:19,365:INFO:Checking exceptions
2024-05-25 15:44:19,367:INFO:Importing libraries
2024-05-25 15:44:19,367:INFO:Copying training dataset
2024-05-25 15:44:19,405:INFO:Defining folds
2024-05-25 15:44:19,405:INFO:Declaring metric variables
2024-05-25 15:44:19,405:INFO:Importing untrained model
2024-05-25 15:44:19,405:INFO:Declaring custom model
2024-05-25 15:44:19,407:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:44:19,407:INFO:Starting cross validation
2024-05-25 15:44:19,410:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:44:24,326:INFO:Calculating mean and std
2024-05-25 15:44:24,327:INFO:Creating metrics dataframe
2024-05-25 15:44:24,330:INFO:Finalizing model
2024-05-25 15:44:25,334:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:44:25,337:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:44:25,348:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002819 seconds.
2024-05-25 15:44:25,348:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:44:25,348:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:44:25,348:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:44:25,349:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:44:25,349:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:44:25,349:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:44:25,606:INFO:Uploading results into container
2024-05-25 15:44:25,606:INFO:Uploading model into container now
2024-05-25 15:44:25,607:INFO:_master_model_container: 28
2024-05-25 15:44:25,607:INFO:_display_container: 4
2024-05-25 15:44:25,610:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.3125,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:44:25,610:INFO:create_model() successfully completed......................................
2024-05-25 15:44:26,527:INFO:Threshold: 0.3125. Accuracy: 0.8146
2024-05-25 15:44:26,528:INFO:Initializing create_model()
2024-05-25 15:44:26,528:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.1875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:44:26,528:INFO:Checking exceptions
2024-05-25 15:44:26,530:INFO:Importing libraries
2024-05-25 15:44:26,530:INFO:Copying training dataset
2024-05-25 15:44:26,574:INFO:Defining folds
2024-05-25 15:44:26,574:INFO:Declaring metric variables
2024-05-25 15:44:26,574:INFO:Importing untrained model
2024-05-25 15:44:26,574:INFO:Declaring custom model
2024-05-25 15:44:26,575:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:44:26,576:INFO:Starting cross validation
2024-05-25 15:44:26,579:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:44:31,821:INFO:Calculating mean and std
2024-05-25 15:44:31,822:INFO:Creating metrics dataframe
2024-05-25 15:44:31,825:INFO:Finalizing model
2024-05-25 15:44:32,764:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:44:32,768:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:44:32,780:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004044 seconds.
2024-05-25 15:44:32,780:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:44:32,780:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:44:32,780:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:44:32,781:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:44:32,781:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:44:32,782:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:44:33,037:INFO:Uploading results into container
2024-05-25 15:44:33,038:INFO:Uploading model into container now
2024-05-25 15:44:33,039:INFO:_master_model_container: 29
2024-05-25 15:44:33,039:INFO:_display_container: 4
2024-05-25 15:44:33,042:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.1875,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:44:33,042:INFO:create_model() successfully completed......................................
2024-05-25 15:44:33,982:INFO:Threshold: 0.1875. Accuracy: 0.7748
2024-05-25 15:44:33,983:INFO:Initializing create_model()
2024-05-25 15:44:33,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.34375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:44:33,984:INFO:Checking exceptions
2024-05-25 15:44:33,986:INFO:Importing libraries
2024-05-25 15:44:33,986:INFO:Copying training dataset
2024-05-25 15:44:34,023:INFO:Defining folds
2024-05-25 15:44:34,024:INFO:Declaring metric variables
2024-05-25 15:44:34,024:INFO:Importing untrained model
2024-05-25 15:44:34,024:INFO:Declaring custom model
2024-05-25 15:44:34,025:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:44:34,025:INFO:Starting cross validation
2024-05-25 15:44:34,029:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:44:38,947:INFO:Calculating mean and std
2024-05-25 15:44:38,948:INFO:Creating metrics dataframe
2024-05-25 15:44:38,951:INFO:Finalizing model
2024-05-25 15:44:39,864:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:44:39,867:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:44:39,879:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003775 seconds.
2024-05-25 15:44:39,879:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:44:39,879:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:44:39,880:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:44:39,880:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:44:39,881:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:44:39,881:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:44:40,136:INFO:Uploading results into container
2024-05-25 15:44:40,137:INFO:Uploading model into container now
2024-05-25 15:44:40,138:INFO:_master_model_container: 30
2024-05-25 15:44:40,138:INFO:_display_container: 4
2024-05-25 15:44:40,141:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.34375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:44:40,141:INFO:create_model() successfully completed......................................
2024-05-25 15:44:41,082:INFO:Threshold: 0.34375. Accuracy: 0.8202
2024-05-25 15:44:41,083:INFO:Initializing create_model()
2024-05-25 15:44:41,083:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.4375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:44:41,083:INFO:Checking exceptions
2024-05-25 15:44:41,085:INFO:Importing libraries
2024-05-25 15:44:41,086:INFO:Copying training dataset
2024-05-25 15:44:41,123:INFO:Defining folds
2024-05-25 15:44:41,123:INFO:Declaring metric variables
2024-05-25 15:44:41,124:INFO:Importing untrained model
2024-05-25 15:44:41,124:INFO:Declaring custom model
2024-05-25 15:44:41,125:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:44:41,125:INFO:Starting cross validation
2024-05-25 15:44:41,128:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:44:46,328:INFO:Calculating mean and std
2024-05-25 15:44:46,329:INFO:Creating metrics dataframe
2024-05-25 15:44:46,332:INFO:Finalizing model
2024-05-25 15:44:47,366:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:44:47,368:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:44:47,378:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003536 seconds.
2024-05-25 15:44:47,378:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:44:47,378:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:44:47,378:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:44:47,379:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:44:47,379:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:44:47,379:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:44:47,637:INFO:Uploading results into container
2024-05-25 15:44:47,638:INFO:Uploading model into container now
2024-05-25 15:44:47,638:INFO:_master_model_container: 31
2024-05-25 15:44:47,638:INFO:_display_container: 4
2024-05-25 15:44:47,641:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.4375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:44:47,641:INFO:create_model() successfully completed......................................
2024-05-25 15:44:48,576:INFO:Threshold: 0.4375. Accuracy: 0.8325
2024-05-25 15:44:48,578:INFO:Initializing create_model()
2024-05-25 15:44:48,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.46875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:44:48,578:INFO:Checking exceptions
2024-05-25 15:44:48,580:INFO:Importing libraries
2024-05-25 15:44:48,580:INFO:Copying training dataset
2024-05-25 15:44:48,618:INFO:Defining folds
2024-05-25 15:44:48,618:INFO:Declaring metric variables
2024-05-25 15:44:48,619:INFO:Importing untrained model
2024-05-25 15:44:48,619:INFO:Declaring custom model
2024-05-25 15:44:48,620:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:44:48,620:INFO:Starting cross validation
2024-05-25 15:44:48,623:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:44:53,560:INFO:Calculating mean and std
2024-05-25 15:44:53,561:INFO:Creating metrics dataframe
2024-05-25 15:44:53,564:INFO:Finalizing model
2024-05-25 15:44:54,487:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:44:54,490:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:44:54,499:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003091 seconds.
2024-05-25 15:44:54,499:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:44:54,499:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:44:54,499:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:44:54,499:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:44:54,500:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:44:54,500:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:44:54,761:INFO:Uploading results into container
2024-05-25 15:44:54,762:INFO:Uploading model into container now
2024-05-25 15:44:54,763:INFO:_master_model_container: 32
2024-05-25 15:44:54,763:INFO:_display_container: 4
2024-05-25 15:44:54,766:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.46875,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:44:54,766:INFO:create_model() successfully completed......................................
2024-05-25 15:44:55,699:INFO:Threshold: 0.46875. Accuracy: 0.8352
2024-05-25 15:44:55,701:INFO:Initializing create_model()
2024-05-25 15:44:55,701:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.5625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:44:55,701:INFO:Checking exceptions
2024-05-25 15:44:55,703:INFO:Importing libraries
2024-05-25 15:44:55,703:INFO:Copying training dataset
2024-05-25 15:44:55,741:INFO:Defining folds
2024-05-25 15:44:55,741:INFO:Declaring metric variables
2024-05-25 15:44:55,742:INFO:Importing untrained model
2024-05-25 15:44:55,742:INFO:Declaring custom model
2024-05-25 15:44:55,743:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:44:55,743:INFO:Starting cross validation
2024-05-25 15:44:55,747:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:45:00,830:INFO:Calculating mean and std
2024-05-25 15:45:00,831:INFO:Creating metrics dataframe
2024-05-25 15:45:00,834:INFO:Finalizing model
2024-05-25 15:45:01,865:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:45:01,868:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:45:01,878:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003182 seconds.
2024-05-25 15:45:01,878:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:45:01,878:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:45:01,878:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:45:01,878:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:45:01,879:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:45:01,879:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:45:02,140:INFO:Uploading results into container
2024-05-25 15:45:02,141:INFO:Uploading model into container now
2024-05-25 15:45:02,141:INFO:_master_model_container: 33
2024-05-25 15:45:02,141:INFO:_display_container: 4
2024-05-25 15:45:02,144:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.5625,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:45:02,144:INFO:create_model() successfully completed......................................
2024-05-25 15:45:03,080:INFO:Threshold: 0.5625. Accuracy: 0.8316
2024-05-25 15:45:03,081:INFO:Initializing create_model()
2024-05-25 15:45:03,081:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.59375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:45:03,082:INFO:Checking exceptions
2024-05-25 15:45:03,084:INFO:Importing libraries
2024-05-25 15:45:03,084:INFO:Copying training dataset
2024-05-25 15:45:03,123:INFO:Defining folds
2024-05-25 15:45:03,123:INFO:Declaring metric variables
2024-05-25 15:45:03,123:INFO:Importing untrained model
2024-05-25 15:45:03,123:INFO:Declaring custom model
2024-05-25 15:45:03,124:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:45:03,125:INFO:Starting cross validation
2024-05-25 15:45:03,128:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:45:08,188:INFO:Calculating mean and std
2024-05-25 15:45:08,189:INFO:Creating metrics dataframe
2024-05-25 15:45:08,192:INFO:Finalizing model
2024-05-25 15:45:09,199:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:45:09,203:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:45:09,215:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004359 seconds.
2024-05-25 15:45:09,216:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:45:09,216:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:45:09,216:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:45:09,216:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:45:09,217:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:45:09,217:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:45:09,473:INFO:Uploading results into container
2024-05-25 15:45:09,474:INFO:Uploading model into container now
2024-05-25 15:45:09,475:INFO:_master_model_container: 34
2024-05-25 15:45:09,475:INFO:_display_container: 4
2024-05-25 15:45:09,478:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.59375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:45:09,478:INFO:create_model() successfully completed......................................
2024-05-25 15:45:10,431:INFO:Threshold: 0.59375. Accuracy: 0.8279
2024-05-25 15:45:10,432:INFO:Initializing create_model()
2024-05-25 15:45:10,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.6875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:45:10,432:INFO:Checking exceptions
2024-05-25 15:45:10,434:INFO:Importing libraries
2024-05-25 15:45:10,434:INFO:Copying training dataset
2024-05-25 15:45:10,471:INFO:Defining folds
2024-05-25 15:45:10,471:INFO:Declaring metric variables
2024-05-25 15:45:10,472:INFO:Importing untrained model
2024-05-25 15:45:10,472:INFO:Declaring custom model
2024-05-25 15:45:10,473:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:45:10,473:INFO:Starting cross validation
2024-05-25 15:45:10,476:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:45:15,765:INFO:Calculating mean and std
2024-05-25 15:45:15,766:INFO:Creating metrics dataframe
2024-05-25 15:45:15,769:INFO:Finalizing model
2024-05-25 15:45:16,779:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:45:16,782:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:45:16,793:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003817 seconds.
2024-05-25 15:45:16,794:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:45:16,794:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:45:16,794:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:45:16,794:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:45:16,795:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:45:16,795:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:45:17,056:INFO:Uploading results into container
2024-05-25 15:45:17,057:INFO:Uploading model into container now
2024-05-25 15:45:17,058:INFO:_master_model_container: 35
2024-05-25 15:45:17,058:INFO:_display_container: 4
2024-05-25 15:45:17,061:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.6875,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:45:17,061:INFO:create_model() successfully completed......................................
2024-05-25 15:45:18,031:INFO:Threshold: 0.6875. Accuracy: 0.812
2024-05-25 15:45:18,032:INFO:Initializing create_model()
2024-05-25 15:45:18,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.71875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:45:18,032:INFO:Checking exceptions
2024-05-25 15:45:18,034:INFO:Importing libraries
2024-05-25 15:45:18,034:INFO:Copying training dataset
2024-05-25 15:45:18,071:INFO:Defining folds
2024-05-25 15:45:18,071:INFO:Declaring metric variables
2024-05-25 15:45:18,071:INFO:Importing untrained model
2024-05-25 15:45:18,072:INFO:Declaring custom model
2024-05-25 15:45:18,073:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:45:18,073:INFO:Starting cross validation
2024-05-25 15:45:18,076:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:45:23,090:INFO:Calculating mean and std
2024-05-25 15:45:23,091:INFO:Creating metrics dataframe
2024-05-25 15:45:23,094:INFO:Finalizing model
2024-05-25 15:45:24,034:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:45:24,037:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:45:24,047:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003349 seconds.
2024-05-25 15:45:24,047:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:45:24,047:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:45:24,047:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:45:24,048:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:45:24,048:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:45:24,049:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:45:24,363:INFO:Uploading results into container
2024-05-25 15:45:24,364:INFO:Uploading model into container now
2024-05-25 15:45:24,365:INFO:_master_model_container: 36
2024-05-25 15:45:24,365:INFO:_display_container: 4
2024-05-25 15:45:24,368:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.71875,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:45:24,368:INFO:create_model() successfully completed......................................
2024-05-25 15:45:25,311:INFO:Threshold: 0.71875. Accuracy: 0.8072
2024-05-25 15:45:25,312:INFO:Initializing create_model()
2024-05-25 15:45:25,312:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.8125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:45:25,312:INFO:Checking exceptions
2024-05-25 15:45:25,314:INFO:Importing libraries
2024-05-25 15:45:25,314:INFO:Copying training dataset
2024-05-25 15:45:25,353:INFO:Defining folds
2024-05-25 15:45:25,353:INFO:Declaring metric variables
2024-05-25 15:45:25,353:INFO:Importing untrained model
2024-05-25 15:45:25,353:INFO:Declaring custom model
2024-05-25 15:45:25,354:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:45:25,355:INFO:Starting cross validation
2024-05-25 15:45:25,358:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:45:30,629:INFO:Calculating mean and std
2024-05-25 15:45:30,630:INFO:Creating metrics dataframe
2024-05-25 15:45:30,633:INFO:Finalizing model
2024-05-25 15:45:31,555:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:45:31,558:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:45:31,569:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003225 seconds.
2024-05-25 15:45:31,569:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:45:31,569:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:45:31,570:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:45:31,570:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:45:31,570:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:45:31,571:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:45:31,830:INFO:Uploading results into container
2024-05-25 15:45:31,831:INFO:Uploading model into container now
2024-05-25 15:45:31,831:INFO:_master_model_container: 37
2024-05-25 15:45:31,831:INFO:_display_container: 4
2024-05-25 15:45:31,834:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.8125,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:45:31,834:INFO:create_model() successfully completed......................................
2024-05-25 15:45:32,761:INFO:Threshold: 0.8125. Accuracy: 0.7828
2024-05-25 15:45:32,762:INFO:Initializing create_model()
2024-05-25 15:45:32,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.84375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:45:32,762:INFO:Checking exceptions
2024-05-25 15:45:32,764:INFO:Importing libraries
2024-05-25 15:45:32,764:INFO:Copying training dataset
2024-05-25 15:45:32,802:INFO:Defining folds
2024-05-25 15:45:32,803:INFO:Declaring metric variables
2024-05-25 15:45:32,803:INFO:Importing untrained model
2024-05-25 15:45:32,803:INFO:Declaring custom model
2024-05-25 15:45:32,804:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:45:32,804:INFO:Starting cross validation
2024-05-25 15:45:32,808:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:45:37,800:INFO:Calculating mean and std
2024-05-25 15:45:37,801:INFO:Creating metrics dataframe
2024-05-25 15:45:37,804:INFO:Finalizing model
2024-05-25 15:45:38,813:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:45:38,816:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:45:38,827:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003361 seconds.
2024-05-25 15:45:38,827:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:45:38,827:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:45:38,827:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:45:38,827:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:45:38,828:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:45:38,828:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:45:39,091:INFO:Uploading results into container
2024-05-25 15:45:39,092:INFO:Uploading model into container now
2024-05-25 15:45:39,092:INFO:_master_model_container: 38
2024-05-25 15:45:39,092:INFO:_display_container: 4
2024-05-25 15:45:39,095:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.84375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:45:39,095:INFO:create_model() successfully completed......................................
2024-05-25 15:45:40,042:INFO:Threshold: 0.84375. Accuracy: 0.7761
2024-05-25 15:45:40,043:INFO:Initializing create_model()
2024-05-25 15:45:40,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.9375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:45:40,043:INFO:Checking exceptions
2024-05-25 15:45:40,045:INFO:Importing libraries
2024-05-25 15:45:40,046:INFO:Copying training dataset
2024-05-25 15:45:40,083:INFO:Defining folds
2024-05-25 15:45:40,083:INFO:Declaring metric variables
2024-05-25 15:45:40,084:INFO:Importing untrained model
2024-05-25 15:45:40,084:INFO:Declaring custom model
2024-05-25 15:45:40,085:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:45:40,085:INFO:Starting cross validation
2024-05-25 15:45:40,088:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:45:45,243:INFO:Calculating mean and std
2024-05-25 15:45:45,244:INFO:Creating metrics dataframe
2024-05-25 15:45:45,247:INFO:Finalizing model
2024-05-25 15:45:46,266:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:45:46,269:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:45:46,278:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003084 seconds.
2024-05-25 15:45:46,278:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:45:46,279:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:45:46,279:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:45:46,279:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:45:46,280:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:45:46,280:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:45:46,535:INFO:Uploading results into container
2024-05-25 15:45:46,536:INFO:Uploading model into container now
2024-05-25 15:45:46,537:INFO:_master_model_container: 39
2024-05-25 15:45:46,537:INFO:_display_container: 4
2024-05-25 15:45:46,540:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.9375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:45:46,540:INFO:create_model() successfully completed......................................
2024-05-25 15:45:47,486:INFO:Threshold: 0.9375. Accuracy: 0.7357
2024-05-25 15:45:47,487:INFO:Initializing create_model()
2024-05-25 15:45:47,487:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.0625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:45:47,487:INFO:Checking exceptions
2024-05-25 15:45:47,489:INFO:Importing libraries
2024-05-25 15:45:47,489:INFO:Copying training dataset
2024-05-25 15:45:47,526:INFO:Defining folds
2024-05-25 15:45:47,526:INFO:Declaring metric variables
2024-05-25 15:45:47,527:INFO:Importing untrained model
2024-05-25 15:45:47,527:INFO:Declaring custom model
2024-05-25 15:45:47,528:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:45:47,528:INFO:Starting cross validation
2024-05-25 15:45:47,531:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:45:52,492:INFO:Calculating mean and std
2024-05-25 15:45:52,493:INFO:Creating metrics dataframe
2024-05-25 15:45:52,496:INFO:Finalizing model
2024-05-25 15:45:53,418:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:45:53,421:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:45:53,430:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003130 seconds.
2024-05-25 15:45:53,430:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:45:53,430:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:45:53,431:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:45:53,431:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:45:53,431:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:45:53,432:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:45:53,691:INFO:Uploading results into container
2024-05-25 15:45:53,692:INFO:Uploading model into container now
2024-05-25 15:45:53,693:INFO:_master_model_container: 40
2024-05-25 15:45:53,693:INFO:_display_container: 4
2024-05-25 15:45:53,696:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.0625,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:45:53,696:INFO:create_model() successfully completed......................................
2024-05-25 15:45:54,639:INFO:Threshold: 0.0625. Accuracy: 0.6362
2024-05-25 15:45:54,640:INFO:Initializing create_model()
2024-05-25 15:45:54,640:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.96875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:45:54,640:INFO:Checking exceptions
2024-05-25 15:45:54,642:INFO:Importing libraries
2024-05-25 15:45:54,643:INFO:Copying training dataset
2024-05-25 15:45:54,685:INFO:Defining folds
2024-05-25 15:45:54,685:INFO:Declaring metric variables
2024-05-25 15:45:54,685:INFO:Importing untrained model
2024-05-25 15:45:54,686:INFO:Declaring custom model
2024-05-25 15:45:54,687:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:45:54,687:INFO:Starting cross validation
2024-05-25 15:45:54,692:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:45:59,828:INFO:Calculating mean and std
2024-05-25 15:45:59,829:INFO:Creating metrics dataframe
2024-05-25 15:45:59,832:INFO:Finalizing model
2024-05-25 15:46:00,875:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:46:00,878:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:46:00,886:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003335 seconds.
2024-05-25 15:46:00,886:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:46:00,886:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:46:00,887:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:46:00,887:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:46:00,887:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:46:00,888:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:46:01,152:INFO:Uploading results into container
2024-05-25 15:46:01,153:INFO:Uploading model into container now
2024-05-25 15:46:01,153:INFO:_master_model_container: 41
2024-05-25 15:46:01,154:INFO:_display_container: 4
2024-05-25 15:46:01,157:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.96875,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:46:01,157:INFO:create_model() successfully completed......................................
2024-05-25 15:46:02,099:INFO:Threshold: 0.96875. Accuracy: 0.6853
2024-05-25 15:46:02,101:INFO:Initializing create_model()
2024-05-25 15:46:02,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.484375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:46:02,101:INFO:Checking exceptions
2024-05-25 15:46:02,103:INFO:Importing libraries
2024-05-25 15:46:02,104:INFO:Copying training dataset
2024-05-25 15:46:02,141:INFO:Defining folds
2024-05-25 15:46:02,142:INFO:Declaring metric variables
2024-05-25 15:46:02,142:INFO:Importing untrained model
2024-05-25 15:46:02,142:INFO:Declaring custom model
2024-05-25 15:46:02,143:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:46:02,143:INFO:Starting cross validation
2024-05-25 15:46:02,147:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:46:07,045:INFO:Calculating mean and std
2024-05-25 15:46:07,046:INFO:Creating metrics dataframe
2024-05-25 15:46:07,049:INFO:Finalizing model
2024-05-25 15:46:08,066:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:46:08,069:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:46:08,080:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003502 seconds.
2024-05-25 15:46:08,080:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:46:08,081:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:46:08,081:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:46:08,081:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:46:08,082:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:46:08,082:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:46:08,343:INFO:Uploading results into container
2024-05-25 15:46:08,344:INFO:Uploading model into container now
2024-05-25 15:46:08,345:INFO:_master_model_container: 42
2024-05-25 15:46:08,345:INFO:_display_container: 4
2024-05-25 15:46:08,348:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.484375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:46:08,348:INFO:create_model() successfully completed......................................
2024-05-25 15:46:09,293:INFO:Threshold: 0.484375. Accuracy: 0.8364
2024-05-25 15:46:09,294:INFO:Initializing create_model()
2024-05-25 15:46:09,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.53125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:46:09,294:INFO:Checking exceptions
2024-05-25 15:46:09,296:INFO:Importing libraries
2024-05-25 15:46:09,296:INFO:Copying training dataset
2024-05-25 15:46:09,334:INFO:Defining folds
2024-05-25 15:46:09,335:INFO:Declaring metric variables
2024-05-25 15:46:09,335:INFO:Importing untrained model
2024-05-25 15:46:09,335:INFO:Declaring custom model
2024-05-25 15:46:09,336:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:46:09,336:INFO:Starting cross validation
2024-05-25 15:46:09,339:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:46:14,779:INFO:Calculating mean and std
2024-05-25 15:46:14,780:INFO:Creating metrics dataframe
2024-05-25 15:46:14,783:INFO:Finalizing model
2024-05-25 15:46:15,761:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:46:15,763:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:46:15,773:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003670 seconds.
2024-05-25 15:46:15,774:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:46:15,774:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:46:15,774:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:46:15,774:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:46:15,775:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:46:15,775:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:46:16,064:INFO:Uploading results into container
2024-05-25 15:46:16,064:INFO:Uploading model into container now
2024-05-25 15:46:16,065:INFO:_master_model_container: 43
2024-05-25 15:46:16,065:INFO:_display_container: 4
2024-05-25 15:46:16,069:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.53125,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:46:16,069:INFO:create_model() successfully completed......................................
2024-05-25 15:46:17,018:INFO:Threshold: 0.53125. Accuracy: 0.835
2024-05-25 15:46:17,019:INFO:Initializing create_model()
2024-05-25 15:46:17,019:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.546875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:46:17,019:INFO:Checking exceptions
2024-05-25 15:46:17,022:INFO:Importing libraries
2024-05-25 15:46:17,022:INFO:Copying training dataset
2024-05-25 15:46:17,065:INFO:Defining folds
2024-05-25 15:46:17,065:INFO:Declaring metric variables
2024-05-25 15:46:17,065:INFO:Importing untrained model
2024-05-25 15:46:17,065:INFO:Declaring custom model
2024-05-25 15:46:17,067:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:46:17,067:INFO:Starting cross validation
2024-05-25 15:46:17,071:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:46:22,052:INFO:Calculating mean and std
2024-05-25 15:46:22,053:INFO:Creating metrics dataframe
2024-05-25 15:46:22,056:INFO:Finalizing model
2024-05-25 15:46:23,071:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:46:23,074:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:46:23,082:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002755 seconds.
2024-05-25 15:46:23,082:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:46:23,082:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:46:23,082:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:46:23,082:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:46:23,083:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:46:23,083:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:46:23,341:INFO:Uploading results into container
2024-05-25 15:46:23,342:INFO:Uploading model into container now
2024-05-25 15:46:23,343:INFO:_master_model_container: 44
2024-05-25 15:46:23,343:INFO:_display_container: 4
2024-05-25 15:46:23,346:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.546875,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:46:23,346:INFO:create_model() successfully completed......................................
2024-05-25 15:46:24,283:INFO:Threshold: 0.546875. Accuracy: 0.834
2024-05-25 15:46:24,284:INFO:Initializing create_model()
2024-05-25 15:46:24,284:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.609375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:46:24,284:INFO:Checking exceptions
2024-05-25 15:46:24,287:INFO:Importing libraries
2024-05-25 15:46:24,287:INFO:Copying training dataset
2024-05-25 15:46:24,326:INFO:Defining folds
2024-05-25 15:46:24,327:INFO:Declaring metric variables
2024-05-25 15:46:24,327:INFO:Importing untrained model
2024-05-25 15:46:24,327:INFO:Declaring custom model
2024-05-25 15:46:24,328:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:46:24,328:INFO:Starting cross validation
2024-05-25 15:46:24,332:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:46:29,519:INFO:Calculating mean and std
2024-05-25 15:46:29,520:INFO:Creating metrics dataframe
2024-05-25 15:46:29,523:INFO:Finalizing model
2024-05-25 15:46:30,548:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:46:30,551:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:46:30,559:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003486 seconds.
2024-05-25 15:46:30,560:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:46:30,560:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:46:30,560:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:46:30,560:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:46:30,561:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:46:30,561:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:46:30,851:INFO:Uploading results into container
2024-05-25 15:46:30,852:INFO:Uploading model into container now
2024-05-25 15:46:30,852:INFO:_master_model_container: 45
2024-05-25 15:46:30,852:INFO:_display_container: 4
2024-05-25 15:46:30,855:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.609375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:46:30,856:INFO:create_model() successfully completed......................................
2024-05-25 15:46:31,798:INFO:Threshold: 0.609375. Accuracy: 0.8247
2024-05-25 15:46:31,799:INFO:Initializing create_model()
2024-05-25 15:46:31,799:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.671875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:46:31,799:INFO:Checking exceptions
2024-05-25 15:46:31,802:INFO:Importing libraries
2024-05-25 15:46:31,802:INFO:Copying training dataset
2024-05-25 15:46:31,840:INFO:Defining folds
2024-05-25 15:46:31,840:INFO:Declaring metric variables
2024-05-25 15:46:31,840:INFO:Importing untrained model
2024-05-25 15:46:31,840:INFO:Declaring custom model
2024-05-25 15:46:31,841:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:46:31,842:INFO:Starting cross validation
2024-05-25 15:46:31,845:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:46:36,878:INFO:Calculating mean and std
2024-05-25 15:46:36,879:INFO:Creating metrics dataframe
2024-05-25 15:46:36,882:INFO:Finalizing model
2024-05-25 15:46:37,892:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:46:37,895:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:46:37,907:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003743 seconds.
2024-05-25 15:46:37,907:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:46:37,907:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:46:37,907:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:46:37,908:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:46:37,909:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:46:37,909:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:46:38,164:INFO:Uploading results into container
2024-05-25 15:46:38,165:INFO:Uploading model into container now
2024-05-25 15:46:38,165:INFO:_master_model_container: 46
2024-05-25 15:46:38,165:INFO:_display_container: 4
2024-05-25 15:46:38,169:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.671875,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:46:38,169:INFO:create_model() successfully completed......................................
2024-05-25 15:46:39,109:INFO:Threshold: 0.671875. Accuracy: 0.8137
2024-05-25 15:46:39,110:INFO:Initializing create_model()
2024-05-25 15:46:39,110:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.78125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:46:39,110:INFO:Checking exceptions
2024-05-25 15:46:39,112:INFO:Importing libraries
2024-05-25 15:46:39,112:INFO:Copying training dataset
2024-05-25 15:46:39,156:INFO:Defining folds
2024-05-25 15:46:39,156:INFO:Declaring metric variables
2024-05-25 15:46:39,156:INFO:Importing untrained model
2024-05-25 15:46:39,156:INFO:Declaring custom model
2024-05-25 15:46:39,158:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:46:39,158:INFO:Starting cross validation
2024-05-25 15:46:39,161:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:46:44,284:INFO:Calculating mean and std
2024-05-25 15:46:44,285:INFO:Creating metrics dataframe
2024-05-25 15:46:44,289:INFO:Finalizing model
2024-05-25 15:46:45,295:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:46:45,298:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:46:45,309:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004188 seconds.
2024-05-25 15:46:45,309:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:46:45,309:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:46:45,309:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:46:45,309:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:46:45,310:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:46:45,310:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:46:45,570:INFO:Uploading results into container
2024-05-25 15:46:45,571:INFO:Uploading model into container now
2024-05-25 15:46:45,571:INFO:_master_model_container: 47
2024-05-25 15:46:45,571:INFO:_display_container: 4
2024-05-25 15:46:45,575:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.78125,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:46:45,575:INFO:create_model() successfully completed......................................
2024-05-25 15:46:46,515:INFO:Threshold: 0.78125. Accuracy: 0.795
2024-05-25 15:46:46,516:INFO:Initializing create_model()
2024-05-25 15:46:46,517:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.03125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:46:46,517:INFO:Checking exceptions
2024-05-25 15:46:46,519:INFO:Importing libraries
2024-05-25 15:46:46,519:INFO:Copying training dataset
2024-05-25 15:46:46,557:INFO:Defining folds
2024-05-25 15:46:46,557:INFO:Declaring metric variables
2024-05-25 15:46:46,557:INFO:Importing untrained model
2024-05-25 15:46:46,557:INFO:Declaring custom model
2024-05-25 15:46:46,558:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:46:46,558:INFO:Starting cross validation
2024-05-25 15:46:46,562:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:46:51,473:INFO:Calculating mean and std
2024-05-25 15:46:51,474:INFO:Creating metrics dataframe
2024-05-25 15:46:51,477:INFO:Finalizing model
2024-05-25 15:46:52,396:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:46:52,398:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:46:52,410:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003406 seconds.
2024-05-25 15:46:52,410:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:46:52,410:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:46:52,411:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:46:52,411:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:46:52,411:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:46:52,411:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:46:52,666:INFO:Uploading results into container
2024-05-25 15:46:52,667:INFO:Uploading model into container now
2024-05-25 15:46:52,667:INFO:_master_model_container: 48
2024-05-25 15:46:52,668:INFO:_display_container: 4
2024-05-25 15:46:52,671:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.03125,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:46:52,671:INFO:create_model() successfully completed......................................
2024-05-25 15:46:53,617:INFO:Threshold: 0.03125. Accuracy: 0.5964
2024-05-25 15:46:53,618:INFO:Initializing create_model()
2024-05-25 15:46:53,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.734375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:46:53,618:INFO:Checking exceptions
2024-05-25 15:46:53,620:INFO:Importing libraries
2024-05-25 15:46:53,621:INFO:Copying training dataset
2024-05-25 15:46:53,658:INFO:Defining folds
2024-05-25 15:46:53,658:INFO:Declaring metric variables
2024-05-25 15:46:53,659:INFO:Importing untrained model
2024-05-25 15:46:53,659:INFO:Declaring custom model
2024-05-25 15:46:53,660:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:46:53,660:INFO:Starting cross validation
2024-05-25 15:46:53,663:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:46:58,784:INFO:Calculating mean and std
2024-05-25 15:46:58,786:INFO:Creating metrics dataframe
2024-05-25 15:46:58,789:INFO:Finalizing model
2024-05-25 15:46:59,813:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:46:59,816:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:46:59,824:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003288 seconds.
2024-05-25 15:46:59,824:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:46:59,824:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:46:59,824:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:46:59,825:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:46:59,825:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:46:59,825:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:47:00,092:INFO:Uploading results into container
2024-05-25 15:47:00,093:INFO:Uploading model into container now
2024-05-25 15:47:00,093:INFO:_master_model_container: 49
2024-05-25 15:47:00,094:INFO:_display_container: 4
2024-05-25 15:47:00,097:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.734375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:47:00,097:INFO:create_model() successfully completed......................................
2024-05-25 15:47:01,032:INFO:Threshold: 0.734375. Accuracy: 0.8046
2024-05-25 15:47:01,033:INFO:Initializing create_model()
2024-05-25 15:47:01,033:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.65625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:47:01,033:INFO:Checking exceptions
2024-05-25 15:47:01,035:INFO:Importing libraries
2024-05-25 15:47:01,035:INFO:Copying training dataset
2024-05-25 15:47:01,073:INFO:Defining folds
2024-05-25 15:47:01,073:INFO:Declaring metric variables
2024-05-25 15:47:01,073:INFO:Importing untrained model
2024-05-25 15:47:01,073:INFO:Declaring custom model
2024-05-25 15:47:01,074:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:47:01,075:INFO:Starting cross validation
2024-05-25 15:47:01,078:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:47:05,964:INFO:Calculating mean and std
2024-05-25 15:47:05,965:INFO:Creating metrics dataframe
2024-05-25 15:47:05,968:INFO:Finalizing model
2024-05-25 15:47:06,991:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:47:06,994:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:47:07,005:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003299 seconds.
2024-05-25 15:47:07,005:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:47:07,005:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:47:07,005:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:47:07,006:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:47:07,006:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:47:07,006:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:47:07,259:INFO:Uploading results into container
2024-05-25 15:47:07,260:INFO:Uploading model into container now
2024-05-25 15:47:07,261:INFO:_master_model_container: 50
2024-05-25 15:47:07,261:INFO:_display_container: 4
2024-05-25 15:47:07,264:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.65625,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:47:07,264:INFO:create_model() successfully completed......................................
2024-05-25 15:47:08,198:INFO:Threshold: 0.65625. Accuracy: 0.815
2024-05-25 15:47:08,199:INFO:Initializing create_model()
2024-05-25 15:47:08,199:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.796875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:47:08,199:INFO:Checking exceptions
2024-05-25 15:47:08,201:INFO:Importing libraries
2024-05-25 15:47:08,202:INFO:Copying training dataset
2024-05-25 15:47:08,240:INFO:Defining folds
2024-05-25 15:47:08,240:INFO:Declaring metric variables
2024-05-25 15:47:08,241:INFO:Importing untrained model
2024-05-25 15:47:08,241:INFO:Declaring custom model
2024-05-25 15:47:08,241:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:47:08,242:INFO:Starting cross validation
2024-05-25 15:47:08,245:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:47:13,428:INFO:Calculating mean and std
2024-05-25 15:47:13,429:INFO:Creating metrics dataframe
2024-05-25 15:47:13,432:INFO:Finalizing model
2024-05-25 15:47:14,371:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:47:14,374:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:47:14,385:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007940 seconds.
2024-05-25 15:47:14,385:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-25 15:47:14,385:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:47:14,386:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:47:14,386:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:47:14,386:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:47:14,690:INFO:Uploading results into container
2024-05-25 15:47:14,691:INFO:Uploading model into container now
2024-05-25 15:47:14,692:INFO:_master_model_container: 51
2024-05-25 15:47:14,692:INFO:_display_container: 4
2024-05-25 15:47:14,695:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.796875,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:47:14,695:INFO:create_model() successfully completed......................................
2024-05-25 15:47:15,635:INFO:Threshold: 0.796875. Accuracy: 0.788
2024-05-25 15:47:15,636:INFO:Initializing create_model()
2024-05-25 15:47:15,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.859375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:47:15,637:INFO:Checking exceptions
2024-05-25 15:47:15,639:INFO:Importing libraries
2024-05-25 15:47:15,639:INFO:Copying training dataset
2024-05-25 15:47:15,677:INFO:Defining folds
2024-05-25 15:47:15,677:INFO:Declaring metric variables
2024-05-25 15:47:15,677:INFO:Importing untrained model
2024-05-25 15:47:15,677:INFO:Declaring custom model
2024-05-25 15:47:15,679:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:47:15,679:INFO:Starting cross validation
2024-05-25 15:47:15,682:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:47:20,601:INFO:Calculating mean and std
2024-05-25 15:47:20,602:INFO:Creating metrics dataframe
2024-05-25 15:47:20,605:INFO:Finalizing model
2024-05-25 15:47:21,611:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:47:21,615:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:47:21,624:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003253 seconds.
2024-05-25 15:47:21,625:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:47:21,625:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:47:21,625:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:47:21,625:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:47:21,626:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:47:21,626:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:47:21,900:INFO:Uploading results into container
2024-05-25 15:47:21,901:INFO:Uploading model into container now
2024-05-25 15:47:21,901:INFO:_master_model_container: 52
2024-05-25 15:47:21,901:INFO:_display_container: 4
2024-05-25 15:47:21,904:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.859375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:47:21,904:INFO:create_model() successfully completed......................................
2024-05-25 15:47:22,844:INFO:Threshold: 0.859375. Accuracy: 0.7734
2024-05-25 15:47:22,845:INFO:Initializing create_model()
2024-05-25 15:47:22,846:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.90625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:47:22,846:INFO:Checking exceptions
2024-05-25 15:47:22,848:INFO:Importing libraries
2024-05-25 15:47:22,848:INFO:Copying training dataset
2024-05-25 15:47:22,886:INFO:Defining folds
2024-05-25 15:47:22,886:INFO:Declaring metric variables
2024-05-25 15:47:22,886:INFO:Importing untrained model
2024-05-25 15:47:22,886:INFO:Declaring custom model
2024-05-25 15:47:22,887:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:47:22,888:INFO:Starting cross validation
2024-05-25 15:47:22,891:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:47:28,076:INFO:Calculating mean and std
2024-05-25 15:47:28,077:INFO:Creating metrics dataframe
2024-05-25 15:47:28,080:INFO:Finalizing model
2024-05-25 15:47:29,095:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:47:29,098:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:47:29,108:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004528 seconds.
2024-05-25 15:47:29,108:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:47:29,108:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:47:29,108:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:47:29,109:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:47:29,109:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:47:29,109:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:47:29,365:INFO:Uploading results into container
2024-05-25 15:47:29,366:INFO:Uploading model into container now
2024-05-25 15:47:29,367:INFO:_master_model_container: 53
2024-05-25 15:47:29,367:INFO:_display_container: 4
2024-05-25 15:47:29,370:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.90625,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:47:29,371:INFO:create_model() successfully completed......................................
2024-05-25 15:47:30,322:INFO:Threshold: 0.90625. Accuracy: 0.7572
2024-05-25 15:47:30,323:INFO:Initializing create_model()
2024-05-25 15:47:30,323:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.921875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:47:30,323:INFO:Checking exceptions
2024-05-25 15:47:30,325:INFO:Importing libraries
2024-05-25 15:47:30,325:INFO:Copying training dataset
2024-05-25 15:47:30,363:INFO:Defining folds
2024-05-25 15:47:30,363:INFO:Declaring metric variables
2024-05-25 15:47:30,364:INFO:Importing untrained model
2024-05-25 15:47:30,364:INFO:Declaring custom model
2024-05-25 15:47:30,365:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:47:30,365:INFO:Starting cross validation
2024-05-25 15:47:30,369:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:47:35,519:INFO:Calculating mean and std
2024-05-25 15:47:35,520:INFO:Creating metrics dataframe
2024-05-25 15:47:35,523:INFO:Finalizing model
2024-05-25 15:47:36,539:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:47:36,542:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:47:36,553:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003506 seconds.
2024-05-25 15:47:36,553:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:47:36,553:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:47:36,554:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:47:36,554:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:47:36,555:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:47:36,555:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:47:36,838:INFO:Uploading results into container
2024-05-25 15:47:36,839:INFO:Uploading model into container now
2024-05-25 15:47:36,840:INFO:_master_model_container: 54
2024-05-25 15:47:36,840:INFO:_display_container: 4
2024-05-25 15:47:36,843:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.921875,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:47:36,843:INFO:create_model() successfully completed......................................
2024-05-25 15:47:37,793:INFO:Threshold: 0.921875. Accuracy: 0.7487
2024-05-25 15:47:37,794:INFO:Initializing create_model()
2024-05-25 15:47:37,795:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.984375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:47:37,795:INFO:Checking exceptions
2024-05-25 15:47:37,797:INFO:Importing libraries
2024-05-25 15:47:37,797:INFO:Copying training dataset
2024-05-25 15:47:37,834:INFO:Defining folds
2024-05-25 15:47:37,835:INFO:Declaring metric variables
2024-05-25 15:47:37,835:INFO:Importing untrained model
2024-05-25 15:47:37,835:INFO:Declaring custom model
2024-05-25 15:47:37,836:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:47:37,836:INFO:Starting cross validation
2024-05-25 15:47:37,840:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:47:43,367:INFO:Calculating mean and std
2024-05-25 15:47:43,368:INFO:Creating metrics dataframe
2024-05-25 15:47:43,371:INFO:Finalizing model
2024-05-25 15:47:44,315:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:47:44,318:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:47:44,329:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004971 seconds.
2024-05-25 15:47:44,330:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:47:44,330:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:47:44,330:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:47:44,330:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:47:44,331:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:47:44,331:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:47:44,598:INFO:Uploading results into container
2024-05-25 15:47:44,599:INFO:Uploading model into container now
2024-05-25 15:47:44,600:INFO:_master_model_container: 55
2024-05-25 15:47:44,600:INFO:_display_container: 4
2024-05-25 15:47:44,603:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.984375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:47:44,603:INFO:create_model() successfully completed......................................
2024-05-25 15:47:45,549:INFO:Threshold: 0.984375. Accuracy: 0.6188
2024-05-25 15:47:45,550:INFO:Initializing create_model()
2024-05-25 15:47:45,550:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.15625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:47:45,550:INFO:Checking exceptions
2024-05-25 15:47:45,552:INFO:Importing libraries
2024-05-25 15:47:45,552:INFO:Copying training dataset
2024-05-25 15:47:45,591:INFO:Defining folds
2024-05-25 15:47:45,592:INFO:Declaring metric variables
2024-05-25 15:47:45,592:INFO:Importing untrained model
2024-05-25 15:47:45,592:INFO:Declaring custom model
2024-05-25 15:47:45,593:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:47:45,593:INFO:Starting cross validation
2024-05-25 15:47:45,597:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:47:50,819:INFO:Calculating mean and std
2024-05-25 15:47:50,820:INFO:Creating metrics dataframe
2024-05-25 15:47:50,823:INFO:Finalizing model
2024-05-25 15:47:51,844:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:47:51,847:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:47:51,856:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003199 seconds.
2024-05-25 15:47:51,856:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:47:51,856:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:47:51,857:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:47:51,857:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:47:51,858:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:47:51,858:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:47:52,116:INFO:Uploading results into container
2024-05-25 15:47:52,117:INFO:Uploading model into container now
2024-05-25 15:47:52,117:INFO:_master_model_container: 56
2024-05-25 15:47:52,117:INFO:_display_container: 4
2024-05-25 15:47:52,121:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.15625,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:47:52,121:INFO:create_model() successfully completed......................................
2024-05-25 15:47:53,075:INFO:Threshold: 0.15625. Accuracy: 0.7606
2024-05-25 15:47:53,076:INFO:Initializing create_model()
2024-05-25 15:47:53,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.046875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:47:53,076:INFO:Checking exceptions
2024-05-25 15:47:53,078:INFO:Importing libraries
2024-05-25 15:47:53,078:INFO:Copying training dataset
2024-05-25 15:47:53,116:INFO:Defining folds
2024-05-25 15:47:53,116:INFO:Declaring metric variables
2024-05-25 15:47:53,117:INFO:Importing untrained model
2024-05-25 15:47:53,117:INFO:Declaring custom model
2024-05-25 15:47:53,118:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:47:53,118:INFO:Starting cross validation
2024-05-25 15:47:53,122:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:47:58,562:INFO:Calculating mean and std
2024-05-25 15:47:58,563:INFO:Creating metrics dataframe
2024-05-25 15:47:58,567:INFO:Finalizing model
2024-05-25 15:47:59,610:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:47:59,613:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:47:59,623:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003840 seconds.
2024-05-25 15:47:59,623:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:47:59,623:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:47:59,623:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:47:59,624:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:47:59,624:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:47:59,624:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:47:59,905:INFO:Uploading results into container
2024-05-25 15:47:59,906:INFO:Uploading model into container now
2024-05-25 15:47:59,907:INFO:_master_model_container: 57
2024-05-25 15:47:59,907:INFO:_display_container: 4
2024-05-25 15:47:59,910:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.046875,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:47:59,910:INFO:create_model() successfully completed......................................
2024-05-25 15:48:00,860:INFO:Threshold: 0.046875. Accuracy: 0.6165
2024-05-25 15:48:00,861:INFO:Initializing create_model()
2024-05-25 15:48:00,861:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.171875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:48:00,862:INFO:Checking exceptions
2024-05-25 15:48:00,863:INFO:Importing libraries
2024-05-25 15:48:00,864:INFO:Copying training dataset
2024-05-25 15:48:00,901:INFO:Defining folds
2024-05-25 15:48:00,901:INFO:Declaring metric variables
2024-05-25 15:48:00,901:INFO:Importing untrained model
2024-05-25 15:48:00,901:INFO:Declaring custom model
2024-05-25 15:48:00,902:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:48:00,903:INFO:Starting cross validation
2024-05-25 15:48:00,906:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:48:06,010:INFO:Calculating mean and std
2024-05-25 15:48:06,011:INFO:Creating metrics dataframe
2024-05-25 15:48:06,014:INFO:Finalizing model
2024-05-25 15:48:07,041:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:48:07,044:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:48:07,053:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003787 seconds.
2024-05-25 15:48:07,054:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:48:07,054:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:48:07,054:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:48:07,054:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:48:07,055:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:48:07,055:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:48:07,308:INFO:Uploading results into container
2024-05-25 15:48:07,308:INFO:Uploading model into container now
2024-05-25 15:48:07,309:INFO:_master_model_container: 58
2024-05-25 15:48:07,309:INFO:_display_container: 4
2024-05-25 15:48:07,312:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.171875,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:48:07,312:INFO:create_model() successfully completed......................................
2024-05-25 15:48:08,246:INFO:Threshold: 0.171875. Accuracy: 0.7693
2024-05-25 15:48:08,247:INFO:Initializing create_model()
2024-05-25 15:48:08,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.109375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:48:08,247:INFO:Checking exceptions
2024-05-25 15:48:08,250:INFO:Importing libraries
2024-05-25 15:48:08,250:INFO:Copying training dataset
2024-05-25 15:48:08,288:INFO:Defining folds
2024-05-25 15:48:08,288:INFO:Declaring metric variables
2024-05-25 15:48:08,288:INFO:Importing untrained model
2024-05-25 15:48:08,288:INFO:Declaring custom model
2024-05-25 15:48:08,289:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:48:08,290:INFO:Starting cross validation
2024-05-25 15:48:08,293:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:48:13,318:INFO:Calculating mean and std
2024-05-25 15:48:13,319:INFO:Creating metrics dataframe
2024-05-25 15:48:13,322:INFO:Finalizing model
2024-05-25 15:48:14,345:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:48:14,348:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:48:14,360:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003546 seconds.
2024-05-25 15:48:14,360:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:48:14,360:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:48:14,360:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:48:14,360:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:48:14,361:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:48:14,361:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:48:14,620:INFO:Uploading results into container
2024-05-25 15:48:14,621:INFO:Uploading model into container now
2024-05-25 15:48:14,622:INFO:_master_model_container: 59
2024-05-25 15:48:14,622:INFO:_display_container: 4
2024-05-25 15:48:14,625:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.109375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:48:14,626:INFO:create_model() successfully completed......................................
2024-05-25 15:48:15,561:INFO:Threshold: 0.109375. Accuracy: 0.6902
2024-05-25 15:48:15,563:INFO:Initializing create_model()
2024-05-25 15:48:15,563:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.234375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:48:15,563:INFO:Checking exceptions
2024-05-25 15:48:15,565:INFO:Importing libraries
2024-05-25 15:48:15,565:INFO:Copying training dataset
2024-05-25 15:48:15,602:INFO:Defining folds
2024-05-25 15:48:15,603:INFO:Declaring metric variables
2024-05-25 15:48:15,603:INFO:Importing untrained model
2024-05-25 15:48:15,603:INFO:Declaring custom model
2024-05-25 15:48:15,604:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:48:15,605:INFO:Starting cross validation
2024-05-25 15:48:15,608:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:48:20,603:INFO:Calculating mean and std
2024-05-25 15:48:20,604:INFO:Creating metrics dataframe
2024-05-25 15:48:20,607:INFO:Finalizing model
2024-05-25 15:48:21,533:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:48:21,536:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:48:21,547:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004310 seconds.
2024-05-25 15:48:21,547:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:48:21,547:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:48:21,548:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:48:21,548:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:48:21,548:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:48:21,548:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:48:21,802:INFO:Uploading results into container
2024-05-25 15:48:21,803:INFO:Uploading model into container now
2024-05-25 15:48:21,803:INFO:_master_model_container: 60
2024-05-25 15:48:21,804:INFO:_display_container: 4
2024-05-25 15:48:21,807:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.234375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:48:21,807:INFO:create_model() successfully completed......................................
2024-05-25 15:48:22,748:INFO:Threshold: 0.234375. Accuracy: 0.7933
2024-05-25 15:48:22,749:INFO:Initializing create_model()
2024-05-25 15:48:22,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.28125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:48:22,749:INFO:Checking exceptions
2024-05-25 15:48:22,751:INFO:Importing libraries
2024-05-25 15:48:22,751:INFO:Copying training dataset
2024-05-25 15:48:22,789:INFO:Defining folds
2024-05-25 15:48:22,789:INFO:Declaring metric variables
2024-05-25 15:48:22,790:INFO:Importing untrained model
2024-05-25 15:48:22,790:INFO:Declaring custom model
2024-05-25 15:48:22,791:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:48:22,791:INFO:Starting cross validation
2024-05-25 15:48:22,794:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:48:27,764:INFO:Calculating mean and std
2024-05-25 15:48:27,765:INFO:Creating metrics dataframe
2024-05-25 15:48:27,768:INFO:Finalizing model
2024-05-25 15:48:28,705:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:48:28,708:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:48:28,717:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003657 seconds.
2024-05-25 15:48:28,717:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:48:28,717:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:48:28,717:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:48:28,717:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:48:28,718:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:48:28,718:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:48:28,981:INFO:Uploading results into container
2024-05-25 15:48:28,982:INFO:Uploading model into container now
2024-05-25 15:48:28,983:INFO:_master_model_container: 61
2024-05-25 15:48:28,983:INFO:_display_container: 4
2024-05-25 15:48:28,986:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.28125,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:48:28,986:INFO:create_model() successfully completed......................................
2024-05-25 15:48:29,923:INFO:Threshold: 0.28125. Accuracy: 0.8025
2024-05-25 15:48:29,924:INFO:Initializing create_model()
2024-05-25 15:48:29,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.296875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:48:29,925:INFO:Checking exceptions
2024-05-25 15:48:29,926:INFO:Importing libraries
2024-05-25 15:48:29,926:INFO:Copying training dataset
2024-05-25 15:48:29,964:INFO:Defining folds
2024-05-25 15:48:29,964:INFO:Declaring metric variables
2024-05-25 15:48:29,964:INFO:Importing untrained model
2024-05-25 15:48:29,965:INFO:Declaring custom model
2024-05-25 15:48:29,966:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:48:29,966:INFO:Starting cross validation
2024-05-25 15:48:29,969:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:48:34,983:INFO:Calculating mean and std
2024-05-25 15:48:34,984:INFO:Creating metrics dataframe
2024-05-25 15:48:34,987:INFO:Finalizing model
2024-05-25 15:48:35,927:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:48:35,930:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:48:35,939:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002839 seconds.
2024-05-25 15:48:35,939:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:48:35,940:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:48:35,940:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:48:35,940:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:48:35,941:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:48:35,941:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:48:36,193:INFO:Uploading results into container
2024-05-25 15:48:36,194:INFO:Uploading model into container now
2024-05-25 15:48:36,195:INFO:_master_model_container: 62
2024-05-25 15:48:36,195:INFO:_display_container: 4
2024-05-25 15:48:36,198:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.296875,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:48:36,198:INFO:create_model() successfully completed......................................
2024-05-25 15:48:37,136:INFO:Threshold: 0.296875. Accuracy: 0.8083
2024-05-25 15:48:37,137:INFO:Initializing create_model()
2024-05-25 15:48:37,137:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.359375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:48:37,137:INFO:Checking exceptions
2024-05-25 15:48:37,140:INFO:Importing libraries
2024-05-25 15:48:37,140:INFO:Copying training dataset
2024-05-25 15:48:37,178:INFO:Defining folds
2024-05-25 15:48:37,178:INFO:Declaring metric variables
2024-05-25 15:48:37,178:INFO:Importing untrained model
2024-05-25 15:48:37,178:INFO:Declaring custom model
2024-05-25 15:48:37,179:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:48:37,180:INFO:Starting cross validation
2024-05-25 15:48:37,183:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:48:42,445:INFO:Calculating mean and std
2024-05-25 15:48:42,446:INFO:Creating metrics dataframe
2024-05-25 15:48:42,449:INFO:Finalizing model
2024-05-25 15:48:43,386:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:48:43,389:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:48:43,398:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003628 seconds.
2024-05-25 15:48:43,398:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:48:43,399:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:48:43,399:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:48:43,399:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:48:43,400:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:48:43,400:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:48:43,661:INFO:Uploading results into container
2024-05-25 15:48:43,662:INFO:Uploading model into container now
2024-05-25 15:48:43,663:INFO:_master_model_container: 63
2024-05-25 15:48:43,663:INFO:_display_container: 4
2024-05-25 15:48:43,667:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.359375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:48:43,667:INFO:create_model() successfully completed......................................
2024-05-25 15:48:44,607:INFO:Threshold: 0.359375. Accuracy: 0.8238
2024-05-25 15:48:44,608:INFO:Initializing create_model()
2024-05-25 15:48:44,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.40625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:48:44,609:INFO:Checking exceptions
2024-05-25 15:48:44,611:INFO:Importing libraries
2024-05-25 15:48:44,611:INFO:Copying training dataset
2024-05-25 15:48:44,650:INFO:Defining folds
2024-05-25 15:48:44,650:INFO:Declaring metric variables
2024-05-25 15:48:44,650:INFO:Importing untrained model
2024-05-25 15:48:44,651:INFO:Declaring custom model
2024-05-25 15:48:44,652:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:48:44,652:INFO:Starting cross validation
2024-05-25 15:48:44,655:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:48:49,571:INFO:Calculating mean and std
2024-05-25 15:48:49,572:INFO:Creating metrics dataframe
2024-05-25 15:48:49,575:INFO:Finalizing model
2024-05-25 15:48:50,515:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:48:50,518:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:48:50,529:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004118 seconds.
2024-05-25 15:48:50,529:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:48:50,529:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:48:50,529:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:48:50,529:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:48:50,530:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:48:50,530:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:48:50,782:INFO:Uploading results into container
2024-05-25 15:48:50,783:INFO:Uploading model into container now
2024-05-25 15:48:50,784:INFO:_master_model_container: 64
2024-05-25 15:48:50,784:INFO:_display_container: 4
2024-05-25 15:48:50,787:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.40625,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:48:50,787:INFO:create_model() successfully completed......................................
2024-05-25 15:48:51,730:INFO:Threshold: 0.40625. Accuracy: 0.8285
2024-05-25 15:48:51,731:INFO:Initializing create_model()
2024-05-25 15:48:51,731:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.421875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:48:51,732:INFO:Checking exceptions
2024-05-25 15:48:51,733:INFO:Importing libraries
2024-05-25 15:48:51,733:INFO:Copying training dataset
2024-05-25 15:48:51,771:INFO:Defining folds
2024-05-25 15:48:51,771:INFO:Declaring metric variables
2024-05-25 15:48:51,771:INFO:Importing untrained model
2024-05-25 15:48:51,771:INFO:Declaring custom model
2024-05-25 15:48:51,772:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:48:51,773:INFO:Starting cross validation
2024-05-25 15:48:51,776:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:48:57,000:INFO:Calculating mean and std
2024-05-25 15:48:57,001:INFO:Creating metrics dataframe
2024-05-25 15:48:57,004:INFO:Finalizing model
2024-05-25 15:48:58,029:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:48:58,032:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:48:58,042:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003617 seconds.
2024-05-25 15:48:58,042:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:48:58,042:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:48:58,043:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:48:58,043:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:48:58,043:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:48:58,044:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:48:58,310:INFO:Uploading results into container
2024-05-25 15:48:58,311:INFO:Uploading model into container now
2024-05-25 15:48:58,311:INFO:_master_model_container: 65
2024-05-25 15:48:58,312:INFO:_display_container: 4
2024-05-25 15:48:58,315:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.421875,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:48:58,315:INFO:create_model() successfully completed......................................
2024-05-25 15:48:59,250:INFO:Threshold: 0.421875. Accuracy: 0.8305
2024-05-25 15:48:59,253:INFO:Initializing create_model()
2024-05-25 15:48:59,253:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.765625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:48:59,253:INFO:Checking exceptions
2024-05-25 15:48:59,255:INFO:Importing libraries
2024-05-25 15:48:59,255:INFO:Copying training dataset
2024-05-25 15:48:59,298:INFO:Defining folds
2024-05-25 15:48:59,298:INFO:Declaring metric variables
2024-05-25 15:48:59,299:INFO:Importing untrained model
2024-05-25 15:48:59,299:INFO:Declaring custom model
2024-05-25 15:48:59,300:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:48:59,300:INFO:Starting cross validation
2024-05-25 15:48:59,304:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:49:04,270:INFO:Calculating mean and std
2024-05-25 15:49:04,271:INFO:Creating metrics dataframe
2024-05-25 15:49:04,274:INFO:Finalizing model
2024-05-25 15:49:05,195:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:49:05,198:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:49:05,206:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003364 seconds.
2024-05-25 15:49:05,207:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:49:05,207:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:49:05,207:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:49:05,207:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:49:05,208:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:49:05,208:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:49:05,462:INFO:Uploading results into container
2024-05-25 15:49:05,463:INFO:Uploading model into container now
2024-05-25 15:49:05,464:INFO:_master_model_container: 66
2024-05-25 15:49:05,464:INFO:_display_container: 4
2024-05-25 15:49:05,467:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.765625,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:49:05,467:INFO:create_model() successfully completed......................................
2024-05-25 15:49:06,413:INFO:Threshold: 0.765625. Accuracy: 0.7996
2024-05-25 15:49:06,414:INFO:Initializing create_model()
2024-05-25 15:49:06,414:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.828125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:49:06,414:INFO:Checking exceptions
2024-05-25 15:49:06,416:INFO:Importing libraries
2024-05-25 15:49:06,416:INFO:Copying training dataset
2024-05-25 15:49:06,454:INFO:Defining folds
2024-05-25 15:49:06,454:INFO:Declaring metric variables
2024-05-25 15:49:06,454:INFO:Importing untrained model
2024-05-25 15:49:06,454:INFO:Declaring custom model
2024-05-25 15:49:06,455:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:49:06,456:INFO:Starting cross validation
2024-05-25 15:49:06,459:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:49:11,777:INFO:Calculating mean and std
2024-05-25 15:49:11,778:INFO:Creating metrics dataframe
2024-05-25 15:49:11,781:INFO:Finalizing model
2024-05-25 15:49:12,738:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:49:12,741:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:49:12,751:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004133 seconds.
2024-05-25 15:49:12,752:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:49:12,752:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:49:12,752:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:49:12,752:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:49:12,753:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:49:12,753:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:49:13,006:INFO:Uploading results into container
2024-05-25 15:49:13,007:INFO:Uploading model into container now
2024-05-25 15:49:13,008:INFO:_master_model_container: 67
2024-05-25 15:49:13,008:INFO:_display_container: 4
2024-05-25 15:49:13,011:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.828125,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:49:13,011:INFO:create_model() successfully completed......................................
2024-05-25 15:49:13,949:INFO:Threshold: 0.828125. Accuracy: 0.7791
2024-05-25 15:49:13,951:INFO:Initializing create_model()
2024-05-25 15:49:13,951:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.890625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:49:13,951:INFO:Checking exceptions
2024-05-25 15:49:13,953:INFO:Importing libraries
2024-05-25 15:49:13,953:INFO:Copying training dataset
2024-05-25 15:49:13,997:INFO:Defining folds
2024-05-25 15:49:13,997:INFO:Declaring metric variables
2024-05-25 15:49:13,997:INFO:Importing untrained model
2024-05-25 15:49:13,997:INFO:Declaring custom model
2024-05-25 15:49:13,999:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:49:13,999:INFO:Starting cross validation
2024-05-25 15:49:14,002:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:49:18,954:INFO:Calculating mean and std
2024-05-25 15:49:18,955:INFO:Creating metrics dataframe
2024-05-25 15:49:18,958:INFO:Finalizing model
2024-05-25 15:49:19,996:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:49:19,999:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:49:20,009:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003609 seconds.
2024-05-25 15:49:20,009:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:49:20,009:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:49:20,009:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:49:20,009:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:49:20,010:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:49:20,010:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:49:20,297:INFO:Uploading results into container
2024-05-25 15:49:20,297:INFO:Uploading model into container now
2024-05-25 15:49:20,298:INFO:_master_model_container: 68
2024-05-25 15:49:20,298:INFO:_display_container: 4
2024-05-25 15:49:20,301:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.890625,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:49:20,301:INFO:create_model() successfully completed......................................
2024-05-25 15:49:21,273:INFO:Threshold: 0.890625. Accuracy: 0.7653
2024-05-25 15:49:21,274:INFO:Initializing create_model()
2024-05-25 15:49:21,274:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.953125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:49:21,274:INFO:Checking exceptions
2024-05-25 15:49:21,276:INFO:Importing libraries
2024-05-25 15:49:21,276:INFO:Copying training dataset
2024-05-25 15:49:21,314:INFO:Defining folds
2024-05-25 15:49:21,314:INFO:Declaring metric variables
2024-05-25 15:49:21,314:INFO:Importing untrained model
2024-05-25 15:49:21,314:INFO:Declaring custom model
2024-05-25 15:49:21,316:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:49:21,316:INFO:Starting cross validation
2024-05-25 15:49:21,319:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:49:26,696:INFO:Calculating mean and std
2024-05-25 15:49:26,697:INFO:Creating metrics dataframe
2024-05-25 15:49:26,700:INFO:Finalizing model
2024-05-25 15:49:27,733:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:49:27,737:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:49:27,745:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003703 seconds.
2024-05-25 15:49:27,746:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:49:27,746:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:49:27,746:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:49:27,746:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:49:27,747:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:49:27,747:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:49:28,007:INFO:Uploading results into container
2024-05-25 15:49:28,008:INFO:Uploading model into container now
2024-05-25 15:49:28,009:INFO:_master_model_container: 69
2024-05-25 15:49:28,009:INFO:_display_container: 4
2024-05-25 15:49:28,012:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.953125,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:49:28,012:INFO:create_model() successfully completed......................................
2024-05-25 15:49:28,977:INFO:Threshold: 0.953125. Accuracy: 0.7169
2024-05-25 15:49:28,979:INFO:Initializing create_model()
2024-05-25 15:49:28,980:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.3359375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:49:28,980:INFO:Checking exceptions
2024-05-25 15:49:28,982:INFO:Importing libraries
2024-05-25 15:49:28,982:INFO:Copying training dataset
2024-05-25 15:49:29,020:INFO:Defining folds
2024-05-25 15:49:29,021:INFO:Declaring metric variables
2024-05-25 15:49:29,021:INFO:Importing untrained model
2024-05-25 15:49:29,021:INFO:Declaring custom model
2024-05-25 15:49:29,022:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:49:29,022:INFO:Starting cross validation
2024-05-25 15:49:29,026:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:49:34,327:INFO:Calculating mean and std
2024-05-25 15:49:34,328:INFO:Creating metrics dataframe
2024-05-25 15:49:34,331:INFO:Finalizing model
2024-05-25 15:49:35,340:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:49:35,343:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:49:35,353:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004117 seconds.
2024-05-25 15:49:35,353:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:49:35,353:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:49:35,354:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:49:35,354:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:49:35,355:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:49:35,355:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:49:35,614:INFO:Uploading results into container
2024-05-25 15:49:35,614:INFO:Uploading model into container now
2024-05-25 15:49:35,615:INFO:_master_model_container: 70
2024-05-25 15:49:35,615:INFO:_display_container: 4
2024-05-25 15:49:35,618:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.3359375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:49:35,618:INFO:create_model() successfully completed......................................
2024-05-25 15:49:36,562:INFO:Threshold: 0.3359375. Accuracy: 0.8188
2024-05-25 15:49:36,563:INFO:Initializing create_model()
2024-05-25 15:49:36,563:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.390625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:49:36,563:INFO:Checking exceptions
2024-05-25 15:49:36,565:INFO:Importing libraries
2024-05-25 15:49:36,565:INFO:Copying training dataset
2024-05-25 15:49:36,609:INFO:Defining folds
2024-05-25 15:49:36,610:INFO:Declaring metric variables
2024-05-25 15:49:36,610:INFO:Importing untrained model
2024-05-25 15:49:36,610:INFO:Declaring custom model
2024-05-25 15:49:36,611:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:49:36,611:INFO:Starting cross validation
2024-05-25 15:49:36,615:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:49:41,848:INFO:Calculating mean and std
2024-05-25 15:49:41,849:INFO:Creating metrics dataframe
2024-05-25 15:49:41,852:INFO:Finalizing model
2024-05-25 15:49:42,774:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:49:42,777:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:49:42,787:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003184 seconds.
2024-05-25 15:49:42,787:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:49:42,787:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:49:42,787:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:49:42,787:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:49:42,788:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:49:42,788:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:49:43,044:INFO:Uploading results into container
2024-05-25 15:49:43,045:INFO:Uploading model into container now
2024-05-25 15:49:43,045:INFO:_master_model_container: 71
2024-05-25 15:49:43,046:INFO:_display_container: 4
2024-05-25 15:49:43,049:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.390625,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:49:43,049:INFO:create_model() successfully completed......................................
2024-05-25 15:49:43,990:INFO:Threshold: 0.390625. Accuracy: 0.8267
2024-05-25 15:49:43,991:INFO:Initializing create_model()
2024-05-25 15:49:43,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.3984375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:49:43,991:INFO:Checking exceptions
2024-05-25 15:49:43,993:INFO:Importing libraries
2024-05-25 15:49:43,993:INFO:Copying training dataset
2024-05-25 15:49:44,032:INFO:Defining folds
2024-05-25 15:49:44,032:INFO:Declaring metric variables
2024-05-25 15:49:44,032:INFO:Importing untrained model
2024-05-25 15:49:44,033:INFO:Declaring custom model
2024-05-25 15:49:44,034:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:49:44,034:INFO:Starting cross validation
2024-05-25 15:49:44,037:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:49:49,071:INFO:Calculating mean and std
2024-05-25 15:49:49,072:INFO:Creating metrics dataframe
2024-05-25 15:49:49,075:INFO:Finalizing model
2024-05-25 15:49:50,087:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:49:50,090:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:49:50,101:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003882 seconds.
2024-05-25 15:49:50,101:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:49:50,101:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:49:50,102:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:49:50,102:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:49:50,102:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:49:50,103:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:49:50,364:INFO:Uploading results into container
2024-05-25 15:49:50,365:INFO:Uploading model into container now
2024-05-25 15:49:50,366:INFO:_master_model_container: 72
2024-05-25 15:49:50,366:INFO:_display_container: 4
2024-05-25 15:49:50,369:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.3984375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:49:50,369:INFO:create_model() successfully completed......................................
2024-05-25 15:49:51,316:INFO:Threshold: 0.3984375. Accuracy: 0.8277
2024-05-25 15:49:51,317:INFO:Initializing create_model()
2024-05-25 15:49:51,317:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.453125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:49:51,318:INFO:Checking exceptions
2024-05-25 15:49:51,319:INFO:Importing libraries
2024-05-25 15:49:51,320:INFO:Copying training dataset
2024-05-25 15:49:51,359:INFO:Defining folds
2024-05-25 15:49:51,359:INFO:Declaring metric variables
2024-05-25 15:49:51,359:INFO:Importing untrained model
2024-05-25 15:49:51,359:INFO:Declaring custom model
2024-05-25 15:49:51,360:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:49:51,361:INFO:Starting cross validation
2024-05-25 15:49:51,364:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:49:56,811:INFO:Calculating mean and std
2024-05-25 15:49:56,812:INFO:Creating metrics dataframe
2024-05-25 15:49:56,815:INFO:Finalizing model
2024-05-25 15:49:57,850:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:49:57,853:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:49:57,863:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003428 seconds.
2024-05-25 15:49:57,864:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:49:57,864:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:49:57,864:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:49:57,864:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:49:57,865:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:49:57,865:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:49:58,123:INFO:Uploading results into container
2024-05-25 15:49:58,124:INFO:Uploading model into container now
2024-05-25 15:49:58,125:INFO:_master_model_container: 73
2024-05-25 15:49:58,125:INFO:_display_container: 4
2024-05-25 15:49:58,128:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.453125,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:49:58,128:INFO:create_model() successfully completed......................................
2024-05-25 15:49:59,095:INFO:Threshold: 0.453125. Accuracy: 0.8335
2024-05-25 15:49:59,096:INFO:Initializing create_model()
2024-05-25 15:49:59,096:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.515625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:49:59,096:INFO:Checking exceptions
2024-05-25 15:49:59,099:INFO:Importing libraries
2024-05-25 15:49:59,099:INFO:Copying training dataset
2024-05-25 15:49:59,136:INFO:Defining folds
2024-05-25 15:49:59,137:INFO:Declaring metric variables
2024-05-25 15:49:59,137:INFO:Importing untrained model
2024-05-25 15:49:59,137:INFO:Declaring custom model
2024-05-25 15:49:59,138:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:49:59,138:INFO:Starting cross validation
2024-05-25 15:49:59,142:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:50:04,156:INFO:Calculating mean and std
2024-05-25 15:50:04,157:INFO:Creating metrics dataframe
2024-05-25 15:50:04,160:INFO:Finalizing model
2024-05-25 15:50:05,198:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:50:05,200:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:50:05,210:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003044 seconds.
2024-05-25 15:50:05,211:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:50:05,211:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:50:05,211:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:50:05,211:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:50:05,212:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:50:05,212:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:50:05,464:INFO:Uploading results into container
2024-05-25 15:50:05,465:INFO:Uploading model into container now
2024-05-25 15:50:05,465:INFO:_master_model_container: 74
2024-05-25 15:50:05,466:INFO:_display_container: 4
2024-05-25 15:50:05,469:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.515625,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:50:05,469:INFO:create_model() successfully completed......................................
2024-05-25 15:50:06,421:INFO:Threshold: 0.515625. Accuracy: 0.8366
2024-05-25 15:50:06,422:INFO:Initializing create_model()
2024-05-25 15:50:06,422:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.578125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:50:06,422:INFO:Checking exceptions
2024-05-25 15:50:06,425:INFO:Importing libraries
2024-05-25 15:50:06,425:INFO:Copying training dataset
2024-05-25 15:50:06,463:INFO:Defining folds
2024-05-25 15:50:06,464:INFO:Declaring metric variables
2024-05-25 15:50:06,464:INFO:Importing untrained model
2024-05-25 15:50:06,464:INFO:Declaring custom model
2024-05-25 15:50:06,465:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:50:06,465:INFO:Starting cross validation
2024-05-25 15:50:06,469:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:50:11,928:INFO:Calculating mean and std
2024-05-25 15:50:11,929:INFO:Creating metrics dataframe
2024-05-25 15:50:11,932:INFO:Finalizing model
2024-05-25 15:50:12,995:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:50:12,998:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:50:13,007:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006254 seconds.
2024-05-25 15:50:13,007:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-25 15:50:13,007:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:50:13,008:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:50:13,008:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:50:13,008:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:50:13,304:INFO:Uploading results into container
2024-05-25 15:50:13,304:INFO:Uploading model into container now
2024-05-25 15:50:13,305:INFO:_master_model_container: 75
2024-05-25 15:50:13,305:INFO:_display_container: 4
2024-05-25 15:50:13,308:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.578125,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:50:13,308:INFO:create_model() successfully completed......................................
2024-05-25 15:50:14,249:INFO:Threshold: 0.578125. Accuracy: 0.8292
2024-05-25 15:50:14,250:INFO:Initializing create_model()
2024-05-25 15:50:14,250:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.015625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:50:14,250:INFO:Checking exceptions
2024-05-25 15:50:14,252:INFO:Importing libraries
2024-05-25 15:50:14,252:INFO:Copying training dataset
2024-05-25 15:50:14,291:INFO:Defining folds
2024-05-25 15:50:14,291:INFO:Declaring metric variables
2024-05-25 15:50:14,292:INFO:Importing untrained model
2024-05-25 15:50:14,292:INFO:Declaring custom model
2024-05-25 15:50:14,293:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:50:14,293:INFO:Starting cross validation
2024-05-25 15:50:14,297:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:50:19,286:INFO:Calculating mean and std
2024-05-25 15:50:19,287:INFO:Creating metrics dataframe
2024-05-25 15:50:19,290:INFO:Finalizing model
2024-05-25 15:50:20,369:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:50:20,372:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:50:20,381:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004043 seconds.
2024-05-25 15:50:20,381:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:50:20,381:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:50:20,382:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:50:20,382:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:50:20,382:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:50:20,383:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:50:20,645:INFO:Uploading results into container
2024-05-25 15:50:20,645:INFO:Uploading model into container now
2024-05-25 15:50:20,646:INFO:_master_model_container: 76
2024-05-25 15:50:20,646:INFO:_display_container: 4
2024-05-25 15:50:20,649:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.015625,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:50:20,649:INFO:create_model() successfully completed......................................
2024-05-25 15:50:21,592:INFO:Threshold: 0.015625. Accuracy: 0.5758
2024-05-25 15:50:21,593:INFO:Initializing create_model()
2024-05-25 15:50:21,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.5234375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:50:21,594:INFO:Checking exceptions
2024-05-25 15:50:21,596:INFO:Importing libraries
2024-05-25 15:50:21,596:INFO:Copying training dataset
2024-05-25 15:50:21,635:INFO:Defining folds
2024-05-25 15:50:21,635:INFO:Declaring metric variables
2024-05-25 15:50:21,635:INFO:Importing untrained model
2024-05-25 15:50:21,635:INFO:Declaring custom model
2024-05-25 15:50:21,636:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:50:21,637:INFO:Starting cross validation
2024-05-25 15:50:21,641:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:50:26,710:INFO:Calculating mean and std
2024-05-25 15:50:26,711:INFO:Creating metrics dataframe
2024-05-25 15:50:26,714:INFO:Finalizing model
2024-05-25 15:50:27,696:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:50:27,699:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:50:27,708:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003060 seconds.
2024-05-25 15:50:27,708:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:50:27,708:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:50:27,709:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:50:27,709:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:50:27,709:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:50:27,710:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:50:27,965:INFO:Uploading results into container
2024-05-25 15:50:27,966:INFO:Uploading model into container now
2024-05-25 15:50:27,967:INFO:_master_model_container: 77
2024-05-25 15:50:27,967:INFO:_display_container: 4
2024-05-25 15:50:27,970:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.5234375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:50:27,970:INFO:create_model() successfully completed......................................
2024-05-25 15:50:28,926:INFO:Threshold: 0.5234375. Accuracy: 0.8358
2024-05-25 15:50:28,927:INFO:Initializing create_model()
2024-05-25 15:50:28,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.4609375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:50:28,928:INFO:Checking exceptions
2024-05-25 15:50:28,929:INFO:Importing libraries
2024-05-25 15:50:28,930:INFO:Copying training dataset
2024-05-25 15:50:28,969:INFO:Defining folds
2024-05-25 15:50:28,970:INFO:Declaring metric variables
2024-05-25 15:50:28,970:INFO:Importing untrained model
2024-05-25 15:50:28,970:INFO:Declaring custom model
2024-05-25 15:50:28,971:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:50:28,971:INFO:Starting cross validation
2024-05-25 15:50:28,975:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:50:34,090:INFO:Calculating mean and std
2024-05-25 15:50:34,091:INFO:Creating metrics dataframe
2024-05-25 15:50:34,094:INFO:Finalizing model
2024-05-25 15:50:35,144:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:50:35,147:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:50:35,158:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004116 seconds.
2024-05-25 15:50:35,158:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:50:35,158:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:50:35,159:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:50:35,159:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:50:35,159:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:50:35,160:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:50:35,437:INFO:Uploading results into container
2024-05-25 15:50:35,438:INFO:Uploading model into container now
2024-05-25 15:50:35,439:INFO:_master_model_container: 78
2024-05-25 15:50:35,439:INFO:_display_container: 4
2024-05-25 15:50:35,442:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.4609375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:50:35,442:INFO:create_model() successfully completed......................................
2024-05-25 15:50:36,393:INFO:Threshold: 0.4609375. Accuracy: 0.8345
2024-05-25 15:50:36,394:INFO:Initializing create_model()
2024-05-25 15:50:36,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.5859375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:50:36,395:INFO:Checking exceptions
2024-05-25 15:50:36,397:INFO:Importing libraries
2024-05-25 15:50:36,397:INFO:Copying training dataset
2024-05-25 15:50:36,436:INFO:Defining folds
2024-05-25 15:50:36,436:INFO:Declaring metric variables
2024-05-25 15:50:36,437:INFO:Importing untrained model
2024-05-25 15:50:36,437:INFO:Declaring custom model
2024-05-25 15:50:36,438:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:50:36,438:INFO:Starting cross validation
2024-05-25 15:50:36,442:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:50:41,693:INFO:Calculating mean and std
2024-05-25 15:50:41,694:INFO:Creating metrics dataframe
2024-05-25 15:50:41,697:INFO:Finalizing model
2024-05-25 15:50:42,754:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:50:42,757:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:50:42,766:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003808 seconds.
2024-05-25 15:50:42,766:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:50:42,766:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:50:42,766:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:50:42,767:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:50:42,767:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:50:42,768:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:50:43,187:INFO:Uploading results into container
2024-05-25 15:50:43,188:INFO:Uploading model into container now
2024-05-25 15:50:43,188:INFO:_master_model_container: 79
2024-05-25 15:50:43,188:INFO:_display_container: 4
2024-05-25 15:50:43,191:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.5859375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:50:43,192:INFO:create_model() successfully completed......................................
2024-05-25 15:50:44,165:INFO:Threshold: 0.5859375. Accuracy: 0.8284
2024-05-25 15:50:44,166:INFO:Initializing create_model()
2024-05-25 15:50:44,166:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.640625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:50:44,166:INFO:Checking exceptions
2024-05-25 15:50:44,168:INFO:Importing libraries
2024-05-25 15:50:44,169:INFO:Copying training dataset
2024-05-25 15:50:44,207:INFO:Defining folds
2024-05-25 15:50:44,207:INFO:Declaring metric variables
2024-05-25 15:50:44,207:INFO:Importing untrained model
2024-05-25 15:50:44,208:INFO:Declaring custom model
2024-05-25 15:50:44,209:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:50:44,209:INFO:Starting cross validation
2024-05-25 15:50:44,213:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:50:49,292:INFO:Calculating mean and std
2024-05-25 15:50:49,293:INFO:Creating metrics dataframe
2024-05-25 15:50:49,296:INFO:Finalizing model
2024-05-25 15:50:50,246:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:50:50,249:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:50:50,258:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003251 seconds.
2024-05-25 15:50:50,258:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:50:50,258:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:50:50,259:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:50:50,259:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:50:50,259:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:50:50,260:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:50:50,520:INFO:Uploading results into container
2024-05-25 15:50:50,521:INFO:Uploading model into container now
2024-05-25 15:50:50,522:INFO:_master_model_container: 80
2024-05-25 15:50:50,522:INFO:_display_container: 4
2024-05-25 15:50:50,525:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.640625,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:50:50,525:INFO:create_model() successfully completed......................................
2024-05-25 15:50:51,477:INFO:Threshold: 0.640625. Accuracy: 0.8174
2024-05-25 15:50:51,478:INFO:Initializing create_model()
2024-05-25 15:50:51,478:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.6484375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:50:51,479:INFO:Checking exceptions
2024-05-25 15:50:51,480:INFO:Importing libraries
2024-05-25 15:50:51,481:INFO:Copying training dataset
2024-05-25 15:50:51,520:INFO:Defining folds
2024-05-25 15:50:51,520:INFO:Declaring metric variables
2024-05-25 15:50:51,521:INFO:Importing untrained model
2024-05-25 15:50:51,521:INFO:Declaring custom model
2024-05-25 15:50:51,522:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:50:51,522:INFO:Starting cross validation
2024-05-25 15:50:51,525:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:50:57,003:INFO:Calculating mean and std
2024-05-25 15:50:57,004:INFO:Creating metrics dataframe
2024-05-25 15:50:57,007:INFO:Finalizing model
2024-05-25 15:50:58,134:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:50:58,137:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:50:58,148:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003310 seconds.
2024-05-25 15:50:58,148:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:50:58,149:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:50:58,149:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:50:58,149:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:50:58,150:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:50:58,150:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:50:58,408:INFO:Uploading results into container
2024-05-25 15:50:58,409:INFO:Uploading model into container now
2024-05-25 15:50:58,409:INFO:_master_model_container: 81
2024-05-25 15:50:58,410:INFO:_display_container: 4
2024-05-25 15:50:58,413:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.6484375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:50:58,413:INFO:create_model() successfully completed......................................
2024-05-25 15:50:59,362:INFO:Threshold: 0.6484375. Accuracy: 0.8164
2024-05-25 15:50:59,363:INFO:Initializing create_model()
2024-05-25 15:50:59,364:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.703125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:50:59,364:INFO:Checking exceptions
2024-05-25 15:50:59,366:INFO:Importing libraries
2024-05-25 15:50:59,366:INFO:Copying training dataset
2024-05-25 15:50:59,410:INFO:Defining folds
2024-05-25 15:50:59,410:INFO:Declaring metric variables
2024-05-25 15:50:59,411:INFO:Importing untrained model
2024-05-25 15:50:59,411:INFO:Declaring custom model
2024-05-25 15:50:59,412:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:50:59,413:INFO:Starting cross validation
2024-05-25 15:50:59,416:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:51:04,763:INFO:Calculating mean and std
2024-05-25 15:51:04,764:INFO:Creating metrics dataframe
2024-05-25 15:51:04,767:INFO:Finalizing model
2024-05-25 15:51:05,818:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:51:05,821:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:51:05,831:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003491 seconds.
2024-05-25 15:51:05,831:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:51:05,831:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:51:05,831:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:51:05,832:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:51:05,832:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:51:05,832:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:51:06,276:INFO:Uploading results into container
2024-05-25 15:51:06,277:INFO:Uploading model into container now
2024-05-25 15:51:06,278:INFO:_master_model_container: 82
2024-05-25 15:51:06,278:INFO:_display_container: 4
2024-05-25 15:51:06,281:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.703125,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:51:06,281:INFO:create_model() successfully completed......................................
2024-05-25 15:51:07,246:INFO:Threshold: 0.703125. Accuracy: 0.8096
2024-05-25 15:51:07,247:INFO:Initializing create_model()
2024-05-25 15:51:07,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.7109375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:51:07,247:INFO:Checking exceptions
2024-05-25 15:51:07,249:INFO:Importing libraries
2024-05-25 15:51:07,249:INFO:Copying training dataset
2024-05-25 15:51:07,289:INFO:Defining folds
2024-05-25 15:51:07,289:INFO:Declaring metric variables
2024-05-25 15:51:07,290:INFO:Importing untrained model
2024-05-25 15:51:07,290:INFO:Declaring custom model
2024-05-25 15:51:07,291:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:51:07,291:INFO:Starting cross validation
2024-05-25 15:51:07,294:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:51:12,600:INFO:Calculating mean and std
2024-05-25 15:51:12,602:INFO:Creating metrics dataframe
2024-05-25 15:51:12,606:INFO:Finalizing model
2024-05-25 15:51:13,642:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:51:13,646:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:51:13,657:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003205 seconds.
2024-05-25 15:51:13,657:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:51:13,657:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:51:13,657:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:51:13,658:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:51:13,659:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:51:13,659:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:51:13,929:INFO:Uploading results into container
2024-05-25 15:51:13,930:INFO:Uploading model into container now
2024-05-25 15:51:13,931:INFO:_master_model_container: 83
2024-05-25 15:51:13,931:INFO:_display_container: 4
2024-05-25 15:51:13,934:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.7109375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:51:13,934:INFO:create_model() successfully completed......................................
2024-05-25 15:51:14,912:INFO:Threshold: 0.7109375. Accuracy: 0.8083
2024-05-25 15:51:14,913:INFO:Initializing create_model()
2024-05-25 15:51:14,913:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.0234375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:51:14,913:INFO:Checking exceptions
2024-05-25 15:51:14,915:INFO:Importing libraries
2024-05-25 15:51:14,915:INFO:Copying training dataset
2024-05-25 15:51:14,956:INFO:Defining folds
2024-05-25 15:51:14,956:INFO:Declaring metric variables
2024-05-25 15:51:14,956:INFO:Importing untrained model
2024-05-25 15:51:14,956:INFO:Declaring custom model
2024-05-25 15:51:14,958:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:51:14,958:INFO:Starting cross validation
2024-05-25 15:51:14,961:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:51:20,237:INFO:Calculating mean and std
2024-05-25 15:51:20,238:INFO:Creating metrics dataframe
2024-05-25 15:51:20,241:INFO:Finalizing model
2024-05-25 15:51:21,301:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:51:21,304:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:51:21,314:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003664 seconds.
2024-05-25 15:51:21,314:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:51:21,314:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:51:21,315:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:51:21,315:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:51:21,316:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:51:21,316:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:51:21,572:INFO:Uploading results into container
2024-05-25 15:51:21,573:INFO:Uploading model into container now
2024-05-25 15:51:21,574:INFO:_master_model_container: 84
2024-05-25 15:51:21,574:INFO:_display_container: 4
2024-05-25 15:51:21,577:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.0234375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:51:21,577:INFO:create_model() successfully completed......................................
2024-05-25 15:51:22,536:INFO:Threshold: 0.0234375. Accuracy: 0.5889
2024-05-25 15:51:22,537:INFO:Initializing create_model()
2024-05-25 15:51:22,537:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.0859375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:51:22,537:INFO:Checking exceptions
2024-05-25 15:51:22,539:INFO:Importing libraries
2024-05-25 15:51:22,539:INFO:Copying training dataset
2024-05-25 15:51:22,578:INFO:Defining folds
2024-05-25 15:51:22,578:INFO:Declaring metric variables
2024-05-25 15:51:22,578:INFO:Importing untrained model
2024-05-25 15:51:22,578:INFO:Declaring custom model
2024-05-25 15:51:22,580:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:51:22,580:INFO:Starting cross validation
2024-05-25 15:51:22,583:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:51:27,798:INFO:Calculating mean and std
2024-05-25 15:51:27,799:INFO:Creating metrics dataframe
2024-05-25 15:51:27,802:INFO:Finalizing model
2024-05-25 15:51:28,773:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:51:28,777:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:51:28,788:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004352 seconds.
2024-05-25 15:51:28,788:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:51:28,788:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:51:28,788:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:51:28,788:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:51:28,789:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:51:28,789:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:51:29,085:INFO:Uploading results into container
2024-05-25 15:51:29,086:INFO:Uploading model into container now
2024-05-25 15:51:29,086:INFO:_master_model_container: 85
2024-05-25 15:51:29,086:INFO:_display_container: 4
2024-05-25 15:51:29,089:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.0859375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:51:29,089:INFO:create_model() successfully completed......................................
2024-05-25 15:51:30,061:INFO:Threshold: 0.0859375. Accuracy: 0.6644
2024-05-25 15:51:30,063:INFO:Initializing create_model()
2024-05-25 15:51:30,063:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.140625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:51:30,063:INFO:Checking exceptions
2024-05-25 15:51:30,066:INFO:Importing libraries
2024-05-25 15:51:30,066:INFO:Copying training dataset
2024-05-25 15:51:30,122:INFO:Defining folds
2024-05-25 15:51:30,122:INFO:Declaring metric variables
2024-05-25 15:51:30,122:INFO:Importing untrained model
2024-05-25 15:51:30,122:INFO:Declaring custom model
2024-05-25 15:51:30,124:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:51:30,124:INFO:Starting cross validation
2024-05-25 15:51:30,128:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:51:35,139:INFO:Calculating mean and std
2024-05-25 15:51:35,140:INFO:Creating metrics dataframe
2024-05-25 15:51:35,143:INFO:Finalizing model
2024-05-25 15:51:36,234:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:51:36,237:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:51:36,248:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004376 seconds.
2024-05-25 15:51:36,248:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:51:36,248:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:51:36,249:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:51:36,249:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:51:36,250:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:51:36,250:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:51:36,516:INFO:Uploading results into container
2024-05-25 15:51:36,517:INFO:Uploading model into container now
2024-05-25 15:51:36,518:INFO:_master_model_container: 86
2024-05-25 15:51:36,518:INFO:_display_container: 4
2024-05-25 15:51:36,521:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.140625,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:51:36,521:INFO:create_model() successfully completed......................................
2024-05-25 15:51:37,468:INFO:Threshold: 0.140625. Accuracy: 0.7406
2024-05-25 15:51:37,469:INFO:Initializing create_model()
2024-05-25 15:51:37,469:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.078125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:51:37,469:INFO:Checking exceptions
2024-05-25 15:51:37,471:INFO:Importing libraries
2024-05-25 15:51:37,471:INFO:Copying training dataset
2024-05-25 15:51:37,509:INFO:Defining folds
2024-05-25 15:51:37,509:INFO:Declaring metric variables
2024-05-25 15:51:37,510:INFO:Importing untrained model
2024-05-25 15:51:37,510:INFO:Declaring custom model
2024-05-25 15:51:37,511:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:51:37,511:INFO:Starting cross validation
2024-05-25 15:51:37,514:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:51:43,233:INFO:Calculating mean and std
2024-05-25 15:51:43,234:INFO:Creating metrics dataframe
2024-05-25 15:51:43,237:INFO:Finalizing model
2024-05-25 15:51:44,297:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:51:44,301:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:51:44,311:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003445 seconds.
2024-05-25 15:51:44,311:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:51:44,311:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:51:44,311:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:51:44,312:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:51:44,312:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:51:44,312:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:51:44,574:INFO:Uploading results into container
2024-05-25 15:51:44,575:INFO:Uploading model into container now
2024-05-25 15:51:44,575:INFO:_master_model_container: 87
2024-05-25 15:51:44,575:INFO:_display_container: 4
2024-05-25 15:51:44,579:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.078125,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:51:44,579:INFO:create_model() successfully completed......................................
2024-05-25 15:51:45,520:INFO:Threshold: 0.078125. Accuracy: 0.6525
2024-05-25 15:51:45,521:INFO:Initializing create_model()
2024-05-25 15:51:45,521:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.1484375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:51:45,522:INFO:Checking exceptions
2024-05-25 15:51:45,523:INFO:Importing libraries
2024-05-25 15:51:45,524:INFO:Copying training dataset
2024-05-25 15:51:45,567:INFO:Defining folds
2024-05-25 15:51:45,568:INFO:Declaring metric variables
2024-05-25 15:51:45,568:INFO:Importing untrained model
2024-05-25 15:51:45,568:INFO:Declaring custom model
2024-05-25 15:51:45,569:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:51:45,569:INFO:Starting cross validation
2024-05-25 15:51:45,573:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:51:50,474:INFO:Calculating mean and std
2024-05-25 15:51:50,475:INFO:Creating metrics dataframe
2024-05-25 15:51:50,478:INFO:Finalizing model
2024-05-25 15:51:51,443:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:51:51,446:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:51:51,457:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003344 seconds.
2024-05-25 15:51:51,457:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:51:51,457:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:51:51,458:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:51:51,458:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:51:51,459:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:51:51,459:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:51:51,720:INFO:Uploading results into container
2024-05-25 15:51:51,721:INFO:Uploading model into container now
2024-05-25 15:51:51,721:INFO:_master_model_container: 88
2024-05-25 15:51:51,722:INFO:_display_container: 4
2024-05-25 15:51:51,725:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.1484375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:51:51,725:INFO:create_model() successfully completed......................................
2024-05-25 15:51:52,674:INFO:Threshold: 0.1484375. Accuracy: 0.7539
2024-05-25 15:51:52,674:INFO:Initializing create_model()
2024-05-25 15:51:52,675:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.203125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:51:52,675:INFO:Checking exceptions
2024-05-25 15:51:52,677:INFO:Importing libraries
2024-05-25 15:51:52,677:INFO:Copying training dataset
2024-05-25 15:51:52,716:INFO:Defining folds
2024-05-25 15:51:52,716:INFO:Declaring metric variables
2024-05-25 15:51:52,716:INFO:Importing untrained model
2024-05-25 15:51:52,716:INFO:Declaring custom model
2024-05-25 15:51:52,717:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:51:52,717:INFO:Starting cross validation
2024-05-25 15:51:52,721:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:51:58,067:INFO:Calculating mean and std
2024-05-25 15:51:58,068:INFO:Creating metrics dataframe
2024-05-25 15:51:58,071:INFO:Finalizing model
2024-05-25 15:51:59,044:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:51:59,047:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:51:59,056:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002811 seconds.
2024-05-25 15:51:59,056:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:51:59,056:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:51:59,057:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:51:59,057:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:51:59,057:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:51:59,057:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:51:59,321:INFO:Uploading results into container
2024-05-25 15:51:59,322:INFO:Uploading model into container now
2024-05-25 15:51:59,323:INFO:_master_model_container: 89
2024-05-25 15:51:59,323:INFO:_display_container: 4
2024-05-25 15:51:59,326:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.203125,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:51:59,326:INFO:create_model() successfully completed......................................
2024-05-25 15:52:00,308:INFO:Threshold: 0.203125. Accuracy: 0.7815
2024-05-25 15:52:00,309:INFO:Initializing create_model()
2024-05-25 15:52:00,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.2109375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:52:00,309:INFO:Checking exceptions
2024-05-25 15:52:00,311:INFO:Importing libraries
2024-05-25 15:52:00,311:INFO:Copying training dataset
2024-05-25 15:52:00,349:INFO:Defining folds
2024-05-25 15:52:00,349:INFO:Declaring metric variables
2024-05-25 15:52:00,350:INFO:Importing untrained model
2024-05-25 15:52:00,350:INFO:Declaring custom model
2024-05-25 15:52:00,351:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:52:00,351:INFO:Starting cross validation
2024-05-25 15:52:00,354:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:52:05,584:INFO:Calculating mean and std
2024-05-25 15:52:05,585:INFO:Creating metrics dataframe
2024-05-25 15:52:05,588:INFO:Finalizing model
2024-05-25 15:52:06,649:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:52:06,652:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:52:06,662:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003822 seconds.
2024-05-25 15:52:06,662:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:52:06,662:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:52:06,662:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:52:06,663:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:52:06,663:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:52:06,663:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:52:06,969:INFO:Uploading results into container
2024-05-25 15:52:06,970:INFO:Uploading model into container now
2024-05-25 15:52:06,971:INFO:_master_model_container: 90
2024-05-25 15:52:06,971:INFO:_display_container: 4
2024-05-25 15:52:06,975:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.2109375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:52:06,975:INFO:create_model() successfully completed......................................
2024-05-25 15:52:07,935:INFO:Threshold: 0.2109375. Accuracy: 0.7854
2024-05-25 15:52:07,936:INFO:Initializing create_model()
2024-05-25 15:52:07,936:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.265625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:52:07,937:INFO:Checking exceptions
2024-05-25 15:52:07,939:INFO:Importing libraries
2024-05-25 15:52:07,939:INFO:Copying training dataset
2024-05-25 15:52:07,977:INFO:Defining folds
2024-05-25 15:52:07,977:INFO:Declaring metric variables
2024-05-25 15:52:07,977:INFO:Importing untrained model
2024-05-25 15:52:07,978:INFO:Declaring custom model
2024-05-25 15:52:07,979:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:52:07,979:INFO:Starting cross validation
2024-05-25 15:52:07,982:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:52:13,639:INFO:Calculating mean and std
2024-05-25 15:52:13,640:INFO:Creating metrics dataframe
2024-05-25 15:52:13,643:INFO:Finalizing model
2024-05-25 15:52:14,753:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:52:14,756:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:52:14,771:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005602 seconds.
2024-05-25 15:52:14,771:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:52:14,771:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:52:14,771:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:52:14,771:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:52:14,772:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:52:14,772:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:52:15,077:INFO:Uploading results into container
2024-05-25 15:52:15,078:INFO:Uploading model into container now
2024-05-25 15:52:15,079:INFO:_master_model_container: 91
2024-05-25 15:52:15,079:INFO:_display_container: 4
2024-05-25 15:52:15,082:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.265625,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:52:15,082:INFO:create_model() successfully completed......................................
2024-05-25 15:52:16,036:INFO:Threshold: 0.265625. Accuracy: 0.8004
2024-05-25 15:52:16,037:INFO:Initializing create_model()
2024-05-25 15:52:16,037:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.2734375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:52:16,037:INFO:Checking exceptions
2024-05-25 15:52:16,039:INFO:Importing libraries
2024-05-25 15:52:16,039:INFO:Copying training dataset
2024-05-25 15:52:16,077:INFO:Defining folds
2024-05-25 15:52:16,077:INFO:Declaring metric variables
2024-05-25 15:52:16,078:INFO:Importing untrained model
2024-05-25 15:52:16,078:INFO:Declaring custom model
2024-05-25 15:52:16,079:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:52:16,079:INFO:Starting cross validation
2024-05-25 15:52:16,083:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:52:21,095:INFO:Calculating mean and std
2024-05-25 15:52:21,096:INFO:Creating metrics dataframe
2024-05-25 15:52:21,099:INFO:Finalizing model
2024-05-25 15:52:22,076:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:52:22,079:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:52:22,090:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003349 seconds.
2024-05-25 15:52:22,090:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:52:22,090:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:52:22,091:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:52:22,091:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:52:22,092:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:52:22,092:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:52:22,353:INFO:Uploading results into container
2024-05-25 15:52:22,354:INFO:Uploading model into container now
2024-05-25 15:52:22,354:INFO:_master_model_container: 92
2024-05-25 15:52:22,354:INFO:_display_container: 4
2024-05-25 15:52:22,357:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.2734375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:52:22,358:INFO:create_model() successfully completed......................................
2024-05-25 15:52:23,326:INFO:Threshold: 0.2734375. Accuracy: 0.8014
2024-05-25 15:52:23,328:INFO:Initializing create_model()
2024-05-25 15:52:23,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.328125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:52:23,328:INFO:Checking exceptions
2024-05-25 15:52:23,331:INFO:Importing libraries
2024-05-25 15:52:23,331:INFO:Copying training dataset
2024-05-25 15:52:23,381:INFO:Defining folds
2024-05-25 15:52:23,381:INFO:Declaring metric variables
2024-05-25 15:52:23,381:INFO:Importing untrained model
2024-05-25 15:52:23,382:INFO:Declaring custom model
2024-05-25 15:52:23,383:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:52:23,383:INFO:Starting cross validation
2024-05-25 15:52:23,387:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:52:28,794:INFO:Calculating mean and std
2024-05-25 15:52:28,795:INFO:Creating metrics dataframe
2024-05-25 15:52:28,798:INFO:Finalizing model
2024-05-25 15:52:29,792:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:52:29,796:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:52:29,804:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003486 seconds.
2024-05-25 15:52:29,804:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:52:29,804:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:52:29,805:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:52:29,805:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:52:29,805:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:52:29,806:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:52:30,064:INFO:Uploading results into container
2024-05-25 15:52:30,065:INFO:Uploading model into container now
2024-05-25 15:52:30,066:INFO:_master_model_container: 93
2024-05-25 15:52:30,066:INFO:_display_container: 4
2024-05-25 15:52:30,069:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.328125,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:52:30,069:INFO:create_model() successfully completed......................................
2024-05-25 15:52:31,048:INFO:Threshold: 0.328125. Accuracy: 0.8179
2024-05-25 15:52:31,049:INFO:Initializing create_model()
2024-05-25 15:52:31,050:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.7734375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:52:31,050:INFO:Checking exceptions
2024-05-25 15:52:31,052:INFO:Importing libraries
2024-05-25 15:52:31,052:INFO:Copying training dataset
2024-05-25 15:52:31,090:INFO:Defining folds
2024-05-25 15:52:31,091:INFO:Declaring metric variables
2024-05-25 15:52:31,091:INFO:Importing untrained model
2024-05-25 15:52:31,091:INFO:Declaring custom model
2024-05-25 15:52:31,092:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:52:31,093:INFO:Starting cross validation
2024-05-25 15:52:31,096:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:52:36,256:INFO:Calculating mean and std
2024-05-25 15:52:36,257:INFO:Creating metrics dataframe
2024-05-25 15:52:36,260:INFO:Finalizing model
2024-05-25 15:52:37,365:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:52:37,369:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:52:37,379:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003904 seconds.
2024-05-25 15:52:37,379:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:52:37,380:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:52:37,380:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:52:37,380:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:52:37,381:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:52:37,381:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:52:37,653:INFO:Uploading results into container
2024-05-25 15:52:37,654:INFO:Uploading model into container now
2024-05-25 15:52:37,655:INFO:_master_model_container: 94
2024-05-25 15:52:37,655:INFO:_display_container: 4
2024-05-25 15:52:37,658:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.7734375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:52:37,658:INFO:create_model() successfully completed......................................
2024-05-25 15:52:38,603:INFO:Threshold: 0.7734375. Accuracy: 0.7974
2024-05-25 15:52:38,604:INFO:Initializing create_model()
2024-05-25 15:52:38,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.8359375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:52:38,605:INFO:Checking exceptions
2024-05-25 15:52:38,607:INFO:Importing libraries
2024-05-25 15:52:38,607:INFO:Copying training dataset
2024-05-25 15:52:38,644:INFO:Defining folds
2024-05-25 15:52:38,645:INFO:Declaring metric variables
2024-05-25 15:52:38,645:INFO:Importing untrained model
2024-05-25 15:52:38,645:INFO:Declaring custom model
2024-05-25 15:52:38,646:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:52:38,646:INFO:Starting cross validation
2024-05-25 15:52:38,650:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:52:43,912:INFO:Calculating mean and std
2024-05-25 15:52:43,913:INFO:Creating metrics dataframe
2024-05-25 15:52:43,916:INFO:Finalizing model
2024-05-25 15:52:45,029:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:52:45,032:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:52:45,041:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003700 seconds.
2024-05-25 15:52:45,041:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:52:45,041:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:52:45,042:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:52:45,042:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:52:45,043:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:52:45,043:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:52:45,317:INFO:Uploading results into container
2024-05-25 15:52:45,318:INFO:Uploading model into container now
2024-05-25 15:52:45,318:INFO:_master_model_container: 95
2024-05-25 15:52:45,319:INFO:_display_container: 4
2024-05-25 15:52:45,322:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.8359375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:52:45,322:INFO:create_model() successfully completed......................................
2024-05-25 15:52:46,273:INFO:Threshold: 0.8359375. Accuracy: 0.7775
2024-05-25 15:52:46,274:INFO:Initializing create_model()
2024-05-25 15:52:46,274:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.8984375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:52:46,274:INFO:Checking exceptions
2024-05-25 15:52:46,276:INFO:Importing libraries
2024-05-25 15:52:46,276:INFO:Copying training dataset
2024-05-25 15:52:46,315:INFO:Defining folds
2024-05-25 15:52:46,315:INFO:Declaring metric variables
2024-05-25 15:52:46,315:INFO:Importing untrained model
2024-05-25 15:52:46,315:INFO:Declaring custom model
2024-05-25 15:52:46,316:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:52:46,317:INFO:Starting cross validation
2024-05-25 15:52:46,320:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:52:51,364:INFO:Calculating mean and std
2024-05-25 15:52:51,365:INFO:Creating metrics dataframe
2024-05-25 15:52:51,368:INFO:Finalizing model
2024-05-25 15:52:52,453:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:52:52,457:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:52:52,468:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003668 seconds.
2024-05-25 15:52:52,468:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:52:52,468:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:52:52,469:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:52:52,469:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:52:52,470:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:52:52,470:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:52:52,738:INFO:Uploading results into container
2024-05-25 15:52:52,739:INFO:Uploading model into container now
2024-05-25 15:52:52,740:INFO:_master_model_container: 96
2024-05-25 15:52:52,740:INFO:_display_container: 4
2024-05-25 15:52:52,743:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.8984375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:52:52,743:INFO:create_model() successfully completed......................................
2024-05-25 15:52:53,693:INFO:Threshold: 0.8984375. Accuracy: 0.7616
2024-05-25 15:52:53,694:INFO:Initializing create_model()
2024-05-25 15:52:53,694:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.9609375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:52:53,694:INFO:Checking exceptions
2024-05-25 15:52:53,696:INFO:Importing libraries
2024-05-25 15:52:53,697:INFO:Copying training dataset
2024-05-25 15:52:53,740:INFO:Defining folds
2024-05-25 15:52:53,741:INFO:Declaring metric variables
2024-05-25 15:52:53,741:INFO:Importing untrained model
2024-05-25 15:52:53,741:INFO:Declaring custom model
2024-05-25 15:52:53,742:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:52:53,742:INFO:Starting cross validation
2024-05-25 15:52:53,746:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:52:59,308:INFO:Calculating mean and std
2024-05-25 15:52:59,309:INFO:Creating metrics dataframe
2024-05-25 15:52:59,312:INFO:Finalizing model
2024-05-25 15:53:00,297:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:53:00,301:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:53:00,311:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003462 seconds.
2024-05-25 15:53:00,311:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:53:00,311:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:53:00,311:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:53:00,311:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:53:00,312:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:53:00,312:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:53:00,610:INFO:Uploading results into container
2024-05-25 15:53:00,611:INFO:Uploading model into container now
2024-05-25 15:53:00,612:INFO:_master_model_container: 97
2024-05-25 15:53:00,612:INFO:_display_container: 4
2024-05-25 15:53:00,615:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.9609375,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:53:00,615:INFO:create_model() successfully completed......................................
2024-05-25 15:53:01,565:INFO:Threshold: 0.9609375. Accuracy: 0.7035
2024-05-25 15:53:01,568:INFO:Initializing create_model()
2024-05-25 15:53:01,568:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.515625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:53:01,568:INFO:Checking exceptions
2024-05-25 15:53:01,570:INFO:Importing libraries
2024-05-25 15:53:01,570:INFO:Copying training dataset
2024-05-25 15:53:01,608:INFO:Defining folds
2024-05-25 15:53:01,608:INFO:Declaring metric variables
2024-05-25 15:53:01,608:INFO:Importing untrained model
2024-05-25 15:53:01,608:INFO:Declaring custom model
2024-05-25 15:53:01,609:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:53:01,610:INFO:Starting cross validation
2024-05-25 15:53:01,613:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:53:06,756:INFO:Calculating mean and std
2024-05-25 15:53:06,757:INFO:Creating metrics dataframe
2024-05-25 15:53:06,760:INFO:Finalizing model
2024-05-25 15:53:07,824:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:53:07,827:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:53:07,838:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003510 seconds.
2024-05-25 15:53:07,839:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:53:07,839:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:53:07,839:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:53:07,839:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:53:07,840:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:53:07,840:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:53:08,097:INFO:Uploading results into container
2024-05-25 15:53:08,098:INFO:Uploading model into container now
2024-05-25 15:53:08,098:INFO:_master_model_container: 98
2024-05-25 15:53:08,098:INFO:_display_container: 4
2024-05-25 15:53:08,102:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.515625,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:53:08,102:INFO:create_model() successfully completed......................................
2024-05-25 15:53:09,045:INFO:Threshold: 0.515625. Accuracy: 0.8366
2024-05-25 15:53:09,046:INFO:Initializing create_model()
2024-05-25 15:53:09,046:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=933, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.5156250149011612, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 15:53:09,046:INFO:Checking exceptions
2024-05-25 15:53:09,048:INFO:Importing libraries
2024-05-25 15:53:09,048:INFO:Copying training dataset
2024-05-25 15:53:09,092:INFO:Defining folds
2024-05-25 15:53:09,092:INFO:Declaring metric variables
2024-05-25 15:53:09,092:INFO:Importing untrained model
2024-05-25 15:53:09,092:INFO:Declaring custom model
2024-05-25 15:53:09,094:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 15:53:09,094:INFO:Starting cross validation
2024-05-25 15:53:09,098:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 15:53:14,556:INFO:Calculating mean and std
2024-05-25 15:53:14,557:INFO:Creating metrics dataframe
2024-05-25 15:53:14,560:INFO:Finalizing model
2024-05-25 15:53:15,549:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 15:53:15,552:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 15:53:15,563:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004010 seconds.
2024-05-25 15:53:15,563:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 15:53:15,563:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 15:53:15,563:INFO:[LightGBM] [Info] Total Bins 1240
2024-05-25 15:53:15,564:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 46
2024-05-25 15:53:15,564:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 15:53:15,564:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 15:53:15,821:INFO:Uploading results into container
2024-05-25 15:53:15,822:INFO:Uploading model into container now
2024-05-25 15:53:15,822:INFO:_master_model_container: 99
2024-05-25 15:53:15,823:INFO:_display_container: 4
2024-05-25 15:53:15,826:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.5156250149011612,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 15:53:15,826:INFO:create_model() successfully completed......................................
2024-05-25 15:53:16,800:INFO:Threshold: 0.5156250149011612. Accuracy: 0.8366
2024-05-25 15:53:16,801:INFO:optimization loop finished successfully. Best threshold: 0.515625 with Accuracy=0.8366
2024-05-25 15:53:16,812:INFO:plotting optimization threshold using plotly
2024-05-25 15:53:18,119:INFO:returning model with best metric
2024-05-25 15:53:18,120:INFO:optimize_threshold() successfully completed......................................
2024-05-25 15:53:18,123:INFO:Initializing plot_model()
2024-05-25 15:53:18,123:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=9...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.515625,
                                     random_state=933, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, system=True)
2024-05-25 15:53:18,123:INFO:Checking exceptions
2024-05-25 15:53:18,139:INFO:Preloading libraries
2024-05-25 15:53:18,146:INFO:Copying training dataset
2024-05-25 15:53:18,146:INFO:Plot type: auc
2024-05-25 15:53:18,490:INFO:Fitting Model
2024-05-25 15:53:18,494:INFO:Scoring test/hold-out set
2024-05-25 15:53:18,838:INFO:Visual Rendered Successfully
2024-05-25 15:53:19,822:INFO:plot_model() successfully completed......................................
2024-05-25 16:02:03,443:INFO:Initializing create_model()
2024-05-25 16:02:03,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276CB84E950>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:02:03,443:INFO:Checking exceptions
2024-05-25 16:02:03,464:INFO:Importing libraries
2024-05-25 16:02:03,465:INFO:Copying training dataset
2024-05-25 16:02:03,509:INFO:Defining folds
2024-05-25 16:02:03,509:INFO:Declaring metric variables
2024-05-25 16:02:03,515:INFO:Importing untrained model
2024-05-25 16:02:03,521:INFO:Logistic Regression Imported successfully
2024-05-25 16:02:03,532:INFO:Starting cross validation
2024-05-25 16:02:03,537:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:02:24,489:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-25 16:02:24,617:INFO:Calculating mean and std
2024-05-25 16:02:24,619:INFO:Creating metrics dataframe
2024-05-25 16:02:24,626:INFO:Finalizing model
2024-05-25 16:22:18,829:INFO:PyCaret ClassificationExperiment
2024-05-25 16:22:18,829:INFO:Logging name: ml_codex
2024-05-25 16:22:18,829:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-25 16:22:18,829:INFO:version 3.3.2
2024-05-25 16:22:18,829:INFO:Initializing setup()
2024-05-25 16:22:18,829:INFO:self.USI: 9df3
2024-05-25 16:22:18,829:INFO:self._variable_keys: {'fold_generator', 'is_multiclass', 'y_train', 'html_param', 'log_plots_param', '_ml_usecase', 'fix_imbalance', 'y_test', 'exp_name_log', 'data', 'pipeline', 'y', 'USI', 'gpu_param', '_available_plots', 'n_jobs_param', 'target_param', 'exp_id', 'seed', 'X_test', 'X', 'logging_param', 'idx', 'fold_shuffle_param', 'memory', 'fold_groups_param', 'gpu_n_jobs_param', 'X_train'}
2024-05-25 16:22:18,830:INFO:Checking environment
2024-05-25 16:22:18,830:INFO:python_version: 3.10.13
2024-05-25 16:22:18,830:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-25 16:22:18,830:INFO:machine: AMD64
2024-05-25 16:22:18,830:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-25 16:22:18,830:INFO:Memory: svmem(total=34267656192, available=12365377536, percent=63.9, used=21902278656, free=12365377536)
2024-05-25 16:22:18,830:INFO:Physical Core: 8
2024-05-25 16:22:18,831:INFO:Logical Core: 16
2024-05-25 16:22:18,831:INFO:Checking libraries
2024-05-25 16:22:18,831:INFO:System:
2024-05-25 16:22:18,831:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-25 16:22:18,831:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-25 16:22:18,831:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-25 16:22:18,832:INFO:PyCaret required dependencies:
2024-05-25 16:22:18,832:INFO:                 pip: 23.3
2024-05-25 16:22:18,832:INFO:          setuptools: 68.0.0
2024-05-25 16:22:18,832:INFO:             pycaret: 3.3.2
2024-05-25 16:22:18,832:INFO:             IPython: 8.24.0
2024-05-25 16:22:18,832:INFO:          ipywidgets: 8.1.2
2024-05-25 16:22:18,832:INFO:                tqdm: 4.66.4
2024-05-25 16:22:18,833:INFO:               numpy: 1.26.4
2024-05-25 16:22:18,833:INFO:              pandas: 2.1.4
2024-05-25 16:22:18,833:INFO:              jinja2: 3.1.4
2024-05-25 16:22:18,833:INFO:               scipy: 1.11.4
2024-05-25 16:22:18,833:INFO:              joblib: 1.3.2
2024-05-25 16:22:18,833:INFO:             sklearn: 1.4.2
2024-05-25 16:22:18,833:INFO:                pyod: 1.1.3
2024-05-25 16:22:18,833:INFO:            imblearn: 0.12.2
2024-05-25 16:22:18,833:INFO:   category_encoders: 2.6.3
2024-05-25 16:22:18,833:INFO:            lightgbm: 4.3.0
2024-05-25 16:22:18,833:INFO:               numba: 0.59.1
2024-05-25 16:22:18,834:INFO:            requests: 2.32.2
2024-05-25 16:22:18,834:INFO:          matplotlib: 3.7.5
2024-05-25 16:22:18,834:INFO:          scikitplot: 0.3.7
2024-05-25 16:22:18,834:INFO:         yellowbrick: 1.5
2024-05-25 16:22:18,834:INFO:              plotly: 5.22.0
2024-05-25 16:22:18,834:INFO:    plotly-resampler: Not installed
2024-05-25 16:22:18,834:INFO:             kaleido: 0.2.1
2024-05-25 16:22:18,834:INFO:           schemdraw: 0.15
2024-05-25 16:22:18,834:INFO:         statsmodels: 0.14.2
2024-05-25 16:22:18,835:INFO:              sktime: 0.26.0
2024-05-25 16:22:18,835:INFO:               tbats: 1.1.3
2024-05-25 16:22:18,835:INFO:            pmdarima: 2.0.4
2024-05-25 16:22:18,835:INFO:              psutil: 5.9.0
2024-05-25 16:22:18,835:INFO:          markupsafe: 2.1.5
2024-05-25 16:22:18,835:INFO:             pickle5: Not installed
2024-05-25 16:22:18,835:INFO:         cloudpickle: 3.0.0
2024-05-25 16:22:18,835:INFO:         deprecation: 2.1.0
2024-05-25 16:22:18,835:INFO:              xxhash: 3.4.1
2024-05-25 16:22:18,835:INFO:           wurlitzer: Not installed
2024-05-25 16:22:18,835:INFO:PyCaret optional dependencies:
2024-05-25 16:22:18,836:INFO:                shap: Not installed
2024-05-25 16:22:18,836:INFO:           interpret: Not installed
2024-05-25 16:22:18,836:INFO:                umap: Not installed
2024-05-25 16:22:18,836:INFO:     ydata_profiling: Not installed
2024-05-25 16:22:18,836:INFO:  explainerdashboard: Not installed
2024-05-25 16:22:18,836:INFO:             autoviz: Not installed
2024-05-25 16:22:18,836:INFO:           fairlearn: Not installed
2024-05-25 16:22:18,836:INFO:          deepchecks: Not installed
2024-05-25 16:22:18,836:INFO:             xgboost: Not installed
2024-05-25 16:22:18,836:INFO:            catboost: Not installed
2024-05-25 16:22:18,836:INFO:              kmodes: Not installed
2024-05-25 16:22:18,837:INFO:             mlxtend: Not installed
2024-05-25 16:22:18,837:INFO:       statsforecast: Not installed
2024-05-25 16:22:18,837:INFO:        tune_sklearn: Not installed
2024-05-25 16:22:18,837:INFO:                 ray: Not installed
2024-05-25 16:22:18,837:INFO:            hyperopt: Not installed
2024-05-25 16:22:18,837:INFO:              optuna: Not installed
2024-05-25 16:22:18,837:INFO:               skopt: Not installed
2024-05-25 16:22:18,837:INFO:              mlflow: 2.13.0
2024-05-25 16:22:18,837:INFO:              gradio: Not installed
2024-05-25 16:22:18,837:INFO:             fastapi: Not installed
2024-05-25 16:22:18,838:INFO:             uvicorn: Not installed
2024-05-25 16:22:18,838:INFO:              m2cgen: Not installed
2024-05-25 16:22:18,838:INFO:           evidently: Not installed
2024-05-25 16:22:18,838:INFO:               fugue: Not installed
2024-05-25 16:22:18,838:INFO:           streamlit: Not installed
2024-05-25 16:22:18,838:INFO:             prophet: Not installed
2024-05-25 16:22:18,838:INFO:None
2024-05-25 16:22:18,838:INFO:Set up data.
2024-05-25 16:22:19,150:INFO:Set up folding strategy.
2024-05-25 16:22:19,150:INFO:Set up train/test split.
2024-05-25 16:22:19,203:INFO:Set up index.
2024-05-25 16:22:19,205:INFO:Assigning column types.
2024-05-25 16:22:19,225:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-25 16:22:19,297:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-25 16:22:19,299:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-25 16:22:19,344:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:22:19,344:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:22:19,416:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-25 16:22:19,418:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-25 16:22:19,463:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:22:19,463:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:22:19,464:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-25 16:22:19,536:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-25 16:22:19,582:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:22:19,582:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:22:19,655:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-25 16:22:19,700:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:22:19,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:22:19,701:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-25 16:22:19,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:22:19,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:22:19,937:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:22:19,937:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:22:19,939:INFO:Preparing preprocessing pipeline...
2024-05-25 16:22:19,943:INFO:Set up simple imputation.
2024-05-25 16:22:19,968:INFO:Set up encoding of ordinal features.
2024-05-25 16:22:19,975:INFO:Set up encoding of categorical features.
2024-05-25 16:22:19,978:INFO:Set up column name cleaning.
2024-05-25 16:22:22,166:INFO:Finished creating preprocessing pipeline.
2024-05-25 16:22:22,194:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-05-25 16:22:22,195:INFO:Creating final display dataframe.
2024-05-25 16:22:23,889:INFO:Setup _display_container:                     Description            Value
0                    Session id             3638
1                        Target           target
2                   Target type           Binary
3           Original data shape     (100000, 19)
4        Transformed data shape     (100000, 69)
5   Transformed train set shape      (90000, 69)
6    Transformed test set shape      (10000, 69)
7              Numeric features                5
8          Categorical features                9
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Fold Generator  StratifiedKFold
16                  Fold Number               10
17                     CPU Jobs               -1
18                      Use GPU            False
19               Log Experiment     MlflowLogger
20              Experiment Name         ml_codex
21                          USI             9df3
2024-05-25 16:22:24,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:22:24,034:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:22:24,156:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:22:24,156:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:22:24,158:INFO:Logging experiment in loggers
2024-05-25 16:22:24,298:INFO:SubProcess save_model() called ==================================
2024-05-25 16:22:24,354:INFO:Initializing save_model()
2024-05-25 16:22:24,354:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\Adm\AppData\Local\Temp\tmpybprzvdg\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-25 16:22:24,354:INFO:Adding model into prep_pipe
2024-05-25 16:22:24,354:WARNING:Only Model saved as it was a pipeline.
2024-05-25 16:22:24,399:INFO:C:\Users\Adm\AppData\Local\Temp\tmpybprzvdg\Transformation Pipeline.pkl saved in current working directory
2024-05-25 16:22:24,427:INFO:Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-05-25 16:22:24,427:INFO:save_model() successfully completed......................................
2024-05-25 16:22:25,688:INFO:SubProcess save_model() end ==================================
2024-05-25 16:22:25,718:INFO:setup() successfully completed in 5.34s...............
2024-05-25 16:22:25,718:INFO:Initializing compare_models()
2024-05-25 16:22:25,718:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276E49E3190>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000276E49E3190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-25 16:22:25,719:INFO:Checking exceptions
2024-05-25 16:22:25,742:INFO:Preparing display monitor
2024-05-25 16:22:25,774:INFO:Initializing Logistic Regression
2024-05-25 16:22:25,775:INFO:Total runtime is 1.6641616821289062e-05 minutes
2024-05-25 16:22:25,782:INFO:SubProcess create_model() called ==================================
2024-05-25 16:22:25,783:INFO:Initializing create_model()
2024-05-25 16:22:25,783:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276E49E3190>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027674873760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:22:25,783:INFO:Checking exceptions
2024-05-25 16:22:25,783:INFO:Importing libraries
2024-05-25 16:22:25,783:INFO:Copying training dataset
2024-05-25 16:22:25,825:INFO:Defining folds
2024-05-25 16:22:25,825:INFO:Declaring metric variables
2024-05-25 16:22:25,830:INFO:Importing untrained model
2024-05-25 16:22:25,835:INFO:Logistic Regression Imported successfully
2024-05-25 16:22:25,844:INFO:Starting cross validation
2024-05-25 16:22:25,849:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:22:52,361:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-25 16:22:52,527:INFO:Calculating mean and std
2024-05-25 16:22:52,529:INFO:Creating metrics dataframe
2024-05-25 16:22:52,532:INFO:Uploading results into container
2024-05-25 16:22:52,532:INFO:Uploading model into container now
2024-05-25 16:22:52,533:INFO:_master_model_container: 1
2024-05-25 16:22:52,533:INFO:_display_container: 2
2024-05-25 16:22:52,534:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3638, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-25 16:22:52,535:INFO:create_model() successfully completed......................................
2024-05-25 16:22:53,555:INFO:SubProcess create_model() end ==================================
2024-05-25 16:22:53,556:INFO:Creating metrics dataframe
2024-05-25 16:22:53,564:INFO:Initializing K Neighbors Classifier
2024-05-25 16:22:53,564:INFO:Total runtime is 0.4631585478782654 minutes
2024-05-25 16:22:53,570:INFO:SubProcess create_model() called ==================================
2024-05-25 16:22:53,570:INFO:Initializing create_model()
2024-05-25 16:22:53,570:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276E49E3190>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027674873760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:22:53,570:INFO:Checking exceptions
2024-05-25 16:22:53,571:INFO:Importing libraries
2024-05-25 16:22:53,571:INFO:Copying training dataset
2024-05-25 16:22:53,611:INFO:Defining folds
2024-05-25 16:22:53,612:INFO:Declaring metric variables
2024-05-25 16:22:53,616:INFO:Importing untrained model
2024-05-25 16:22:53,621:INFO:K Neighbors Classifier Imported successfully
2024-05-25 16:22:53,630:INFO:Starting cross validation
2024-05-25 16:22:53,635:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:23:22,605:INFO:Calculating mean and std
2024-05-25 16:23:22,607:INFO:Creating metrics dataframe
2024-05-25 16:23:22,609:INFO:Uploading results into container
2024-05-25 16:23:22,610:INFO:Uploading model into container now
2024-05-25 16:23:22,610:INFO:_master_model_container: 2
2024-05-25 16:23:22,611:INFO:_display_container: 2
2024-05-25 16:23:22,611:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-25 16:23:22,611:INFO:create_model() successfully completed......................................
2024-05-25 16:23:23,641:INFO:SubProcess create_model() end ==================================
2024-05-25 16:23:23,641:INFO:Creating metrics dataframe
2024-05-25 16:23:23,651:INFO:Initializing Naive Bayes
2024-05-25 16:23:23,651:INFO:Total runtime is 0.9646058638890584 minutes
2024-05-25 16:23:23,655:INFO:SubProcess create_model() called ==================================
2024-05-25 16:23:23,656:INFO:Initializing create_model()
2024-05-25 16:23:23,656:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276E49E3190>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027674873760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:23:23,656:INFO:Checking exceptions
2024-05-25 16:23:23,656:INFO:Importing libraries
2024-05-25 16:23:23,657:INFO:Copying training dataset
2024-05-25 16:23:23,698:INFO:Defining folds
2024-05-25 16:23:23,698:INFO:Declaring metric variables
2024-05-25 16:23:23,703:INFO:Importing untrained model
2024-05-25 16:23:23,709:INFO:Naive Bayes Imported successfully
2024-05-25 16:23:23,719:INFO:Starting cross validation
2024-05-25 16:23:23,725:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:23:28,278:INFO:Calculating mean and std
2024-05-25 16:23:28,280:INFO:Creating metrics dataframe
2024-05-25 16:23:28,282:INFO:Uploading results into container
2024-05-25 16:23:28,283:INFO:Uploading model into container now
2024-05-25 16:23:28,284:INFO:_master_model_container: 3
2024-05-25 16:23:28,284:INFO:_display_container: 2
2024-05-25 16:23:28,284:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-25 16:23:28,285:INFO:create_model() successfully completed......................................
2024-05-25 16:23:29,297:INFO:SubProcess create_model() end ==================================
2024-05-25 16:23:29,297:INFO:Creating metrics dataframe
2024-05-25 16:23:29,309:INFO:Initializing Decision Tree Classifier
2024-05-25 16:23:29,309:INFO:Total runtime is 1.0589001337687174 minutes
2024-05-25 16:23:29,313:INFO:SubProcess create_model() called ==================================
2024-05-25 16:23:29,314:INFO:Initializing create_model()
2024-05-25 16:23:29,314:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276E49E3190>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027674873760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:23:29,314:INFO:Checking exceptions
2024-05-25 16:23:29,314:INFO:Importing libraries
2024-05-25 16:23:29,315:INFO:Copying training dataset
2024-05-25 16:23:29,357:INFO:Defining folds
2024-05-25 16:23:29,357:INFO:Declaring metric variables
2024-05-25 16:23:29,362:INFO:Importing untrained model
2024-05-25 16:23:29,367:INFO:Decision Tree Classifier Imported successfully
2024-05-25 16:23:29,376:INFO:Starting cross validation
2024-05-25 16:23:29,382:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:23:34,612:INFO:Calculating mean and std
2024-05-25 16:23:34,614:INFO:Creating metrics dataframe
2024-05-25 16:23:34,616:INFO:Uploading results into container
2024-05-25 16:23:34,617:INFO:Uploading model into container now
2024-05-25 16:23:34,618:INFO:_master_model_container: 4
2024-05-25 16:23:34,618:INFO:_display_container: 2
2024-05-25 16:23:34,618:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3638, splitter='best')
2024-05-25 16:23:34,619:INFO:create_model() successfully completed......................................
2024-05-25 16:23:35,643:INFO:SubProcess create_model() end ==================================
2024-05-25 16:23:35,643:INFO:Creating metrics dataframe
2024-05-25 16:23:35,653:INFO:Initializing SVM - Linear Kernel
2024-05-25 16:23:35,654:INFO:Total runtime is 1.164663549264272 minutes
2024-05-25 16:23:35,658:INFO:SubProcess create_model() called ==================================
2024-05-25 16:23:35,659:INFO:Initializing create_model()
2024-05-25 16:23:35,659:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276E49E3190>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027674873760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:23:35,659:INFO:Checking exceptions
2024-05-25 16:23:35,659:INFO:Importing libraries
2024-05-25 16:23:35,660:INFO:Copying training dataset
2024-05-25 16:23:35,701:INFO:Defining folds
2024-05-25 16:23:35,701:INFO:Declaring metric variables
2024-05-25 16:23:35,706:INFO:Importing untrained model
2024-05-25 16:23:35,711:INFO:SVM - Linear Kernel Imported successfully
2024-05-25 16:23:35,721:INFO:Starting cross validation
2024-05-25 16:23:35,728:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:23:40,245:INFO:Calculating mean and std
2024-05-25 16:23:40,247:INFO:Creating metrics dataframe
2024-05-25 16:23:40,250:INFO:Uploading results into container
2024-05-25 16:23:40,251:INFO:Uploading model into container now
2024-05-25 16:23:40,251:INFO:_master_model_container: 5
2024-05-25 16:23:40,251:INFO:_display_container: 2
2024-05-25 16:23:40,252:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3638, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-25 16:23:40,253:INFO:create_model() successfully completed......................................
2024-05-25 16:23:41,269:INFO:SubProcess create_model() end ==================================
2024-05-25 16:23:41,270:INFO:Creating metrics dataframe
2024-05-25 16:23:41,281:INFO:Initializing Ridge Classifier
2024-05-25 16:23:41,281:INFO:Total runtime is 1.2584453701972962 minutes
2024-05-25 16:23:41,286:INFO:SubProcess create_model() called ==================================
2024-05-25 16:23:41,286:INFO:Initializing create_model()
2024-05-25 16:23:41,286:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276E49E3190>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027674873760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:23:41,286:INFO:Checking exceptions
2024-05-25 16:23:41,287:INFO:Importing libraries
2024-05-25 16:23:41,287:INFO:Copying training dataset
2024-05-25 16:23:41,329:INFO:Defining folds
2024-05-25 16:23:41,330:INFO:Declaring metric variables
2024-05-25 16:23:41,334:INFO:Importing untrained model
2024-05-25 16:23:41,340:INFO:Ridge Classifier Imported successfully
2024-05-25 16:23:41,350:INFO:Starting cross validation
2024-05-25 16:23:41,355:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:23:45,027:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.75449e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 16:23:45,049:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.75479e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 16:23:45,113:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.76841e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 16:23:45,162:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=7.1849e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 16:23:45,174:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.8252e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 16:23:45,212:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.75435e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 16:23:45,268:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.7546e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 16:23:45,290:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.75458e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 16:23:45,320:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.7661e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 16:23:45,610:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 176, in _reorder_cols
    new_df = new_df.drop(new_df.filter(regex="__drop__$").columns, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5344, in drop
    return super().drop(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4711, in drop
    obj = obj._drop_axis(labels, axis, level=level, errors=errors)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4792, in _drop_axis
    new_mgr = self._mgr.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 38.3 MiB for an array with shape (62, 81000) and data type float64



2024-05-25 16:23:45,610:INFO:Calculating mean and std
2024-05-25 16:23:45,612:INFO:Creating metrics dataframe
2024-05-25 16:23:45,615:INFO:Uploading results into container
2024-05-25 16:23:45,615:INFO:Uploading model into container now
2024-05-25 16:23:45,616:INFO:_master_model_container: 6
2024-05-25 16:23:45,616:INFO:_display_container: 2
2024-05-25 16:23:45,617:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3638, solver='auto',
                tol=0.0001)
2024-05-25 16:23:45,617:INFO:create_model() successfully completed......................................
2024-05-25 16:23:46,640:INFO:SubProcess create_model() end ==================================
2024-05-25 16:23:46,640:INFO:Creating metrics dataframe
2024-05-25 16:23:46,652:INFO:Initializing Random Forest Classifier
2024-05-25 16:23:46,652:INFO:Total runtime is 1.3479604164759318 minutes
2024-05-25 16:23:46,657:INFO:SubProcess create_model() called ==================================
2024-05-25 16:23:46,657:INFO:Initializing create_model()
2024-05-25 16:23:46,657:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276E49E3190>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027674873760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:23:46,658:INFO:Checking exceptions
2024-05-25 16:23:46,658:INFO:Importing libraries
2024-05-25 16:23:46,658:INFO:Copying training dataset
2024-05-25 16:23:46,702:INFO:Defining folds
2024-05-25 16:23:46,702:INFO:Declaring metric variables
2024-05-25 16:23:46,707:INFO:Importing untrained model
2024-05-25 16:23:46,712:INFO:Random Forest Classifier Imported successfully
2024-05-25 16:23:46,723:INFO:Starting cross validation
2024-05-25 16:23:46,728:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:23:58,751:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 274, in get_dummies
    X = X.reindex(columns=cols)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5141, in reindex
    return super().reindex(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 5521, in reindex
    return self._reindex_axes(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 5549, in _reindex_axes
    obj = obj._reindex_with_indexers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 5597, in _reindex_with_indexers
    new_data = new_data.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.47 MiB for an array with shape (4, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.8 MiB for an array with shape (58, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.4 MiB for an array with shape (20, 81000) and data type float64

--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 633. KiB for an array with shape (1, 81000) and data type float64



2024-05-25 16:23:58,752:INFO:Calculating mean and std
2024-05-25 16:23:58,753:INFO:Creating metrics dataframe
2024-05-25 16:23:58,756:INFO:Uploading results into container
2024-05-25 16:23:58,757:INFO:Uploading model into container now
2024-05-25 16:23:58,758:INFO:_master_model_container: 7
2024-05-25 16:23:58,758:INFO:_display_container: 2
2024-05-25 16:23:58,759:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3638, verbose=0,
                       warm_start=False)
2024-05-25 16:23:58,759:INFO:create_model() successfully completed......................................
2024-05-25 16:23:59,790:INFO:SubProcess create_model() end ==================================
2024-05-25 16:23:59,790:INFO:Creating metrics dataframe
2024-05-25 16:23:59,802:INFO:Initializing Quadratic Discriminant Analysis
2024-05-25 16:23:59,803:INFO:Total runtime is 1.5671401540438334 minutes
2024-05-25 16:23:59,807:INFO:SubProcess create_model() called ==================================
2024-05-25 16:23:59,807:INFO:Initializing create_model()
2024-05-25 16:23:59,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276E49E3190>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027674873760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:23:59,808:INFO:Checking exceptions
2024-05-25 16:23:59,808:INFO:Importing libraries
2024-05-25 16:23:59,808:INFO:Copying training dataset
2024-05-25 16:23:59,849:INFO:Defining folds
2024-05-25 16:23:59,849:INFO:Declaring metric variables
2024-05-25 16:23:59,855:INFO:Importing untrained model
2024-05-25 16:23:59,861:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-25 16:23:59,870:INFO:Starting cross validation
2024-05-25 16:23:59,875:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:24:04,253:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:24:04,307:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:24:04,319:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:24:04,405:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:24:04,421:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:24:04,443:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:24:04,492:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:24:05,354:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-25 16:24:05,709:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 34.6 MiB for an array with shape (56, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 225, in fit
    args.append(X[self._include])
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 3908, in __getitem__
    data = self._take_with_is_copy(indexer, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4088, in _take_with_is_copy
    result = self.take(indices=indices, axis=axis)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4068, in take
    new_data = self._mgr.take(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 877, in take
    return self.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 38.3 MiB for an array with shape (62, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 38.3 MiB for an array with shape (62, 81000) and data type float64



2024-05-25 16:24:05,709:INFO:Calculating mean and std
2024-05-25 16:24:05,711:INFO:Creating metrics dataframe
2024-05-25 16:24:05,714:INFO:Uploading results into container
2024-05-25 16:24:05,714:INFO:Uploading model into container now
2024-05-25 16:24:05,715:INFO:_master_model_container: 8
2024-05-25 16:24:05,715:INFO:_display_container: 2
2024-05-25 16:24:05,716:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-25 16:24:05,716:INFO:create_model() successfully completed......................................
2024-05-25 16:24:06,773:INFO:SubProcess create_model() end ==================================
2024-05-25 16:24:06,773:INFO:Creating metrics dataframe
2024-05-25 16:24:06,786:INFO:Initializing Ada Boost Classifier
2024-05-25 16:24:06,786:INFO:Total runtime is 1.6835249384244284 minutes
2024-05-25 16:24:06,791:INFO:SubProcess create_model() called ==================================
2024-05-25 16:24:06,791:INFO:Initializing create_model()
2024-05-25 16:24:06,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276E49E3190>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027674873760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:24:06,791:INFO:Checking exceptions
2024-05-25 16:24:06,792:INFO:Importing libraries
2024-05-25 16:24:06,792:INFO:Copying training dataset
2024-05-25 16:24:06,839:INFO:Defining folds
2024-05-25 16:24:06,839:INFO:Declaring metric variables
2024-05-25 16:24:06,845:INFO:Importing untrained model
2024-05-25 16:24:06,850:INFO:Ada Boost Classifier Imported successfully
2024-05-25 16:24:06,861:INFO:Starting cross validation
2024-05-25 16:24:06,866:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:24:09,697:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:24:09,823:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:24:09,844:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:24:09,880:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:24:09,900:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:24:16,265:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 34.6 MiB for an array with shape (56, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.2 MiB for an array with shape (57, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (25, 81000) and data type float64



2024-05-25 16:24:16,265:INFO:Calculating mean and std
2024-05-25 16:24:16,267:INFO:Creating metrics dataframe
2024-05-25 16:24:16,269:INFO:Uploading results into container
2024-05-25 16:24:16,270:INFO:Uploading model into container now
2024-05-25 16:24:16,271:INFO:_master_model_container: 9
2024-05-25 16:24:16,271:INFO:_display_container: 2
2024-05-25 16:24:16,272:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3638)
2024-05-25 16:24:16,272:INFO:create_model() successfully completed......................................
2024-05-25 16:24:17,294:INFO:SubProcess create_model() end ==================================
2024-05-25 16:24:17,294:INFO:Creating metrics dataframe
2024-05-25 16:24:17,308:INFO:Initializing Gradient Boosting Classifier
2024-05-25 16:24:17,308:INFO:Total runtime is 1.8588910460472108 minutes
2024-05-25 16:24:17,313:INFO:SubProcess create_model() called ==================================
2024-05-25 16:24:17,313:INFO:Initializing create_model()
2024-05-25 16:24:17,313:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276E49E3190>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027674873760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:24:17,314:INFO:Checking exceptions
2024-05-25 16:24:17,314:INFO:Importing libraries
2024-05-25 16:24:17,314:INFO:Copying training dataset
2024-05-25 16:24:17,356:INFO:Defining folds
2024-05-25 16:24:17,357:INFO:Declaring metric variables
2024-05-25 16:24:17,362:INFO:Importing untrained model
2024-05-25 16:24:17,367:INFO:Gradient Boosting Classifier Imported successfully
2024-05-25 16:24:17,377:INFO:Starting cross validation
2024-05-25 16:24:17,382:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:24:36,322:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


4 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.2 MiB for an array with shape (57, 81000) and data type float64

--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.4 MiB for an array with shape (20, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 9.89 MiB for an array with shape (16, 81000) and data type float64



2024-05-25 16:24:36,322:INFO:Calculating mean and std
2024-05-25 16:24:36,324:INFO:Creating metrics dataframe
2024-05-25 16:24:36,327:INFO:Uploading results into container
2024-05-25 16:24:36,328:INFO:Uploading model into container now
2024-05-25 16:24:36,328:INFO:_master_model_container: 10
2024-05-25 16:24:36,328:INFO:_display_container: 2
2024-05-25 16:24:36,330:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3638, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-25 16:24:36,330:INFO:create_model() successfully completed......................................
2024-05-25 16:24:37,350:INFO:SubProcess create_model() end ==================================
2024-05-25 16:24:37,350:INFO:Creating metrics dataframe
2024-05-25 16:24:37,364:INFO:Initializing Linear Discriminant Analysis
2024-05-25 16:24:37,365:INFO:Total runtime is 2.1931718826293944 minutes
2024-05-25 16:24:37,369:INFO:SubProcess create_model() called ==================================
2024-05-25 16:24:37,370:INFO:Initializing create_model()
2024-05-25 16:24:37,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276E49E3190>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027674873760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:24:37,370:INFO:Checking exceptions
2024-05-25 16:24:37,370:INFO:Importing libraries
2024-05-25 16:24:37,370:INFO:Copying training dataset
2024-05-25 16:24:37,412:INFO:Defining folds
2024-05-25 16:24:37,413:INFO:Declaring metric variables
2024-05-25 16:24:37,418:INFO:Importing untrained model
2024-05-25 16:24:37,423:INFO:Linear Discriminant Analysis Imported successfully
2024-05-25 16:24:37,434:INFO:Starting cross validation
2024-05-25 16:24:37,439:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:24:42,361:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


6 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 178, in _reorder_cols
    return new_df[columns]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 3908, in __getitem__
    data = self._take_with_is_copy(indexer, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4088, in _take_with_is_copy
    result = self.take(indices=indices, axis=axis)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4068, in take
    new_data = self._mgr.take(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 877, in take
    return self.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 34.6 MiB for an array with shape (56, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 42.0 MiB for an array with shape (81000, 68) and data type float64

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py", line 628, in fit
    self._solve_svd(X, y)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py", line 522, in _solve_svd
    U, S, Vt = svd(X, full_matrices=False)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\scipy\linalg\_decomp_svd.py", line 127, in svd
    u, s, v, info = gesXd(a1, compute_uv=compute_uv, lwork=lwork,
TypeError: _ArrayMemoryError.__init__() missing 1 required positional argument: 'dtype'

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 34.6 MiB for an array with shape (56, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.4 MiB for an array with shape (20, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 8.03 MiB for an array with shape (13, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py", line 628, in fit
    self._solve_svd(X, y)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py", line 506, in _solve_svd
    Xg = X[y == group]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 22.6 MiB for an array with shape (43544, 68) and data type float64



2024-05-25 16:24:42,361:INFO:Calculating mean and std
2024-05-25 16:24:42,363:INFO:Creating metrics dataframe
2024-05-25 16:24:42,366:INFO:Uploading results into container
2024-05-25 16:24:42,366:INFO:Uploading model into container now
2024-05-25 16:24:42,367:INFO:_master_model_container: 11
2024-05-25 16:24:42,367:INFO:_display_container: 2
2024-05-25 16:24:42,368:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-25 16:24:42,368:INFO:create_model() successfully completed......................................
2024-05-25 16:24:43,391:WARNING:create_model() for LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-25 16:24:43,392:WARNING:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2024-05-25 16:24:43,392:INFO:Initializing create_model()
2024-05-25 16:24:43,392:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276E49E3190>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027674873760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:24:43,392:INFO:Checking exceptions
2024-05-25 16:24:43,392:INFO:Importing libraries
2024-05-25 16:24:43,392:INFO:Copying training dataset
2024-05-25 16:24:43,433:INFO:Defining folds
2024-05-25 16:24:43,433:INFO:Declaring metric variables
2024-05-25 16:24:43,438:INFO:Importing untrained model
2024-05-25 16:24:43,443:INFO:Linear Discriminant Analysis Imported successfully
2024-05-25 16:24:43,453:INFO:Starting cross validation
2024-05-25 16:24:43,458:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:24:48,094:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


7 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 34.6 MiB for an array with shape (56, 81000) and data type float64

--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py", line 628, in fit
    self._solve_svd(X, y)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py", line 520, in _solve_svd
    X = xp.sqrt(fac) * (Xc / std)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 42.0 MiB for an array with shape (81000, 68) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.2 MiB for an array with shape (57, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.8 MiB for an array with shape (58, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.8 MiB for an array with shape (58, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py", line 628, in fit
    self._solve_svd(X, y)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py", line 511, in _solve_svd
    Xc = xp.concat(Xc, axis=0)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_array_api.py", line 310, in concat
    return numpy.concatenate(arrays, axis=axis)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 42.0 MiB for an array with shape (81000, 68) and data type float64



2024-05-25 16:24:48,094:INFO:Calculating mean and std
2024-05-25 16:24:48,096:INFO:Creating metrics dataframe
2024-05-25 16:24:48,099:INFO:Uploading results into container
2024-05-25 16:24:48,099:INFO:Uploading model into container now
2024-05-25 16:24:48,100:INFO:_master_model_container: 12
2024-05-25 16:24:48,100:INFO:_display_container: 2
2024-05-25 16:24:48,101:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-25 16:24:48,101:INFO:create_model() successfully completed......................................
2024-05-25 16:24:49,126:ERROR:create_model() for LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) raised an exception or returned all 0.0:
2024-05-25 16:24:49,126:ERROR:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2024-05-25 16:24:49,127:INFO:Initializing Extra Trees Classifier
2024-05-25 16:24:49,127:INFO:Total runtime is 2.3892098267873125 minutes
2024-05-25 16:24:49,131:INFO:SubProcess create_model() called ==================================
2024-05-25 16:24:49,131:INFO:Initializing create_model()
2024-05-25 16:24:49,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276E49E3190>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027674873760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:24:49,132:INFO:Checking exceptions
2024-05-25 16:24:49,132:INFO:Importing libraries
2024-05-25 16:24:49,132:INFO:Copying training dataset
2024-05-25 16:24:49,174:INFO:Defining folds
2024-05-25 16:24:49,174:INFO:Declaring metric variables
2024-05-25 16:24:49,179:INFO:Importing untrained model
2024-05-25 16:24:49,184:INFO:Extra Trees Classifier Imported successfully
2024-05-25 16:24:49,193:INFO:Starting cross validation
2024-05-25 16:24:49,198:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:24:57,635:WARNING:create_model() for et raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-25 16:24:57,637:WARNING:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 4194304 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 4194304 bytes

--------------------------------------------------------------------------------
4 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 2097152 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 2097152 bytes

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.8 MiB for an array with shape (58, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.8 MiB for an array with shape (58, 81000) and data type float64

--------------------------------------------------------------------------------
2 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 303, in _fit
    y_encoded = np.zeros(y.shape, dtype=int)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 316. KiB for an array with shape (81000, 1) and data type int32
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 316. KiB for an array with shape (81000, 1) and data type int32

--------------------------------------------------------------------------------
1 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 1048576 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 1048576 bytes


2024-05-25 16:24:57,638:INFO:Initializing create_model()
2024-05-25 16:24:57,638:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276E49E3190>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027674873760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:24:57,638:INFO:Checking exceptions
2024-05-25 16:24:57,638:INFO:Importing libraries
2024-05-25 16:24:57,638:INFO:Copying training dataset
2024-05-25 16:24:57,799:INFO:Defining folds
2024-05-25 16:24:57,800:INFO:Declaring metric variables
2024-05-25 16:24:57,810:INFO:Importing untrained model
2024-05-25 16:24:57,821:INFO:Extra Trees Classifier Imported successfully
2024-05-25 16:24:57,845:INFO:Starting cross validation
2024-05-25 16:24:57,857:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:25:02,966:ERROR:create_model() for et raised an exception or returned all 0.0:
2024-05-25 16:25:02,969:ERROR:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 4194304 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 4194304 bytes

--------------------------------------------------------------------------------
4 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 2097152 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 2097152 bytes

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.8 MiB for an array with shape (58, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.8 MiB for an array with shape (58, 81000) and data type float64

--------------------------------------------------------------------------------
2 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 303, in _fit
    y_encoded = np.zeros(y.shape, dtype=int)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 316. KiB for an array with shape (81000, 1) and data type int32
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 316. KiB for an array with shape (81000, 1) and data type int32

--------------------------------------------------------------------------------
1 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 1048576 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 1048576 bytes


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 4.33 MiB for an array with shape (7, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (25, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 178, in _reorder_cols
    return new_df[columns]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 3908, in __getitem__
    data = self._take_with_is_copy(indexer, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4088, in _take_with_is_copy
    result = self.take(indices=indices, axis=axis)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4068, in take
    new_data = self._mgr.take(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 877, in take
    return self.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 34.6 MiB for an array with shape (56, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 189, in _transform
    X = self.ordinal_encoder.transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\ordinal.py", line 113, in _transform
    X, _ = self.ordinal_encoding(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\ordinal.py", line 198, in ordinal_encoding
    X[column] = X[column].astype("object").fillna(np.nan).map(col_mapping)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 7212, in fillna
    new_data = self._mgr.fillna(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\base.py", line 173, in fillna
    return self.apply_with_block(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1408, in fillna
    nbs = nb._maybe_downcast([nb], downcast=downcast, using_cow=using_cow)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 512, in _maybe_downcast
    [blk.convert(using_cow=using_cow, copy=not using_cow) for blk in blocks]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 512, in <listcomp>
    [blk.convert(using_cow=using_cow, copy=not using_cow) for blk in blocks]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 566, in convert
    res_values = lib.maybe_convert_objects(
  File "lib.pyx", line 2521, in pandas._libs.lib.maybe_convert_objects
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.24 MiB for an array with shape (81000,) and data type complex128

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.85 MiB for an array with shape (3, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.4 MiB for an array with shape (20, 81000) and data type float64

--------------------------------------------------------------------------------
2 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 4194304 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 4194304 bytes

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 189, in _transform
    X = self.ordinal_encoder.transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\ordinal.py", line 113, in _transform
    X, _ = self.ordinal_encoding(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\ordinal.py", line 198, in ordinal_encoding
    X[column] = X[column].astype("object").fillna(np.nan).map(col_mapping)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\series.py", line 4544, in map
    new_values = self._map_values(arg, na_action=na_action)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\base.py", line 921, in _map_values
    return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\algorithms.py", line 1803, in map_array
    indexer = mapper.index.get_indexer(arr)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\indexes\base.py", line 3870, in get_indexer
    target = self._maybe_cast_listlike_indexer(target)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\indexes\base.py", line 6623, in _maybe_cast_listlike_indexer
    return ensure_index(target)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\indexes\base.py", line 7577, in ensure_index
    return Index(index_like, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\indexes\base.py", line 560, in __new__
    arr = sanitize_array(data, None, dtype=dtype, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\construction.py", line 608, in sanitize_array
    subarr = maybe_infer_to_datetimelike(data)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\dtypes\cast.py", line 1180, in maybe_infer_to_datetimelike
    return lib.maybe_convert_objects(  # type: ignore[return-value]
  File "lib.pyx", line 2521, in pandas._libs.lib.maybe_convert_objects
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.24 MiB for an array with shape (81000,) and data type complex128


2024-05-25 16:25:02,970:INFO:Initializing Light Gradient Boosting Machine
2024-05-25 16:25:02,970:INFO:Total runtime is 2.6199302275975542 minutes
2024-05-25 16:25:02,980:INFO:SubProcess create_model() called ==================================
2024-05-25 16:25:02,980:INFO:Initializing create_model()
2024-05-25 16:25:02,981:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276E49E3190>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027674873760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:25:02,982:INFO:Checking exceptions
2024-05-25 16:25:02,982:INFO:Importing libraries
2024-05-25 16:25:02,982:INFO:Copying training dataset
2024-05-25 16:25:03,116:INFO:Defining folds
2024-05-25 16:25:03,117:INFO:Declaring metric variables
2024-05-25 16:25:03,130:INFO:Importing untrained model
2024-05-25 16:25:03,141:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 16:25:03,166:INFO:Starting cross validation
2024-05-25 16:25:03,177:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:25:06,191:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


8 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 9.89 MiB for an array with shape (16, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 34.6 MiB for an array with shape (56, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 633. KiB for an array with shape (1, 81000) and data type float64

--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 4.33 MiB for an array with shape (7, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 189, in _transform
    X = self.ordinal_encoder.transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\ordinal.py", line 113, in _transform
    X, _ = self.ordinal_encoding(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\ordinal.py", line 198, in ordinal_encoding
    X[column] = X[column].astype("object").fillna(np.nan).map(col_mapping)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 7212, in fillna
    new_data = self._mgr.fillna(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\base.py", line 173, in fillna
    return self.apply_with_block(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1408, in fillna
    nbs = nb._maybe_downcast([nb], downcast=downcast, using_cow=using_cow)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 512, in _maybe_downcast
    [blk.convert(using_cow=using_cow, copy=not using_cow) for blk in blocks]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 512, in <listcomp>
    [blk.convert(using_cow=using_cow, copy=not using_cow) for blk in blocks]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 566, in convert
    res_values = lib.maybe_convert_objects(
  File "lib.pyx", line 2521, in pandas._libs.lib.maybe_convert_objects
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.24 MiB for an array with shape (81000,) and data type complex128

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 9.89 MiB for an array with shape (16, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 189, in _transform
    X = self.ordinal_encoder.transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 482, in transform
    X = convert_input(X, deep=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 116, in convert_input
    X = X.copy(deep=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 3.71 MiB for an array with shape (6, 81000) and data type object



2024-05-25 16:25:06,192:INFO:Calculating mean and std
2024-05-25 16:25:06,193:INFO:Creating metrics dataframe
2024-05-25 16:25:06,196:INFO:Uploading results into container
2024-05-25 16:25:06,197:INFO:Uploading model into container now
2024-05-25 16:25:06,198:INFO:_master_model_container: 13
2024-05-25 16:25:06,198:INFO:_display_container: 2
2024-05-25 16:25:06,199:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3638, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-25 16:25:06,200:INFO:create_model() successfully completed......................................
2024-05-25 16:25:07,222:WARNING:create_model() for LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3638, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-25 16:25:07,222:WARNING:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2024-05-25 16:25:07,222:INFO:Initializing create_model()
2024-05-25 16:25:07,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276E49E3190>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027674873760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:25:07,223:INFO:Checking exceptions
2024-05-25 16:25:07,223:INFO:Importing libraries
2024-05-25 16:25:07,223:INFO:Copying training dataset
2024-05-25 16:25:07,263:INFO:Defining folds
2024-05-25 16:25:07,264:INFO:Declaring metric variables
2024-05-25 16:25:07,268:INFO:Importing untrained model
2024-05-25 16:25:07,275:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 16:25:07,283:INFO:Starting cross validation
2024-05-25 16:25:07,288:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:25:10,605:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


7 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 9.89 MiB for an array with shape (16, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (25, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 34.6 MiB for an array with shape (56, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 9.89 MiB for an array with shape (16, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 8.03 MiB for an array with shape (13, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 4.33 MiB for an array with shape (7, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64



2024-05-25 16:25:10,606:INFO:Calculating mean and std
2024-05-25 16:25:10,613:INFO:Creating metrics dataframe
2024-05-25 16:25:10,617:INFO:Uploading results into container
2024-05-25 16:25:10,618:INFO:Uploading model into container now
2024-05-25 16:25:10,619:INFO:_master_model_container: 14
2024-05-25 16:25:10,620:INFO:_display_container: 2
2024-05-25 16:25:10,621:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3638, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-25 16:25:10,621:INFO:create_model() successfully completed......................................
2024-05-25 16:25:11,677:ERROR:create_model() for LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3638, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0:
2024-05-25 16:25:11,678:ERROR:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2024-05-25 16:25:11,678:INFO:Initializing Dummy Classifier
2024-05-25 16:25:11,678:INFO:Total runtime is 2.765061529477437 minutes
2024-05-25 16:25:11,682:INFO:SubProcess create_model() called ==================================
2024-05-25 16:25:11,682:INFO:Initializing create_model()
2024-05-25 16:25:11,683:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276E49E3190>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027674873760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:25:11,683:INFO:Checking exceptions
2024-05-25 16:25:11,683:INFO:Importing libraries
2024-05-25 16:25:11,683:INFO:Copying training dataset
2024-05-25 16:25:11,724:INFO:Defining folds
2024-05-25 16:25:11,725:INFO:Declaring metric variables
2024-05-25 16:25:11,729:INFO:Importing untrained model
2024-05-25 16:25:11,734:INFO:Dummy Classifier Imported successfully
2024-05-25 16:25:11,744:INFO:Starting cross validation
2024-05-25 16:25:11,749:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:25:14,031:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


8 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 34.6 MiB for an array with shape (56, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (25, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 8.03 MiB for an array with shape (13, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 9.89 MiB for an array with shape (16, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 8.03 MiB for an array with shape (13, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 189, in _transform
    X = self.ordinal_encoder.transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\ordinal.py", line 113, in _transform
    X, _ = self.ordinal_encoding(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\ordinal.py", line 198, in ordinal_encoding
    X[column] = X[column].astype("object").fillna(np.nan).map(col_mapping)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 7212, in fillna
    new_data = self._mgr.fillna(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\base.py", line 173, in fillna
    return self.apply_with_block(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1408, in fillna
    nbs = nb._maybe_downcast([nb], downcast=downcast, using_cow=using_cow)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 512, in _maybe_downcast
    [blk.convert(using_cow=using_cow, copy=not using_cow) for blk in blocks]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 512, in <listcomp>
    [blk.convert(using_cow=using_cow, copy=not using_cow) for blk in blocks]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 566, in convert
    res_values = lib.maybe_convert_objects(
  File "lib.pyx", line 2523, in pandas._libs.lib.maybe_convert_objects
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 633. KiB for an array with shape (81000,) and data type uint64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.47 MiB for an array with shape (4, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.8 MiB for an array with shape (58, 81000) and data type float64



2024-05-25 16:25:14,032:INFO:Calculating mean and std
2024-05-25 16:25:14,032:INFO:Creating metrics dataframe
2024-05-25 16:25:14,035:INFO:Uploading results into container
2024-05-25 16:25:14,035:INFO:Uploading model into container now
2024-05-25 16:25:14,036:INFO:_master_model_container: 15
2024-05-25 16:25:14,036:INFO:_display_container: 2
2024-05-25 16:25:14,036:INFO:DummyClassifier(constant=None, random_state=3638, strategy='prior')
2024-05-25 16:25:14,036:INFO:create_model() successfully completed......................................
2024-05-25 16:25:15,052:WARNING:create_model() for DummyClassifier(constant=None, random_state=3638, strategy='prior') raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-25 16:25:15,052:WARNING:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2024-05-25 16:25:15,053:INFO:Initializing create_model()
2024-05-25 16:25:15,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276E49E3190>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027674873760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:25:15,053:INFO:Checking exceptions
2024-05-25 16:25:15,053:INFO:Importing libraries
2024-05-25 16:25:15,053:INFO:Copying training dataset
2024-05-25 16:25:15,093:INFO:Defining folds
2024-05-25 16:25:15,094:INFO:Declaring metric variables
2024-05-25 16:25:15,098:INFO:Importing untrained model
2024-05-25 16:25:15,103:INFO:Dummy Classifier Imported successfully
2024-05-25 16:25:15,112:INFO:Starting cross validation
2024-05-25 16:25:15,117:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:25:17,305:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


8 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.8 MiB for an array with shape (58, 81000) and data type float64

--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (25, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 8.03 MiB for an array with shape (13, 81000) and data type float64

--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 633. KiB for an array with shape (1, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 267, in get_dummies
    base_df = mod.reindex(X[col].fillna(-2))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5141, in reindex
    return super().reindex(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 5521, in reindex
    return self._reindex_axes(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 5549, in _reindex_axes
    obj = obj._reindex_with_indexers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 5597, in _reindex_with_indexers
    new_data = new_data.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 670, in reindex_indexer
    new_blocks = [
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 671, in <listcomp>
    blk.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 633. KiB for an array with shape (81000, 1) and data type float64



2024-05-25 16:25:17,305:INFO:Calculating mean and std
2024-05-25 16:25:17,306:INFO:Creating metrics dataframe
2024-05-25 16:25:17,309:INFO:Uploading results into container
2024-05-25 16:25:17,309:INFO:Uploading model into container now
2024-05-25 16:25:17,310:INFO:_master_model_container: 16
2024-05-25 16:25:17,310:INFO:_display_container: 2
2024-05-25 16:25:17,310:INFO:DummyClassifier(constant=None, random_state=3638, strategy='prior')
2024-05-25 16:25:17,310:INFO:create_model() successfully completed......................................
2024-05-25 16:25:18,325:ERROR:create_model() for DummyClassifier(constant=None, random_state=3638, strategy='prior') raised an exception or returned all 0.0:
2024-05-25 16:25:18,325:ERROR:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2024-05-25 16:25:18,326:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2024-05-25 16:25:18,337:INFO:Initializing create_model()
2024-05-25 16:25:18,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000276E49E3190>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3638, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:25:18,337:INFO:Checking exceptions
2024-05-25 16:25:18,340:INFO:Importing libraries
2024-05-25 16:25:18,340:INFO:Copying training dataset
2024-05-25 16:25:18,382:INFO:Defining folds
2024-05-25 16:25:18,382:INFO:Declaring metric variables
2024-05-25 16:25:18,382:INFO:Importing untrained model
2024-05-25 16:25:18,382:INFO:Declaring custom model
2024-05-25 16:25:18,383:INFO:Decision Tree Classifier Imported successfully
2024-05-25 16:25:18,388:INFO:Cross validation set to False
2024-05-25 16:25:18,388:INFO:Fitting Model
2024-05-25 16:25:20,619:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3638, splitter='best')
2024-05-25 16:25:20,619:INFO:create_model() successfully completed......................................
2024-05-25 16:25:21,637:ERROR:create_model() for DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3638, splitter='best') raised an exception or returned all 0.0:
2024-05-25 16:25:21,637:ERROR:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 954, in compare_models
    np.sum(
AssertionError

2024-05-25 16:25:21,639:INFO:Creating Dashboard logs
2024-05-25 16:25:21,643:INFO:Model: K Neighbors Classifier
2024-05-25 16:25:21,712:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2024-05-25 16:25:23,084:INFO:Creating Dashboard logs
2024-05-25 16:25:23,089:INFO:Model: Ridge Classifier
2024-05-25 16:25:23,158:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 3638, 'solver': 'auto', 'tol': 0.0001}
2024-05-25 16:25:24,583:INFO:Creating Dashboard logs
2024-05-25 16:25:24,587:INFO:Model: Logistic Regression
2024-05-25 16:25:24,655:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 3638, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-05-25 16:25:26,014:INFO:Creating Dashboard logs
2024-05-25 16:25:26,018:INFO:Model: SVM - Linear Kernel
2024-05-25 16:25:26,118:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 3638, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-25 16:25:27,593:INFO:Creating Dashboard logs
2024-05-25 16:25:27,597:INFO:Model: Gradient Boosting Classifier
2024-05-25 16:25:27,668:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 3638, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-25 16:25:29,035:INFO:Creating Dashboard logs
2024-05-25 16:25:29,040:INFO:Model: Naive Bayes
2024-05-25 16:25:29,110:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-05-25 16:25:30,426:INFO:Creating Dashboard logs
2024-05-25 16:25:30,431:INFO:Model: Random Forest Classifier
2024-05-25 16:25:30,502:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 3638, 'verbose': 0, 'warm_start': False}
2024-05-25 16:25:31,960:INFO:Creating Dashboard logs
2024-05-25 16:25:31,965:INFO:Model: Ada Boost Classifier
2024-05-25 16:25:32,034:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 3638}
2024-05-25 16:25:33,361:INFO:Creating Dashboard logs
2024-05-25 16:25:33,365:INFO:Model: Quadratic Discriminant Analysis
2024-05-25 16:25:33,438:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2024-05-25 16:25:34,780:INFO:_master_model_container: 16
2024-05-25 16:25:34,780:INFO:_display_container: 2
2024-05-25 16:25:34,781:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3638, splitter='best')
2024-05-25 16:25:34,781:INFO:compare_models() successfully completed......................................
2024-05-25 16:34:00,961:INFO:PyCaret ClassificationExperiment
2024-05-25 16:34:00,961:INFO:Logging name: ml_codex
2024-05-25 16:34:00,961:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-25 16:34:00,962:INFO:version 3.3.2
2024-05-25 16:34:00,962:INFO:Initializing setup()
2024-05-25 16:34:00,962:INFO:self.USI: a4c8
2024-05-25 16:34:00,962:INFO:self._variable_keys: {'fold_generator', 'is_multiclass', 'y_train', 'html_param', 'log_plots_param', '_ml_usecase', 'fix_imbalance', 'y_test', 'exp_name_log', 'data', 'pipeline', 'y', 'USI', 'gpu_param', '_available_plots', 'n_jobs_param', 'target_param', 'exp_id', 'seed', 'X_test', 'X', 'logging_param', 'idx', 'fold_shuffle_param', 'memory', 'fold_groups_param', 'gpu_n_jobs_param', 'X_train'}
2024-05-25 16:34:00,962:INFO:Checking environment
2024-05-25 16:34:00,962:INFO:python_version: 3.10.13
2024-05-25 16:34:00,963:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-25 16:34:00,963:INFO:machine: AMD64
2024-05-25 16:34:00,963:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-25 16:34:00,963:INFO:Memory: svmem(total=34267656192, available=11771588608, percent=65.6, used=22496067584, free=11771588608)
2024-05-25 16:34:00,963:INFO:Physical Core: 8
2024-05-25 16:34:00,963:INFO:Logical Core: 16
2024-05-25 16:34:00,963:INFO:Checking libraries
2024-05-25 16:34:00,964:INFO:System:
2024-05-25 16:34:00,964:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-25 16:34:00,964:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-25 16:34:00,964:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-25 16:34:00,964:INFO:PyCaret required dependencies:
2024-05-25 16:34:00,964:INFO:                 pip: 23.3
2024-05-25 16:34:00,965:INFO:          setuptools: 68.0.0
2024-05-25 16:34:00,965:INFO:             pycaret: 3.3.2
2024-05-25 16:34:00,965:INFO:             IPython: 8.24.0
2024-05-25 16:34:00,965:INFO:          ipywidgets: 8.1.2
2024-05-25 16:34:00,965:INFO:                tqdm: 4.66.4
2024-05-25 16:34:00,965:INFO:               numpy: 1.26.4
2024-05-25 16:34:00,965:INFO:              pandas: 2.1.4
2024-05-25 16:34:00,966:INFO:              jinja2: 3.1.4
2024-05-25 16:34:00,966:INFO:               scipy: 1.11.4
2024-05-25 16:34:00,966:INFO:              joblib: 1.3.2
2024-05-25 16:34:00,966:INFO:             sklearn: 1.4.2
2024-05-25 16:34:00,966:INFO:                pyod: 1.1.3
2024-05-25 16:34:00,966:INFO:            imblearn: 0.12.2
2024-05-25 16:34:00,967:INFO:   category_encoders: 2.6.3
2024-05-25 16:34:00,967:INFO:            lightgbm: 4.3.0
2024-05-25 16:34:00,967:INFO:               numba: 0.59.1
2024-05-25 16:34:00,967:INFO:            requests: 2.32.2
2024-05-25 16:34:00,967:INFO:          matplotlib: 3.7.5
2024-05-25 16:34:00,967:INFO:          scikitplot: 0.3.7
2024-05-25 16:34:00,968:INFO:         yellowbrick: 1.5
2024-05-25 16:34:00,968:INFO:              plotly: 5.22.0
2024-05-25 16:34:00,968:INFO:    plotly-resampler: Not installed
2024-05-25 16:34:00,968:INFO:             kaleido: 0.2.1
2024-05-25 16:34:00,968:INFO:           schemdraw: 0.15
2024-05-25 16:34:00,968:INFO:         statsmodels: 0.14.2
2024-05-25 16:34:00,968:INFO:              sktime: 0.26.0
2024-05-25 16:34:00,969:INFO:               tbats: 1.1.3
2024-05-25 16:34:00,969:INFO:            pmdarima: 2.0.4
2024-05-25 16:34:00,969:INFO:              psutil: 5.9.0
2024-05-25 16:34:00,969:INFO:          markupsafe: 2.1.5
2024-05-25 16:34:00,969:INFO:             pickle5: Not installed
2024-05-25 16:34:00,969:INFO:         cloudpickle: 3.0.0
2024-05-25 16:34:00,969:INFO:         deprecation: 2.1.0
2024-05-25 16:34:00,970:INFO:              xxhash: 3.4.1
2024-05-25 16:34:00,970:INFO:           wurlitzer: Not installed
2024-05-25 16:34:00,970:INFO:PyCaret optional dependencies:
2024-05-25 16:34:00,970:INFO:                shap: Not installed
2024-05-25 16:34:00,970:INFO:           interpret: Not installed
2024-05-25 16:34:00,971:INFO:                umap: Not installed
2024-05-25 16:34:00,971:INFO:     ydata_profiling: Not installed
2024-05-25 16:34:00,971:INFO:  explainerdashboard: Not installed
2024-05-25 16:34:00,971:INFO:             autoviz: Not installed
2024-05-25 16:34:00,971:INFO:           fairlearn: Not installed
2024-05-25 16:34:00,971:INFO:          deepchecks: Not installed
2024-05-25 16:34:00,971:INFO:             xgboost: Not installed
2024-05-25 16:34:00,972:INFO:            catboost: Not installed
2024-05-25 16:34:00,972:INFO:              kmodes: Not installed
2024-05-25 16:34:00,972:INFO:             mlxtend: Not installed
2024-05-25 16:34:00,972:INFO:       statsforecast: Not installed
2024-05-25 16:34:00,972:INFO:        tune_sklearn: Not installed
2024-05-25 16:34:00,972:INFO:                 ray: Not installed
2024-05-25 16:34:00,972:INFO:            hyperopt: Not installed
2024-05-25 16:34:00,973:INFO:              optuna: Not installed
2024-05-25 16:34:00,973:INFO:               skopt: Not installed
2024-05-25 16:34:00,973:INFO:              mlflow: 2.13.0
2024-05-25 16:34:00,973:INFO:              gradio: Not installed
2024-05-25 16:34:00,973:INFO:             fastapi: Not installed
2024-05-25 16:34:00,973:INFO:             uvicorn: Not installed
2024-05-25 16:34:00,973:INFO:              m2cgen: Not installed
2024-05-25 16:34:00,974:INFO:           evidently: Not installed
2024-05-25 16:34:00,974:INFO:               fugue: Not installed
2024-05-25 16:34:00,974:INFO:           streamlit: Not installed
2024-05-25 16:34:00,974:INFO:             prophet: Not installed
2024-05-25 16:34:00,974:INFO:None
2024-05-25 16:34:00,974:INFO:Set up data.
2024-05-25 16:34:01,345:INFO:Set up folding strategy.
2024-05-25 16:34:01,345:INFO:Set up train/test split.
2024-05-25 16:34:01,398:INFO:Set up index.
2024-05-25 16:34:01,400:INFO:Assigning column types.
2024-05-25 16:34:01,420:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-25 16:34:01,493:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-25 16:34:01,494:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-25 16:34:01,539:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:34:01,540:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:34:01,612:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-25 16:34:01,614:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-25 16:34:01,659:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:34:01,660:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:34:01,660:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-25 16:34:01,736:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-25 16:34:01,781:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:34:01,782:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:34:01,857:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-25 16:34:01,903:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:34:01,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:34:01,904:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-25 16:34:02,023:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:34:02,024:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:34:02,142:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:34:02,143:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:34:02,144:INFO:Preparing preprocessing pipeline...
2024-05-25 16:34:02,149:INFO:Set up simple imputation.
2024-05-25 16:34:02,174:INFO:Set up encoding of ordinal features.
2024-05-25 16:34:02,182:INFO:Set up encoding of categorical features.
2024-05-25 16:34:02,185:INFO:Set up column name cleaning.
2024-05-25 16:34:04,366:INFO:Finished creating preprocessing pipeline.
2024-05-25 16:34:04,395:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-05-25 16:34:04,395:INFO:Creating final display dataframe.
2024-05-25 16:34:06,120:INFO:Setup _display_container:                     Description            Value
0                    Session id             8375
1                        Target           target
2                   Target type           Binary
3           Original data shape     (100000, 19)
4        Transformed data shape     (100000, 69)
5   Transformed train set shape      (90000, 69)
6    Transformed test set shape      (10000, 69)
7              Numeric features                5
8          Categorical features                9
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Fold Generator  StratifiedKFold
16                  Fold Number               10
17                     CPU Jobs               -1
18                      Use GPU            False
19               Log Experiment     MlflowLogger
20              Experiment Name         ml_codex
21                          USI             a4c8
2024-05-25 16:34:06,250:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:34:06,250:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:34:06,371:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:34:06,372:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:34:06,373:INFO:Logging experiment in loggers
2024-05-25 16:34:06,591:INFO:SubProcess save_model() called ==================================
2024-05-25 16:34:06,648:INFO:Initializing save_model()
2024-05-25 16:34:06,648:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\Adm\AppData\Local\Temp\tmpne0gwbe0\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-25 16:34:06,649:INFO:Adding model into prep_pipe
2024-05-25 16:34:06,649:WARNING:Only Model saved as it was a pipeline.
2024-05-25 16:34:06,682:INFO:C:\Users\Adm\AppData\Local\Temp\tmpne0gwbe0\Transformation Pipeline.pkl saved in current working directory
2024-05-25 16:34:06,710:INFO:Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-05-25 16:34:06,711:INFO:save_model() successfully completed......................................
2024-05-25 16:34:07,775:INFO:SubProcess save_model() end ==================================
2024-05-25 16:34:07,805:INFO:setup() successfully completed in 5.43s...............
2024-05-25 16:34:07,842:INFO:Initializing compare_models()
2024-05-25 16:34:07,842:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-25 16:34:07,843:INFO:Checking exceptions
2024-05-25 16:34:07,867:INFO:Preparing display monitor
2024-05-25 16:34:07,897:INFO:Initializing Logistic Regression
2024-05-25 16:34:07,897:INFO:Total runtime is 0.0 minutes
2024-05-25 16:34:07,902:INFO:SubProcess create_model() called ==================================
2024-05-25 16:34:07,903:INFO:Initializing create_model()
2024-05-25 16:34:07,903:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276B3730100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:34:07,903:INFO:Checking exceptions
2024-05-25 16:34:07,904:INFO:Importing libraries
2024-05-25 16:34:07,904:INFO:Copying training dataset
2024-05-25 16:34:07,951:INFO:Defining folds
2024-05-25 16:34:07,951:INFO:Declaring metric variables
2024-05-25 16:34:07,956:INFO:Importing untrained model
2024-05-25 16:34:07,961:INFO:Logistic Regression Imported successfully
2024-05-25 16:34:07,972:INFO:Starting cross validation
2024-05-25 16:34:07,978:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:34:33,717:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-25 16:34:33,878:INFO:Calculating mean and std
2024-05-25 16:34:33,880:INFO:Creating metrics dataframe
2024-05-25 16:34:33,882:INFO:Uploading results into container
2024-05-25 16:34:33,883:INFO:Uploading model into container now
2024-05-25 16:34:33,884:INFO:_master_model_container: 1
2024-05-25 16:34:33,884:INFO:_display_container: 2
2024-05-25 16:34:33,885:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8375, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-25 16:34:33,885:INFO:create_model() successfully completed......................................
2024-05-25 16:34:34,910:INFO:SubProcess create_model() end ==================================
2024-05-25 16:34:34,910:INFO:Creating metrics dataframe
2024-05-25 16:34:34,920:INFO:Initializing K Neighbors Classifier
2024-05-25 16:34:34,920:INFO:Total runtime is 0.45038195451100665 minutes
2024-05-25 16:34:34,925:INFO:SubProcess create_model() called ==================================
2024-05-25 16:34:34,926:INFO:Initializing create_model()
2024-05-25 16:34:34,926:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276B3730100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:34:34,926:INFO:Checking exceptions
2024-05-25 16:34:34,926:INFO:Importing libraries
2024-05-25 16:34:34,926:INFO:Copying training dataset
2024-05-25 16:34:34,970:INFO:Defining folds
2024-05-25 16:34:34,971:INFO:Declaring metric variables
2024-05-25 16:34:34,976:INFO:Importing untrained model
2024-05-25 16:34:34,981:INFO:K Neighbors Classifier Imported successfully
2024-05-25 16:34:34,991:INFO:Starting cross validation
2024-05-25 16:34:34,996:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:35:02,606:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 32.1 MiB for an array with shape (52, 81000) and data type float64



2024-05-25 16:35:02,607:INFO:Calculating mean and std
2024-05-25 16:35:02,609:INFO:Creating metrics dataframe
2024-05-25 16:35:02,612:INFO:Uploading results into container
2024-05-25 16:35:02,613:INFO:Uploading model into container now
2024-05-25 16:35:02,614:INFO:_master_model_container: 2
2024-05-25 16:35:02,614:INFO:_display_container: 2
2024-05-25 16:35:02,615:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-25 16:35:02,615:INFO:create_model() successfully completed......................................
2024-05-25 16:35:03,630:WARNING:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-25 16:35:03,630:WARNING:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2024-05-25 16:35:03,631:INFO:Initializing create_model()
2024-05-25 16:35:03,631:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276B3730100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:35:03,631:INFO:Checking exceptions
2024-05-25 16:35:03,631:INFO:Importing libraries
2024-05-25 16:35:03,631:INFO:Copying training dataset
2024-05-25 16:35:03,672:INFO:Defining folds
2024-05-25 16:35:03,672:INFO:Declaring metric variables
2024-05-25 16:35:03,678:INFO:Importing untrained model
2024-05-25 16:35:03,682:INFO:K Neighbors Classifier Imported successfully
2024-05-25 16:35:03,692:INFO:Starting cross validation
2024-05-25 16:35:03,698:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:35:23,525:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 176, in _reorder_cols
    new_df = new_df.drop(new_df.filter(regex="__drop__$").columns, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5344, in drop
    return super().drop(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4711, in drop
    obj = obj._drop_axis(labels, axis, level=level, errors=errors)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4792, in _drop_axis
    new_mgr = self._mgr.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 34.6 MiB for an array with shape (56, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.8 MiB for an array with shape (58, 81000) and data type float64



2024-05-25 16:35:23,525:INFO:Calculating mean and std
2024-05-25 16:35:23,527:INFO:Creating metrics dataframe
2024-05-25 16:35:23,530:INFO:Uploading results into container
2024-05-25 16:35:23,531:INFO:Uploading model into container now
2024-05-25 16:35:23,531:INFO:_master_model_container: 3
2024-05-25 16:35:23,531:INFO:_display_container: 2
2024-05-25 16:35:23,532:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-25 16:35:23,532:INFO:create_model() successfully completed......................................
2024-05-25 16:35:24,551:ERROR:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0:
2024-05-25 16:35:24,551:ERROR:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2024-05-25 16:35:24,551:INFO:Initializing Naive Bayes
2024-05-25 16:35:24,551:INFO:Total runtime is 1.2775648832321167 minutes
2024-05-25 16:35:24,556:INFO:SubProcess create_model() called ==================================
2024-05-25 16:35:24,556:INFO:Initializing create_model()
2024-05-25 16:35:24,556:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276B3730100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:35:24,557:INFO:Checking exceptions
2024-05-25 16:35:24,557:INFO:Importing libraries
2024-05-25 16:35:24,557:INFO:Copying training dataset
2024-05-25 16:35:24,599:INFO:Defining folds
2024-05-25 16:35:24,599:INFO:Declaring metric variables
2024-05-25 16:35:24,604:INFO:Importing untrained model
2024-05-25 16:35:24,610:INFO:Naive Bayes Imported successfully
2024-05-25 16:35:24,619:INFO:Starting cross validation
2024-05-25 16:35:24,624:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:35:27,773:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.4 MiB for an array with shape (20, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.2 MiB for an array with shape (57, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.4 MiB for an array with shape (20, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 9.89 MiB for an array with shape (16, 81000) and data type float64



2024-05-25 16:35:27,773:INFO:Calculating mean and std
2024-05-25 16:35:27,775:INFO:Creating metrics dataframe
2024-05-25 16:35:27,777:INFO:Uploading results into container
2024-05-25 16:35:27,778:INFO:Uploading model into container now
2024-05-25 16:35:27,779:INFO:_master_model_container: 4
2024-05-25 16:35:27,779:INFO:_display_container: 2
2024-05-25 16:35:27,779:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-25 16:35:27,779:INFO:create_model() successfully completed......................................
2024-05-25 16:35:28,818:INFO:SubProcess create_model() end ==================================
2024-05-25 16:35:28,818:INFO:Creating metrics dataframe
2024-05-25 16:35:28,829:INFO:Initializing Decision Tree Classifier
2024-05-25 16:35:28,829:INFO:Total runtime is 1.3488768100738526 minutes
2024-05-25 16:35:28,833:INFO:SubProcess create_model() called ==================================
2024-05-25 16:35:28,834:INFO:Initializing create_model()
2024-05-25 16:35:28,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276B3730100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:35:28,834:INFO:Checking exceptions
2024-05-25 16:35:28,834:INFO:Importing libraries
2024-05-25 16:35:28,835:INFO:Copying training dataset
2024-05-25 16:35:28,878:INFO:Defining folds
2024-05-25 16:35:28,878:INFO:Declaring metric variables
2024-05-25 16:35:28,884:INFO:Importing untrained model
2024-05-25 16:35:28,890:INFO:Decision Tree Classifier Imported successfully
2024-05-25 16:35:28,900:INFO:Starting cross validation
2024-05-25 16:35:28,906:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:35:32,170:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


7 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64

--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 267, in get_dummies
    base_df = mod.reindex(X[col].fillna(-2))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5141, in reindex
    return super().reindex(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 5521, in reindex
    return self._reindex_axes(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 5549, in _reindex_axes
    obj = obj._reindex_with_indexers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 5597, in _reindex_with_indexers
    new_data = new_data.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 670, in reindex_indexer
    new_blocks = [
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 671, in <listcomp>
    blk.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 633. KiB for an array with shape (81000, 1) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (25, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (25, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.85 MiB for an array with shape (3, 81000) and data type float64



2024-05-25 16:35:32,170:INFO:Calculating mean and std
2024-05-25 16:35:32,172:INFO:Creating metrics dataframe
2024-05-25 16:35:32,175:INFO:Uploading results into container
2024-05-25 16:35:32,176:INFO:Uploading model into container now
2024-05-25 16:35:32,176:INFO:_master_model_container: 5
2024-05-25 16:35:32,176:INFO:_display_container: 2
2024-05-25 16:35:32,177:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8375, splitter='best')
2024-05-25 16:35:32,178:INFO:create_model() successfully completed......................................
2024-05-25 16:35:33,195:WARNING:create_model() for DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8375, splitter='best') raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-25 16:35:33,195:WARNING:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2024-05-25 16:35:33,195:INFO:Initializing create_model()
2024-05-25 16:35:33,195:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276B3730100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:35:33,196:INFO:Checking exceptions
2024-05-25 16:35:33,196:INFO:Importing libraries
2024-05-25 16:35:33,196:INFO:Copying training dataset
2024-05-25 16:35:33,236:INFO:Defining folds
2024-05-25 16:35:33,237:INFO:Declaring metric variables
2024-05-25 16:35:33,242:INFO:Importing untrained model
2024-05-25 16:35:33,247:INFO:Decision Tree Classifier Imported successfully
2024-05-25 16:35:33,257:INFO:Starting cross validation
2024-05-25 16:35:33,262:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:35:36,729:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


8 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 176, in _reorder_cols
    new_df = new_df.drop(new_df.filter(regex="__drop__$").columns, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5344, in drop
    return super().drop(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4711, in drop
    obj = obj._drop_axis(labels, axis, level=level, errors=errors)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4792, in _drop_axis
    new_mgr = self._mgr.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 3.71 MiB for an array with shape (6, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 34.6 MiB for an array with shape (56, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 8.03 MiB for an array with shape (13, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (25, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.4 MiB for an array with shape (20, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 4.33 MiB for an array with shape (7, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64



2024-05-25 16:35:36,729:INFO:Calculating mean and std
2024-05-25 16:35:36,731:INFO:Creating metrics dataframe
2024-05-25 16:35:36,734:INFO:Uploading results into container
2024-05-25 16:35:36,734:INFO:Uploading model into container now
2024-05-25 16:35:36,735:INFO:_master_model_container: 6
2024-05-25 16:35:36,735:INFO:_display_container: 2
2024-05-25 16:35:36,736:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8375, splitter='best')
2024-05-25 16:35:36,736:INFO:create_model() successfully completed......................................
2024-05-25 16:35:37,750:ERROR:create_model() for DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8375, splitter='best') raised an exception or returned all 0.0:
2024-05-25 16:35:37,751:ERROR:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2024-05-25 16:35:37,751:INFO:Initializing SVM - Linear Kernel
2024-05-25 16:35:37,751:INFO:Total runtime is 1.4975750168164572 minutes
2024-05-25 16:35:37,756:INFO:SubProcess create_model() called ==================================
2024-05-25 16:35:37,756:INFO:Initializing create_model()
2024-05-25 16:35:37,756:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276B3730100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:35:37,757:INFO:Checking exceptions
2024-05-25 16:35:37,757:INFO:Importing libraries
2024-05-25 16:35:37,757:INFO:Copying training dataset
2024-05-25 16:35:37,798:INFO:Defining folds
2024-05-25 16:35:37,798:INFO:Declaring metric variables
2024-05-25 16:35:37,804:INFO:Importing untrained model
2024-05-25 16:35:37,810:INFO:SVM - Linear Kernel Imported successfully
2024-05-25 16:35:37,819:INFO:Starting cross validation
2024-05-25 16:35:37,825:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:35:40,575:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


7 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (25, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (25, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 11.7 MiB for an array with shape (19, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 267, in get_dummies
    base_df = mod.reindex(X[col].fillna(-2))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5141, in reindex
    return super().reindex(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 5521, in reindex
    return self._reindex_axes(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 5549, in _reindex_axes
    obj = obj._reindex_with_indexers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 5597, in _reindex_with_indexers
    new_data = new_data.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 670, in reindex_indexer
    new_blocks = [
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 671, in <listcomp>
    blk.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 633. KiB for an array with shape (81000, 1) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 9.89 MiB for an array with shape (16, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 3.71 MiB for an array with shape (6, 81000) and data type float64



2024-05-25 16:35:40,575:INFO:Calculating mean and std
2024-05-25 16:35:40,577:INFO:Creating metrics dataframe
2024-05-25 16:35:40,579:INFO:Uploading results into container
2024-05-25 16:35:40,580:INFO:Uploading model into container now
2024-05-25 16:35:40,581:INFO:_master_model_container: 7
2024-05-25 16:35:40,581:INFO:_display_container: 2
2024-05-25 16:35:40,582:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8375, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-25 16:35:40,582:INFO:create_model() successfully completed......................................
2024-05-25 16:35:41,591:WARNING:create_model() for SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8375, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-25 16:35:41,592:WARNING:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2024-05-25 16:35:41,592:INFO:Initializing create_model()
2024-05-25 16:35:41,592:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276B3730100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:35:41,592:INFO:Checking exceptions
2024-05-25 16:35:41,592:INFO:Importing libraries
2024-05-25 16:35:41,592:INFO:Copying training dataset
2024-05-25 16:35:41,633:INFO:Defining folds
2024-05-25 16:35:41,633:INFO:Declaring metric variables
2024-05-25 16:35:41,639:INFO:Importing untrained model
2024-05-25 16:35:41,644:INFO:SVM - Linear Kernel Imported successfully
2024-05-25 16:35:41,653:INFO:Starting cross validation
2024-05-25 16:35:41,658:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:35:44,262:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


8 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.8 MiB for an array with shape (58, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.8 MiB for an array with shape (58, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (25, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (25, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 9.89 MiB for an array with shape (16, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.85 MiB for an array with shape (3, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (25, 81000) and data type float64



2024-05-25 16:35:44,262:INFO:Calculating mean and std
2024-05-25 16:35:44,264:INFO:Creating metrics dataframe
2024-05-25 16:35:44,267:INFO:Uploading results into container
2024-05-25 16:35:44,267:INFO:Uploading model into container now
2024-05-25 16:35:44,268:INFO:_master_model_container: 8
2024-05-25 16:35:44,268:INFO:_display_container: 2
2024-05-25 16:35:44,269:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8375, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-25 16:35:44,269:INFO:create_model() successfully completed......................................
2024-05-25 16:35:45,308:ERROR:create_model() for SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8375, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False) raised an exception or returned all 0.0:
2024-05-25 16:35:45,308:ERROR:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2024-05-25 16:35:45,309:INFO:Initializing Ridge Classifier
2024-05-25 16:35:45,309:INFO:Total runtime is 1.6235342383384705 minutes
2024-05-25 16:35:45,313:INFO:SubProcess create_model() called ==================================
2024-05-25 16:35:45,314:INFO:Initializing create_model()
2024-05-25 16:35:45,314:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276B3730100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:35:45,314:INFO:Checking exceptions
2024-05-25 16:35:45,314:INFO:Importing libraries
2024-05-25 16:35:45,314:INFO:Copying training dataset
2024-05-25 16:35:45,356:INFO:Defining folds
2024-05-25 16:35:45,357:INFO:Declaring metric variables
2024-05-25 16:35:45,362:INFO:Importing untrained model
2024-05-25 16:35:45,366:INFO:Ridge Classifier Imported successfully
2024-05-25 16:35:45,377:INFO:Starting cross validation
2024-05-25 16:35:45,383:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:35:47,682:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.43616e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 16:35:47,866:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


9 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (25, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (25, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.8 MiB for an array with shape (58, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.8 MiB for an array with shape (58, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 9.89 MiB for an array with shape (16, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64

--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 9.89 MiB for an array with shape (16, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.4 MiB for an array with shape (20, 81000) and data type float64



2024-05-25 16:35:47,866:INFO:Calculating mean and std
2024-05-25 16:35:47,868:INFO:Creating metrics dataframe
2024-05-25 16:35:47,871:INFO:Uploading results into container
2024-05-25 16:35:47,871:INFO:Uploading model into container now
2024-05-25 16:35:47,872:INFO:_master_model_container: 9
2024-05-25 16:35:47,872:INFO:_display_container: 2
2024-05-25 16:35:47,873:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8375, solver='auto',
                tol=0.0001)
2024-05-25 16:35:47,873:INFO:create_model() successfully completed......................................
2024-05-25 16:35:48,877:INFO:SubProcess create_model() end ==================================
2024-05-25 16:35:48,878:INFO:Creating metrics dataframe
2024-05-25 16:35:48,888:INFO:Initializing Random Forest Classifier
2024-05-25 16:35:48,888:INFO:Total runtime is 1.6831888516743978 minutes
2024-05-25 16:35:48,893:INFO:SubProcess create_model() called ==================================
2024-05-25 16:35:48,893:INFO:Initializing create_model()
2024-05-25 16:35:48,893:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276B3730100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:35:48,893:INFO:Checking exceptions
2024-05-25 16:35:48,894:INFO:Importing libraries
2024-05-25 16:35:48,894:INFO:Copying training dataset
2024-05-25 16:35:48,936:INFO:Defining folds
2024-05-25 16:35:48,936:INFO:Declaring metric variables
2024-05-25 16:35:48,941:INFO:Importing untrained model
2024-05-25 16:35:48,946:INFO:Random Forest Classifier Imported successfully
2024-05-25 16:35:48,956:INFO:Starting cross validation
2024-05-25 16:35:48,962:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:35:53,749:WARNING:create_model() for rf raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-25 16:35:53,750:WARNING:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (25, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.8 MiB for an array with shape (58, 81000) and data type float64

--------------------------------------------------------------------------------
3 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 192, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 2097152 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 2097152 bytes

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 8.03 MiB for an array with shape (13, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 182, in _parallel_build_trees
    sample_counts = np.bincount(indices, minlength=n_samples)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 633. KiB for an array with shape (81000,) and data type int64
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 633. KiB for an array with shape (81000,) and data type int64


2024-05-25 16:35:53,751:INFO:Initializing create_model()
2024-05-25 16:35:53,751:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276B3730100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:35:53,751:INFO:Checking exceptions
2024-05-25 16:35:53,751:INFO:Importing libraries
2024-05-25 16:35:53,751:INFO:Copying training dataset
2024-05-25 16:35:53,813:INFO:Defining folds
2024-05-25 16:35:53,813:INFO:Declaring metric variables
2024-05-25 16:35:53,821:INFO:Importing untrained model
2024-05-25 16:35:53,827:INFO:Random Forest Classifier Imported successfully
2024-05-25 16:35:53,839:INFO:Starting cross validation
2024-05-25 16:35:53,846:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:35:54,617:ERROR:create_model() for rf raised an exception or returned all 0.0:
2024-05-25 16:35:54,618:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\externals\loky\backend\queues.py", line 159, in _feed
    obj_ = dumps(obj, reducers=reducers)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 215, in dumps
    dump(obj, buf, reducers=reducers, protocol=protocol)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 208, in dump
    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\externals\cloudpickle\cloudpickle_fast.py", line 632, in dump
    return Pickler.dump(self, obj)
MemoryError
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
_pickle.PicklingError: Could not pickle the task to send it to the workers.

2024-05-25 16:35:54,618:INFO:Initializing Quadratic Discriminant Analysis
2024-05-25 16:35:54,618:INFO:Total runtime is 1.7786868611971538 minutes
2024-05-25 16:35:54,623:INFO:SubProcess create_model() called ==================================
2024-05-25 16:35:54,623:INFO:Initializing create_model()
2024-05-25 16:35:54,624:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276B3730100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:35:54,624:INFO:Checking exceptions
2024-05-25 16:35:54,624:INFO:Importing libraries
2024-05-25 16:35:54,624:INFO:Copying training dataset
2024-05-25 16:35:54,676:INFO:Defining folds
2024-05-25 16:35:54,677:INFO:Declaring metric variables
2024-05-25 16:35:54,682:INFO:Importing untrained model
2024-05-25 16:35:54,688:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-25 16:35:54,700:INFO:Starting cross validation
2024-05-25 16:35:54,706:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:36:05,550:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:36:06,361:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:36:06,500:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:36:06,514:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:36:06,527:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:36:06,543:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:36:06,571:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-05-25 16:36:06,573:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-05-25 16:36:06,576:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:36:06,636:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-05-25 16:36:06,646:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:36:06,664:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-05-25 16:36:06,665:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-05-25 16:36:06,730:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-05-25 16:36:06,769:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-25 16:36:06,796:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:36:06,840:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-25 16:36:08,487:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py", line 930, in fit
    Xgc = Xg - meang
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 22.6 MiB for an array with shape (43544, 68) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py", line 930, in fit
    Xgc = Xg - meang
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 19.4 MiB for an array with shape (37456, 68) and data type float64



2024-05-25 16:36:08,488:INFO:Calculating mean and std
2024-05-25 16:36:08,491:INFO:Creating metrics dataframe
2024-05-25 16:36:08,494:INFO:Uploading results into container
2024-05-25 16:36:08,495:INFO:Uploading model into container now
2024-05-25 16:36:08,496:INFO:_master_model_container: 10
2024-05-25 16:36:08,497:INFO:_display_container: 2
2024-05-25 16:36:08,498:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-25 16:36:08,498:INFO:create_model() successfully completed......................................
2024-05-25 16:36:09,758:INFO:SubProcess create_model() end ==================================
2024-05-25 16:36:09,759:INFO:Creating metrics dataframe
2024-05-25 16:36:09,771:INFO:Initializing Ada Boost Classifier
2024-05-25 16:36:09,771:INFO:Total runtime is 2.031232802073161 minutes
2024-05-25 16:36:09,777:INFO:SubProcess create_model() called ==================================
2024-05-25 16:36:09,778:INFO:Initializing create_model()
2024-05-25 16:36:09,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276B3730100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:36:09,778:INFO:Checking exceptions
2024-05-25 16:36:09,778:INFO:Importing libraries
2024-05-25 16:36:09,779:INFO:Copying training dataset
2024-05-25 16:36:09,830:INFO:Defining folds
2024-05-25 16:36:09,831:INFO:Declaring metric variables
2024-05-25 16:36:09,836:INFO:Importing untrained model
2024-05-25 16:36:09,843:INFO:Ada Boost Classifier Imported successfully
2024-05-25 16:36:09,853:INFO:Starting cross validation
2024-05-25 16:36:09,862:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:36:12,645:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:36:12,698:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:36:12,729:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:36:12,743:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:36:17,133:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:36:17,411:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:36:23,926:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


4 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 9.89 MiB for an array with shape (16, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 4.33 MiB for an array with shape (7, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.8 MiB for an array with shape (58, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.47 MiB for an array with shape (4, 81000) and data type float64



2024-05-25 16:36:23,926:INFO:Calculating mean and std
2024-05-25 16:36:23,929:INFO:Creating metrics dataframe
2024-05-25 16:36:23,932:INFO:Uploading results into container
2024-05-25 16:36:23,932:INFO:Uploading model into container now
2024-05-25 16:36:23,933:INFO:_master_model_container: 11
2024-05-25 16:36:23,933:INFO:_display_container: 2
2024-05-25 16:36:23,933:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8375)
2024-05-25 16:36:23,934:INFO:create_model() successfully completed......................................
2024-05-25 16:36:25,065:WARNING:create_model() for AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8375) raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-25 16:36:25,066:WARNING:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2024-05-25 16:36:25,066:INFO:Initializing create_model()
2024-05-25 16:36:25,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276B3730100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:36:25,066:INFO:Checking exceptions
2024-05-25 16:36:25,066:INFO:Importing libraries
2024-05-25 16:36:25,067:INFO:Copying training dataset
2024-05-25 16:36:25,108:INFO:Defining folds
2024-05-25 16:36:25,109:INFO:Declaring metric variables
2024-05-25 16:36:25,113:INFO:Importing untrained model
2024-05-25 16:36:25,118:INFO:Ada Boost Classifier Imported successfully
2024-05-25 16:36:25,128:INFO:Starting cross validation
2024-05-25 16:36:25,133:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:36:27,658:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:36:27,704:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:36:27,720:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:36:27,738:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:36:27,873:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:36:34,389:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 267, in get_dummies
    base_df = mod.reindex(X[col].fillna(-2))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5141, in reindex
    return super().reindex(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 5521, in reindex
    return self._reindex_axes(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 5549, in _reindex_axes
    obj = obj._reindex_with_indexers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 5597, in _reindex_with_indexers
    new_data = new_data.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 670, in reindex_indexer
    new_blocks = [
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 671, in <listcomp>
    blk.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 633. KiB for an array with shape (81000, 1) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 9.89 MiB for an array with shape (16, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 633. KiB for an array with shape (1, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 8.03 MiB for an array with shape (13, 81000) and data type float64



2024-05-25 16:36:34,390:INFO:Calculating mean and std
2024-05-25 16:36:34,392:INFO:Creating metrics dataframe
2024-05-25 16:36:34,396:INFO:Uploading results into container
2024-05-25 16:36:34,397:INFO:Uploading model into container now
2024-05-25 16:36:34,398:INFO:_master_model_container: 12
2024-05-25 16:36:34,398:INFO:_display_container: 2
2024-05-25 16:36:34,399:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8375)
2024-05-25 16:36:34,399:INFO:create_model() successfully completed......................................
2024-05-25 16:36:35,494:INFO:SubProcess create_model() end ==================================
2024-05-25 16:36:35,494:INFO:Creating metrics dataframe
2024-05-25 16:36:35,506:INFO:Initializing Gradient Boosting Classifier
2024-05-25 16:36:35,506:INFO:Total runtime is 2.460158717632294 minutes
2024-05-25 16:36:35,511:INFO:SubProcess create_model() called ==================================
2024-05-25 16:36:35,511:INFO:Initializing create_model()
2024-05-25 16:36:35,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276B3730100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:36:35,512:INFO:Checking exceptions
2024-05-25 16:36:35,512:INFO:Importing libraries
2024-05-25 16:36:35,512:INFO:Copying training dataset
2024-05-25 16:36:35,555:INFO:Defining folds
2024-05-25 16:36:35,555:INFO:Declaring metric variables
2024-05-25 16:36:35,560:INFO:Importing untrained model
2024-05-25 16:36:35,566:INFO:Gradient Boosting Classifier Imported successfully
2024-05-25 16:36:35,577:INFO:Starting cross validation
2024-05-25 16:36:35,583:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:36:53,785:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 178, in _reorder_cols
    return new_df[columns]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 3908, in __getitem__
    data = self._take_with_is_copy(indexer, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4088, in _take_with_is_copy
    result = self.take(indices=indices, axis=axis)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4068, in take
    new_data = self._mgr.take(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 877, in take
    return self.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 34.6 MiB for an array with shape (56, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 34.6 MiB for an array with shape (56, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.8 MiB for an array with shape (58, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.4 MiB for an array with shape (20, 81000) and data type float64



2024-05-25 16:36:53,785:INFO:Calculating mean and std
2024-05-25 16:36:53,787:INFO:Creating metrics dataframe
2024-05-25 16:36:53,790:INFO:Uploading results into container
2024-05-25 16:36:53,790:INFO:Uploading model into container now
2024-05-25 16:36:53,791:INFO:_master_model_container: 13
2024-05-25 16:36:53,791:INFO:_display_container: 2
2024-05-25 16:36:53,792:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8375, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-25 16:36:53,793:INFO:create_model() successfully completed......................................
2024-05-25 16:36:54,822:INFO:SubProcess create_model() end ==================================
2024-05-25 16:36:54,822:INFO:Creating metrics dataframe
2024-05-25 16:36:54,834:INFO:Initializing Linear Discriminant Analysis
2024-05-25 16:36:54,834:INFO:Total runtime is 2.7822867870330814 minutes
2024-05-25 16:36:54,839:INFO:SubProcess create_model() called ==================================
2024-05-25 16:36:54,839:INFO:Initializing create_model()
2024-05-25 16:36:54,839:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276B3730100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:36:54,840:INFO:Checking exceptions
2024-05-25 16:36:54,840:INFO:Importing libraries
2024-05-25 16:36:54,840:INFO:Copying training dataset
2024-05-25 16:36:54,883:INFO:Defining folds
2024-05-25 16:36:54,884:INFO:Declaring metric variables
2024-05-25 16:36:54,888:INFO:Importing untrained model
2024-05-25 16:36:54,896:INFO:Linear Discriminant Analysis Imported successfully
2024-05-25 16:36:54,906:INFO:Starting cross validation
2024-05-25 16:36:54,911:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:36:59,445:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


7 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 274, in get_dummies
    X = X.reindex(columns=cols)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5141, in reindex
    return super().reindex(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 5521, in reindex
    return self._reindex_axes(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 5549, in _reindex_axes
    obj = obj._reindex_with_indexers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 5597, in _reindex_with_indexers
    new_data = new_data.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.47 MiB for an array with shape (4, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py", line 628, in fit
    self._solve_svd(X, y)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py", line 520, in _solve_svd
    X = xp.sqrt(fac) * (Xc / std)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 42.0 MiB for an array with shape (81000, 68) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.4 MiB for an array with shape (20, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py", line 628, in fit
    self._solve_svd(X, y)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py", line 511, in _solve_svd
    Xc = xp.concat(Xc, axis=0)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_array_api.py", line 310, in concat
    return numpy.concatenate(arrays, axis=axis)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 42.0 MiB for an array with shape (81000, 68) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.8 MiB for an array with shape (58, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 42.0 MiB for an array with shape (81000, 68) and data type float64

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py", line 628, in fit
    self._solve_svd(X, y)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py", line 522, in _solve_svd
    U, S, Vt = svd(X, full_matrices=False)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\scipy\linalg\_decomp_svd.py", line 127, in svd
    u, s, v, info = gesXd(a1, compute_uv=compute_uv, lwork=lwork,
TypeError: _ArrayMemoryError.__init__() missing 1 required positional argument: 'dtype'

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.4 MiB for an array with shape (20, 81000) and data type float64



2024-05-25 16:36:59,445:INFO:Calculating mean and std
2024-05-25 16:36:59,451:INFO:Creating metrics dataframe
2024-05-25 16:36:59,454:INFO:Uploading results into container
2024-05-25 16:36:59,455:INFO:Uploading model into container now
2024-05-25 16:36:59,455:INFO:_master_model_container: 14
2024-05-25 16:36:59,456:INFO:_display_container: 2
2024-05-25 16:36:59,456:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-25 16:36:59,457:INFO:create_model() successfully completed......................................
2024-05-25 16:37:00,600:INFO:SubProcess create_model() end ==================================
2024-05-25 16:37:00,600:INFO:Creating metrics dataframe
2024-05-25 16:37:00,613:INFO:Initializing Extra Trees Classifier
2024-05-25 16:37:00,614:INFO:Total runtime is 2.878620608647665 minutes
2024-05-25 16:37:00,618:INFO:SubProcess create_model() called ==================================
2024-05-25 16:37:00,619:INFO:Initializing create_model()
2024-05-25 16:37:00,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276B3730100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:37:00,619:INFO:Checking exceptions
2024-05-25 16:37:00,619:INFO:Importing libraries
2024-05-25 16:37:00,619:INFO:Copying training dataset
2024-05-25 16:37:00,663:INFO:Defining folds
2024-05-25 16:37:00,664:INFO:Declaring metric variables
2024-05-25 16:37:00,669:INFO:Importing untrained model
2024-05-25 16:37:00,674:INFO:Extra Trees Classifier Imported successfully
2024-05-25 16:37:00,685:INFO:Starting cross validation
2024-05-25 16:37:00,690:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:37:09,133:WARNING:create_model() for et raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-25 16:37:09,135:WARNING:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.8 MiB for an array with shape (58, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.4 MiB for an array with shape (20, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 1048576 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 1048576 bytes

--------------------------------------------------------------------------------
2 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 4194304 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 4194304 bytes

--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 633. KiB for an array with shape (1, 81000) and data type float64


2024-05-25 16:37:09,135:INFO:Initializing create_model()
2024-05-25 16:37:09,136:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276B3730100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:37:09,136:INFO:Checking exceptions
2024-05-25 16:37:09,136:INFO:Importing libraries
2024-05-25 16:37:09,136:INFO:Copying training dataset
2024-05-25 16:37:09,240:INFO:Defining folds
2024-05-25 16:37:09,241:INFO:Declaring metric variables
2024-05-25 16:37:09,248:INFO:Importing untrained model
2024-05-25 16:37:09,257:INFO:Extra Trees Classifier Imported successfully
2024-05-25 16:37:09,302:INFO:Starting cross validation
2024-05-25 16:37:09,312:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:37:14,140:ERROR:create_model() for et raised an exception or returned all 0.0:
2024-05-25 16:37:14,143:ERROR:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 35.8 MiB for an array with shape (58, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.4 MiB for an array with shape (20, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 1048576 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 1048576 bytes

--------------------------------------------------------------------------------
2 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 4194304 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 4194304 bytes

--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 633. KiB for an array with shape (1, 81000) and data type float64


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 27.8 MiB for an array with shape (45, 81000) and data type float64

--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (25, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 2097152 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 2097152 bytes

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (25, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 9.89 MiB for an array with shape (16, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 4194304 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 4194304 bytes

--------------------------------------------------------------------------------
1 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 303, in _fit
    y_encoded = np.zeros(y.shape, dtype=int)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 316. KiB for an array with shape (81000, 1) and data type int32
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 316. KiB for an array with shape (81000, 1) and data type int32

--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 189, in _transform
    X = self.ordinal_encoder.transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\ordinal.py", line 113, in _transform
    X, _ = self.ordinal_encoding(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\ordinal.py", line 198, in ordinal_encoding
    X[column] = X[column].astype("object").fillna(np.nan).map(col_mapping)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\series.py", line 4544, in map
    new_values = self._map_values(arg, na_action=na_action)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\base.py", line 921, in _map_values
    return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\algorithms.py", line 1803, in map_array
    indexer = mapper.index.get_indexer(arr)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\indexes\base.py", line 3870, in get_indexer
    target = self._maybe_cast_listlike_indexer(target)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\indexes\base.py", line 6623, in _maybe_cast_listlike_indexer
    return ensure_index(target)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\indexes\base.py", line 7577, in ensure_index
    return Index(index_like, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\indexes\base.py", line 560, in __new__
    arr = sanitize_array(data, None, dtype=dtype, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\construction.py", line 608, in sanitize_array
    subarr = maybe_infer_to_datetimelike(data)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\dtypes\cast.py", line 1180, in maybe_infer_to_datetimelike
    return lib.maybe_convert_objects(  # type: ignore[return-value]
  File "lib.pyx", line 2521, in pandas._libs.lib.maybe_convert_objects
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.24 MiB for an array with shape (81000,) and data type complex128


2024-05-25 16:37:14,144:INFO:Initializing Light Gradient Boosting Machine
2024-05-25 16:37:14,144:INFO:Total runtime is 3.104127514362336 minutes
2024-05-25 16:37:14,151:INFO:SubProcess create_model() called ==================================
2024-05-25 16:37:14,152:INFO:Initializing create_model()
2024-05-25 16:37:14,152:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276B3730100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:37:14,152:INFO:Checking exceptions
2024-05-25 16:37:14,152:INFO:Importing libraries
2024-05-25 16:37:14,153:INFO:Copying training dataset
2024-05-25 16:37:14,234:INFO:Defining folds
2024-05-25 16:37:14,234:INFO:Declaring metric variables
2024-05-25 16:37:14,240:INFO:Importing untrained model
2024-05-25 16:37:14,247:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 16:37:14,260:INFO:Starting cross validation
2024-05-25 16:37:14,269:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:37:15,199:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-25 16:37:15,200:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\externals\loky\process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\multiprocessing\queues.py", line 122, in get
    return _ForkingPickler.loads(res)
MemoryError
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.

2024-05-25 16:37:15,201:INFO:Initializing create_model()
2024-05-25 16:37:15,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276B3730100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:37:15,201:INFO:Checking exceptions
2024-05-25 16:37:15,201:INFO:Importing libraries
2024-05-25 16:37:15,201:INFO:Copying training dataset
2024-05-25 16:37:15,241:INFO:Defining folds
2024-05-25 16:37:15,242:INFO:Declaring metric variables
2024-05-25 16:37:15,246:INFO:Importing untrained model
2024-05-25 16:37:15,251:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 16:37:15,261:INFO:Starting cross validation
2024-05-25 16:37:15,267:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:37:27,156:INFO:Calculating mean and std
2024-05-25 16:37:27,163:INFO:Creating metrics dataframe
2024-05-25 16:37:27,166:INFO:Uploading results into container
2024-05-25 16:37:27,167:INFO:Uploading model into container now
2024-05-25 16:37:27,168:INFO:_master_model_container: 15
2024-05-25 16:37:27,168:INFO:_display_container: 2
2024-05-25 16:37:27,169:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8375, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-25 16:37:27,170:INFO:create_model() successfully completed......................................
2024-05-25 16:37:28,221:INFO:SubProcess create_model() end ==================================
2024-05-25 16:37:28,221:INFO:Creating metrics dataframe
2024-05-25 16:37:28,234:INFO:Initializing Dummy Classifier
2024-05-25 16:37:28,235:INFO:Total runtime is 3.3389773567517604 minutes
2024-05-25 16:37:28,239:INFO:SubProcess create_model() called ==================================
2024-05-25 16:37:28,240:INFO:Initializing create_model()
2024-05-25 16:37:28,240:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000276B3730100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:37:28,240:INFO:Checking exceptions
2024-05-25 16:37:28,240:INFO:Importing libraries
2024-05-25 16:37:28,241:INFO:Copying training dataset
2024-05-25 16:37:28,282:INFO:Defining folds
2024-05-25 16:37:28,283:INFO:Declaring metric variables
2024-05-25 16:37:28,288:INFO:Importing untrained model
2024-05-25 16:37:28,294:INFO:Dummy Classifier Imported successfully
2024-05-25 16:37:28,305:INFO:Starting cross validation
2024-05-25 16:37:28,310:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:37:35,296:INFO:Calculating mean and std
2024-05-25 16:37:35,297:INFO:Creating metrics dataframe
2024-05-25 16:37:35,300:INFO:Uploading results into container
2024-05-25 16:37:35,301:INFO:Uploading model into container now
2024-05-25 16:37:35,301:INFO:_master_model_container: 16
2024-05-25 16:37:35,302:INFO:_display_container: 2
2024-05-25 16:37:35,302:INFO:DummyClassifier(constant=None, random_state=8375, strategy='prior')
2024-05-25 16:37:35,302:INFO:create_model() successfully completed......................................
2024-05-25 16:37:36,334:INFO:SubProcess create_model() end ==================================
2024-05-25 16:37:36,334:INFO:Creating metrics dataframe
2024-05-25 16:37:36,348:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2024-05-25 16:37:36,359:INFO:Initializing create_model()
2024-05-25 16:37:36,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8375, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:37:36,360:INFO:Checking exceptions
2024-05-25 16:37:36,362:INFO:Importing libraries
2024-05-25 16:37:36,362:INFO:Copying training dataset
2024-05-25 16:37:36,405:INFO:Defining folds
2024-05-25 16:37:36,405:INFO:Declaring metric variables
2024-05-25 16:37:36,406:INFO:Importing untrained model
2024-05-25 16:37:36,406:INFO:Declaring custom model
2024-05-25 16:37:36,407:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 16:37:36,411:INFO:Cross validation set to False
2024-05-25 16:37:36,411:INFO:Fitting Model
2024-05-25 16:37:37,927:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 16:37:37,932:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 16:37:37,944:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004069 seconds.
2024-05-25 16:37:37,944:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 16:37:37,944:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 16:37:37,945:INFO:[LightGBM] [Info] Total Bins 1652
2024-05-25 16:37:37,945:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 62
2024-05-25 16:37:37,946:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 16:37:37,946:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 16:37:38,238:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8375, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-25 16:37:38,238:INFO:create_model() successfully completed......................................
2024-05-25 16:37:39,264:INFO:Creating Dashboard logs
2024-05-25 16:37:39,269:INFO:Model: Light Gradient Boosting Machine
2024-05-25 16:37:39,357:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 8375, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-05-25 16:37:39,574:INFO:Initializing predict_model()
2024-05-25 16:37:39,574:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002769D277C70>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8375, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027696F5AA70>)
2024-05-25 16:37:39,575:INFO:Checking exceptions
2024-05-25 16:37:39,575:INFO:Preloading libraries
2024-05-25 16:37:42,122:INFO:Creating Dashboard logs
2024-05-25 16:37:42,127:INFO:Model: Logistic Regression
2024-05-25 16:37:42,197:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 8375, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-05-25 16:37:43,567:INFO:Creating Dashboard logs
2024-05-25 16:37:43,572:INFO:Model: Dummy Classifier
2024-05-25 16:37:43,723:INFO:Logged params: {'constant': None, 'random_state': 8375, 'strategy': 'prior'}
2024-05-25 16:37:45,472:INFO:Creating Dashboard logs
2024-05-25 16:37:45,477:INFO:Model: Quadratic Discriminant Analysis
2024-05-25 16:37:45,547:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2024-05-25 16:37:46,872:INFO:Creating Dashboard logs
2024-05-25 16:37:46,877:INFO:Model: Gradient Boosting Classifier
2024-05-25 16:37:46,952:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 8375, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-25 16:37:48,494:INFO:Creating Dashboard logs
2024-05-25 16:37:48,499:INFO:Model: Ada Boost Classifier
2024-05-25 16:37:48,569:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 8375}
2024-05-25 16:37:49,881:INFO:Creating Dashboard logs
2024-05-25 16:37:49,886:INFO:Model: Linear Discriminant Analysis
2024-05-25 16:37:49,956:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-05-25 16:37:51,276:INFO:Creating Dashboard logs
2024-05-25 16:37:51,281:INFO:Model: Naive Bayes
2024-05-25 16:37:51,351:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-05-25 16:37:52,744:INFO:Creating Dashboard logs
2024-05-25 16:37:52,748:INFO:Model: Ridge Classifier
2024-05-25 16:37:52,820:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 8375, 'solver': 'auto', 'tol': 0.0001}
2024-05-25 16:37:54,211:INFO:_master_model_container: 16
2024-05-25 16:37:54,211:INFO:_display_container: 2
2024-05-25 16:37:54,212:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8375, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-25 16:37:54,212:INFO:compare_models() successfully completed......................................
2024-05-25 16:51:59,769:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-25 16:51:59,769:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-25 16:51:59,769:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-25 16:51:59,769:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-25 16:57:22,678:INFO:PyCaret ClassificationExperiment
2024-05-25 16:57:22,679:INFO:Logging name: ml_codex
2024-05-25 16:57:22,679:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-25 16:57:22,679:INFO:version 3.3.2
2024-05-25 16:57:22,679:INFO:Initializing setup()
2024-05-25 16:57:22,679:INFO:self.USI: eb97
2024-05-25 16:57:22,679:INFO:self._variable_keys: {'exp_id', '_available_plots', 'memory', 'y_test', 'gpu_n_jobs_param', 'fold_generator', '_ml_usecase', 'USI', 'fold_groups_param', 'n_jobs_param', 'X_train', 'y_train', 'html_param', 'logging_param', 'X', 'X_test', 'seed', 'data', 'target_param', 'fold_shuffle_param', 'gpu_param', 'idx', 'pipeline', 'fix_imbalance', 'y', 'exp_name_log', 'is_multiclass', 'log_plots_param'}
2024-05-25 16:57:22,679:INFO:Checking environment
2024-05-25 16:57:22,679:INFO:python_version: 3.10.13
2024-05-25 16:57:22,679:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-25 16:57:22,680:INFO:machine: AMD64
2024-05-25 16:57:22,680:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-25 16:57:22,680:INFO:Memory: svmem(total=34267656192, available=13913989120, percent=59.4, used=20353667072, free=13913989120)
2024-05-25 16:57:22,680:INFO:Physical Core: 8
2024-05-25 16:57:22,680:INFO:Logical Core: 16
2024-05-25 16:57:22,680:INFO:Checking libraries
2024-05-25 16:57:22,680:INFO:System:
2024-05-25 16:57:22,680:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-25 16:57:22,680:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-25 16:57:22,680:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-25 16:57:22,680:INFO:PyCaret required dependencies:
2024-05-25 16:57:22,718:INFO:                 pip: 23.3
2024-05-25 16:57:22,718:INFO:          setuptools: 68.0.0
2024-05-25 16:57:22,719:INFO:             pycaret: 3.3.2
2024-05-25 16:57:22,719:INFO:             IPython: 8.24.0
2024-05-25 16:57:22,719:INFO:          ipywidgets: 8.1.2
2024-05-25 16:57:22,719:INFO:                tqdm: 4.66.4
2024-05-25 16:57:22,719:INFO:               numpy: 1.26.4
2024-05-25 16:57:22,719:INFO:              pandas: 2.1.4
2024-05-25 16:57:22,719:INFO:              jinja2: 3.1.4
2024-05-25 16:57:22,719:INFO:               scipy: 1.11.4
2024-05-25 16:57:22,719:INFO:              joblib: 1.3.2
2024-05-25 16:57:22,719:INFO:             sklearn: 1.4.2
2024-05-25 16:57:22,719:INFO:                pyod: 1.1.3
2024-05-25 16:57:22,719:INFO:            imblearn: 0.12.2
2024-05-25 16:57:22,720:INFO:   category_encoders: 2.6.3
2024-05-25 16:57:22,720:INFO:            lightgbm: 4.3.0
2024-05-25 16:57:22,720:INFO:               numba: 0.59.1
2024-05-25 16:57:22,720:INFO:            requests: 2.32.2
2024-05-25 16:57:22,720:INFO:          matplotlib: 3.7.5
2024-05-25 16:57:22,720:INFO:          scikitplot: 0.3.7
2024-05-25 16:57:22,720:INFO:         yellowbrick: 1.5
2024-05-25 16:57:22,720:INFO:              plotly: 5.22.0
2024-05-25 16:57:22,720:INFO:    plotly-resampler: Not installed
2024-05-25 16:57:22,720:INFO:             kaleido: 0.2.1
2024-05-25 16:57:22,720:INFO:           schemdraw: 0.15
2024-05-25 16:57:22,720:INFO:         statsmodels: 0.14.2
2024-05-25 16:57:22,721:INFO:              sktime: 0.26.0
2024-05-25 16:57:22,721:INFO:               tbats: 1.1.3
2024-05-25 16:57:22,721:INFO:            pmdarima: 2.0.4
2024-05-25 16:57:22,721:INFO:              psutil: 5.9.0
2024-05-25 16:57:22,721:INFO:          markupsafe: 2.1.5
2024-05-25 16:57:22,721:INFO:             pickle5: Not installed
2024-05-25 16:57:22,721:INFO:         cloudpickle: 3.0.0
2024-05-25 16:57:22,721:INFO:         deprecation: 2.1.0
2024-05-25 16:57:22,721:INFO:              xxhash: 3.4.1
2024-05-25 16:57:22,721:INFO:           wurlitzer: Not installed
2024-05-25 16:57:22,722:INFO:PyCaret optional dependencies:
2024-05-25 16:57:22,794:INFO:                shap: Not installed
2024-05-25 16:57:22,794:INFO:           interpret: Not installed
2024-05-25 16:57:22,794:INFO:                umap: Not installed
2024-05-25 16:57:22,794:INFO:     ydata_profiling: Not installed
2024-05-25 16:57:22,794:INFO:  explainerdashboard: Not installed
2024-05-25 16:57:22,794:INFO:             autoviz: Not installed
2024-05-25 16:57:22,794:INFO:           fairlearn: Not installed
2024-05-25 16:57:22,794:INFO:          deepchecks: Not installed
2024-05-25 16:57:22,794:INFO:             xgboost: 2.0.3
2024-05-25 16:57:22,795:INFO:            catboost: Not installed
2024-05-25 16:57:22,795:INFO:              kmodes: Not installed
2024-05-25 16:57:22,795:INFO:             mlxtend: Not installed
2024-05-25 16:57:22,795:INFO:       statsforecast: Not installed
2024-05-25 16:57:22,795:INFO:        tune_sklearn: Not installed
2024-05-25 16:57:22,795:INFO:                 ray: Not installed
2024-05-25 16:57:22,795:INFO:            hyperopt: Not installed
2024-05-25 16:57:22,795:INFO:              optuna: Not installed
2024-05-25 16:57:22,795:INFO:               skopt: Not installed
2024-05-25 16:57:22,795:INFO:              mlflow: 2.13.0
2024-05-25 16:57:22,795:INFO:              gradio: Not installed
2024-05-25 16:57:22,795:INFO:             fastapi: Not installed
2024-05-25 16:57:22,796:INFO:             uvicorn: Not installed
2024-05-25 16:57:22,796:INFO:              m2cgen: Not installed
2024-05-25 16:57:22,796:INFO:           evidently: Not installed
2024-05-25 16:57:22,796:INFO:               fugue: Not installed
2024-05-25 16:57:22,796:INFO:           streamlit: Not installed
2024-05-25 16:57:22,796:INFO:             prophet: Not installed
2024-05-25 16:57:22,796:INFO:None
2024-05-25 16:57:22,796:INFO:Set up data.
2024-05-25 16:57:23,130:INFO:Set up folding strategy.
2024-05-25 16:57:23,130:INFO:Set up train/test split.
2024-05-25 16:57:23,188:INFO:Set up index.
2024-05-25 16:57:23,189:INFO:Assigning column types.
2024-05-25 16:57:23,211:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-25 16:57:23,285:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-25 16:57:23,290:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-25 16:57:23,344:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-25 16:57:23,348:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:57:23,422:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-25 16:57:23,423:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-25 16:57:23,470:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-25 16:57:23,474:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:57:23,475:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-25 16:57:23,549:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-25 16:57:23,595:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-25 16:57:23,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:57:23,674:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-25 16:57:23,721:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-25 16:57:23,725:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:57:23,726:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-25 16:57:23,847:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-25 16:57:23,851:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:57:23,972:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-25 16:57:23,976:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:57:23,979:INFO:Preparing preprocessing pipeline...
2024-05-25 16:57:23,984:INFO:Set up simple imputation.
2024-05-25 16:57:24,008:INFO:Set up encoding of ordinal features.
2024-05-25 16:57:24,016:INFO:Set up encoding of categorical features.
2024-05-25 16:57:24,019:INFO:Set up column name cleaning.
2024-05-25 16:57:26,253:INFO:Finished creating preprocessing pipeline.
2024-05-25 16:57:26,282:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id',
                                                                    'seller_address.city.name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-05-25 16:57:26,282:INFO:Creating final display dataframe.
2024-05-25 16:57:27,835:INFO:Setup _display_container:                     Description            Value
0                    Session id             5411
1                        Target           target
2                   Target type           Binary
3           Original data shape     (100000, 19)
4        Transformed data shape     (100000, 56)
5   Transformed train set shape      (90000, 56)
6    Transformed test set shape      (10000, 56)
7              Numeric features                5
8          Categorical features                9
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Fold Generator  StratifiedKFold
16                  Fold Number               10
17                     CPU Jobs               -1
18                      Use GPU            False
19               Log Experiment     MlflowLogger
20              Experiment Name         ml_codex
21                          USI             eb97
2024-05-25 16:57:27,964:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-25 16:57:27,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:57:28,089:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-25 16:57:28,094:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-25 16:57:28,096:INFO:Logging experiment in loggers
2024-05-25 16:57:28,492:INFO:SubProcess save_model() called ==================================
2024-05-25 16:57:28,548:INFO:Initializing save_model()
2024-05-25 16:57:28,548:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id',
                                                                    'seller_address.city.name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\Adm\AppData\Local\Temp\tmp2vogyx95\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id',
                                                                    'seller_address.city.name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-25 16:57:28,548:INFO:Adding model into prep_pipe
2024-05-25 16:57:28,548:WARNING:Only Model saved as it was a pipeline.
2024-05-25 16:57:28,579:INFO:C:\Users\Adm\AppData\Local\Temp\tmp2vogyx95\Transformation Pipeline.pkl saved in current working directory
2024-05-25 16:57:28,607:INFO:Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id',
                                                                    'seller_address.city.name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-05-25 16:57:28,607:INFO:save_model() successfully completed......................................
2024-05-25 16:57:29,496:INFO:SubProcess save_model() end ==================================
2024-05-25 16:57:29,527:INFO:setup() successfully completed in 5.44s...............
2024-05-25 16:57:29,528:INFO:Initializing compare_models()
2024-05-25 16:57:29,528:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-25 16:57:29,528:INFO:Checking exceptions
2024-05-25 16:57:29,548:INFO:Preparing display monitor
2024-05-25 16:57:29,577:INFO:Initializing Logistic Regression
2024-05-25 16:57:29,577:INFO:Total runtime is 0.0 minutes
2024-05-25 16:57:29,582:INFO:SubProcess create_model() called ==================================
2024-05-25 16:57:29,583:INFO:Initializing create_model()
2024-05-25 16:57:29,583:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026151C0C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:57:29,583:INFO:Checking exceptions
2024-05-25 16:57:29,583:INFO:Importing libraries
2024-05-25 16:57:29,583:INFO:Copying training dataset
2024-05-25 16:57:29,625:INFO:Defining folds
2024-05-25 16:57:29,625:INFO:Declaring metric variables
2024-05-25 16:57:29,630:INFO:Importing untrained model
2024-05-25 16:57:29,634:INFO:Logistic Regression Imported successfully
2024-05-25 16:57:29,644:INFO:Starting cross validation
2024-05-25 16:57:29,649:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:57:55,500:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-25 16:57:55,656:INFO:Calculating mean and std
2024-05-25 16:57:55,658:INFO:Creating metrics dataframe
2024-05-25 16:57:55,661:INFO:Uploading results into container
2024-05-25 16:57:55,661:INFO:Uploading model into container now
2024-05-25 16:57:55,662:INFO:_master_model_container: 1
2024-05-25 16:57:55,662:INFO:_display_container: 2
2024-05-25 16:57:55,663:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5411, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-25 16:57:55,663:INFO:create_model() successfully completed......................................
2024-05-25 16:57:56,425:INFO:SubProcess create_model() end ==================================
2024-05-25 16:57:56,425:INFO:Creating metrics dataframe
2024-05-25 16:57:56,434:INFO:Initializing K Neighbors Classifier
2024-05-25 16:57:56,434:INFO:Total runtime is 0.44760929346084594 minutes
2024-05-25 16:57:56,439:INFO:SubProcess create_model() called ==================================
2024-05-25 16:57:56,439:INFO:Initializing create_model()
2024-05-25 16:57:56,439:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026151C0C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:57:56,440:INFO:Checking exceptions
2024-05-25 16:57:56,440:INFO:Importing libraries
2024-05-25 16:57:56,440:INFO:Copying training dataset
2024-05-25 16:57:56,480:INFO:Defining folds
2024-05-25 16:57:56,480:INFO:Declaring metric variables
2024-05-25 16:57:56,485:INFO:Importing untrained model
2024-05-25 16:57:56,489:INFO:K Neighbors Classifier Imported successfully
2024-05-25 16:57:56,498:INFO:Starting cross validation
2024-05-25 16:57:56,503:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:58:22,801:INFO:Calculating mean and std
2024-05-25 16:58:22,803:INFO:Creating metrics dataframe
2024-05-25 16:58:22,806:INFO:Uploading results into container
2024-05-25 16:58:22,807:INFO:Uploading model into container now
2024-05-25 16:58:22,807:INFO:_master_model_container: 2
2024-05-25 16:58:22,808:INFO:_display_container: 2
2024-05-25 16:58:22,808:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-25 16:58:22,808:INFO:create_model() successfully completed......................................
2024-05-25 16:58:23,574:INFO:SubProcess create_model() end ==================================
2024-05-25 16:58:23,574:INFO:Creating metrics dataframe
2024-05-25 16:58:23,584:INFO:Initializing Naive Bayes
2024-05-25 16:58:23,584:INFO:Total runtime is 0.9001182079315185 minutes
2024-05-25 16:58:23,588:INFO:SubProcess create_model() called ==================================
2024-05-25 16:58:23,588:INFO:Initializing create_model()
2024-05-25 16:58:23,589:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026151C0C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:58:23,589:INFO:Checking exceptions
2024-05-25 16:58:23,589:INFO:Importing libraries
2024-05-25 16:58:23,589:INFO:Copying training dataset
2024-05-25 16:58:23,629:INFO:Defining folds
2024-05-25 16:58:23,630:INFO:Declaring metric variables
2024-05-25 16:58:23,634:INFO:Importing untrained model
2024-05-25 16:58:23,638:INFO:Naive Bayes Imported successfully
2024-05-25 16:58:23,647:INFO:Starting cross validation
2024-05-25 16:58:23,652:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:58:27,413:INFO:Calculating mean and std
2024-05-25 16:58:27,415:INFO:Creating metrics dataframe
2024-05-25 16:58:27,418:INFO:Uploading results into container
2024-05-25 16:58:27,419:INFO:Uploading model into container now
2024-05-25 16:58:27,419:INFO:_master_model_container: 3
2024-05-25 16:58:27,419:INFO:_display_container: 2
2024-05-25 16:58:27,420:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-25 16:58:27,420:INFO:create_model() successfully completed......................................
2024-05-25 16:58:28,182:INFO:SubProcess create_model() end ==================================
2024-05-25 16:58:28,183:INFO:Creating metrics dataframe
2024-05-25 16:58:28,193:INFO:Initializing Decision Tree Classifier
2024-05-25 16:58:28,193:INFO:Total runtime is 0.976933487256368 minutes
2024-05-25 16:58:28,197:INFO:SubProcess create_model() called ==================================
2024-05-25 16:58:28,198:INFO:Initializing create_model()
2024-05-25 16:58:28,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026151C0C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:58:28,198:INFO:Checking exceptions
2024-05-25 16:58:28,198:INFO:Importing libraries
2024-05-25 16:58:28,198:INFO:Copying training dataset
2024-05-25 16:58:28,239:INFO:Defining folds
2024-05-25 16:58:28,239:INFO:Declaring metric variables
2024-05-25 16:58:28,243:INFO:Importing untrained model
2024-05-25 16:58:28,248:INFO:Decision Tree Classifier Imported successfully
2024-05-25 16:58:28,256:INFO:Starting cross validation
2024-05-25 16:58:28,261:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:58:32,616:INFO:Calculating mean and std
2024-05-25 16:58:32,618:INFO:Creating metrics dataframe
2024-05-25 16:58:32,620:INFO:Uploading results into container
2024-05-25 16:58:32,621:INFO:Uploading model into container now
2024-05-25 16:58:32,621:INFO:_master_model_container: 4
2024-05-25 16:58:32,621:INFO:_display_container: 2
2024-05-25 16:58:32,622:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=5411, splitter='best')
2024-05-25 16:58:32,622:INFO:create_model() successfully completed......................................
2024-05-25 16:58:33,372:INFO:SubProcess create_model() end ==================================
2024-05-25 16:58:33,372:INFO:Creating metrics dataframe
2024-05-25 16:58:33,383:INFO:Initializing SVM - Linear Kernel
2024-05-25 16:58:33,383:INFO:Total runtime is 1.0634305238723754 minutes
2024-05-25 16:58:33,387:INFO:SubProcess create_model() called ==================================
2024-05-25 16:58:33,387:INFO:Initializing create_model()
2024-05-25 16:58:33,387:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026151C0C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:58:33,388:INFO:Checking exceptions
2024-05-25 16:58:33,388:INFO:Importing libraries
2024-05-25 16:58:33,388:INFO:Copying training dataset
2024-05-25 16:58:33,428:INFO:Defining folds
2024-05-25 16:58:33,428:INFO:Declaring metric variables
2024-05-25 16:58:33,433:INFO:Importing untrained model
2024-05-25 16:58:33,437:INFO:SVM - Linear Kernel Imported successfully
2024-05-25 16:58:33,446:INFO:Starting cross validation
2024-05-25 16:58:33,451:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:58:37,422:INFO:Calculating mean and std
2024-05-25 16:58:37,424:INFO:Creating metrics dataframe
2024-05-25 16:58:37,427:INFO:Uploading results into container
2024-05-25 16:58:37,428:INFO:Uploading model into container now
2024-05-25 16:58:37,429:INFO:_master_model_container: 5
2024-05-25 16:58:37,429:INFO:_display_container: 2
2024-05-25 16:58:37,430:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5411, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-25 16:58:37,431:INFO:create_model() successfully completed......................................
2024-05-25 16:58:38,164:INFO:SubProcess create_model() end ==================================
2024-05-25 16:58:38,164:INFO:Creating metrics dataframe
2024-05-25 16:58:38,175:INFO:Initializing Ridge Classifier
2024-05-25 16:58:38,175:INFO:Total runtime is 1.1432973702748614 minutes
2024-05-25 16:58:38,179:INFO:SubProcess create_model() called ==================================
2024-05-25 16:58:38,180:INFO:Initializing create_model()
2024-05-25 16:58:38,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026151C0C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:58:38,180:INFO:Checking exceptions
2024-05-25 16:58:38,180:INFO:Importing libraries
2024-05-25 16:58:38,181:INFO:Copying training dataset
2024-05-25 16:58:38,220:INFO:Defining folds
2024-05-25 16:58:38,220:INFO:Declaring metric variables
2024-05-25 16:58:38,225:INFO:Importing untrained model
2024-05-25 16:58:38,229:INFO:Ridge Classifier Imported successfully
2024-05-25 16:58:38,238:INFO:Starting cross validation
2024-05-25 16:58:38,243:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:58:41,185:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.79944e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 16:58:41,320:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.42896e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 16:58:41,487:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.8077e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 16:58:41,491:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.75454e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 16:58:41,506:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.79953e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 16:58:41,536:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.79933e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 16:58:41,586:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.75488e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 16:58:41,601:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.80916e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 16:58:41,602:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.79949e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 16:58:41,605:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.79936e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-25 16:58:41,916:INFO:Calculating mean and std
2024-05-25 16:58:41,918:INFO:Creating metrics dataframe
2024-05-25 16:58:41,920:INFO:Uploading results into container
2024-05-25 16:58:41,921:INFO:Uploading model into container now
2024-05-25 16:58:41,922:INFO:_master_model_container: 6
2024-05-25 16:58:41,922:INFO:_display_container: 2
2024-05-25 16:58:41,922:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5411, solver='auto',
                tol=0.0001)
2024-05-25 16:58:41,922:INFO:create_model() successfully completed......................................
2024-05-25 16:58:42,689:INFO:SubProcess create_model() end ==================================
2024-05-25 16:58:42,689:INFO:Creating metrics dataframe
2024-05-25 16:58:42,701:INFO:Initializing Random Forest Classifier
2024-05-25 16:58:42,701:INFO:Total runtime is 1.2187295675277707 minutes
2024-05-25 16:58:42,705:INFO:SubProcess create_model() called ==================================
2024-05-25 16:58:42,705:INFO:Initializing create_model()
2024-05-25 16:58:42,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026151C0C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:58:42,706:INFO:Checking exceptions
2024-05-25 16:58:42,706:INFO:Importing libraries
2024-05-25 16:58:42,706:INFO:Copying training dataset
2024-05-25 16:58:42,746:INFO:Defining folds
2024-05-25 16:58:42,747:INFO:Declaring metric variables
2024-05-25 16:58:42,751:INFO:Importing untrained model
2024-05-25 16:58:42,756:INFO:Random Forest Classifier Imported successfully
2024-05-25 16:58:42,764:INFO:Starting cross validation
2024-05-25 16:58:42,769:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:59:01,151:INFO:Calculating mean and std
2024-05-25 16:59:01,153:INFO:Creating metrics dataframe
2024-05-25 16:59:01,156:INFO:Uploading results into container
2024-05-25 16:59:01,157:INFO:Uploading model into container now
2024-05-25 16:59:01,157:INFO:_master_model_container: 7
2024-05-25 16:59:01,158:INFO:_display_container: 2
2024-05-25 16:59:01,159:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=5411, verbose=0,
                       warm_start=False)
2024-05-25 16:59:01,159:INFO:create_model() successfully completed......................................
2024-05-25 16:59:01,945:INFO:SubProcess create_model() end ==================================
2024-05-25 16:59:01,945:INFO:Creating metrics dataframe
2024-05-25 16:59:01,957:INFO:Initializing Quadratic Discriminant Analysis
2024-05-25 16:59:01,957:INFO:Total runtime is 1.5396574934323626 minutes
2024-05-25 16:59:01,961:INFO:SubProcess create_model() called ==================================
2024-05-25 16:59:01,962:INFO:Initializing create_model()
2024-05-25 16:59:01,962:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026151C0C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:59:01,962:INFO:Checking exceptions
2024-05-25 16:59:01,962:INFO:Importing libraries
2024-05-25 16:59:01,962:INFO:Copying training dataset
2024-05-25 16:59:02,003:INFO:Defining folds
2024-05-25 16:59:02,003:INFO:Declaring metric variables
2024-05-25 16:59:02,008:INFO:Importing untrained model
2024-05-25 16:59:02,012:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-25 16:59:02,021:INFO:Starting cross validation
2024-05-25 16:59:02,026:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:59:05,843:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:59:05,881:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:59:05,914:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:59:05,949:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:59:05,956:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:59:06,203:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:59:06,221:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:59:06,237:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:59:06,268:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:59:06,414:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-25 16:59:07,877:INFO:Calculating mean and std
2024-05-25 16:59:07,879:INFO:Creating metrics dataframe
2024-05-25 16:59:07,882:INFO:Uploading results into container
2024-05-25 16:59:07,882:INFO:Uploading model into container now
2024-05-25 16:59:07,883:INFO:_master_model_container: 8
2024-05-25 16:59:07,883:INFO:_display_container: 2
2024-05-25 16:59:07,883:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-25 16:59:07,884:INFO:create_model() successfully completed......................................
2024-05-25 16:59:08,629:INFO:SubProcess create_model() end ==================================
2024-05-25 16:59:08,630:INFO:Creating metrics dataframe
2024-05-25 16:59:08,642:INFO:Initializing Ada Boost Classifier
2024-05-25 16:59:08,642:INFO:Total runtime is 1.6510764559110003 minutes
2024-05-25 16:59:08,647:INFO:SubProcess create_model() called ==================================
2024-05-25 16:59:08,647:INFO:Initializing create_model()
2024-05-25 16:59:08,647:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026151C0C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:59:08,647:INFO:Checking exceptions
2024-05-25 16:59:08,648:INFO:Importing libraries
2024-05-25 16:59:08,648:INFO:Copying training dataset
2024-05-25 16:59:08,688:INFO:Defining folds
2024-05-25 16:59:08,689:INFO:Declaring metric variables
2024-05-25 16:59:08,693:INFO:Importing untrained model
2024-05-25 16:59:08,698:INFO:Ada Boost Classifier Imported successfully
2024-05-25 16:59:08,706:INFO:Starting cross validation
2024-05-25 16:59:08,711:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:59:11,486:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:59:11,497:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:59:11,637:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:59:11,661:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:59:11,737:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:59:11,745:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:59:11,770:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:59:11,775:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:59:11,796:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:59:11,798:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-25 16:59:20,488:INFO:Calculating mean and std
2024-05-25 16:59:20,490:INFO:Creating metrics dataframe
2024-05-25 16:59:20,493:INFO:Uploading results into container
2024-05-25 16:59:20,493:INFO:Uploading model into container now
2024-05-25 16:59:20,494:INFO:_master_model_container: 9
2024-05-25 16:59:20,494:INFO:_display_container: 2
2024-05-25 16:59:20,495:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5411)
2024-05-25 16:59:20,495:INFO:create_model() successfully completed......................................
2024-05-25 16:59:21,253:INFO:SubProcess create_model() end ==================================
2024-05-25 16:59:21,254:INFO:Creating metrics dataframe
2024-05-25 16:59:21,267:INFO:Initializing Gradient Boosting Classifier
2024-05-25 16:59:21,267:INFO:Total runtime is 1.861495463053385 minutes
2024-05-25 16:59:21,272:INFO:SubProcess create_model() called ==================================
2024-05-25 16:59:21,272:INFO:Initializing create_model()
2024-05-25 16:59:21,272:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026151C0C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:59:21,273:INFO:Checking exceptions
2024-05-25 16:59:21,273:INFO:Importing libraries
2024-05-25 16:59:21,273:INFO:Copying training dataset
2024-05-25 16:59:21,312:INFO:Defining folds
2024-05-25 16:59:21,313:INFO:Declaring metric variables
2024-05-25 16:59:21,317:INFO:Importing untrained model
2024-05-25 16:59:21,322:INFO:Gradient Boosting Classifier Imported successfully
2024-05-25 16:59:21,330:INFO:Starting cross validation
2024-05-25 16:59:21,335:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:59:45,416:INFO:Calculating mean and std
2024-05-25 16:59:45,418:INFO:Creating metrics dataframe
2024-05-25 16:59:45,420:INFO:Uploading results into container
2024-05-25 16:59:45,421:INFO:Uploading model into container now
2024-05-25 16:59:45,422:INFO:_master_model_container: 10
2024-05-25 16:59:45,422:INFO:_display_container: 2
2024-05-25 16:59:45,423:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5411, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-25 16:59:45,423:INFO:create_model() successfully completed......................................
2024-05-25 16:59:46,174:INFO:SubProcess create_model() end ==================================
2024-05-25 16:59:46,174:INFO:Creating metrics dataframe
2024-05-25 16:59:46,187:INFO:Initializing Linear Discriminant Analysis
2024-05-25 16:59:46,188:INFO:Total runtime is 2.2768469651540117 minutes
2024-05-25 16:59:46,192:INFO:SubProcess create_model() called ==================================
2024-05-25 16:59:46,192:INFO:Initializing create_model()
2024-05-25 16:59:46,192:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026151C0C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:59:46,193:INFO:Checking exceptions
2024-05-25 16:59:46,193:INFO:Importing libraries
2024-05-25 16:59:46,193:INFO:Copying training dataset
2024-05-25 16:59:46,233:INFO:Defining folds
2024-05-25 16:59:46,233:INFO:Declaring metric variables
2024-05-25 16:59:46,238:INFO:Importing untrained model
2024-05-25 16:59:46,242:INFO:Linear Discriminant Analysis Imported successfully
2024-05-25 16:59:46,251:INFO:Starting cross validation
2024-05-25 16:59:46,255:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 16:59:52,192:INFO:Calculating mean and std
2024-05-25 16:59:52,194:INFO:Creating metrics dataframe
2024-05-25 16:59:52,196:INFO:Uploading results into container
2024-05-25 16:59:52,197:INFO:Uploading model into container now
2024-05-25 16:59:52,198:INFO:_master_model_container: 11
2024-05-25 16:59:52,198:INFO:_display_container: 2
2024-05-25 16:59:52,198:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-25 16:59:52,199:INFO:create_model() successfully completed......................................
2024-05-25 16:59:52,946:INFO:SubProcess create_model() end ==================================
2024-05-25 16:59:52,946:INFO:Creating metrics dataframe
2024-05-25 16:59:52,960:INFO:Initializing Extra Trees Classifier
2024-05-25 16:59:52,960:INFO:Total runtime is 2.389710744222005 minutes
2024-05-25 16:59:52,965:INFO:SubProcess create_model() called ==================================
2024-05-25 16:59:52,965:INFO:Initializing create_model()
2024-05-25 16:59:52,965:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026151C0C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 16:59:52,966:INFO:Checking exceptions
2024-05-25 16:59:52,966:INFO:Importing libraries
2024-05-25 16:59:52,966:INFO:Copying training dataset
2024-05-25 16:59:53,006:INFO:Defining folds
2024-05-25 16:59:53,006:INFO:Declaring metric variables
2024-05-25 16:59:53,011:INFO:Importing untrained model
2024-05-25 16:59:53,015:INFO:Extra Trees Classifier Imported successfully
2024-05-25 16:59:53,024:INFO:Starting cross validation
2024-05-25 16:59:53,029:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:00:07,728:WARNING:create_model() for et raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-25 17:00:07,737:WARNING:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
3 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 1048576 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 1048576 bytes

--------------------------------------------------------------------------------
4 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 4194304 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 4194304 bytes

--------------------------------------------------------------------------------
3 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 2097152 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 2097152 bytes


2024-05-25 17:00:07,738:INFO:Initializing create_model()
2024-05-25 17:00:07,739:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026151C0C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:00:07,739:INFO:Checking exceptions
2024-05-25 17:00:07,739:INFO:Importing libraries
2024-05-25 17:00:07,739:INFO:Copying training dataset
2024-05-25 17:00:07,809:INFO:Defining folds
2024-05-25 17:00:07,810:INFO:Declaring metric variables
2024-05-25 17:00:07,819:INFO:Importing untrained model
2024-05-25 17:00:07,826:INFO:Extra Trees Classifier Imported successfully
2024-05-25 17:00:07,841:INFO:Starting cross validation
2024-05-25 17:00:07,848:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:00:20,110:ERROR:create_model() for et raised an exception or returned all 0.0:
2024-05-25 17:00:20,112:ERROR:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
3 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 1048576 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 1048576 bytes

--------------------------------------------------------------------------------
4 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 4194304 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 4194304 bytes

--------------------------------------------------------------------------------
3 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 2097152 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 2097152 bytes


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
7 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 4194304 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 4194304 bytes

--------------------------------------------------------------------------------
3 fits failed with the following error:
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\_parallel_backends.py", line 273, in _wrap_func_call
    return func()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in __call__
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 589, in <listcomp>
    return [func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 129, in __call__
    return self.function(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 200, in _parallel_build_trees
    tree._fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\tree\_classes.py", line 472, in _fit
    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)
  File "sklearn\\tree\\_tree.pyx", line 166, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 285, in sklearn.tree._tree.DepthFirstTreeBuilder.build
  File "sklearn\\tree\\_tree.pyx", line 940, in sklearn.tree._tree.Tree._add_node
  File "sklearn\\tree\\_tree.pyx", line 908, in sklearn.tree._tree.Tree._resize_c
  File "sklearn\\tree\\_utils.pyx", line 35, in sklearn.tree._utils.safe_realloc
MemoryError: could not allocate 2097152 bytes
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_forest.py", line 489, in fit
    trees = Parallel(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
MemoryError: could not allocate 2097152 bytes


2024-05-25 17:00:20,113:INFO:Initializing Extreme Gradient Boosting
2024-05-25 17:00:20,114:INFO:Total runtime is 2.842282970746358 minutes
2024-05-25 17:00:20,124:INFO:SubProcess create_model() called ==================================
2024-05-25 17:00:20,125:INFO:Initializing create_model()
2024-05-25 17:00:20,125:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026151C0C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:00:20,125:INFO:Checking exceptions
2024-05-25 17:00:20,126:INFO:Importing libraries
2024-05-25 17:00:20,126:INFO:Copying training dataset
2024-05-25 17:00:20,229:INFO:Defining folds
2024-05-25 17:00:20,230:INFO:Declaring metric variables
2024-05-25 17:00:20,238:INFO:Importing untrained model
2024-05-25 17:00:20,248:INFO:Extreme Gradient Boosting Imported successfully
2024-05-25 17:00:20,261:INFO:Starting cross validation
2024-05-25 17:00:20,269:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:00:26,020:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
8 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 26.6 MiB for an array with shape (43, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 730, in inner_f
    return func(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\sklearn.py", line 1500, in fit
    train_dmatrix, evals = _wrap_evaluation_matrices(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\sklearn.py", line 521, in _wrap_evaluation_matrices
    train_dmatrix = create_dmatrix(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\sklearn.py", line 958, in _create_dmatrix
    return QuantileDMatrix(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 730, in inner_f
    return func(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 1529, in __init__
    self._init(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 1588, in _init
    it.reraise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 576, in reraise
    raise exc  # pylint: disable=raising-bad-type
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 557, in _handle_exception
    return fn()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 641, in <lambda>
    return self._handle_exception(lambda: self.next(input_data), 0)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\data.py", line 1280, in next
    input_data(**self.kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 730, in inner_f
    return func(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 624, in input_data
    new, cat_codes, feature_names, feature_types = _proxy_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\data.py", line 1315, in _proxy_transform
    arr, feature_names, feature_types = _transform_pandas_df(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\data.py", line 508, in _transform_pandas_df
    arr: np.ndarray = transformed.values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1697, in _interleave
    arr = blk.get_values(dtype)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 2247, in get_values
    return self.values.astype(_dtype_obj)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 31.5 MiB for an array with shape (51, 81000) and data type object

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 730, in inner_f
    return func(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\sklearn.py", line 1500, in fit
    train_dmatrix, evals = _wrap_evaluation_matrices(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\sklearn.py", line 521, in _wrap_evaluation_matrices
    train_dmatrix = create_dmatrix(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\sklearn.py", line 958, in _create_dmatrix
    return QuantileDMatrix(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 730, in inner_f
    return func(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 1529, in __init__
    self._init(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 1588, in _init
    it.reraise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 576, in reraise
    raise exc  # pylint: disable=raising-bad-type
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 557, in _handle_exception
    return fn()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 641, in <lambda>
    return self._handle_exception(lambda: self.next(input_data), 0)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\data.py", line 1280, in next
    input_data(**self.kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 730, in inner_f
    return func(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 624, in input_data
    new, cat_codes, feature_names, feature_types = _proxy_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\data.py", line 1315, in _proxy_transform
    arr, feature_names, feature_types = _transform_pandas_df(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\data.py", line 508, in _transform_pandas_df
    arr: np.ndarray = transformed.values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 34.0 MiB for an array with shape (55, 81000) and data type object

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 269, in get_dummies
    X = pd.concat([base_df, X], axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 11.1 MiB for an array with shape (18, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 730, in inner_f
    return func(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\sklearn.py", line 1500, in fit
    train_dmatrix, evals = _wrap_evaluation_matrices(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\sklearn.py", line 521, in _wrap_evaluation_matrices
    train_dmatrix = create_dmatrix(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\sklearn.py", line 958, in _create_dmatrix
    return QuantileDMatrix(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 730, in inner_f
    return func(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 1529, in __init__
    self._init(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 1588, in _init
    it.reraise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 576, in reraise
    raise exc  # pylint: disable=raising-bad-type
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 557, in _handle_exception
    return fn()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 641, in <lambda>
    return self._handle_exception(lambda: self.next(input_data), 0)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\data.py", line 1280, in next
    input_data(**self.kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 730, in inner_f
    return func(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 624, in input_data
    new, cat_codes, feature_names, feature_types = _proxy_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\data.py", line 1315, in _proxy_transform
    arr, feature_names, feature_types = _transform_pandas_df(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\data.py", line 508, in _transform_pandas_df
    arr: np.ndarray = transformed.values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1697, in _interleave
    arr = blk.get_values(dtype)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 2247, in get_values
    return self.values.astype(_dtype_obj)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.47 MiB for an array with shape (4, 81000) and data type object

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 31.5 MiB for an array with shape (51, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 315, in fit
    X_transformed = self.transform(X, override_return_df=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 488, in transform
    X = self._transform(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 195, in _transform
    X = self.get_dummies(X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\one_hot.py", line 268, in get_dummies
    base_df = base_df.set_index(X.index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5876, in set_index
    frame = self.copy(deep=None)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.4 MiB for an array with shape (25, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.85 MiB for an array with shape (3, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:00:26,020:INFO:Calculating mean and std
2024-05-25 17:00:26,022:INFO:Creating metrics dataframe
2024-05-25 17:00:26,025:INFO:Uploading results into container
2024-05-25 17:00:26,026:INFO:Uploading model into container now
2024-05-25 17:00:26,026:INFO:_master_model_container: 12
2024-05-25 17:00:26,026:INFO:_display_container: 2
2024-05-25 17:00:26,028:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-25 17:00:26,028:INFO:create_model() successfully completed......................................
2024-05-25 17:00:26,766:WARNING:create_model() for XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...) raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-25 17:00:26,766:WARNING:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2024-05-25 17:00:26,766:INFO:Initializing create_model()
2024-05-25 17:00:26,766:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026151C0C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:00:26,767:INFO:Checking exceptions
2024-05-25 17:00:26,767:INFO:Importing libraries
2024-05-25 17:00:26,767:INFO:Copying training dataset
2024-05-25 17:00:26,807:INFO:Defining folds
2024-05-25 17:00:26,807:INFO:Declaring metric variables
2024-05-25 17:00:26,812:INFO:Importing untrained model
2024-05-25 17:00:26,818:INFO:Extreme Gradient Boosting Imported successfully
2024-05-25 17:00:26,825:INFO:Starting cross validation
2024-05-25 17:00:26,830:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:00:33,100:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
6 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 730, in inner_f
    return func(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\sklearn.py", line 1500, in fit
    train_dmatrix, evals = _wrap_evaluation_matrices(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\sklearn.py", line 521, in _wrap_evaluation_matrices
    train_dmatrix = create_dmatrix(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\sklearn.py", line 958, in _create_dmatrix
    return QuantileDMatrix(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 730, in inner_f
    return func(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 1529, in __init__
    self._init(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 1590, in _init
    _check_call(ret)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 282, in _check_call
    raise XGBoostError(py_str(_LIB.XGBGetLastError()))
xgboost.core.XGBoostError: bad allocation

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 730, in inner_f
    return func(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\sklearn.py", line 1500, in fit
    train_dmatrix, evals = _wrap_evaluation_matrices(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\sklearn.py", line 521, in _wrap_evaluation_matrices
    train_dmatrix = create_dmatrix(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\sklearn.py", line 958, in _create_dmatrix
    return QuantileDMatrix(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 730, in inner_f
    return func(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 1529, in __init__
    self._init(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 1588, in _init
    it.reraise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 576, in reraise
    raise exc  # pylint: disable=raising-bad-type
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 557, in _handle_exception
    return fn()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 641, in <lambda>
    return self._handle_exception(lambda: self.next(input_data), 0)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\data.py", line 1280, in next
    input_data(**self.kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 730, in inner_f
    return func(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 624, in input_data
    new, cat_codes, feature_names, feature_types = _proxy_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\data.py", line 1315, in _proxy_transform
    arr, feature_names, feature_types = _transform_pandas_df(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\data.py", line 508, in _transform_pandas_df
    arr: np.ndarray = transformed.values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1697, in _interleave
    arr = blk.get_values(dtype)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 2247, in get_values
    return self.values.astype(_dtype_obj)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.47 MiB for an array with shape (4, 81000) and data type object

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 176, in _reorder_cols
    new_df = new_df.drop(new_df.filter(regex="__drop__$").columns, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5344, in drop
    return super().drop(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4711, in drop
    obj = obj._drop_axis(labels, axis, level=level, errors=errors)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4792, in _drop_axis
    new_mgr = self._mgr.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 730, in inner_f
    return func(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\sklearn.py", line 1500, in fit
    train_dmatrix, evals = _wrap_evaluation_matrices(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\sklearn.py", line 521, in _wrap_evaluation_matrices
    train_dmatrix = create_dmatrix(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\sklearn.py", line 958, in _create_dmatrix
    return QuantileDMatrix(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 730, in inner_f
    return func(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 1529, in __init__
    self._init(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 1588, in _init
    it.reraise()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 576, in reraise
    raise exc  # pylint: disable=raising-bad-type
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 557, in _handle_exception
    return fn()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 641, in <lambda>
    return self._handle_exception(lambda: self.next(input_data), 0)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\data.py", line 1280, in next
    input_data(**self.kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 730, in inner_f
    return func(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 624, in input_data
    new, cat_codes, feature_names, feature_types = _proxy_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\data.py", line 1315, in _proxy_transform
    arr, feature_names, feature_types = _transform_pandas_df(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\data.py", line 508, in _transform_pandas_df
    arr: np.ndarray = transformed.values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1697, in _interleave
    arr = blk.get_values(dtype)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 2247, in get_values
    return self.values.astype(_dtype_obj)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 31.5 MiB for an array with shape (51, 81000) and data type object

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:00:33,100:INFO:Calculating mean and std
2024-05-25 17:00:33,102:INFO:Creating metrics dataframe
2024-05-25 17:00:33,105:INFO:Uploading results into container
2024-05-25 17:00:33,105:INFO:Uploading model into container now
2024-05-25 17:00:33,106:INFO:_master_model_container: 13
2024-05-25 17:00:33,106:INFO:_display_container: 2
2024-05-25 17:00:33,107:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-25 17:00:33,108:INFO:create_model() successfully completed......................................
2024-05-25 17:00:33,876:INFO:SubProcess create_model() end ==================================
2024-05-25 17:00:33,876:INFO:Creating metrics dataframe
2024-05-25 17:00:33,891:INFO:Initializing Light Gradient Boosting Machine
2024-05-25 17:00:33,891:INFO:Total runtime is 3.071899930636088 minutes
2024-05-25 17:00:33,896:INFO:SubProcess create_model() called ==================================
2024-05-25 17:00:33,896:INFO:Initializing create_model()
2024-05-25 17:00:33,896:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026151C0C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:00:33,896:INFO:Checking exceptions
2024-05-25 17:00:33,896:INFO:Importing libraries
2024-05-25 17:00:33,897:INFO:Copying training dataset
2024-05-25 17:00:33,939:INFO:Defining folds
2024-05-25 17:00:33,939:INFO:Declaring metric variables
2024-05-25 17:00:33,943:INFO:Importing untrained model
2024-05-25 17:00:33,948:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:00:33,958:INFO:Starting cross validation
2024-05-25 17:00:33,963:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:00:38,892:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\sklearn.py", line 1187, in fit
    super().fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\sklearn.py", line 885, in fit
    self._Booster = train(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\engine.py", line 255, in train
    booster = Booster(params=params, train_set=train_set)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\basic.py", line 3433, in __init__
    train_set.construct()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\basic.py", line 2462, in construct
    self._lazy_init(data=self.data, label=self.label, reference=None,
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\basic.py", line 2079, in _lazy_init
    self.__init_from_np2d(data, params_str, ref_dataset)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\basic.py", line 2218, in __init_from_np2d
    _safe_call(_LIB.LGBM_DatasetCreateFromMat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\basic.py", line 263, in _safe_call
    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))
lightgbm.basic.LightGBMError: bad allocation

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 170, in _reorder_cols
    right=original_df[[col for col in original_df if col in columns]],
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 3908, in __getitem__
    data = self._take_with_is_copy(indexer, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4088, in _take_with_is_copy
    result = self.take(indices=indices, axis=axis)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4068, in take
    new_data = self._mgr.take(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 877, in take
    return self.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:00:38,892:INFO:Calculating mean and std
2024-05-25 17:00:38,894:INFO:Creating metrics dataframe
2024-05-25 17:00:38,897:INFO:Uploading results into container
2024-05-25 17:00:38,898:INFO:Uploading model into container now
2024-05-25 17:00:38,899:INFO:_master_model_container: 14
2024-05-25 17:00:38,899:INFO:_display_container: 2
2024-05-25 17:00:38,900:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-25 17:00:38,900:INFO:create_model() successfully completed......................................
2024-05-25 17:00:39,667:INFO:SubProcess create_model() end ==================================
2024-05-25 17:00:39,667:INFO:Creating metrics dataframe
2024-05-25 17:00:39,682:INFO:Initializing Dummy Classifier
2024-05-25 17:00:39,682:INFO:Total runtime is 3.1684135794639587 minutes
2024-05-25 17:00:39,687:INFO:SubProcess create_model() called ==================================
2024-05-25 17:00:39,688:INFO:Initializing create_model()
2024-05-25 17:00:39,688:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026151C0C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:00:39,688:INFO:Checking exceptions
2024-05-25 17:00:39,688:INFO:Importing libraries
2024-05-25 17:00:39,688:INFO:Copying training dataset
2024-05-25 17:00:39,734:INFO:Defining folds
2024-05-25 17:00:39,735:INFO:Declaring metric variables
2024-05-25 17:00:39,739:INFO:Importing untrained model
2024-05-25 17:00:39,743:INFO:Dummy Classifier Imported successfully
2024-05-25 17:00:39,752:INFO:Starting cross validation
2024-05-25 17:00:39,756:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:00:43,031:INFO:Calculating mean and std
2024-05-25 17:00:43,037:INFO:Creating metrics dataframe
2024-05-25 17:00:43,040:INFO:Uploading results into container
2024-05-25 17:00:43,041:INFO:Uploading model into container now
2024-05-25 17:00:43,042:INFO:_master_model_container: 15
2024-05-25 17:00:43,042:INFO:_display_container: 2
2024-05-25 17:00:43,042:INFO:DummyClassifier(constant=None, random_state=5411, strategy='prior')
2024-05-25 17:00:43,042:INFO:create_model() successfully completed......................................
2024-05-25 17:00:43,799:INFO:SubProcess create_model() end ==================================
2024-05-25 17:00:43,800:INFO:Creating metrics dataframe
2024-05-25 17:00:43,815:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-25 17:00:43,827:INFO:Initializing create_model()
2024-05-25 17:00:43,827:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5411, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:00:43,828:INFO:Checking exceptions
2024-05-25 17:00:43,831:INFO:Importing libraries
2024-05-25 17:00:43,831:INFO:Copying training dataset
2024-05-25 17:00:43,875:INFO:Defining folds
2024-05-25 17:00:43,875:INFO:Declaring metric variables
2024-05-25 17:00:43,875:INFO:Importing untrained model
2024-05-25 17:00:43,875:INFO:Declaring custom model
2024-05-25 17:00:43,876:INFO:Gradient Boosting Classifier Imported successfully
2024-05-25 17:00:43,881:INFO:Cross validation set to False
2024-05-25 17:00:43,881:INFO:Fitting Model
2024-05-25 17:00:59,667:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5411, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-25 17:00:59,667:INFO:create_model() successfully completed......................................
2024-05-25 17:01:00,424:INFO:Creating Dashboard logs
2024-05-25 17:01:00,428:INFO:Model: Gradient Boosting Classifier
2024-05-25 17:01:00,502:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 5411, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-25 17:01:00,722:INFO:Initializing predict_model()
2024-05-25 17:01:00,722:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5411, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000261ADC67640>)
2024-05-25 17:01:00,722:INFO:Checking exceptions
2024-05-25 17:01:00,722:INFO:Preloading libraries
2024-05-25 17:01:01,795:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2024-05-25 17:01:04,227:INFO:Creating Dashboard logs
2024-05-25 17:01:04,232:INFO:Model: Random Forest Classifier
2024-05-25 17:01:04,301:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 5411, 'verbose': 0, 'warm_start': False}
2024-05-25 17:01:05,387:INFO:Creating Dashboard logs
2024-05-25 17:01:05,392:INFO:Model: Ada Boost Classifier
2024-05-25 17:01:05,461:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 5411}
2024-05-25 17:01:06,506:INFO:Creating Dashboard logs
2024-05-25 17:01:06,511:INFO:Model: Ridge Classifier
2024-05-25 17:01:06,580:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 5411, 'solver': 'auto', 'tol': 0.0001}
2024-05-25 17:01:07,646:INFO:Creating Dashboard logs
2024-05-25 17:01:07,650:INFO:Model: Linear Discriminant Analysis
2024-05-25 17:01:07,720:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-05-25 17:01:08,775:INFO:Creating Dashboard logs
2024-05-25 17:01:08,779:INFO:Model: Decision Tree Classifier
2024-05-25 17:01:08,849:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 5411, 'splitter': 'best'}
2024-05-25 17:01:09,913:INFO:Creating Dashboard logs
2024-05-25 17:01:09,918:INFO:Model: K Neighbors Classifier
2024-05-25 17:01:09,989:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2024-05-25 17:01:11,032:INFO:Creating Dashboard logs
2024-05-25 17:01:11,036:INFO:Model: Logistic Regression
2024-05-25 17:01:11,107:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 5411, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-05-25 17:01:12,161:INFO:Creating Dashboard logs
2024-05-25 17:01:12,166:INFO:Model: Light Gradient Boosting Machine
2024-05-25 17:01:12,237:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 5411, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-05-25 17:01:13,329:INFO:Creating Dashboard logs
2024-05-25 17:01:13,335:INFO:Model: Quadratic Discriminant Analysis
2024-05-25 17:01:13,408:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2024-05-25 17:01:14,487:INFO:Creating Dashboard logs
2024-05-25 17:01:14,492:INFO:Model: Dummy Classifier
2024-05-25 17:01:14,562:INFO:Logged params: {'constant': None, 'random_state': 5411, 'strategy': 'prior'}
2024-05-25 17:01:15,583:INFO:Creating Dashboard logs
2024-05-25 17:01:15,587:INFO:Model: SVM - Linear Kernel
2024-05-25 17:01:15,657:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 5411, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-25 17:01:16,726:INFO:Creating Dashboard logs
2024-05-25 17:01:16,731:INFO:Model: Naive Bayes
2024-05-25 17:01:16,801:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-05-25 17:01:17,857:INFO:Creating Dashboard logs
2024-05-25 17:01:17,862:INFO:Model: Extreme Gradient Boosting
2024-05-25 17:01:17,931:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 5411, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2024-05-25 17:01:19,088:INFO:_master_model_container: 15
2024-05-25 17:01:19,088:INFO:_display_container: 2
2024-05-25 17:01:19,089:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5411, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-25 17:01:19,089:INFO:compare_models() successfully completed......................................
2024-05-25 17:01:19,111:INFO:Initializing create_model()
2024-05-25 17:01:19,111:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:01:19,112:INFO:Checking exceptions
2024-05-25 17:01:19,129:INFO:Importing libraries
2024-05-25 17:01:19,129:INFO:Copying training dataset
2024-05-25 17:01:19,172:INFO:Defining folds
2024-05-25 17:01:19,172:INFO:Declaring metric variables
2024-05-25 17:01:19,176:INFO:Importing untrained model
2024-05-25 17:01:19,181:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:01:19,188:INFO:Starting cross validation
2024-05-25 17:01:19,194:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:01:25,266:INFO:Calculating mean and std
2024-05-25 17:01:25,268:INFO:Creating metrics dataframe
2024-05-25 17:01:25,276:INFO:Finalizing model
2024-05-25 17:01:26,740:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:01:26,745:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:01:26,755:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002713 seconds.
2024-05-25 17:01:26,755:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:01:26,755:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:01:26,755:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:01:26,755:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:01:26,756:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:01:26,756:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:01:27,054:INFO:Creating Dashboard logs
2024-05-25 17:01:27,059:INFO:Model: Light Gradient Boosting Machine
2024-05-25 17:01:27,140:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 5411, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-05-25 17:01:27,364:INFO:Initializing predict_model()
2024-05-25 17:01:27,364:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000261C06BB760>)
2024-05-25 17:01:27,364:INFO:Checking exceptions
2024-05-25 17:01:27,364:INFO:Preloading libraries
2024-05-25 17:01:29,329:INFO:Uploading results into container
2024-05-25 17:01:29,330:INFO:Uploading model into container now
2024-05-25 17:01:29,343:INFO:_master_model_container: 16
2024-05-25 17:01:29,344:INFO:_display_container: 3
2024-05-25 17:01:29,344:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-25 17:01:29,345:INFO:create_model() successfully completed......................................
2024-05-25 17:01:30,095:INFO:Initializing optimize_threshold()
2024-05-25 17:01:30,096:INFO:optimize_threshold(return_data=False, plot_kwargs=None, shgo_kwargs={}, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), optimize=Accuracy, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, verbose=True)
2024-05-25 17:01:30,096:INFO:Importing libraries
2024-05-25 17:01:30,096:INFO:Checking exceptions
2024-05-25 17:01:30,096:INFO:defining variables
2024-05-25 17:01:30,097:INFO:starting optimization
2024-05-25 17:01:30,110:INFO:Initializing create_model()
2024-05-25 17:01:30,110:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:01:30,110:INFO:Checking exceptions
2024-05-25 17:01:30,111:INFO:Importing libraries
2024-05-25 17:01:30,111:INFO:Copying training dataset
2024-05-25 17:01:30,151:INFO:Defining folds
2024-05-25 17:01:30,151:INFO:Declaring metric variables
2024-05-25 17:01:30,151:INFO:Importing untrained model
2024-05-25 17:01:30,151:INFO:Declaring custom model
2024-05-25 17:01:30,152:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:01:30,153:INFO:Starting cross validation
2024-05-25 17:01:30,156:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:01:36,443:INFO:Calculating mean and std
2024-05-25 17:01:36,444:INFO:Creating metrics dataframe
2024-05-25 17:01:36,447:INFO:Finalizing model
2024-05-25 17:01:37,839:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:01:37,844:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:01:37,854:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003644 seconds.
2024-05-25 17:01:37,855:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:01:37,855:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:01:37,855:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:01:37,855:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:01:37,856:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:01:37,856:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:01:38,156:INFO:Uploading results into container
2024-05-25 17:01:38,157:INFO:Uploading model into container now
2024-05-25 17:01:38,157:INFO:_master_model_container: 17
2024-05-25 17:01:38,157:INFO:_display_container: 4
2024-05-25 17:01:38,161:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.375,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:01:38,161:INFO:create_model() successfully completed......................................
2024-05-25 17:01:38,938:INFO:Threshold: 0.375. Accuracy: 0.8917
2024-05-25 17:01:38,939:INFO:Initializing create_model()
2024-05-25 17:01:38,939:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:01:38,939:INFO:Checking exceptions
2024-05-25 17:01:38,941:INFO:Importing libraries
2024-05-25 17:01:38,941:INFO:Copying training dataset
2024-05-25 17:01:38,982:INFO:Defining folds
2024-05-25 17:01:38,982:INFO:Declaring metric variables
2024-05-25 17:01:38,982:INFO:Importing untrained model
2024-05-25 17:01:38,982:INFO:Declaring custom model
2024-05-25 17:01:38,983:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:01:38,984:INFO:Starting cross validation
2024-05-25 17:01:38,988:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:01:45,423:INFO:Calculating mean and std
2024-05-25 17:01:45,424:INFO:Creating metrics dataframe
2024-05-25 17:01:45,427:INFO:Finalizing model
2024-05-25 17:01:46,818:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:01:46,823:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:01:46,834:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003006 seconds.
2024-05-25 17:01:46,835:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:01:46,835:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:01:46,835:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:01:46,835:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:01:46,836:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:01:46,836:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:01:47,140:INFO:Uploading results into container
2024-05-25 17:01:47,141:INFO:Uploading model into container now
2024-05-25 17:01:47,142:INFO:_master_model_container: 18
2024-05-25 17:01:47,142:INFO:_display_container: 4
2024-05-25 17:01:47,145:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.125,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:01:47,145:INFO:create_model() successfully completed......................................
2024-05-25 17:01:47,924:INFO:Threshold: 0.125. Accuracy: 0.8159
2024-05-25 17:01:47,925:INFO:Initializing create_model()
2024-05-25 17:01:47,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.5, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:01:47,926:INFO:Checking exceptions
2024-05-25 17:01:47,927:INFO:Importing libraries
2024-05-25 17:01:47,927:INFO:Copying training dataset
2024-05-25 17:01:47,970:INFO:Defining folds
2024-05-25 17:01:47,970:INFO:Declaring metric variables
2024-05-25 17:01:47,970:INFO:Importing untrained model
2024-05-25 17:01:47,971:INFO:Declaring custom model
2024-05-25 17:01:47,971:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:01:47,972:INFO:Starting cross validation
2024-05-25 17:01:47,976:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:01:54,115:INFO:Calculating mean and std
2024-05-25 17:01:54,116:INFO:Creating metrics dataframe
2024-05-25 17:01:54,119:INFO:Finalizing model
2024-05-25 17:01:55,519:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:01:55,523:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:01:55,538:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003276 seconds.
2024-05-25 17:01:55,538:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:01:55,538:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:01:55,538:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:01:55,539:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:01:55,539:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:01:55,540:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:01:55,846:INFO:Uploading results into container
2024-05-25 17:01:55,847:INFO:Uploading model into container now
2024-05-25 17:01:55,848:INFO:_master_model_container: 19
2024-05-25 17:01:55,848:INFO:_display_container: 4
2024-05-25 17:01:55,851:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None, probability_threshold=0.5,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:01:55,852:INFO:create_model() successfully completed......................................
2024-05-25 17:01:56,629:INFO:Threshold: 0.5. Accuracy: 0.8949
2024-05-25 17:01:56,630:INFO:Initializing create_model()
2024-05-25 17:01:56,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.25, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:01:56,630:INFO:Checking exceptions
2024-05-25 17:01:56,632:INFO:Importing libraries
2024-05-25 17:01:56,632:INFO:Copying training dataset
2024-05-25 17:01:56,675:INFO:Defining folds
2024-05-25 17:01:56,675:INFO:Declaring metric variables
2024-05-25 17:01:56,675:INFO:Importing untrained model
2024-05-25 17:01:56,675:INFO:Declaring custom model
2024-05-25 17:01:56,676:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:01:56,677:INFO:Starting cross validation
2024-05-25 17:01:56,681:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:02:03,171:INFO:Calculating mean and std
2024-05-25 17:02:03,172:INFO:Creating metrics dataframe
2024-05-25 17:02:03,175:INFO:Finalizing model
2024-05-25 17:02:04,593:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:02:04,597:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:02:04,610:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004005 seconds.
2024-05-25 17:02:04,610:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:02:04,610:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:02:04,611:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:02:04,611:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:02:04,611:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:02:04,612:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:02:04,907:INFO:Uploading results into container
2024-05-25 17:02:04,908:INFO:Uploading model into container now
2024-05-25 17:02:04,908:INFO:_master_model_container: 20
2024-05-25 17:02:04,908:INFO:_display_container: 4
2024-05-25 17:02:04,911:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None, probability_threshold=0.25,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:02:04,911:INFO:create_model() successfully completed......................................
2024-05-25 17:02:05,687:INFO:Threshold: 0.25. Accuracy: 0.8784
2024-05-25 17:02:05,688:INFO:Initializing create_model()
2024-05-25 17:02:05,689:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:02:05,689:INFO:Checking exceptions
2024-05-25 17:02:05,691:INFO:Importing libraries
2024-05-25 17:02:05,691:INFO:Copying training dataset
2024-05-25 17:02:05,739:INFO:Defining folds
2024-05-25 17:02:05,739:INFO:Declaring metric variables
2024-05-25 17:02:05,739:INFO:Importing untrained model
2024-05-25 17:02:05,739:INFO:Declaring custom model
2024-05-25 17:02:05,741:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:02:05,741:INFO:Starting cross validation
2024-05-25 17:02:05,745:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:02:12,066:INFO:Calculating mean and std
2024-05-25 17:02:12,067:INFO:Creating metrics dataframe
2024-05-25 17:02:12,070:INFO:Finalizing model
2024-05-25 17:02:13,457:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:02:13,462:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:02:13,477:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003509 seconds.
2024-05-25 17:02:13,477:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:02:13,478:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:02:13,478:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:02:13,478:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:02:13,479:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:02:13,479:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:02:13,792:INFO:Uploading results into container
2024-05-25 17:02:13,793:INFO:Uploading model into container now
2024-05-25 17:02:13,793:INFO:_master_model_container: 21
2024-05-25 17:02:13,793:INFO:_display_container: 4
2024-05-25 17:02:13,796:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.625,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:02:13,796:INFO:create_model() successfully completed......................................
2024-05-25 17:02:14,571:INFO:Threshold: 0.625. Accuracy: 0.8891
2024-05-25 17:02:14,572:INFO:Initializing create_model()
2024-05-25 17:02:14,572:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.75, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:02:14,572:INFO:Checking exceptions
2024-05-25 17:02:14,574:INFO:Importing libraries
2024-05-25 17:02:14,574:INFO:Copying training dataset
2024-05-25 17:02:14,617:INFO:Defining folds
2024-05-25 17:02:14,617:INFO:Declaring metric variables
2024-05-25 17:02:14,618:INFO:Importing untrained model
2024-05-25 17:02:14,618:INFO:Declaring custom model
2024-05-25 17:02:14,619:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:02:14,619:INFO:Starting cross validation
2024-05-25 17:02:14,623:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:02:20,694:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:02:20,694:INFO:Calculating mean and std
2024-05-25 17:02:20,695:INFO:Creating metrics dataframe
2024-05-25 17:02:20,698:INFO:Finalizing model
2024-05-25 17:02:22,083:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:02:22,089:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:02:22,103:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003522 seconds.
2024-05-25 17:02:22,104:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:02:22,104:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:02:22,104:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:02:22,104:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:02:22,105:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:02:22,105:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:02:22,420:INFO:Uploading results into container
2024-05-25 17:02:22,421:INFO:Uploading model into container now
2024-05-25 17:02:22,421:INFO:_master_model_container: 22
2024-05-25 17:02:22,422:INFO:_display_container: 4
2024-05-25 17:02:22,425:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None, probability_threshold=0.75,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:02:22,425:INFO:create_model() successfully completed......................................
2024-05-25 17:02:23,214:INFO:Threshold: 0.75. Accuracy: 0.7909
2024-05-25 17:02:23,215:INFO:Initializing create_model()
2024-05-25 17:02:23,215:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:02:23,215:INFO:Checking exceptions
2024-05-25 17:02:23,217:INFO:Importing libraries
2024-05-25 17:02:23,217:INFO:Copying training dataset
2024-05-25 17:02:23,260:INFO:Defining folds
2024-05-25 17:02:23,260:INFO:Declaring metric variables
2024-05-25 17:02:23,260:INFO:Importing untrained model
2024-05-25 17:02:23,260:INFO:Declaring custom model
2024-05-25 17:02:23,261:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:02:23,261:INFO:Starting cross validation
2024-05-25 17:02:23,266:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:02:29,490:INFO:Calculating mean and std
2024-05-25 17:02:29,491:INFO:Creating metrics dataframe
2024-05-25 17:02:29,494:INFO:Finalizing model
2024-05-25 17:02:30,869:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:02:30,874:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:02:30,889:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003372 seconds.
2024-05-25 17:02:30,889:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:02:30,889:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:02:30,889:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:02:30,889:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:02:30,890:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:02:30,890:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:02:31,184:INFO:Uploading results into container
2024-05-25 17:02:31,185:INFO:Uploading model into container now
2024-05-25 17:02:31,185:INFO:_master_model_container: 23
2024-05-25 17:02:31,185:INFO:_display_container: 4
2024-05-25 17:02:31,188:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.875,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:02:31,188:INFO:create_model() successfully completed......................................
2024-05-25 17:02:31,971:INFO:Threshold: 0.875. Accuracy: 0.8478
2024-05-25 17:02:31,972:INFO:Initializing create_model()
2024-05-25 17:02:31,972:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.0, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:02:31,972:INFO:Checking exceptions
2024-05-25 17:02:31,974:INFO:Importing libraries
2024-05-25 17:02:31,974:INFO:Copying training dataset
2024-05-25 17:02:32,017:INFO:Defining folds
2024-05-25 17:02:32,017:INFO:Declaring metric variables
2024-05-25 17:02:32,017:INFO:Importing untrained model
2024-05-25 17:02:32,017:INFO:Declaring custom model
2024-05-25 17:02:32,018:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:02:32,019:INFO:Starting cross validation
2024-05-25 17:02:32,023:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:02:38,508:INFO:Calculating mean and std
2024-05-25 17:02:38,509:INFO:Creating metrics dataframe
2024-05-25 17:02:38,512:INFO:Finalizing model
2024-05-25 17:02:39,955:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:02:39,960:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:02:39,972:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003412 seconds.
2024-05-25 17:02:39,972:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:02:39,972:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:02:39,972:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:02:39,973:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:02:39,973:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:02:39,974:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:02:40,277:INFO:Uploading results into container
2024-05-25 17:02:40,278:INFO:Uploading model into container now
2024-05-25 17:02:40,279:INFO:_master_model_container: 24
2024-05-25 17:02:40,279:INFO:_display_container: 4
2024-05-25 17:02:40,282:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None, probability_threshold=0.0,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:02:40,282:INFO:create_model() successfully completed......................................
2024-05-25 17:02:41,060:INFO:Threshold: 0.0. Accuracy: 0.5376
2024-05-25 17:02:41,062:INFO:Initializing create_model()
2024-05-25 17:02:41,062:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.5, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:02:41,062:INFO:Checking exceptions
2024-05-25 17:02:41,064:INFO:Importing libraries
2024-05-25 17:02:41,064:INFO:Copying training dataset
2024-05-25 17:02:41,112:INFO:Defining folds
2024-05-25 17:02:41,113:INFO:Declaring metric variables
2024-05-25 17:02:41,113:INFO:Importing untrained model
2024-05-25 17:02:41,113:INFO:Declaring custom model
2024-05-25 17:02:41,114:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:02:41,114:INFO:Starting cross validation
2024-05-25 17:02:41,118:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:02:47,342:INFO:Calculating mean and std
2024-05-25 17:02:47,343:INFO:Creating metrics dataframe
2024-05-25 17:02:47,346:INFO:Finalizing model
2024-05-25 17:02:48,744:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:02:48,749:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:02:48,760:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004059 seconds.
2024-05-25 17:02:48,760:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:02:48,761:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:02:48,761:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:02:48,761:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:02:48,762:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:02:48,762:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:02:49,078:INFO:Uploading results into container
2024-05-25 17:02:49,079:INFO:Uploading model into container now
2024-05-25 17:02:49,080:INFO:_master_model_container: 25
2024-05-25 17:02:49,080:INFO:_display_container: 4
2024-05-25 17:02:49,083:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None, probability_threshold=0.5,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:02:49,083:INFO:create_model() successfully completed......................................
2024-05-25 17:02:49,864:INFO:Threshold: 0.5. Accuracy: 0.8949
2024-05-25 17:02:49,866:INFO:Initializing create_model()
2024-05-25 17:02:49,866:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.5000000149011612, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:02:49,866:INFO:Checking exceptions
2024-05-25 17:02:49,868:INFO:Importing libraries
2024-05-25 17:02:49,868:INFO:Copying training dataset
2024-05-25 17:02:49,917:INFO:Defining folds
2024-05-25 17:02:49,917:INFO:Declaring metric variables
2024-05-25 17:02:49,917:INFO:Importing untrained model
2024-05-25 17:02:49,917:INFO:Declaring custom model
2024-05-25 17:02:49,919:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:02:49,919:INFO:Starting cross validation
2024-05-25 17:02:49,923:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:02:56,360:INFO:Calculating mean and std
2024-05-25 17:02:56,361:INFO:Creating metrics dataframe
2024-05-25 17:02:56,364:INFO:Finalizing model
2024-05-25 17:02:57,741:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:02:57,746:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:02:57,758:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003773 seconds.
2024-05-25 17:02:57,758:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:02:57,758:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:02:57,758:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:02:57,759:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:02:57,760:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:02:57,760:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:02:58,052:INFO:Uploading results into container
2024-05-25 17:02:58,053:INFO:Uploading model into container now
2024-05-25 17:02:58,053:INFO:_master_model_container: 26
2024-05-25 17:02:58,054:INFO:_display_container: 4
2024-05-25 17:02:58,057:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.5000000149011612,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:02:58,057:INFO:create_model() successfully completed......................................
2024-05-25 17:02:58,842:INFO:Threshold: 0.5000000149011612. Accuracy: 0.8949
2024-05-25 17:02:58,844:INFO:Initializing create_model()
2024-05-25 17:02:58,844:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:02:58,844:INFO:Checking exceptions
2024-05-25 17:02:58,846:INFO:Importing libraries
2024-05-25 17:02:58,846:INFO:Copying training dataset
2024-05-25 17:02:58,895:INFO:Defining folds
2024-05-25 17:02:58,895:INFO:Declaring metric variables
2024-05-25 17:02:58,896:INFO:Importing untrained model
2024-05-25 17:02:58,896:INFO:Declaring custom model
2024-05-25 17:02:58,897:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:02:58,897:INFO:Starting cross validation
2024-05-25 17:02:58,901:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:03:05,205:INFO:Calculating mean and std
2024-05-25 17:03:05,206:INFO:Creating metrics dataframe
2024-05-25 17:03:05,209:INFO:Finalizing model
2024-05-25 17:03:06,589:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:03:06,593:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:03:06,606:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003767 seconds.
2024-05-25 17:03:06,606:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:03:06,606:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:03:06,606:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:03:06,606:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:03:06,607:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:03:06,607:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:03:06,896:INFO:Uploading results into container
2024-05-25 17:03:06,897:INFO:Uploading model into container now
2024-05-25 17:03:06,898:INFO:_master_model_container: 27
2024-05-25 17:03:06,898:INFO:_display_container: 4
2024-05-25 17:03:06,901:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.875,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:03:06,901:INFO:create_model() successfully completed......................................
2024-05-25 17:03:07,678:INFO:Threshold: 0.875. Accuracy: 0.8478
2024-05-25 17:03:07,680:INFO:Initializing create_model()
2024-05-25 17:03:07,680:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.8750000149011612, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:03:07,680:INFO:Checking exceptions
2024-05-25 17:03:07,682:INFO:Importing libraries
2024-05-25 17:03:07,682:INFO:Copying training dataset
2024-05-25 17:03:07,725:INFO:Defining folds
2024-05-25 17:03:07,725:INFO:Declaring metric variables
2024-05-25 17:03:07,726:INFO:Importing untrained model
2024-05-25 17:03:07,726:INFO:Declaring custom model
2024-05-25 17:03:07,727:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:03:07,727:INFO:Starting cross validation
2024-05-25 17:03:07,732:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:03:13,923:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 289, in transform
    return X.rename(columns=lambda x: re.sub(self.match, "", str(x)))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 31.5 MiB for an array with shape (51, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:03:13,923:INFO:Calculating mean and std
2024-05-25 17:03:13,924:INFO:Creating metrics dataframe
2024-05-25 17:03:13,927:INFO:Finalizing model
2024-05-25 17:03:15,303:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:03:15,309:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:03:15,324:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003884 seconds.
2024-05-25 17:03:15,325:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:03:15,325:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:03:15,325:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:03:15,325:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:03:15,326:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:03:15,326:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:03:15,669:INFO:Uploading results into container
2024-05-25 17:03:15,670:INFO:Uploading model into container now
2024-05-25 17:03:15,671:INFO:_master_model_container: 28
2024-05-25 17:03:15,671:INFO:_display_container: 4
2024-05-25 17:03:15,674:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.8750000149011612,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:03:15,674:INFO:create_model() successfully completed......................................
2024-05-25 17:03:16,444:INFO:Threshold: 0.8750000149011612. Accuracy: 0.7631
2024-05-25 17:03:16,446:INFO:Initializing create_model()
2024-05-25 17:03:16,446:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.21875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:03:16,446:INFO:Checking exceptions
2024-05-25 17:03:16,448:INFO:Importing libraries
2024-05-25 17:03:16,449:INFO:Copying training dataset
2024-05-25 17:03:16,497:INFO:Defining folds
2024-05-25 17:03:16,497:INFO:Declaring metric variables
2024-05-25 17:03:16,497:INFO:Importing untrained model
2024-05-25 17:03:16,498:INFO:Declaring custom model
2024-05-25 17:03:16,499:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:03:16,499:INFO:Starting cross validation
2024-05-25 17:03:16,503:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:03:22,297:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:03:22,297:INFO:Calculating mean and std
2024-05-25 17:03:22,298:INFO:Creating metrics dataframe
2024-05-25 17:03:22,301:INFO:Finalizing model
2024-05-25 17:03:23,673:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:03:23,677:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:03:23,690:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003710 seconds.
2024-05-25 17:03:23,690:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:03:23,690:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:03:23,690:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:03:23,691:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:03:23,691:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:03:23,691:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:03:23,986:INFO:Uploading results into container
2024-05-25 17:03:23,987:INFO:Uploading model into container now
2024-05-25 17:03:23,988:INFO:_master_model_container: 29
2024-05-25 17:03:23,988:INFO:_display_container: 4
2024-05-25 17:03:23,991:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.21875,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:03:23,991:INFO:create_model() successfully completed......................................
2024-05-25 17:03:24,777:INFO:Threshold: 0.21875. Accuracy: 0.7841
2024-05-25 17:03:24,778:INFO:Initializing create_model()
2024-05-25 17:03:24,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.09375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:03:24,778:INFO:Checking exceptions
2024-05-25 17:03:24,780:INFO:Importing libraries
2024-05-25 17:03:24,780:INFO:Copying training dataset
2024-05-25 17:03:24,822:INFO:Defining folds
2024-05-25 17:03:24,823:INFO:Declaring metric variables
2024-05-25 17:03:24,823:INFO:Importing untrained model
2024-05-25 17:03:24,823:INFO:Declaring custom model
2024-05-25 17:03:24,824:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:03:24,824:INFO:Starting cross validation
2024-05-25 17:03:24,828:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:03:30,424:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 289, in transform
    return X.rename(columns=lambda x: re.sub(self.match, "", str(x)))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 31.5 MiB for an array with shape (51, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:03:30,424:INFO:Calculating mean and std
2024-05-25 17:03:30,425:INFO:Creating metrics dataframe
2024-05-25 17:03:30,428:INFO:Finalizing model
2024-05-25 17:03:31,805:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:03:31,810:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:03:31,824:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003110 seconds.
2024-05-25 17:03:31,825:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:03:31,825:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:03:31,825:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:03:31,825:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:03:31,826:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:03:31,826:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:03:32,122:INFO:Uploading results into container
2024-05-25 17:03:32,123:INFO:Uploading model into container now
2024-05-25 17:03:32,124:INFO:_master_model_container: 30
2024-05-25 17:03:32,124:INFO:_display_container: 4
2024-05-25 17:03:32,127:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.09375,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:03:32,127:INFO:create_model() successfully completed......................................
2024-05-25 17:03:32,911:INFO:Threshold: 0.09375. Accuracy: 0.6301
2024-05-25 17:03:32,912:INFO:Initializing create_model()
2024-05-25 17:03:32,912:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.3125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:03:32,912:INFO:Checking exceptions
2024-05-25 17:03:32,914:INFO:Importing libraries
2024-05-25 17:03:32,914:INFO:Copying training dataset
2024-05-25 17:03:32,957:INFO:Defining folds
2024-05-25 17:03:32,957:INFO:Declaring metric variables
2024-05-25 17:03:32,957:INFO:Importing untrained model
2024-05-25 17:03:32,957:INFO:Declaring custom model
2024-05-25 17:03:32,958:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:03:32,959:INFO:Starting cross validation
2024-05-25 17:03:32,963:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:03:38,727:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 289, in transform
    return X.rename(columns=lambda x: re.sub(self.match, "", str(x)))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 30.9 MiB for an array with shape (50, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 31.5 MiB for an array with shape (51, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:03:38,727:INFO:Calculating mean and std
2024-05-25 17:03:38,728:INFO:Creating metrics dataframe
2024-05-25 17:03:38,731:INFO:Finalizing model
2024-05-25 17:03:40,085:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:03:40,089:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:03:40,102:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003504 seconds.
2024-05-25 17:03:40,102:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:03:40,102:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:03:40,102:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:03:40,102:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:03:40,103:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:03:40,103:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:03:40,417:INFO:Uploading results into container
2024-05-25 17:03:40,418:INFO:Uploading model into container now
2024-05-25 17:03:40,419:INFO:_master_model_container: 31
2024-05-25 17:03:40,419:INFO:_display_container: 4
2024-05-25 17:03:40,422:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.3125,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:03:40,422:INFO:create_model() successfully completed......................................
2024-05-25 17:03:41,206:INFO:Threshold: 0.3125. Accuracy: 0.7099
2024-05-25 17:03:41,207:INFO:Initializing create_model()
2024-05-25 17:03:41,207:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.1875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:03:41,207:INFO:Checking exceptions
2024-05-25 17:03:41,209:INFO:Importing libraries
2024-05-25 17:03:41,209:INFO:Copying training dataset
2024-05-25 17:03:41,252:INFO:Defining folds
2024-05-25 17:03:41,252:INFO:Declaring metric variables
2024-05-25 17:03:41,252:INFO:Importing untrained model
2024-05-25 17:03:41,252:INFO:Declaring custom model
2024-05-25 17:03:41,253:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:03:41,254:INFO:Starting cross validation
2024-05-25 17:03:41,258:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:03:47,693:INFO:Calculating mean and std
2024-05-25 17:03:47,694:INFO:Creating metrics dataframe
2024-05-25 17:03:47,697:INFO:Finalizing model
2024-05-25 17:03:49,072:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:03:49,077:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:03:49,089:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003088 seconds.
2024-05-25 17:03:49,089:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:03:49,089:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:03:49,089:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:03:49,090:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:03:49,090:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:03:49,091:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:03:49,406:INFO:Uploading results into container
2024-05-25 17:03:49,407:INFO:Uploading model into container now
2024-05-25 17:03:49,408:INFO:_master_model_container: 32
2024-05-25 17:03:49,408:INFO:_display_container: 4
2024-05-25 17:03:49,411:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.1875,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:03:49,411:INFO:create_model() successfully completed......................................
2024-05-25 17:03:50,188:INFO:Threshold: 0.1875. Accuracy: 0.8605
2024-05-25 17:03:50,191:INFO:Initializing create_model()
2024-05-25 17:03:50,191:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.34375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:03:50,191:INFO:Checking exceptions
2024-05-25 17:03:50,193:INFO:Importing libraries
2024-05-25 17:03:50,194:INFO:Copying training dataset
2024-05-25 17:03:50,243:INFO:Defining folds
2024-05-25 17:03:50,243:INFO:Declaring metric variables
2024-05-25 17:03:50,243:INFO:Importing untrained model
2024-05-25 17:03:50,244:INFO:Declaring custom model
2024-05-25 17:03:50,245:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:03:50,245:INFO:Starting cross validation
2024-05-25 17:03:50,249:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:03:55,737:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 289, in transform
    return X.rename(columns=lambda x: re.sub(self.match, "", str(x)))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 31.5 MiB for an array with shape (51, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 176, in _reorder_cols
    new_df = new_df.drop(new_df.filter(regex="__drop__$").columns, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5344, in drop
    return super().drop(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4711, in drop
    obj = obj._drop_axis(labels, axis, level=level, errors=errors)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4792, in _drop_axis
    new_mgr = self._mgr.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:03:55,737:INFO:Calculating mean and std
2024-05-25 17:03:55,738:INFO:Creating metrics dataframe
2024-05-25 17:03:55,741:INFO:Finalizing model
2024-05-25 17:03:57,122:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:03:57,127:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:03:57,137:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003477 seconds.
2024-05-25 17:03:57,137:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:03:57,137:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:03:57,137:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:03:57,138:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:03:57,138:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:03:57,139:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:03:57,457:INFO:Uploading results into container
2024-05-25 17:03:57,458:INFO:Uploading model into container now
2024-05-25 17:03:57,459:INFO:_master_model_container: 33
2024-05-25 17:03:57,459:INFO:_display_container: 4
2024-05-25 17:03:57,462:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.34375,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:03:57,462:INFO:create_model() successfully completed......................................
2024-05-25 17:03:58,244:INFO:Threshold: 0.34375. Accuracy: 0.7106
2024-05-25 17:03:58,245:INFO:Initializing create_model()
2024-05-25 17:03:58,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.4375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:03:58,245:INFO:Checking exceptions
2024-05-25 17:03:58,247:INFO:Importing libraries
2024-05-25 17:03:58,247:INFO:Copying training dataset
2024-05-25 17:03:58,290:INFO:Defining folds
2024-05-25 17:03:58,290:INFO:Declaring metric variables
2024-05-25 17:03:58,290:INFO:Importing untrained model
2024-05-25 17:03:58,290:INFO:Declaring custom model
2024-05-25 17:03:58,291:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:03:58,292:INFO:Starting cross validation
2024-05-25 17:03:58,296:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:04:04,643:INFO:Calculating mean and std
2024-05-25 17:04:04,644:INFO:Creating metrics dataframe
2024-05-25 17:04:04,647:INFO:Finalizing model
2024-05-25 17:04:06,026:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:04:06,031:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:04:06,045:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003356 seconds.
2024-05-25 17:04:06,046:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:04:06,046:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:04:06,046:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:04:06,046:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:04:06,047:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:04:06,047:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:04:06,360:INFO:Uploading results into container
2024-05-25 17:04:06,361:INFO:Uploading model into container now
2024-05-25 17:04:06,362:INFO:_master_model_container: 34
2024-05-25 17:04:06,362:INFO:_display_container: 4
2024-05-25 17:04:06,365:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.4375,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:04:06,365:INFO:create_model() successfully completed......................................
2024-05-25 17:04:07,145:INFO:Threshold: 0.4375. Accuracy: 0.8941
2024-05-25 17:04:07,146:INFO:Initializing create_model()
2024-05-25 17:04:07,146:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.46875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:04:07,146:INFO:Checking exceptions
2024-05-25 17:04:07,148:INFO:Importing libraries
2024-05-25 17:04:07,148:INFO:Copying training dataset
2024-05-25 17:04:07,190:INFO:Defining folds
2024-05-25 17:04:07,190:INFO:Declaring metric variables
2024-05-25 17:04:07,190:INFO:Importing untrained model
2024-05-25 17:04:07,190:INFO:Declaring custom model
2024-05-25 17:04:07,191:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:04:07,192:INFO:Starting cross validation
2024-05-25 17:04:07,196:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:04:13,440:INFO:Calculating mean and std
2024-05-25 17:04:13,441:INFO:Creating metrics dataframe
2024-05-25 17:04:13,444:INFO:Finalizing model
2024-05-25 17:04:14,824:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:04:14,829:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:04:14,841:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003486 seconds.
2024-05-25 17:04:14,842:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:04:14,842:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:04:14,842:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:04:14,842:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:04:14,842:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:04:14,842:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:04:15,134:INFO:Uploading results into container
2024-05-25 17:04:15,135:INFO:Uploading model into container now
2024-05-25 17:04:15,135:INFO:_master_model_container: 35
2024-05-25 17:04:15,135:INFO:_display_container: 4
2024-05-25 17:04:15,138:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.46875,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:04:15,139:INFO:create_model() successfully completed......................................
2024-05-25 17:04:15,919:INFO:Threshold: 0.46875. Accuracy: 0.8949
2024-05-25 17:04:15,920:INFO:Initializing create_model()
2024-05-25 17:04:15,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.5625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:04:15,920:INFO:Checking exceptions
2024-05-25 17:04:15,922:INFO:Importing libraries
2024-05-25 17:04:15,923:INFO:Copying training dataset
2024-05-25 17:04:15,972:INFO:Defining folds
2024-05-25 17:04:15,972:INFO:Declaring metric variables
2024-05-25 17:04:15,972:INFO:Importing untrained model
2024-05-25 17:04:15,972:INFO:Declaring custom model
2024-05-25 17:04:15,973:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:04:15,973:INFO:Starting cross validation
2024-05-25 17:04:15,977:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:04:21,840:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.0 MiB for an array with shape (47, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:04:21,840:INFO:Calculating mean and std
2024-05-25 17:04:21,841:INFO:Creating metrics dataframe
2024-05-25 17:04:21,844:INFO:Finalizing model
2024-05-25 17:04:23,205:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:04:23,210:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:04:23,219:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003161 seconds.
2024-05-25 17:04:23,219:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:04:23,219:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:04:23,220:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:04:23,220:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:04:23,221:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:04:23,221:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:04:23,566:INFO:Uploading results into container
2024-05-25 17:04:23,567:INFO:Uploading model into container now
2024-05-25 17:04:23,567:INFO:_master_model_container: 36
2024-05-25 17:04:23,567:INFO:_display_container: 4
2024-05-25 17:04:23,570:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.5625,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:04:23,571:INFO:create_model() successfully completed......................................
2024-05-25 17:04:24,335:INFO:Threshold: 0.5625. Accuracy: 0.7149
2024-05-25 17:04:24,336:INFO:Initializing create_model()
2024-05-25 17:04:24,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.59375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:04:24,336:INFO:Checking exceptions
2024-05-25 17:04:24,338:INFO:Importing libraries
2024-05-25 17:04:24,339:INFO:Copying training dataset
2024-05-25 17:04:24,382:INFO:Defining folds
2024-05-25 17:04:24,382:INFO:Declaring metric variables
2024-05-25 17:04:24,382:INFO:Importing untrained model
2024-05-25 17:04:24,382:INFO:Declaring custom model
2024-05-25 17:04:24,383:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:04:24,384:INFO:Starting cross validation
2024-05-25 17:04:24,388:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:04:29,539:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 176, in _reorder_cols
    new_df = new_df.drop(new_df.filter(regex="__drop__$").columns, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5344, in drop
    return super().drop(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4711, in drop
    obj = obj._drop_axis(labels, axis, level=level, errors=errors)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4792, in _drop_axis
    new_mgr = self._mgr.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.0 MiB for an array with shape (47, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:04:29,540:INFO:Calculating mean and std
2024-05-25 17:04:29,540:INFO:Creating metrics dataframe
2024-05-25 17:04:29,543:INFO:Finalizing model
2024-05-25 17:04:30,910:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:04:30,915:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:04:30,927:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003362 seconds.
2024-05-25 17:04:30,928:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:04:30,928:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:04:30,928:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:04:30,928:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:04:30,929:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:04:30,929:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:04:31,223:INFO:Uploading results into container
2024-05-25 17:04:31,224:INFO:Uploading model into container now
2024-05-25 17:04:31,224:INFO:_master_model_container: 37
2024-05-25 17:04:31,224:INFO:_display_container: 4
2024-05-25 17:04:31,227:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.59375,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:04:31,228:INFO:create_model() successfully completed......................................
2024-05-25 17:04:32,018:INFO:Threshold: 0.59375. Accuracy: 0.6244
2024-05-25 17:04:32,019:INFO:Initializing create_model()
2024-05-25 17:04:32,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.6875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:04:32,020:INFO:Checking exceptions
2024-05-25 17:04:32,022:INFO:Importing libraries
2024-05-25 17:04:32,022:INFO:Copying training dataset
2024-05-25 17:04:32,061:INFO:Defining folds
2024-05-25 17:04:32,062:INFO:Declaring metric variables
2024-05-25 17:04:32,062:INFO:Importing untrained model
2024-05-25 17:04:32,062:INFO:Declaring custom model
2024-05-25 17:04:32,063:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:04:32,063:INFO:Starting cross validation
2024-05-25 17:04:32,067:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:04:38,570:INFO:Calculating mean and std
2024-05-25 17:04:38,571:INFO:Creating metrics dataframe
2024-05-25 17:04:38,574:INFO:Finalizing model
2024-05-25 17:04:39,935:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:04:39,940:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:04:39,951:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003054 seconds.
2024-05-25 17:04:39,951:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:04:39,951:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:04:39,951:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:04:39,952:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:04:39,952:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:04:39,952:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:04:40,255:INFO:Uploading results into container
2024-05-25 17:04:40,256:INFO:Uploading model into container now
2024-05-25 17:04:40,257:INFO:_master_model_container: 38
2024-05-25 17:04:40,257:INFO:_display_container: 4
2024-05-25 17:04:40,260:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.6875,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:04:40,260:INFO:create_model() successfully completed......................................
2024-05-25 17:04:41,051:INFO:Threshold: 0.6875. Accuracy: 0.8842
2024-05-25 17:04:41,052:INFO:Initializing create_model()
2024-05-25 17:04:41,052:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.71875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:04:41,052:INFO:Checking exceptions
2024-05-25 17:04:41,054:INFO:Importing libraries
2024-05-25 17:04:41,054:INFO:Copying training dataset
2024-05-25 17:04:41,096:INFO:Defining folds
2024-05-25 17:04:41,096:INFO:Declaring metric variables
2024-05-25 17:04:41,097:INFO:Importing untrained model
2024-05-25 17:04:41,097:INFO:Declaring custom model
2024-05-25 17:04:41,098:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:04:41,098:INFO:Starting cross validation
2024-05-25 17:04:41,102:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:04:47,266:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:04:47,266:INFO:Calculating mean and std
2024-05-25 17:04:47,267:INFO:Creating metrics dataframe
2024-05-25 17:04:47,270:INFO:Finalizing model
2024-05-25 17:04:48,643:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:04:48,647:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:04:48,659:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003409 seconds.
2024-05-25 17:04:48,660:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:04:48,660:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:04:48,660:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:04:48,660:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:04:48,661:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:04:48,661:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:04:48,956:INFO:Uploading results into container
2024-05-25 17:04:48,958:INFO:Uploading model into container now
2024-05-25 17:04:48,958:INFO:_master_model_container: 39
2024-05-25 17:04:48,959:INFO:_display_container: 4
2024-05-25 17:04:48,962:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.71875,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:04:48,962:INFO:create_model() successfully completed......................................
2024-05-25 17:04:49,738:INFO:Threshold: 0.71875. Accuracy: 0.793
2024-05-25 17:04:49,739:INFO:Initializing create_model()
2024-05-25 17:04:49,739:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.8125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:04:49,739:INFO:Checking exceptions
2024-05-25 17:04:49,741:INFO:Importing libraries
2024-05-25 17:04:49,741:INFO:Copying training dataset
2024-05-25 17:04:49,780:INFO:Defining folds
2024-05-25 17:04:49,781:INFO:Declaring metric variables
2024-05-25 17:04:49,781:INFO:Importing untrained model
2024-05-25 17:04:49,781:INFO:Declaring custom model
2024-05-25 17:04:49,782:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:04:49,782:INFO:Starting cross validation
2024-05-25 17:04:49,786:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:04:55,023:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.85 MiB for an array with shape (3, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 31.5 MiB for an array with shape (51, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 176, in _reorder_cols
    new_df = new_df.drop(new_df.filter(regex="__drop__$").columns, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5344, in drop
    return super().drop(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4711, in drop
    obj = obj._drop_axis(labels, axis, level=level, errors=errors)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4792, in _drop_axis
    new_mgr = self._mgr.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:04:55,023:INFO:Calculating mean and std
2024-05-25 17:04:55,024:INFO:Creating metrics dataframe
2024-05-25 17:04:55,027:INFO:Finalizing model
2024-05-25 17:04:56,387:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:04:56,391:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:04:56,407:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003796 seconds.
2024-05-25 17:04:56,407:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:04:56,407:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:04:56,407:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:04:56,408:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:04:56,408:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:04:56,409:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:04:56,701:INFO:Uploading results into container
2024-05-25 17:04:56,702:INFO:Uploading model into container now
2024-05-25 17:04:56,702:INFO:_master_model_container: 40
2024-05-25 17:04:56,702:INFO:_display_container: 4
2024-05-25 17:04:56,705:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.8125,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:04:56,705:INFO:create_model() successfully completed......................................
2024-05-25 17:04:57,482:INFO:Threshold: 0.8125. Accuracy: 0.6053
2024-05-25 17:04:57,483:INFO:Initializing create_model()
2024-05-25 17:04:57,483:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.84375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:04:57,483:INFO:Checking exceptions
2024-05-25 17:04:57,485:INFO:Importing libraries
2024-05-25 17:04:57,485:INFO:Copying training dataset
2024-05-25 17:04:57,528:INFO:Defining folds
2024-05-25 17:04:57,528:INFO:Declaring metric variables
2024-05-25 17:04:57,529:INFO:Importing untrained model
2024-05-25 17:04:57,529:INFO:Declaring custom model
2024-05-25 17:04:57,530:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:04:57,530:INFO:Starting cross validation
2024-05-25 17:04:57,534:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:05:03,346:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 170, in _reorder_cols
    right=original_df[[col for col in original_df if col in columns]],
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 3908, in __getitem__
    data = self._take_with_is_copy(indexer, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4088, in _take_with_is_copy
    result = self.take(indices=indices, axis=axis)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4068, in take
    new_data = self._mgr.take(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 877, in take
    return self.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:05:03,347:INFO:Calculating mean and std
2024-05-25 17:05:03,347:INFO:Creating metrics dataframe
2024-05-25 17:05:03,351:INFO:Finalizing model
2024-05-25 17:05:04,713:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:05:04,718:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:05:04,728:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003510 seconds.
2024-05-25 17:05:04,728:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:05:04,729:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:05:04,729:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:05:04,729:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:05:04,730:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:05:04,730:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:05:05,023:INFO:Uploading results into container
2024-05-25 17:05:05,024:INFO:Uploading model into container now
2024-05-25 17:05:05,025:INFO:_master_model_container: 41
2024-05-25 17:05:05,025:INFO:_display_container: 4
2024-05-25 17:05:05,028:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.84375,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:05:05,028:INFO:create_model() successfully completed......................................
2024-05-25 17:05:05,798:INFO:Threshold: 0.84375. Accuracy: 0.686
2024-05-25 17:05:05,799:INFO:Initializing create_model()
2024-05-25 17:05:05,799:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.9375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:05:05,799:INFO:Checking exceptions
2024-05-25 17:05:05,801:INFO:Importing libraries
2024-05-25 17:05:05,801:INFO:Copying training dataset
2024-05-25 17:05:05,847:INFO:Defining folds
2024-05-25 17:05:05,847:INFO:Declaring metric variables
2024-05-25 17:05:05,847:INFO:Importing untrained model
2024-05-25 17:05:05,848:INFO:Declaring custom model
2024-05-25 17:05:05,849:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:05:05,849:INFO:Starting cross validation
2024-05-25 17:05:05,853:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:05:12,256:INFO:Calculating mean and std
2024-05-25 17:05:12,257:INFO:Creating metrics dataframe
2024-05-25 17:05:12,260:INFO:Finalizing model
2024-05-25 17:05:13,622:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:05:13,628:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:05:13,643:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004395 seconds.
2024-05-25 17:05:13,644:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:05:13,644:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:05:13,644:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:05:13,644:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:05:13,645:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:05:13,645:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:05:13,940:INFO:Uploading results into container
2024-05-25 17:05:13,941:INFO:Uploading model into container now
2024-05-25 17:05:13,942:INFO:_master_model_container: 42
2024-05-25 17:05:13,942:INFO:_display_container: 4
2024-05-25 17:05:13,945:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.9375,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:05:13,945:INFO:create_model() successfully completed......................................
2024-05-25 17:05:14,709:INFO:Threshold: 0.9375. Accuracy: 0.8115
2024-05-25 17:05:14,710:INFO:Initializing create_model()
2024-05-25 17:05:14,710:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.0625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:05:14,711:INFO:Checking exceptions
2024-05-25 17:05:14,712:INFO:Importing libraries
2024-05-25 17:05:14,713:INFO:Copying training dataset
2024-05-25 17:05:14,752:INFO:Defining folds
2024-05-25 17:05:14,752:INFO:Declaring metric variables
2024-05-25 17:05:14,752:INFO:Importing untrained model
2024-05-25 17:05:14,752:INFO:Declaring custom model
2024-05-25 17:05:14,753:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:05:14,754:INFO:Starting cross validation
2024-05-25 17:05:14,758:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:05:20,234:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 31.5 MiB for an array with shape (51, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:05:20,234:INFO:Calculating mean and std
2024-05-25 17:05:20,235:INFO:Creating metrics dataframe
2024-05-25 17:05:20,238:INFO:Finalizing model
2024-05-25 17:05:21,611:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:05:21,615:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:05:21,628:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003815 seconds.
2024-05-25 17:05:21,628:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:05:21,628:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:05:21,628:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:05:21,628:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:05:21,629:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:05:21,629:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:05:21,922:INFO:Uploading results into container
2024-05-25 17:05:21,923:INFO:Uploading model into container now
2024-05-25 17:05:21,924:INFO:_master_model_container: 43
2024-05-25 17:05:21,924:INFO:_display_container: 4
2024-05-25 17:05:21,927:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.0625,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:05:21,927:INFO:create_model() successfully completed......................................
2024-05-25 17:05:22,697:INFO:Threshold: 0.0625. Accuracy: 0.6003
2024-05-25 17:05:22,701:INFO:Initializing create_model()
2024-05-25 17:05:22,701:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.96875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:05:22,701:INFO:Checking exceptions
2024-05-25 17:05:22,703:INFO:Importing libraries
2024-05-25 17:05:22,703:INFO:Copying training dataset
2024-05-25 17:05:22,746:INFO:Defining folds
2024-05-25 17:05:22,746:INFO:Declaring metric variables
2024-05-25 17:05:22,746:INFO:Importing untrained model
2024-05-25 17:05:22,746:INFO:Declaring custom model
2024-05-25 17:05:22,747:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:05:22,748:INFO:Starting cross validation
2024-05-25 17:05:22,752:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:05:29,335:INFO:Calculating mean and std
2024-05-25 17:05:29,336:INFO:Creating metrics dataframe
2024-05-25 17:05:29,339:INFO:Finalizing model
2024-05-25 17:05:30,709:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:05:30,713:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:05:30,724:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003563 seconds.
2024-05-25 17:05:30,724:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:05:30,724:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:05:30,725:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:05:30,725:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:05:30,726:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:05:30,726:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:05:31,016:INFO:Uploading results into container
2024-05-25 17:05:31,017:INFO:Uploading model into container now
2024-05-25 17:05:31,018:INFO:_master_model_container: 44
2024-05-25 17:05:31,018:INFO:_display_container: 4
2024-05-25 17:05:31,021:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.96875,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:05:31,021:INFO:create_model() successfully completed......................................
2024-05-25 17:05:31,788:INFO:Threshold: 0.96875. Accuracy: 0.7691
2024-05-25 17:05:31,791:INFO:Initializing create_model()
2024-05-25 17:05:31,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.1875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:05:31,791:INFO:Checking exceptions
2024-05-25 17:05:31,793:INFO:Importing libraries
2024-05-25 17:05:31,793:INFO:Copying training dataset
2024-05-25 17:05:31,835:INFO:Defining folds
2024-05-25 17:05:31,836:INFO:Declaring metric variables
2024-05-25 17:05:31,836:INFO:Importing untrained model
2024-05-25 17:05:31,836:INFO:Declaring custom model
2024-05-25 17:05:31,837:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:05:31,837:INFO:Starting cross validation
2024-05-25 17:05:31,841:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:05:37,581:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:05:37,581:INFO:Calculating mean and std
2024-05-25 17:05:37,582:INFO:Creating metrics dataframe
2024-05-25 17:05:37,585:INFO:Finalizing model
2024-05-25 17:05:38,946:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:05:38,950:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:05:38,963:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003786 seconds.
2024-05-25 17:05:38,963:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:05:38,963:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:05:38,963:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:05:38,963:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:05:38,964:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:05:38,964:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:05:39,255:INFO:Uploading results into container
2024-05-25 17:05:39,256:INFO:Uploading model into container now
2024-05-25 17:05:39,257:INFO:_master_model_container: 45
2024-05-25 17:05:39,257:INFO:_display_container: 4
2024-05-25 17:05:39,260:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.1875,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:05:39,260:INFO:create_model() successfully completed......................................
2024-05-25 17:05:40,054:INFO:Threshold: 0.1875. Accuracy: 0.7745
2024-05-25 17:05:40,057:INFO:Initializing create_model()
2024-05-25 17:05:40,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.1875000149011612, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:05:40,057:INFO:Checking exceptions
2024-05-25 17:05:40,059:INFO:Importing libraries
2024-05-25 17:05:40,060:INFO:Copying training dataset
2024-05-25 17:05:40,103:INFO:Defining folds
2024-05-25 17:05:40,103:INFO:Declaring metric variables
2024-05-25 17:05:40,103:INFO:Importing untrained model
2024-05-25 17:05:40,103:INFO:Declaring custom model
2024-05-25 17:05:40,105:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:05:40,105:INFO:Starting cross validation
2024-05-25 17:05:40,109:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:05:45,580:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 178, in _reorder_cols
    return new_df[columns]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 3908, in __getitem__
    data = self._take_with_is_copy(indexer, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4088, in _take_with_is_copy
    result = self.take(indices=indices, axis=axis)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4068, in take
    new_data = self._mgr.take(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 877, in take
    return self.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 170, in _reorder_cols
    right=original_df[[col for col in original_df if col in columns]],
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 3908, in __getitem__
    data = self._take_with_is_copy(indexer, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4088, in _take_with_is_copy
    result = self.take(indices=indices, axis=axis)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4068, in take
    new_data = self._mgr.take(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 877, in take
    return self.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:05:45,580:INFO:Calculating mean and std
2024-05-25 17:05:45,581:INFO:Creating metrics dataframe
2024-05-25 17:05:45,584:INFO:Finalizing model
2024-05-25 17:05:46,976:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:05:46,981:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:05:46,994:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003816 seconds.
2024-05-25 17:05:46,994:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:05:46,994:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:05:46,994:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:05:46,994:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:05:46,995:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:05:46,995:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:05:47,294:INFO:Uploading results into container
2024-05-25 17:05:47,295:INFO:Uploading model into container now
2024-05-25 17:05:47,295:INFO:_master_model_container: 46
2024-05-25 17:05:47,295:INFO:_display_container: 4
2024-05-25 17:05:47,298:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.1875000149011612,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:05:47,299:INFO:create_model() successfully completed......................................
2024-05-25 17:05:48,095:INFO:Threshold: 0.1875000149011612. Accuracy: 0.6888
2024-05-25 17:05:48,097:INFO:Initializing create_model()
2024-05-25 17:05:48,097:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.6875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:05:48,097:INFO:Checking exceptions
2024-05-25 17:05:48,099:INFO:Importing libraries
2024-05-25 17:05:48,099:INFO:Copying training dataset
2024-05-25 17:05:48,137:INFO:Defining folds
2024-05-25 17:05:48,138:INFO:Declaring metric variables
2024-05-25 17:05:48,138:INFO:Importing untrained model
2024-05-25 17:05:48,138:INFO:Declaring custom model
2024-05-25 17:05:48,139:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:05:48,139:INFO:Starting cross validation
2024-05-25 17:05:48,144:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:05:54,287:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 170, in _reorder_cols
    right=original_df[[col for col in original_df if col in columns]],
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 3908, in __getitem__
    data = self._take_with_is_copy(indexer, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4088, in _take_with_is_copy
    result = self.take(indices=indices, axis=axis)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4068, in take
    new_data = self._mgr.take(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 877, in take
    return self.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:05:54,287:INFO:Calculating mean and std
2024-05-25 17:05:54,288:INFO:Creating metrics dataframe
2024-05-25 17:05:54,291:INFO:Finalizing model
2024-05-25 17:05:55,667:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:05:55,671:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:05:55,686:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003367 seconds.
2024-05-25 17:05:55,686:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:05:55,686:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:05:55,686:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:05:55,687:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:05:55,687:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:05:55,687:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:05:55,978:INFO:Uploading results into container
2024-05-25 17:05:55,979:INFO:Uploading model into container now
2024-05-25 17:05:55,980:INFO:_master_model_container: 47
2024-05-25 17:05:55,980:INFO:_display_container: 4
2024-05-25 17:05:55,983:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.6875,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:05:55,983:INFO:create_model() successfully completed......................................
2024-05-25 17:05:56,764:INFO:Threshold: 0.6875. Accuracy: 0.7955
2024-05-25 17:05:56,765:INFO:Initializing create_model()
2024-05-25 17:05:56,765:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.6875000149011612, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:05:56,765:INFO:Checking exceptions
2024-05-25 17:05:56,767:INFO:Importing libraries
2024-05-25 17:05:56,767:INFO:Copying training dataset
2024-05-25 17:05:56,810:INFO:Defining folds
2024-05-25 17:05:56,810:INFO:Declaring metric variables
2024-05-25 17:05:56,810:INFO:Importing untrained model
2024-05-25 17:05:56,810:INFO:Declaring custom model
2024-05-25 17:05:56,811:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:05:56,812:INFO:Starting cross validation
2024-05-25 17:05:56,816:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:06:03,217:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 176, in _reorder_cols
    new_df = new_df.drop(new_df.filter(regex="__drop__$").columns, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5344, in drop
    return super().drop(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4711, in drop
    obj = obj._drop_axis(labels, axis, level=level, errors=errors)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4792, in _drop_axis
    new_mgr = self._mgr.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:06:03,217:INFO:Calculating mean and std
2024-05-25 17:06:03,218:INFO:Creating metrics dataframe
2024-05-25 17:06:03,221:INFO:Finalizing model
2024-05-25 17:06:04,622:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:06:04,626:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:06:04,641:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003973 seconds.
2024-05-25 17:06:04,641:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:06:04,642:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:06:04,642:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:06:04,642:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:06:04,643:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:06:04,643:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:06:04,974:INFO:Uploading results into container
2024-05-25 17:06:04,975:INFO:Uploading model into container now
2024-05-25 17:06:04,976:INFO:_master_model_container: 48
2024-05-25 17:06:04,976:INFO:_display_container: 4
2024-05-25 17:06:04,979:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.6875000149011612,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:06:04,979:INFO:create_model() successfully completed......................................
2024-05-25 17:06:05,768:INFO:Threshold: 0.6875000149011612. Accuracy: 0.7078
2024-05-25 17:06:05,769:INFO:Initializing create_model()
2024-05-25 17:06:05,769:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.0, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:06:05,769:INFO:Checking exceptions
2024-05-25 17:06:05,771:INFO:Importing libraries
2024-05-25 17:06:05,771:INFO:Copying training dataset
2024-05-25 17:06:05,811:INFO:Defining folds
2024-05-25 17:06:05,811:INFO:Declaring metric variables
2024-05-25 17:06:05,812:INFO:Importing untrained model
2024-05-25 17:06:05,812:INFO:Declaring custom model
2024-05-25 17:06:05,813:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:06:05,813:INFO:Starting cross validation
2024-05-25 17:06:05,817:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:06:11,536:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 176, in _reorder_cols
    new_df = new_df.drop(new_df.filter(regex="__drop__$").columns, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5344, in drop
    return super().drop(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4711, in drop
    obj = obj._drop_axis(labels, axis, level=level, errors=errors)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4792, in _drop_axis
    new_mgr = self._mgr.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:06:11,536:INFO:Calculating mean and std
2024-05-25 17:06:11,537:INFO:Creating metrics dataframe
2024-05-25 17:06:11,540:INFO:Finalizing model
2024-05-25 17:06:12,917:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:06:12,921:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:06:12,932:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003761 seconds.
2024-05-25 17:06:12,932:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:06:12,932:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:06:12,932:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:06:12,933:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:06:12,933:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:06:12,933:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:06:13,249:INFO:Uploading results into container
2024-05-25 17:06:13,250:INFO:Uploading model into container now
2024-05-25 17:06:13,251:INFO:_master_model_container: 49
2024-05-25 17:06:13,251:INFO:_display_container: 4
2024-05-25 17:06:13,255:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None, probability_threshold=0.0,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:06:13,255:INFO:create_model() successfully completed......................................
2024-05-25 17:06:14,053:INFO:Threshold: 0.0. Accuracy: 0.4301
2024-05-25 17:06:14,054:INFO:Initializing create_model()
2024-05-25 17:06:14,055:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.3437500310426671, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:06:14,055:INFO:Checking exceptions
2024-05-25 17:06:14,056:INFO:Importing libraries
2024-05-25 17:06:14,057:INFO:Copying training dataset
2024-05-25 17:06:14,099:INFO:Defining folds
2024-05-25 17:06:14,099:INFO:Declaring metric variables
2024-05-25 17:06:14,100:INFO:Importing untrained model
2024-05-25 17:06:14,100:INFO:Declaring custom model
2024-05-25 17:06:14,101:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:06:14,101:INFO:Starting cross validation
2024-05-25 17:06:14,105:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:06:18,686:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
4 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 31.5 MiB for an array with shape (51, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 178, in _reorder_cols
    return new_df[columns]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 3908, in __getitem__
    data = self._take_with_is_copy(indexer, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4088, in _take_with_is_copy
    result = self.take(indices=indices, axis=axis)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4068, in take
    new_data = self._mgr.take(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 877, in take
    return self.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.85 MiB for an array with shape (3, 81000) and data type object

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 289, in transform
    return X.rename(columns=lambda x: re.sub(self.match, "", str(x)))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 31.5 MiB for an array with shape (51, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:06:18,687:INFO:Calculating mean and std
2024-05-25 17:06:18,687:INFO:Creating metrics dataframe
2024-05-25 17:06:18,691:INFO:Finalizing model
2024-05-25 17:06:20,068:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:06:20,073:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:06:20,083:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003624 seconds.
2024-05-25 17:06:20,083:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:06:20,083:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:06:20,084:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:06:20,084:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:06:20,085:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:06:20,085:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:06:20,426:INFO:Uploading results into container
2024-05-25 17:06:20,427:INFO:Uploading model into container now
2024-05-25 17:06:20,427:INFO:_master_model_container: 50
2024-05-25 17:06:20,428:INFO:_display_container: 4
2024-05-25 17:06:20,431:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.3437500310426671,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:06:20,431:INFO:create_model() successfully completed......................................
2024-05-25 17:06:21,195:INFO:Threshold: 0.3437500310426671. Accuracy: 0.534
2024-05-25 17:06:21,196:INFO:Initializing create_model()
2024-05-25 17:06:21,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.515625037737144, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:06:21,197:INFO:Checking exceptions
2024-05-25 17:06:21,198:INFO:Importing libraries
2024-05-25 17:06:21,198:INFO:Copying training dataset
2024-05-25 17:06:21,238:INFO:Defining folds
2024-05-25 17:06:21,239:INFO:Declaring metric variables
2024-05-25 17:06:21,239:INFO:Importing untrained model
2024-05-25 17:06:21,239:INFO:Declaring custom model
2024-05-25 17:06:21,240:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:06:21,240:INFO:Starting cross validation
2024-05-25 17:06:21,244:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:06:26,356:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 31.5 MiB for an array with shape (51, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 31.5 MiB for an array with shape (51, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:06:26,356:INFO:Calculating mean and std
2024-05-25 17:06:26,357:INFO:Creating metrics dataframe
2024-05-25 17:06:26,360:INFO:Finalizing model
2024-05-25 17:06:27,722:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:06:27,727:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:06:27,742:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003932 seconds.
2024-05-25 17:06:27,743:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:06:27,743:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:06:27,743:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:06:27,743:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:06:27,744:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:06:27,744:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:06:28,041:INFO:Uploading results into container
2024-05-25 17:06:28,042:INFO:Uploading model into container now
2024-05-25 17:06:28,043:INFO:_master_model_container: 51
2024-05-25 17:06:28,043:INFO:_display_container: 4
2024-05-25 17:06:28,046:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.515625037737144,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:06:28,046:INFO:create_model() successfully completed......................................
2024-05-25 17:06:28,831:INFO:Threshold: 0.515625037737144. Accuracy: 0.6265
2024-05-25 17:06:28,834:INFO:Initializing create_model()
2024-05-25 17:06:28,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.6015625332260168, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:06:28,834:INFO:Checking exceptions
2024-05-25 17:06:28,836:INFO:Importing libraries
2024-05-25 17:06:28,836:INFO:Copying training dataset
2024-05-25 17:06:28,879:INFO:Defining folds
2024-05-25 17:06:28,879:INFO:Declaring metric variables
2024-05-25 17:06:28,879:INFO:Importing untrained model
2024-05-25 17:06:28,879:INFO:Declaring custom model
2024-05-25 17:06:28,880:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:06:28,881:INFO:Starting cross validation
2024-05-25 17:06:28,885:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:06:34,455:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:06:34,455:INFO:Calculating mean and std
2024-05-25 17:06:34,456:INFO:Creating metrics dataframe
2024-05-25 17:06:34,459:INFO:Finalizing model
2024-05-25 17:06:35,845:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:06:35,850:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:06:35,864:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003308 seconds.
2024-05-25 17:06:35,864:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:06:35,864:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:06:35,865:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:06:35,865:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:06:35,866:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:06:35,866:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:06:36,160:INFO:Uploading results into container
2024-05-25 17:06:36,161:INFO:Uploading model into container now
2024-05-25 17:06:36,161:INFO:_master_model_container: 52
2024-05-25 17:06:36,161:INFO:_display_container: 4
2024-05-25 17:06:36,165:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.6015625332260168,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:06:36,165:INFO:create_model() successfully completed......................................
2024-05-25 17:06:36,955:INFO:Threshold: 0.6015625332260168. Accuracy: 0.7125
2024-05-25 17:06:36,957:INFO:Initializing create_model()
2024-05-25 17:06:36,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.6445312736642979, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:06:36,957:INFO:Checking exceptions
2024-05-25 17:06:36,959:INFO:Importing libraries
2024-05-25 17:06:36,959:INFO:Copying training dataset
2024-05-25 17:06:37,001:INFO:Defining folds
2024-05-25 17:06:37,001:INFO:Declaring metric variables
2024-05-25 17:06:37,002:INFO:Importing untrained model
2024-05-25 17:06:37,002:INFO:Declaring custom model
2024-05-25 17:06:37,003:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:06:37,003:INFO:Starting cross validation
2024-05-25 17:06:37,007:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:06:42,311:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 178, in _reorder_cols
    return new_df[columns]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 3908, in __getitem__
    data = self._take_with_is_copy(indexer, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4088, in _take_with_is_copy
    result = self.take(indices=indices, axis=axis)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4068, in take
    new_data = self._mgr.take(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 877, in take
    return self.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 26.0 MiB for an array with shape (42, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:06:42,311:INFO:Calculating mean and std
2024-05-25 17:06:42,312:INFO:Creating metrics dataframe
2024-05-25 17:06:42,315:INFO:Finalizing model
2024-05-25 17:06:43,681:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:06:43,686:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:06:43,698:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003322 seconds.
2024-05-25 17:06:43,698:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:06:43,698:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:06:43,699:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:06:43,699:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:06:43,700:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:06:43,700:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:06:43,993:INFO:Uploading results into container
2024-05-25 17:06:43,994:INFO:Uploading model into container now
2024-05-25 17:06:43,995:INFO:_master_model_container: 53
2024-05-25 17:06:43,995:INFO:_display_container: 4
2024-05-25 17:06:43,998:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.6445312736642979,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:06:43,998:INFO:create_model() successfully completed......................................
2024-05-25 17:06:44,788:INFO:Threshold: 0.6445312736642979. Accuracy: 0.7102
2024-05-25 17:06:44,792:INFO:Initializing create_model()
2024-05-25 17:06:44,792:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.6660156440788344, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:06:44,792:INFO:Checking exceptions
2024-05-25 17:06:44,794:INFO:Importing libraries
2024-05-25 17:06:44,794:INFO:Copying training dataset
2024-05-25 17:06:44,837:INFO:Defining folds
2024-05-25 17:06:44,837:INFO:Declaring metric variables
2024-05-25 17:06:44,838:INFO:Importing untrained model
2024-05-25 17:06:44,838:INFO:Declaring custom model
2024-05-25 17:06:44,839:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:06:44,839:INFO:Starting cross validation
2024-05-25 17:06:44,843:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:06:50,511:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 176, in _reorder_cols
    new_df = new_df.drop(new_df.filter(regex="__drop__$").columns, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5344, in drop
    return super().drop(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4711, in drop
    obj = obj._drop_axis(labels, axis, level=level, errors=errors)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4792, in _drop_axis
    new_mgr = self._mgr.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.0 MiB for an array with shape (47, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:06:50,511:INFO:Calculating mean and std
2024-05-25 17:06:50,512:INFO:Creating metrics dataframe
2024-05-25 17:06:50,515:INFO:Finalizing model
2024-05-25 17:06:51,904:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:06:51,908:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:06:51,921:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004319 seconds.
2024-05-25 17:06:51,921:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:06:51,921:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:06:51,921:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:06:51,922:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:06:51,922:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:06:51,923:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:06:52,215:INFO:Uploading results into container
2024-05-25 17:06:52,216:INFO:Uploading model into container now
2024-05-25 17:06:52,217:INFO:_master_model_container: 54
2024-05-25 17:06:52,217:INFO:_display_container: 4
2024-05-25 17:06:52,220:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.6660156440788344,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:06:52,220:INFO:create_model() successfully completed......................................
2024-05-25 17:06:53,007:INFO:Threshold: 0.6660156440788344. Accuracy: 0.7974
2024-05-25 17:06:53,008:INFO:Initializing create_model()
2024-05-25 17:06:53,008:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.676757821878002, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:06:53,008:INFO:Checking exceptions
2024-05-25 17:06:53,011:INFO:Importing libraries
2024-05-25 17:06:53,011:INFO:Copying training dataset
2024-05-25 17:06:53,050:INFO:Defining folds
2024-05-25 17:06:53,051:INFO:Declaring metric variables
2024-05-25 17:06:53,051:INFO:Importing untrained model
2024-05-25 17:06:53,051:INFO:Declaring custom model
2024-05-25 17:06:53,052:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:06:53,052:INFO:Starting cross validation
2024-05-25 17:06:53,056:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:06:59,428:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 176, in _reorder_cols
    new_df = new_df.drop(new_df.filter(regex="__drop__$").columns, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5344, in drop
    return super().drop(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4711, in drop
    obj = obj._drop_axis(labels, axis, level=level, errors=errors)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4792, in _drop_axis
    new_mgr = self._mgr.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:06:59,428:INFO:Calculating mean and std
2024-05-25 17:06:59,429:INFO:Creating metrics dataframe
2024-05-25 17:06:59,432:INFO:Finalizing model
2024-05-25 17:07:00,832:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:07:00,837:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:07:00,849:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003392 seconds.
2024-05-25 17:07:00,849:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:07:00,849:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:07:00,849:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:07:00,850:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:07:00,850:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:07:00,851:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:07:01,154:INFO:Uploading results into container
2024-05-25 17:07:01,155:INFO:Uploading model into container now
2024-05-25 17:07:01,156:INFO:_master_model_container: 55
2024-05-25 17:07:01,156:INFO:_display_container: 4
2024-05-25 17:07:01,159:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.676757821878002,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:07:01,159:INFO:create_model() successfully completed......................................
2024-05-25 17:07:01,937:INFO:Threshold: 0.676757821878002. Accuracy: 0.7961
2024-05-25 17:07:01,939:INFO:Initializing create_model()
2024-05-25 17:07:01,939:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.6821289108880279, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:07:01,939:INFO:Checking exceptions
2024-05-25 17:07:01,941:INFO:Importing libraries
2024-05-25 17:07:01,941:INFO:Copying training dataset
2024-05-25 17:07:01,986:INFO:Defining folds
2024-05-25 17:07:01,986:INFO:Declaring metric variables
2024-05-25 17:07:01,987:INFO:Importing untrained model
2024-05-25 17:07:01,987:INFO:Declaring custom model
2024-05-25 17:07:01,988:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:07:01,988:INFO:Starting cross validation
2024-05-25 17:07:01,992:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:07:07,304:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 289, in transform
    return X.rename(columns=lambda x: re.sub(self.match, "", str(x)))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 31.5 MiB for an array with shape (51, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 31.5 MiB for an array with shape (51, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:07:07,304:INFO:Calculating mean and std
2024-05-25 17:07:07,305:INFO:Creating metrics dataframe
2024-05-25 17:07:07,308:INFO:Finalizing model
2024-05-25 17:07:08,702:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:07:08,707:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:07:08,718:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004043 seconds.
2024-05-25 17:07:08,718:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:07:08,718:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:07:08,718:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:07:08,718:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:07:08,719:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:07:08,719:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:07:09,017:INFO:Uploading results into container
2024-05-25 17:07:09,018:INFO:Uploading model into container now
2024-05-25 17:07:09,019:INFO:_master_model_container: 56
2024-05-25 17:07:09,019:INFO:_display_container: 4
2024-05-25 17:07:09,022:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.6821289108880279,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:07:09,022:INFO:create_model() successfully completed......................................
2024-05-25 17:07:09,807:INFO:Threshold: 0.6821289108880279. Accuracy: 0.6185
2024-05-25 17:07:09,808:INFO:Initializing create_model()
2024-05-25 17:07:09,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.6848144704810194, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:07:09,808:INFO:Checking exceptions
2024-05-25 17:07:09,810:INFO:Importing libraries
2024-05-25 17:07:09,811:INFO:Copying training dataset
2024-05-25 17:07:09,851:INFO:Defining folds
2024-05-25 17:07:09,851:INFO:Declaring metric variables
2024-05-25 17:07:09,851:INFO:Importing untrained model
2024-05-25 17:07:09,851:INFO:Declaring custom model
2024-05-25 17:07:09,852:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:07:09,852:INFO:Starting cross validation
2024-05-25 17:07:09,856:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:07:15,523:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 176, in _reorder_cols
    new_df = new_df.drop(new_df.filter(regex="__drop__$").columns, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5344, in drop
    return super().drop(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4711, in drop
    obj = obj._drop_axis(labels, axis, level=level, errors=errors)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4792, in _drop_axis
    new_mgr = self._mgr.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 26.0 MiB for an array with shape (42, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:07:15,523:INFO:Calculating mean and std
2024-05-25 17:07:15,524:INFO:Creating metrics dataframe
2024-05-25 17:07:15,528:INFO:Finalizing model
2024-05-25 17:07:16,918:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:07:16,923:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:07:16,934:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004100 seconds.
2024-05-25 17:07:16,934:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:07:16,934:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:07:16,935:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:07:16,935:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:07:16,936:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:07:16,936:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:07:17,255:INFO:Uploading results into container
2024-05-25 17:07:17,256:INFO:Uploading model into container now
2024-05-25 17:07:17,257:INFO:_master_model_container: 57
2024-05-25 17:07:17,257:INFO:_display_container: 4
2024-05-25 17:07:17,260:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.6848144704810194,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:07:17,260:INFO:create_model() successfully completed......................................
2024-05-25 17:07:18,047:INFO:Threshold: 0.6848144704810194. Accuracy: 0.7067
2024-05-25 17:07:18,051:INFO:Initializing create_model()
2024-05-25 17:07:18,051:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.6861572427844987, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:07:18,051:INFO:Checking exceptions
2024-05-25 17:07:18,053:INFO:Importing libraries
2024-05-25 17:07:18,053:INFO:Copying training dataset
2024-05-25 17:07:18,096:INFO:Defining folds
2024-05-25 17:07:18,096:INFO:Declaring metric variables
2024-05-25 17:07:18,096:INFO:Importing untrained model
2024-05-25 17:07:18,096:INFO:Declaring custom model
2024-05-25 17:07:18,098:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:07:18,098:INFO:Starting cross validation
2024-05-25 17:07:18,102:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:07:23,321:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 176, in _reorder_cols
    new_df = new_df.drop(new_df.filter(regex="__drop__$").columns, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5344, in drop
    return super().drop(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4711, in drop
    obj = obj._drop_axis(labels, axis, level=level, errors=errors)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4792, in _drop_axis
    new_mgr = self._mgr.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.85 MiB for an array with shape (3, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.85 MiB for an array with shape (3, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 170, in _reorder_cols
    right=original_df[[col for col in original_df if col in columns]],
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 3908, in __getitem__
    data = self._take_with_is_copy(indexer, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4088, in _take_with_is_copy
    result = self.take(indices=indices, axis=axis)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4068, in take
    new_data = self._mgr.take(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 877, in take
    return self.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.85 MiB for an array with shape (3, 81000) and data type object

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:07:23,321:INFO:Calculating mean and std
2024-05-25 17:07:23,322:INFO:Creating metrics dataframe
2024-05-25 17:07:23,325:INFO:Finalizing model
2024-05-25 17:07:24,705:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:07:24,710:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:07:24,722:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004189 seconds.
2024-05-25 17:07:24,723:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:07:24,723:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:07:24,723:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:07:24,723:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:07:24,724:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:07:24,724:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:07:25,020:INFO:Uploading results into container
2024-05-25 17:07:25,021:INFO:Uploading model into container now
2024-05-25 17:07:25,021:INFO:_master_model_container: 58
2024-05-25 17:07:25,021:INFO:_display_container: 4
2024-05-25 17:07:25,024:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.6861572427844987,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:07:25,024:INFO:create_model() successfully completed......................................
2024-05-25 17:07:25,808:INFO:Threshold: 0.6861572427844987. Accuracy: 0.619
2024-05-25 17:07:25,809:INFO:Initializing create_model()
2024-05-25 17:07:25,809:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.6868286363865266, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:07:25,809:INFO:Checking exceptions
2024-05-25 17:07:25,811:INFO:Importing libraries
2024-05-25 17:07:25,812:INFO:Copying training dataset
2024-05-25 17:07:25,851:INFO:Defining folds
2024-05-25 17:07:25,851:INFO:Declaring metric variables
2024-05-25 17:07:25,851:INFO:Importing untrained model
2024-05-25 17:07:25,852:INFO:Declaring custom model
2024-05-25 17:07:25,853:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:07:25,853:INFO:Starting cross validation
2024-05-25 17:07:25,857:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:07:30,633:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 3908, in __getitem__
    data = self._take_with_is_copy(indexer, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4088, in _take_with_is_copy
    result = self.take(indices=indices, axis=axis)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4068, in take
    new_data = self._mgr.take(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 877, in take
    return self.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 31.5 MiB for an array with shape (51, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 31.5 MiB for an array with shape (51, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 30.9 MiB for an array with shape (50, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:07:30,633:INFO:Calculating mean and std
2024-05-25 17:07:30,634:INFO:Creating metrics dataframe
2024-05-25 17:07:30,637:INFO:Finalizing model
2024-05-25 17:07:32,003:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:07:32,008:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:07:32,021:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003837 seconds.
2024-05-25 17:07:32,021:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:07:32,021:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:07:32,021:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:07:32,021:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:07:32,022:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:07:32,022:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:07:32,329:INFO:Uploading results into container
2024-05-25 17:07:32,330:INFO:Uploading model into container now
2024-05-25 17:07:32,331:INFO:_master_model_container: 59
2024-05-25 17:07:32,331:INFO:_display_container: 4
2024-05-25 17:07:32,334:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.6868286363865266,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:07:32,334:INFO:create_model() successfully completed......................................
2024-05-25 17:07:33,116:INFO:Threshold: 0.6868286363865266. Accuracy: 0.6193
2024-05-25 17:07:33,118:INFO:Initializing create_model()
2024-05-25 17:07:33,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.484375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:07:33,118:INFO:Checking exceptions
2024-05-25 17:07:33,120:INFO:Importing libraries
2024-05-25 17:07:33,121:INFO:Copying training dataset
2024-05-25 17:07:33,166:INFO:Defining folds
2024-05-25 17:07:33,166:INFO:Declaring metric variables
2024-05-25 17:07:33,166:INFO:Importing untrained model
2024-05-25 17:07:33,167:INFO:Declaring custom model
2024-05-25 17:07:33,168:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:07:33,168:INFO:Starting cross validation
2024-05-25 17:07:33,172:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:07:38,537:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 31.5 MiB for an array with shape (51, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:07:38,537:INFO:Calculating mean and std
2024-05-25 17:07:38,538:INFO:Creating metrics dataframe
2024-05-25 17:07:38,541:INFO:Finalizing model
2024-05-25 17:07:39,938:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:07:39,943:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:07:39,956:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004083 seconds.
2024-05-25 17:07:39,956:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:07:39,957:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:07:39,957:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:07:39,957:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:07:39,958:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:07:39,958:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:07:40,274:INFO:Uploading results into container
2024-05-25 17:07:40,275:INFO:Uploading model into container now
2024-05-25 17:07:40,275:INFO:_master_model_container: 60
2024-05-25 17:07:40,275:INFO:_display_container: 4
2024-05-25 17:07:40,278:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.484375,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:07:40,279:INFO:create_model() successfully completed......................................
2024-05-25 17:07:41,063:INFO:Threshold: 0.484375. Accuracy: 0.8054
2024-05-25 17:07:41,064:INFO:Initializing create_model()
2024-05-25 17:07:41,064:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.53125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:07:41,064:INFO:Checking exceptions
2024-05-25 17:07:41,066:INFO:Importing libraries
2024-05-25 17:07:41,067:INFO:Copying training dataset
2024-05-25 17:07:41,112:INFO:Defining folds
2024-05-25 17:07:41,112:INFO:Declaring metric variables
2024-05-25 17:07:41,113:INFO:Importing untrained model
2024-05-25 17:07:41,113:INFO:Declaring custom model
2024-05-25 17:07:41,114:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:07:41,114:INFO:Starting cross validation
2024-05-25 17:07:41,118:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:07:46,162:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 26.0 MiB for an array with shape (42, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:07:46,162:INFO:Calculating mean and std
2024-05-25 17:07:46,163:INFO:Creating metrics dataframe
2024-05-25 17:07:46,166:INFO:Finalizing model
2024-05-25 17:07:47,547:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:07:47,552:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:07:47,562:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003682 seconds.
2024-05-25 17:07:47,562:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:07:47,562:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:07:47,563:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:07:47,563:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:07:47,564:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:07:47,564:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:07:47,863:INFO:Uploading results into container
2024-05-25 17:07:47,864:INFO:Uploading model into container now
2024-05-25 17:07:47,865:INFO:_master_model_container: 61
2024-05-25 17:07:47,865:INFO:_display_container: 4
2024-05-25 17:07:47,868:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.53125,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:07:47,868:INFO:create_model() successfully completed......................................
2024-05-25 17:07:48,641:INFO:Threshold: 0.53125. Accuracy: 0.7156
2024-05-25 17:07:48,642:INFO:Initializing create_model()
2024-05-25 17:07:48,642:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.546875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:07:48,642:INFO:Checking exceptions
2024-05-25 17:07:48,644:INFO:Importing libraries
2024-05-25 17:07:48,644:INFO:Copying training dataset
2024-05-25 17:07:48,683:INFO:Defining folds
2024-05-25 17:07:48,684:INFO:Declaring metric variables
2024-05-25 17:07:48,684:INFO:Importing untrained model
2024-05-25 17:07:48,684:INFO:Declaring custom model
2024-05-25 17:07:48,685:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:07:48,685:INFO:Starting cross validation
2024-05-25 17:07:48,689:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:07:53,890:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 289, in transform
    return X.rename(columns=lambda x: re.sub(self.match, "", str(x)))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 31.5 MiB for an array with shape (51, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 170, in _reorder_cols
    right=original_df[[col for col in original_df if col in columns]],
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 3908, in __getitem__
    data = self._take_with_is_copy(indexer, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4088, in _take_with_is_copy
    result = self.take(indices=indices, axis=axis)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4068, in take
    new_data = self._mgr.take(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 877, in take
    return self.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:07:53,891:INFO:Calculating mean and std
2024-05-25 17:07:53,892:INFO:Creating metrics dataframe
2024-05-25 17:07:53,895:INFO:Finalizing model
2024-05-25 17:07:55,285:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:07:55,289:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:07:55,301:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003956 seconds.
2024-05-25 17:07:55,301:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:07:55,301:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:07:55,301:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:07:55,302:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:07:55,302:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:07:55,303:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:07:55,598:INFO:Uploading results into container
2024-05-25 17:07:55,599:INFO:Uploading model into container now
2024-05-25 17:07:55,600:INFO:_master_model_container: 62
2024-05-25 17:07:55,600:INFO:_display_container: 4
2024-05-25 17:07:55,603:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.546875,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:07:55,603:INFO:create_model() successfully completed......................................
2024-05-25 17:07:56,376:INFO:Threshold: 0.546875. Accuracy: 0.7151
2024-05-25 17:07:56,377:INFO:Initializing create_model()
2024-05-25 17:07:56,377:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.609375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:07:56,377:INFO:Checking exceptions
2024-05-25 17:07:56,379:INFO:Importing libraries
2024-05-25 17:07:56,380:INFO:Copying training dataset
2024-05-25 17:07:56,419:INFO:Defining folds
2024-05-25 17:07:56,419:INFO:Declaring metric variables
2024-05-25 17:07:56,420:INFO:Importing untrained model
2024-05-25 17:07:56,420:INFO:Declaring custom model
2024-05-25 17:07:56,421:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:07:56,421:INFO:Starting cross validation
2024-05-25 17:07:56,425:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:08:01,568:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 30.9 MiB for an array with shape (50, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:08:01,568:INFO:Calculating mean and std
2024-05-25 17:08:01,569:INFO:Creating metrics dataframe
2024-05-25 17:08:01,572:INFO:Finalizing model
2024-05-25 17:08:02,947:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:08:02,952:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:08:02,964:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004487 seconds.
2024-05-25 17:08:02,964:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:08:02,964:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:08:02,964:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:08:02,965:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:08:02,966:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:08:02,966:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:08:03,267:INFO:Uploading results into container
2024-05-25 17:08:03,268:INFO:Uploading model into container now
2024-05-25 17:08:03,269:INFO:_master_model_container: 63
2024-05-25 17:08:03,269:INFO:_display_container: 4
2024-05-25 17:08:03,272:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.609375,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:08:03,272:INFO:create_model() successfully completed......................................
2024-05-25 17:08:04,055:INFO:Threshold: 0.609375. Accuracy: 0.7121
2024-05-25 17:08:04,056:INFO:Initializing create_model()
2024-05-25 17:08:04,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.671875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:08:04,056:INFO:Checking exceptions
2024-05-25 17:08:04,058:INFO:Importing libraries
2024-05-25 17:08:04,058:INFO:Copying training dataset
2024-05-25 17:08:04,098:INFO:Defining folds
2024-05-25 17:08:04,098:INFO:Declaring metric variables
2024-05-25 17:08:04,098:INFO:Importing untrained model
2024-05-25 17:08:04,098:INFO:Declaring custom model
2024-05-25 17:08:04,099:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:08:04,100:INFO:Starting cross validation
2024-05-25 17:08:04,103:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:08:09,670:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 170, in _reorder_cols
    right=original_df[[col for col in original_df if col in columns]],
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 3908, in __getitem__
    data = self._take_with_is_copy(indexer, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4088, in _take_with_is_copy
    result = self.take(indices=indices, axis=axis)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4068, in take
    new_data = self._mgr.take(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 877, in take
    return self.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:08:09,670:INFO:Calculating mean and std
2024-05-25 17:08:09,671:INFO:Creating metrics dataframe
2024-05-25 17:08:09,674:INFO:Finalizing model
2024-05-25 17:08:11,048:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:08:11,052:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:08:11,068:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004470 seconds.
2024-05-25 17:08:11,068:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:08:11,069:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:08:11,069:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:08:11,069:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:08:11,070:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:08:11,070:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:08:11,364:INFO:Uploading results into container
2024-05-25 17:08:11,365:INFO:Uploading model into container now
2024-05-25 17:08:11,366:INFO:_master_model_container: 64
2024-05-25 17:08:11,366:INFO:_display_container: 4
2024-05-25 17:08:11,369:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.671875,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:08:11,369:INFO:create_model() successfully completed......................................
2024-05-25 17:08:12,142:INFO:Threshold: 0.671875. Accuracy: 0.7963
2024-05-25 17:08:12,143:INFO:Initializing create_model()
2024-05-25 17:08:12,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.03125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:08:12,143:INFO:Checking exceptions
2024-05-25 17:08:12,145:INFO:Importing libraries
2024-05-25 17:08:12,145:INFO:Copying training dataset
2024-05-25 17:08:12,194:INFO:Defining folds
2024-05-25 17:08:12,194:INFO:Declaring metric variables
2024-05-25 17:08:12,194:INFO:Importing untrained model
2024-05-25 17:08:12,194:INFO:Declaring custom model
2024-05-25 17:08:12,195:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:08:12,196:INFO:Starting cross validation
2024-05-25 17:08:12,200:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:08:17,697:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.85 MiB for an array with shape (3, 81000) and data type object

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 436, in transform
    X, y = convert_inputs(X, y, deep=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 80, in convert_inputs
    X = convert_input(X, columns=columns, deep=deep, index=X_alt_index)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\category_encoders\utils.py", line 116, in convert_input
    X = X.copy(deep=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.85 MiB for an array with shape (3, 81000) and data type object

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:08:17,697:INFO:Calculating mean and std
2024-05-25 17:08:17,698:INFO:Creating metrics dataframe
2024-05-25 17:08:17,701:INFO:Finalizing model
2024-05-25 17:08:19,091:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:08:19,097:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:08:19,113:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004203 seconds.
2024-05-25 17:08:19,113:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:08:19,113:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:08:19,113:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:08:19,114:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:08:19,114:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:08:19,114:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:08:19,420:INFO:Uploading results into container
2024-05-25 17:08:19,421:INFO:Uploading model into container now
2024-05-25 17:08:19,421:INFO:_master_model_container: 65
2024-05-25 17:08:19,421:INFO:_display_container: 4
2024-05-25 17:08:19,424:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.03125,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:08:19,424:INFO:create_model() successfully completed......................................
2024-05-25 17:08:20,197:INFO:Threshold: 0.03125. Accuracy: 0.5591
2024-05-25 17:08:20,198:INFO:Initializing create_model()
2024-05-25 17:08:20,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.734375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:08:20,198:INFO:Checking exceptions
2024-05-25 17:08:20,200:INFO:Importing libraries
2024-05-25 17:08:20,200:INFO:Copying training dataset
2024-05-25 17:08:20,239:INFO:Defining folds
2024-05-25 17:08:20,240:INFO:Declaring metric variables
2024-05-25 17:08:20,240:INFO:Importing untrained model
2024-05-25 17:08:20,240:INFO:Declaring custom model
2024-05-25 17:08:20,241:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:08:20,241:INFO:Starting cross validation
2024-05-25 17:08:20,245:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:08:25,311:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 178, in _reorder_cols
    return new_df[columns]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 3908, in __getitem__
    data = self._take_with_is_copy(indexer, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4088, in _take_with_is_copy
    result = self.take(indices=indices, axis=axis)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4068, in take
    new_data = self._mgr.take(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 877, in take
    return self.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 26.0 MiB for an array with shape (42, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2242, in _merge_blocks
    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\numpy\core\shape_base.py", line 289, in vstack
    return _nx.concatenate(arrs, 0, dtype=dtype, casting=casting)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:08:25,312:INFO:Calculating mean and std
2024-05-25 17:08:25,312:INFO:Creating metrics dataframe
2024-05-25 17:08:25,315:INFO:Finalizing model
2024-05-25 17:08:26,696:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:08:26,701:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:08:26,714:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003977 seconds.
2024-05-25 17:08:26,714:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:08:26,714:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:08:26,714:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:08:26,715:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:08:26,715:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:08:26,715:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:08:27,037:INFO:Uploading results into container
2024-05-25 17:08:27,038:INFO:Uploading model into container now
2024-05-25 17:08:27,039:INFO:_master_model_container: 66
2024-05-25 17:08:27,039:INFO:_display_container: 4
2024-05-25 17:08:27,042:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.734375,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:08:27,042:INFO:create_model() successfully completed......................................
2024-05-25 17:08:27,817:INFO:Threshold: 0.734375. Accuracy: 0.617
2024-05-25 17:08:27,818:INFO:Initializing create_model()
2024-05-25 17:08:27,818:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.65625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:08:27,818:INFO:Checking exceptions
2024-05-25 17:08:27,820:INFO:Importing libraries
2024-05-25 17:08:27,820:INFO:Copying training dataset
2024-05-25 17:08:27,866:INFO:Defining folds
2024-05-25 17:08:27,866:INFO:Declaring metric variables
2024-05-25 17:08:27,866:INFO:Importing untrained model
2024-05-25 17:08:27,866:INFO:Declaring custom model
2024-05-25 17:08:27,868:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:08:27,868:INFO:Starting cross validation
2024-05-25 17:08:27,872:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:08:34,145:INFO:Calculating mean and std
2024-05-25 17:08:34,146:INFO:Creating metrics dataframe
2024-05-25 17:08:34,149:INFO:Finalizing model
2024-05-25 17:08:35,553:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:08:35,558:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:08:35,571:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004104 seconds.
2024-05-25 17:08:35,571:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:08:35,572:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:08:35,572:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:08:35,572:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:08:35,573:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:08:35,573:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:08:35,871:INFO:Uploading results into container
2024-05-25 17:08:35,872:INFO:Uploading model into container now
2024-05-25 17:08:35,873:INFO:_master_model_container: 67
2024-05-25 17:08:35,873:INFO:_display_container: 4
2024-05-25 17:08:35,876:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.65625,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:08:35,876:INFO:create_model() successfully completed......................................
2024-05-25 17:08:36,644:INFO:Threshold: 0.65625. Accuracy: 0.8864
2024-05-25 17:08:36,645:INFO:Initializing create_model()
2024-05-25 17:08:36,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.78125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:08:36,646:INFO:Checking exceptions
2024-05-25 17:08:36,648:INFO:Importing libraries
2024-05-25 17:08:36,648:INFO:Copying training dataset
2024-05-25 17:08:36,695:INFO:Defining folds
2024-05-25 17:08:36,695:INFO:Declaring metric variables
2024-05-25 17:08:36,695:INFO:Importing untrained model
2024-05-25 17:08:36,695:INFO:Declaring custom model
2024-05-25 17:08:36,696:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:08:36,697:INFO:Starting cross validation
2024-05-25 17:08:36,701:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:08:43,114:INFO:Calculating mean and std
2024-05-25 17:08:43,115:INFO:Creating metrics dataframe
2024-05-25 17:08:43,118:INFO:Finalizing model
2024-05-25 17:08:44,498:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:08:44,503:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:08:44,515:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004242 seconds.
2024-05-25 17:08:44,516:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:08:44,516:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:08:44,516:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:08:44,516:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:08:44,517:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:08:44,517:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:08:44,817:INFO:Uploading results into container
2024-05-25 17:08:44,818:INFO:Uploading model into container now
2024-05-25 17:08:44,818:INFO:_master_model_container: 68
2024-05-25 17:08:44,819:INFO:_display_container: 4
2024-05-25 17:08:44,822:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.78125,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:08:44,822:INFO:create_model() successfully completed......................................
2024-05-25 17:08:45,592:INFO:Threshold: 0.78125. Accuracy: 0.8731
2024-05-25 17:08:45,593:INFO:Initializing create_model()
2024-05-25 17:08:45,593:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.796875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:08:45,593:INFO:Checking exceptions
2024-05-25 17:08:45,595:INFO:Importing libraries
2024-05-25 17:08:45,595:INFO:Copying training dataset
2024-05-25 17:08:45,636:INFO:Defining folds
2024-05-25 17:08:45,636:INFO:Declaring metric variables
2024-05-25 17:08:45,636:INFO:Importing untrained model
2024-05-25 17:08:45,636:INFO:Declaring custom model
2024-05-25 17:08:45,637:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:08:45,638:INFO:Starting cross validation
2024-05-25 17:08:45,641:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:08:52,194:INFO:Calculating mean and std
2024-05-25 17:08:52,195:INFO:Creating metrics dataframe
2024-05-25 17:08:52,198:INFO:Finalizing model
2024-05-25 17:08:53,599:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:08:53,604:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:08:53,618:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004522 seconds.
2024-05-25 17:08:53,618:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:08:53,618:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:08:53,619:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:08:53,619:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:08:53,620:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:08:53,620:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:08:53,915:INFO:Uploading results into container
2024-05-25 17:08:53,916:INFO:Uploading model into container now
2024-05-25 17:08:53,917:INFO:_master_model_container: 69
2024-05-25 17:08:53,917:INFO:_display_container: 4
2024-05-25 17:08:53,920:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.796875,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:08:53,920:INFO:create_model() successfully completed......................................
2024-05-25 17:08:54,692:INFO:Threshold: 0.796875. Accuracy: 0.8688
2024-05-25 17:08:54,693:INFO:Initializing create_model()
2024-05-25 17:08:54,693:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.859375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:08:54,693:INFO:Checking exceptions
2024-05-25 17:08:54,695:INFO:Importing libraries
2024-05-25 17:08:54,695:INFO:Copying training dataset
2024-05-25 17:08:54,735:INFO:Defining folds
2024-05-25 17:08:54,736:INFO:Declaring metric variables
2024-05-25 17:08:54,736:INFO:Importing untrained model
2024-05-25 17:08:54,736:INFO:Declaring custom model
2024-05-25 17:08:54,737:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:08:54,737:INFO:Starting cross validation
2024-05-25 17:08:54,741:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:09:01,095:INFO:Calculating mean and std
2024-05-25 17:09:01,096:INFO:Creating metrics dataframe
2024-05-25 17:09:01,099:INFO:Finalizing model
2024-05-25 17:09:02,472:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:09:02,476:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:09:02,492:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003556 seconds.
2024-05-25 17:09:02,492:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:09:02,492:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:09:02,492:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:09:02,492:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:09:02,493:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:09:02,493:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:09:02,796:INFO:Uploading results into container
2024-05-25 17:09:02,797:INFO:Uploading model into container now
2024-05-25 17:09:02,798:INFO:_master_model_container: 70
2024-05-25 17:09:02,798:INFO:_display_container: 4
2024-05-25 17:09:02,801:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.859375,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:09:02,801:INFO:create_model() successfully completed......................................
2024-05-25 17:09:03,573:INFO:Threshold: 0.859375. Accuracy: 0.8534
2024-05-25 17:09:03,574:INFO:Initializing create_model()
2024-05-25 17:09:03,574:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.90625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:09:03,574:INFO:Checking exceptions
2024-05-25 17:09:03,575:INFO:Importing libraries
2024-05-25 17:09:03,576:INFO:Copying training dataset
2024-05-25 17:09:03,616:INFO:Defining folds
2024-05-25 17:09:03,616:INFO:Declaring metric variables
2024-05-25 17:09:03,617:INFO:Importing untrained model
2024-05-25 17:09:03,617:INFO:Declaring custom model
2024-05-25 17:09:03,618:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:09:03,618:INFO:Starting cross validation
2024-05-25 17:09:03,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:09:10,090:INFO:Calculating mean and std
2024-05-25 17:09:10,091:INFO:Creating metrics dataframe
2024-05-25 17:09:10,094:INFO:Finalizing model
2024-05-25 17:09:11,484:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:09:11,488:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:09:11,499:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003628 seconds.
2024-05-25 17:09:11,499:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:09:11,499:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:09:11,500:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:09:11,500:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:09:11,501:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:09:11,501:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:09:11,795:INFO:Uploading results into container
2024-05-25 17:09:11,796:INFO:Uploading model into container now
2024-05-25 17:09:11,796:INFO:_master_model_container: 71
2024-05-25 17:09:11,796:INFO:_display_container: 4
2024-05-25 17:09:11,800:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.90625,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:09:11,800:INFO:create_model() successfully completed......................................
2024-05-25 17:09:12,568:INFO:Threshold: 0.90625. Accuracy: 0.8334
2024-05-25 17:09:12,569:INFO:Initializing create_model()
2024-05-25 17:09:12,569:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.921875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:09:12,569:INFO:Checking exceptions
2024-05-25 17:09:12,571:INFO:Importing libraries
2024-05-25 17:09:12,571:INFO:Copying training dataset
2024-05-25 17:09:12,616:INFO:Defining folds
2024-05-25 17:09:12,616:INFO:Declaring metric variables
2024-05-25 17:09:12,617:INFO:Importing untrained model
2024-05-25 17:09:12,617:INFO:Declaring custom model
2024-05-25 17:09:12,618:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:09:12,618:INFO:Starting cross validation
2024-05-25 17:09:12,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:09:18,888:INFO:Calculating mean and std
2024-05-25 17:09:18,889:INFO:Creating metrics dataframe
2024-05-25 17:09:18,892:INFO:Finalizing model
2024-05-25 17:09:20,261:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:09:20,265:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:09:20,282:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004980 seconds.
2024-05-25 17:09:20,282:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:09:20,282:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:09:20,283:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:09:20,283:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:09:20,284:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:09:20,284:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:09:20,578:INFO:Uploading results into container
2024-05-25 17:09:20,579:INFO:Uploading model into container now
2024-05-25 17:09:20,579:INFO:_master_model_container: 72
2024-05-25 17:09:20,579:INFO:_display_container: 4
2024-05-25 17:09:20,582:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.921875,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:09:20,583:INFO:create_model() successfully completed......................................
2024-05-25 17:09:21,355:INFO:Threshold: 0.921875. Accuracy: 0.8239
2024-05-25 17:09:21,356:INFO:Initializing create_model()
2024-05-25 17:09:21,356:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.984375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:09:21,356:INFO:Checking exceptions
2024-05-25 17:09:21,358:INFO:Importing libraries
2024-05-25 17:09:21,359:INFO:Copying training dataset
2024-05-25 17:09:21,398:INFO:Defining folds
2024-05-25 17:09:21,398:INFO:Declaring metric variables
2024-05-25 17:09:21,399:INFO:Importing untrained model
2024-05-25 17:09:21,399:INFO:Declaring custom model
2024-05-25 17:09:21,400:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:09:21,400:INFO:Starting cross validation
2024-05-25 17:09:21,404:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:09:27,924:INFO:Calculating mean and std
2024-05-25 17:09:27,925:INFO:Creating metrics dataframe
2024-05-25 17:09:27,928:INFO:Finalizing model
2024-05-25 17:09:29,312:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:09:29,316:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:09:29,329:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004075 seconds.
2024-05-25 17:09:29,329:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:09:29,329:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:09:29,329:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:09:29,330:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:09:29,331:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:09:29,331:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:09:29,631:INFO:Uploading results into container
2024-05-25 17:09:29,632:INFO:Uploading model into container now
2024-05-25 17:09:29,633:INFO:_master_model_container: 73
2024-05-25 17:09:29,633:INFO:_display_container: 4
2024-05-25 17:09:29,636:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.984375,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:09:29,636:INFO:create_model() successfully completed......................................
2024-05-25 17:09:30,407:INFO:Threshold: 0.984375. Accuracy: 0.7144
2024-05-25 17:09:30,408:INFO:Initializing create_model()
2024-05-25 17:09:30,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.6868286363865266, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:09:30,409:INFO:Checking exceptions
2024-05-25 17:09:30,410:INFO:Importing libraries
2024-05-25 17:09:30,411:INFO:Copying training dataset
2024-05-25 17:09:30,457:INFO:Defining folds
2024-05-25 17:09:30,457:INFO:Declaring metric variables
2024-05-25 17:09:30,457:INFO:Importing untrained model
2024-05-25 17:09:30,457:INFO:Declaring custom model
2024-05-25 17:09:30,459:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:09:30,459:INFO:Starting cross validation
2024-05-25 17:09:30,463:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:09:36,668:INFO:Calculating mean and std
2024-05-25 17:09:36,669:INFO:Creating metrics dataframe
2024-05-25 17:09:36,672:INFO:Finalizing model
2024-05-25 17:09:38,055:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:09:38,059:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:09:38,072:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003823 seconds.
2024-05-25 17:09:38,072:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:09:38,072:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:09:38,072:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:09:38,073:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:09:38,074:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:09:38,074:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:09:38,372:INFO:Uploading results into container
2024-05-25 17:09:38,373:INFO:Uploading model into container now
2024-05-25 17:09:38,374:INFO:_master_model_container: 74
2024-05-25 17:09:38,374:INFO:_display_container: 4
2024-05-25 17:09:38,377:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.6868286363865266,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:09:38,377:INFO:create_model() successfully completed......................................
2024-05-25 17:09:39,144:INFO:Threshold: 0.6868286363865266. Accuracy: 0.8843
2024-05-25 17:09:39,145:INFO:Initializing create_model()
2024-05-25 17:09:39,146:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.15625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:09:39,146:INFO:Checking exceptions
2024-05-25 17:09:39,148:INFO:Importing libraries
2024-05-25 17:09:39,148:INFO:Copying training dataset
2024-05-25 17:09:39,194:INFO:Defining folds
2024-05-25 17:09:39,194:INFO:Declaring metric variables
2024-05-25 17:09:39,195:INFO:Importing untrained model
2024-05-25 17:09:39,195:INFO:Declaring custom model
2024-05-25 17:09:39,196:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:09:39,196:INFO:Starting cross validation
2024-05-25 17:09:39,200:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:09:45,747:INFO:Calculating mean and std
2024-05-25 17:09:45,748:INFO:Creating metrics dataframe
2024-05-25 17:09:45,751:INFO:Finalizing model
2024-05-25 17:09:47,132:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:09:47,137:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:09:47,150:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004365 seconds.
2024-05-25 17:09:47,150:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:09:47,151:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:09:47,151:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:09:47,151:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:09:47,152:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:09:47,152:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:09:47,454:INFO:Uploading results into container
2024-05-25 17:09:47,455:INFO:Uploading model into container now
2024-05-25 17:09:47,456:INFO:_master_model_container: 75
2024-05-25 17:09:47,456:INFO:_display_container: 4
2024-05-25 17:09:47,459:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.15625,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:09:47,459:INFO:create_model() successfully completed......................................
2024-05-25 17:09:48,227:INFO:Threshold: 0.15625. Accuracy: 0.8422
2024-05-25 17:09:48,228:INFO:Initializing create_model()
2024-05-25 17:09:48,228:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.046875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:09:48,228:INFO:Checking exceptions
2024-05-25 17:09:48,230:INFO:Importing libraries
2024-05-25 17:09:48,230:INFO:Copying training dataset
2024-05-25 17:09:48,276:INFO:Defining folds
2024-05-25 17:09:48,276:INFO:Declaring metric variables
2024-05-25 17:09:48,276:INFO:Importing untrained model
2024-05-25 17:09:48,276:INFO:Declaring custom model
2024-05-25 17:09:48,277:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:09:48,278:INFO:Starting cross validation
2024-05-25 17:09:48,282:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:09:54,633:INFO:Calculating mean and std
2024-05-25 17:09:54,634:INFO:Creating metrics dataframe
2024-05-25 17:09:54,637:INFO:Finalizing model
2024-05-25 17:09:56,003:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:09:56,008:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:09:56,021:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003682 seconds.
2024-05-25 17:09:56,021:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:09:56,021:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:09:56,022:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:09:56,022:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:09:56,023:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:09:56,023:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:09:56,323:INFO:Uploading results into container
2024-05-25 17:09:56,324:INFO:Uploading model into container now
2024-05-25 17:09:56,324:INFO:_master_model_container: 76
2024-05-25 17:09:56,324:INFO:_display_container: 4
2024-05-25 17:09:56,327:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.046875,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:09:56,327:INFO:create_model() successfully completed......................................
2024-05-25 17:09:57,106:INFO:Threshold: 0.046875. Accuracy: 0.7231
2024-05-25 17:09:57,107:INFO:Initializing create_model()
2024-05-25 17:09:57,107:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.171875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:09:57,107:INFO:Checking exceptions
2024-05-25 17:09:57,109:INFO:Importing libraries
2024-05-25 17:09:57,110:INFO:Copying training dataset
2024-05-25 17:09:57,150:INFO:Defining folds
2024-05-25 17:09:57,150:INFO:Declaring metric variables
2024-05-25 17:09:57,150:INFO:Importing untrained model
2024-05-25 17:09:57,150:INFO:Declaring custom model
2024-05-25 17:09:57,151:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:09:57,152:INFO:Starting cross validation
2024-05-25 17:09:57,156:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:10:03,626:INFO:Calculating mean and std
2024-05-25 17:10:03,627:INFO:Creating metrics dataframe
2024-05-25 17:10:03,630:INFO:Finalizing model
2024-05-25 17:10:05,017:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:10:05,022:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:10:05,036:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004456 seconds.
2024-05-25 17:10:05,036:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:10:05,036:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:10:05,036:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:10:05,037:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:10:05,038:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:10:05,038:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:10:05,333:INFO:Uploading results into container
2024-05-25 17:10:05,334:INFO:Uploading model into container now
2024-05-25 17:10:05,335:INFO:_master_model_container: 77
2024-05-25 17:10:05,335:INFO:_display_container: 4
2024-05-25 17:10:05,338:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.171875,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:10:05,338:INFO:create_model() successfully completed......................................
2024-05-25 17:10:06,113:INFO:Threshold: 0.171875. Accuracy: 0.852
2024-05-25 17:10:06,114:INFO:Initializing create_model()
2024-05-25 17:10:06,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.109375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:10:06,114:INFO:Checking exceptions
2024-05-25 17:10:06,116:INFO:Importing libraries
2024-05-25 17:10:06,116:INFO:Copying training dataset
2024-05-25 17:10:06,156:INFO:Defining folds
2024-05-25 17:10:06,156:INFO:Declaring metric variables
2024-05-25 17:10:06,157:INFO:Importing untrained model
2024-05-25 17:10:06,157:INFO:Declaring custom model
2024-05-25 17:10:06,158:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:10:06,158:INFO:Starting cross validation
2024-05-25 17:10:06,162:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:10:12,633:INFO:Calculating mean and std
2024-05-25 17:10:12,634:INFO:Creating metrics dataframe
2024-05-25 17:10:12,637:INFO:Finalizing model
2024-05-25 17:10:14,019:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:10:14,024:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:10:14,036:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003361 seconds.
2024-05-25 17:10:14,036:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:10:14,036:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:10:14,036:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:10:14,037:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:10:14,037:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:10:14,037:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:10:14,339:INFO:Uploading results into container
2024-05-25 17:10:14,340:INFO:Uploading model into container now
2024-05-25 17:10:14,340:INFO:_master_model_container: 78
2024-05-25 17:10:14,340:INFO:_display_container: 4
2024-05-25 17:10:14,343:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.109375,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:10:14,343:INFO:create_model() successfully completed......................................
2024-05-25 17:10:15,118:INFO:Threshold: 0.109375. Accuracy: 0.8022
2024-05-25 17:10:15,120:INFO:Initializing create_model()
2024-05-25 17:10:15,120:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.234375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:10:15,120:INFO:Checking exceptions
2024-05-25 17:10:15,122:INFO:Importing libraries
2024-05-25 17:10:15,122:INFO:Copying training dataset
2024-05-25 17:10:15,161:INFO:Defining folds
2024-05-25 17:10:15,161:INFO:Declaring metric variables
2024-05-25 17:10:15,162:INFO:Importing untrained model
2024-05-25 17:10:15,162:INFO:Declaring custom model
2024-05-25 17:10:15,163:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:10:15,163:INFO:Starting cross validation
2024-05-25 17:10:15,167:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:10:21,772:INFO:Calculating mean and std
2024-05-25 17:10:21,773:INFO:Creating metrics dataframe
2024-05-25 17:10:21,776:INFO:Finalizing model
2024-05-25 17:10:23,170:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:10:23,174:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:10:23,187:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003929 seconds.
2024-05-25 17:10:23,187:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:10:23,187:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:10:23,188:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:10:23,188:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:10:23,189:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:10:23,189:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:10:23,495:INFO:Uploading results into container
2024-05-25 17:10:23,496:INFO:Uploading model into container now
2024-05-25 17:10:23,497:INFO:_master_model_container: 79
2024-05-25 17:10:23,497:INFO:_display_container: 4
2024-05-25 17:10:23,500:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.234375,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:10:23,500:INFO:create_model() successfully completed......................................
2024-05-25 17:10:24,272:INFO:Threshold: 0.234375. Accuracy: 0.8754
2024-05-25 17:10:24,273:INFO:Initializing create_model()
2024-05-25 17:10:24,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.28125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:10:24,273:INFO:Checking exceptions
2024-05-25 17:10:24,275:INFO:Importing libraries
2024-05-25 17:10:24,275:INFO:Copying training dataset
2024-05-25 17:10:24,314:INFO:Defining folds
2024-05-25 17:10:24,314:INFO:Declaring metric variables
2024-05-25 17:10:24,314:INFO:Importing untrained model
2024-05-25 17:10:24,315:INFO:Declaring custom model
2024-05-25 17:10:24,316:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:10:24,316:INFO:Starting cross validation
2024-05-25 17:10:24,320:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:10:30,859:INFO:Calculating mean and std
2024-05-25 17:10:30,860:INFO:Creating metrics dataframe
2024-05-25 17:10:30,863:INFO:Finalizing model
2024-05-25 17:10:32,247:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:10:32,252:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:10:32,263:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003783 seconds.
2024-05-25 17:10:32,263:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:10:32,263:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:10:32,263:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:10:32,264:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:10:32,264:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:10:32,265:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:10:32,593:INFO:Uploading results into container
2024-05-25 17:10:32,594:INFO:Uploading model into container now
2024-05-25 17:10:32,595:INFO:_master_model_container: 80
2024-05-25 17:10:32,595:INFO:_display_container: 4
2024-05-25 17:10:32,598:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.28125,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:10:32,598:INFO:create_model() successfully completed......................................
2024-05-25 17:10:33,375:INFO:Threshold: 0.28125. Accuracy: 0.8835
2024-05-25 17:10:33,376:INFO:Initializing create_model()
2024-05-25 17:10:33,376:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.296875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:10:33,376:INFO:Checking exceptions
2024-05-25 17:10:33,378:INFO:Importing libraries
2024-05-25 17:10:33,378:INFO:Copying training dataset
2024-05-25 17:10:33,418:INFO:Defining folds
2024-05-25 17:10:33,418:INFO:Declaring metric variables
2024-05-25 17:10:33,418:INFO:Importing untrained model
2024-05-25 17:10:33,418:INFO:Declaring custom model
2024-05-25 17:10:33,419:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:10:33,420:INFO:Starting cross validation
2024-05-25 17:10:33,424:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:10:40,139:INFO:Calculating mean and std
2024-05-25 17:10:40,140:INFO:Creating metrics dataframe
2024-05-25 17:10:40,143:INFO:Finalizing model
2024-05-25 17:10:41,526:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:10:41,530:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:10:41,541:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004254 seconds.
2024-05-25 17:10:41,541:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:10:41,541:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:10:41,541:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:10:41,542:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:10:41,543:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:10:41,543:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:10:41,848:INFO:Uploading results into container
2024-05-25 17:10:41,849:INFO:Uploading model into container now
2024-05-25 17:10:41,849:INFO:_master_model_container: 81
2024-05-25 17:10:41,850:INFO:_display_container: 4
2024-05-25 17:10:41,853:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.296875,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:10:41,853:INFO:create_model() successfully completed......................................
2024-05-25 17:10:42,628:INFO:Threshold: 0.296875. Accuracy: 0.8856
2024-05-25 17:10:42,628:INFO:Initializing create_model()
2024-05-25 17:10:42,629:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.359375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:10:42,629:INFO:Checking exceptions
2024-05-25 17:10:42,630:INFO:Importing libraries
2024-05-25 17:10:42,631:INFO:Copying training dataset
2024-05-25 17:10:42,670:INFO:Defining folds
2024-05-25 17:10:42,670:INFO:Declaring metric variables
2024-05-25 17:10:42,671:INFO:Importing untrained model
2024-05-25 17:10:42,671:INFO:Declaring custom model
2024-05-25 17:10:42,672:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:10:42,672:INFO:Starting cross validation
2024-05-25 17:10:42,676:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:10:48,531:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 289, in transform
    return X.rename(columns=lambda x: re.sub(self.match, "", str(x)))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 31.5 MiB for an array with shape (51, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:10:48,531:INFO:Calculating mean and std
2024-05-25 17:10:48,532:INFO:Creating metrics dataframe
2024-05-25 17:10:48,535:INFO:Finalizing model
2024-05-25 17:10:49,917:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:10:49,922:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:10:49,937:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003586 seconds.
2024-05-25 17:10:49,937:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:10:49,937:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:10:49,937:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:10:49,938:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:10:49,938:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:10:49,938:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:10:50,239:INFO:Uploading results into container
2024-05-25 17:10:50,240:INFO:Uploading model into container now
2024-05-25 17:10:50,241:INFO:_master_model_container: 82
2024-05-25 17:10:50,241:INFO:_display_container: 4
2024-05-25 17:10:50,244:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.359375,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:10:50,244:INFO:create_model() successfully completed......................................
2024-05-25 17:10:51,043:INFO:Threshold: 0.359375. Accuracy: 0.8017
2024-05-25 17:10:51,044:INFO:Initializing create_model()
2024-05-25 17:10:51,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.40625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:10:51,045:INFO:Checking exceptions
2024-05-25 17:10:51,047:INFO:Importing libraries
2024-05-25 17:10:51,047:INFO:Copying training dataset
2024-05-25 17:10:51,086:INFO:Defining folds
2024-05-25 17:10:51,086:INFO:Declaring metric variables
2024-05-25 17:10:51,087:INFO:Importing untrained model
2024-05-25 17:10:51,087:INFO:Declaring custom model
2024-05-25 17:10:51,088:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:10:51,088:INFO:Starting cross validation
2024-05-25 17:10:51,092:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:10:57,453:INFO:Calculating mean and std
2024-05-25 17:10:57,454:INFO:Creating metrics dataframe
2024-05-25 17:10:57,457:INFO:Finalizing model
2024-05-25 17:10:58,864:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:10:58,870:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:10:58,883:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004236 seconds.
2024-05-25 17:10:58,883:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:10:58,883:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:10:58,883:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:10:58,883:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:10:58,884:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:10:58,884:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:10:59,180:INFO:Uploading results into container
2024-05-25 17:10:59,181:INFO:Uploading model into container now
2024-05-25 17:10:59,181:INFO:_master_model_container: 83
2024-05-25 17:10:59,181:INFO:_display_container: 4
2024-05-25 17:10:59,184:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.40625,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:10:59,184:INFO:create_model() successfully completed......................................
2024-05-25 17:10:59,959:INFO:Threshold: 0.40625. Accuracy: 0.8929
2024-05-25 17:10:59,960:INFO:Initializing create_model()
2024-05-25 17:10:59,960:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.421875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:10:59,960:INFO:Checking exceptions
2024-05-25 17:10:59,962:INFO:Importing libraries
2024-05-25 17:10:59,962:INFO:Copying training dataset
2024-05-25 17:11:00,009:INFO:Defining folds
2024-05-25 17:11:00,010:INFO:Declaring metric variables
2024-05-25 17:11:00,010:INFO:Importing untrained model
2024-05-25 17:11:00,010:INFO:Declaring custom model
2024-05-25 17:11:00,011:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:11:00,011:INFO:Starting cross validation
2024-05-25 17:11:00,015:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:11:06,450:INFO:Calculating mean and std
2024-05-25 17:11:06,451:INFO:Creating metrics dataframe
2024-05-25 17:11:06,454:INFO:Finalizing model
2024-05-25 17:11:07,853:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:11:07,858:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:11:07,870:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003168 seconds.
2024-05-25 17:11:07,870:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:11:07,870:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:11:07,870:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:11:07,871:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:11:07,871:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:11:07,871:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:11:08,169:INFO:Uploading results into container
2024-05-25 17:11:08,170:INFO:Uploading model into container now
2024-05-25 17:11:08,171:INFO:_master_model_container: 84
2024-05-25 17:11:08,171:INFO:_display_container: 4
2024-05-25 17:11:08,174:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.421875,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:11:08,174:INFO:create_model() successfully completed......................................
2024-05-25 17:11:08,999:INFO:Threshold: 0.421875. Accuracy: 0.8936
2024-05-25 17:11:09,003:INFO:Initializing create_model()
2024-05-25 17:11:09,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.296875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:11:09,003:INFO:Checking exceptions
2024-05-25 17:11:09,005:INFO:Importing libraries
2024-05-25 17:11:09,005:INFO:Copying training dataset
2024-05-25 17:11:09,045:INFO:Defining folds
2024-05-25 17:11:09,045:INFO:Declaring metric variables
2024-05-25 17:11:09,045:INFO:Importing untrained model
2024-05-25 17:11:09,045:INFO:Declaring custom model
2024-05-25 17:11:09,046:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:11:09,047:INFO:Starting cross validation
2024-05-25 17:11:09,051:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:11:15,645:INFO:Calculating mean and std
2024-05-25 17:11:15,646:INFO:Creating metrics dataframe
2024-05-25 17:11:15,649:INFO:Finalizing model
2024-05-25 17:11:17,070:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:11:17,074:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:11:17,087:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003886 seconds.
2024-05-25 17:11:17,088:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:11:17,088:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:11:17,088:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:11:17,088:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:11:17,089:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:11:17,089:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:11:17,438:INFO:Uploading results into container
2024-05-25 17:11:17,439:INFO:Uploading model into container now
2024-05-25 17:11:17,440:INFO:_master_model_container: 85
2024-05-25 17:11:17,440:INFO:_display_container: 4
2024-05-25 17:11:17,443:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.296875,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:11:17,443:INFO:create_model() successfully completed......................................
2024-05-25 17:11:18,227:INFO:Threshold: 0.296875. Accuracy: 0.8856
2024-05-25 17:11:18,228:INFO:Initializing create_model()
2024-05-25 17:11:18,228:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.2968750149011612, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:11:18,228:INFO:Checking exceptions
2024-05-25 17:11:18,230:INFO:Importing libraries
2024-05-25 17:11:18,230:INFO:Copying training dataset
2024-05-25 17:11:18,270:INFO:Defining folds
2024-05-25 17:11:18,270:INFO:Declaring metric variables
2024-05-25 17:11:18,270:INFO:Importing untrained model
2024-05-25 17:11:18,270:INFO:Declaring custom model
2024-05-25 17:11:18,271:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:11:18,272:INFO:Starting cross validation
2024-05-25 17:11:18,276:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:11:24,681:INFO:Calculating mean and std
2024-05-25 17:11:24,682:INFO:Creating metrics dataframe
2024-05-25 17:11:24,685:INFO:Finalizing model
2024-05-25 17:11:26,073:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:11:26,077:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:11:26,090:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003782 seconds.
2024-05-25 17:11:26,090:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:11:26,090:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:11:26,091:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:11:26,091:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:11:26,092:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:11:26,092:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:11:26,428:INFO:Uploading results into container
2024-05-25 17:11:26,429:INFO:Uploading model into container now
2024-05-25 17:11:26,430:INFO:_master_model_container: 86
2024-05-25 17:11:26,430:INFO:_display_container: 4
2024-05-25 17:11:26,433:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.2968750149011612,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:11:26,433:INFO:create_model() successfully completed......................................
2024-05-25 17:11:27,215:INFO:Threshold: 0.2968750149011612. Accuracy: 0.8856
2024-05-25 17:11:27,216:INFO:Initializing create_model()
2024-05-25 17:11:27,216:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.78125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:11:27,216:INFO:Checking exceptions
2024-05-25 17:11:27,218:INFO:Importing libraries
2024-05-25 17:11:27,219:INFO:Copying training dataset
2024-05-25 17:11:27,258:INFO:Defining folds
2024-05-25 17:11:27,258:INFO:Declaring metric variables
2024-05-25 17:11:27,259:INFO:Importing untrained model
2024-05-25 17:11:27,259:INFO:Declaring custom model
2024-05-25 17:11:27,260:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:11:27,260:INFO:Starting cross validation
2024-05-25 17:11:27,264:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:11:33,760:INFO:Calculating mean and std
2024-05-25 17:11:33,761:INFO:Creating metrics dataframe
2024-05-25 17:11:33,764:INFO:Finalizing model
2024-05-25 17:11:35,335:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:11:35,340:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:11:35,353:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003752 seconds.
2024-05-25 17:11:35,353:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:11:35,353:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:11:35,353:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:11:35,354:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:11:35,354:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:11:35,354:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:11:35,682:INFO:Uploading results into container
2024-05-25 17:11:35,684:INFO:Uploading model into container now
2024-05-25 17:11:35,684:INFO:_master_model_container: 87
2024-05-25 17:11:35,685:INFO:_display_container: 4
2024-05-25 17:11:35,688:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.78125,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:11:35,688:INFO:create_model() successfully completed......................................
2024-05-25 17:11:36,472:INFO:Threshold: 0.78125. Accuracy: 0.8731
2024-05-25 17:11:36,474:INFO:Initializing create_model()
2024-05-25 17:11:36,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.7812500149011612, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:11:36,474:INFO:Checking exceptions
2024-05-25 17:11:36,476:INFO:Importing libraries
2024-05-25 17:11:36,476:INFO:Copying training dataset
2024-05-25 17:11:36,516:INFO:Defining folds
2024-05-25 17:11:36,516:INFO:Declaring metric variables
2024-05-25 17:11:36,516:INFO:Importing untrained model
2024-05-25 17:11:36,516:INFO:Declaring custom model
2024-05-25 17:11:36,518:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:11:36,518:INFO:Starting cross validation
2024-05-25 17:11:36,522:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:11:42,723:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:11:42,723:INFO:Calculating mean and std
2024-05-25 17:11:42,724:INFO:Creating metrics dataframe
2024-05-25 17:11:42,727:INFO:Finalizing model
2024-05-25 17:11:44,099:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:11:44,104:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:11:44,117:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004170 seconds.
2024-05-25 17:11:44,117:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:11:44,117:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:11:44,118:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:11:44,118:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:11:44,119:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:11:44,119:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:11:44,457:INFO:Uploading results into container
2024-05-25 17:11:44,457:INFO:Uploading model into container now
2024-05-25 17:11:44,458:INFO:_master_model_container: 88
2024-05-25 17:11:44,458:INFO:_display_container: 4
2024-05-25 17:11:44,461:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.7812500149011612,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:11:44,461:INFO:create_model() successfully completed......................................
2024-05-25 17:11:45,253:INFO:Threshold: 0.7812500149011612. Accuracy: 0.7854
2024-05-25 17:11:45,255:INFO:Initializing create_model()
2024-05-25 17:11:45,255:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.421875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:11:45,256:INFO:Checking exceptions
2024-05-25 17:11:45,258:INFO:Importing libraries
2024-05-25 17:11:45,258:INFO:Copying training dataset
2024-05-25 17:11:45,301:INFO:Defining folds
2024-05-25 17:11:45,301:INFO:Declaring metric variables
2024-05-25 17:11:45,301:INFO:Importing untrained model
2024-05-25 17:11:45,301:INFO:Declaring custom model
2024-05-25 17:11:45,303:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:11:45,303:INFO:Starting cross validation
2024-05-25 17:11:45,307:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:11:52,055:INFO:Calculating mean and std
2024-05-25 17:11:52,056:INFO:Creating metrics dataframe
2024-05-25 17:11:52,059:INFO:Finalizing model
2024-05-25 17:11:53,470:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:11:53,475:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:11:53,488:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004030 seconds.
2024-05-25 17:11:53,488:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:11:53,488:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:11:53,488:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:11:53,489:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:11:53,489:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:11:53,489:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:11:53,792:INFO:Uploading results into container
2024-05-25 17:11:53,793:INFO:Uploading model into container now
2024-05-25 17:11:53,794:INFO:_master_model_container: 89
2024-05-25 17:11:53,794:INFO:_display_container: 4
2024-05-25 17:11:53,797:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.421875,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:11:53,797:INFO:create_model() successfully completed......................................
2024-05-25 17:11:54,577:INFO:Threshold: 0.421875. Accuracy: 0.8936
2024-05-25 17:11:54,578:INFO:Initializing create_model()
2024-05-25 17:11:54,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.4218750149011612, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:11:54,578:INFO:Checking exceptions
2024-05-25 17:11:54,580:INFO:Importing libraries
2024-05-25 17:11:54,580:INFO:Copying training dataset
2024-05-25 17:11:54,620:INFO:Defining folds
2024-05-25 17:11:54,620:INFO:Declaring metric variables
2024-05-25 17:11:54,621:INFO:Importing untrained model
2024-05-25 17:11:54,621:INFO:Declaring custom model
2024-05-25 17:11:54,622:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:11:54,622:INFO:Starting cross validation
2024-05-25 17:11:54,626:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:12:00,733:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 29.7 MiB for an array with shape (48, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:12:00,733:INFO:Calculating mean and std
2024-05-25 17:12:00,734:INFO:Creating metrics dataframe
2024-05-25 17:12:00,737:INFO:Finalizing model
2024-05-25 17:12:02,108:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:12:02,112:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:12:02,123:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003354 seconds.
2024-05-25 17:12:02,123:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:12:02,124:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:12:02,124:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:12:02,124:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:12:02,125:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:12:02,125:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:12:02,447:INFO:Uploading results into container
2024-05-25 17:12:02,448:INFO:Uploading model into container now
2024-05-25 17:12:02,449:INFO:_master_model_container: 90
2024-05-25 17:12:02,449:INFO:_display_container: 4
2024-05-25 17:12:02,452:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.4218750149011612,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:12:02,452:INFO:create_model() successfully completed......................................
2024-05-25 17:12:03,242:INFO:Threshold: 0.4218750149011612. Accuracy: 0.8045
2024-05-25 17:12:03,243:INFO:Initializing create_model()
2024-05-25 17:12:03,243:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.0, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:12:03,243:INFO:Checking exceptions
2024-05-25 17:12:03,245:INFO:Importing libraries
2024-05-25 17:12:03,245:INFO:Copying training dataset
2024-05-25 17:12:03,285:INFO:Defining folds
2024-05-25 17:12:03,285:INFO:Declaring metric variables
2024-05-25 17:12:03,285:INFO:Importing untrained model
2024-05-25 17:12:03,285:INFO:Declaring custom model
2024-05-25 17:12:03,286:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:12:03,287:INFO:Starting cross validation
2024-05-25 17:12:03,290:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:12:08,965:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\meta_estimators.py", line 152, in fit
    self.classifier_.fit(X, y, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\sklearn.py", line 1187, in fit
    super().fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\sklearn.py", line 885, in fit
    self._Booster = train(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\engine.py", line 255, in train
    booster = Booster(params=params, train_set=train_set)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\basic.py", line 3433, in __init__
    train_set.construct()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\basic.py", line 2462, in construct
    self._lazy_init(data=self.data, label=self.label, reference=None,
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\basic.py", line 2022, in _lazy_init
    data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\basic.py", line 825, in _data_from_pandas
    _pandas_to_numpy(data, target_dtype=target_dtype),
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\basic.py", line 774, in _pandas_to_numpy
    return data.to_numpy(dtype=target_dtype, copy=False)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1889, in to_numpy
    result = self._mgr.as_array(dtype=dtype, copy=copy, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 34.0 MiB for an array with shape (55, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\meta_estimators.py", line 152, in fit
    self.classifier_.fit(X, y, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\sklearn.py", line 1187, in fit
    super().fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\sklearn.py", line 885, in fit
    self._Booster = train(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\engine.py", line 255, in train
    booster = Booster(params=params, train_set=train_set)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\basic.py", line 3433, in __init__
    train_set.construct()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\basic.py", line 2462, in construct
    self._lazy_init(data=self.data, label=self.label, reference=None,
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\basic.py", line 2079, in _lazy_init
    self.__init_from_np2d(data, params_str, ref_dataset)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\lightgbm\basic.py", line 2213, in __init_from_np2d
    data = np.array(mat.reshape(mat.size), dtype=mat.dtype, copy=False)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 34.0 MiB for an array with shape (81000, 55) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:12:08,965:INFO:Calculating mean and std
2024-05-25 17:12:08,966:INFO:Creating metrics dataframe
2024-05-25 17:12:08,969:INFO:Finalizing model
2024-05-25 17:12:10,361:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:12:10,368:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:12:10,378:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003941 seconds.
2024-05-25 17:12:10,378:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:12:10,378:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:12:10,379:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:12:10,379:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:12:10,380:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:12:10,380:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:12:10,698:INFO:Uploading results into container
2024-05-25 17:12:10,699:INFO:Uploading model into container now
2024-05-25 17:12:10,699:INFO:_master_model_container: 91
2024-05-25 17:12:10,699:INFO:_display_container: 4
2024-05-25 17:12:10,702:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_for_bin=200000,
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None, probability_threshold=0.0,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:12:10,703:INFO:create_model() successfully completed......................................
2024-05-25 17:12:11,480:INFO:Threshold: 0.0. Accuracy: 0.4301
2024-05-25 17:12:11,481:INFO:Initializing create_model()
2024-05-25 17:12:11,482:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.21093753875806368, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:12:11,482:INFO:Checking exceptions
2024-05-25 17:12:11,483:INFO:Importing libraries
2024-05-25 17:12:11,483:INFO:Copying training dataset
2024-05-25 17:12:11,524:INFO:Defining folds
2024-05-25 17:12:11,524:INFO:Declaring metric variables
2024-05-25 17:12:11,524:INFO:Importing untrained model
2024-05-25 17:12:11,524:INFO:Declaring custom model
2024-05-25 17:12:11,525:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:12:11,526:INFO:Starting cross validation
2024-05-25 17:12:11,530:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:12:18,497:INFO:Calculating mean and std
2024-05-25 17:12:18,498:INFO:Creating metrics dataframe
2024-05-25 17:12:18,501:INFO:Finalizing model
2024-05-25 17:12:19,899:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-25 17:12:19,904:INFO:[LightGBM] [Info] Number of positive: 48382, number of negative: 41618
2024-05-25 17:12:19,919:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003732 seconds.
2024-05-25 17:12:19,920:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-25 17:12:19,920:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-25 17:12:19,920:INFO:[LightGBM] [Info] Total Bins 1725
2024-05-25 17:12:19,921:INFO:[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 49
2024-05-25 17:12:19,921:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537578 -> initscore=0.150595
2024-05-25 17:12:19,922:INFO:[LightGBM] [Info] Start training from score 0.150595
2024-05-25 17:12:20,268:INFO:Uploading results into container
2024-05-25 17:12:20,269:INFO:Uploading model into container now
2024-05-25 17:12:20,270:INFO:_master_model_container: 92
2024-05-25 17:12:20,270:INFO:_display_container: 4
2024-05-25 17:12:20,273:INFO:CustomProbabilityThresholdClassifier(boosting_type='gbdt', class_weight=None,
                                     classifier=LGBMClassifier(boosting_type='gbdt',
                                                               class_weight=None,
                                                               colsample_bytree=1.0,
                                                               importance_type='split',
                                                               learning_rate=0.1,
                                                               max_depth=-1,
                                                               min_child_samples=20,
                                                               min_child_weight=0.001,
                                                               min_split_gain=0.0,
                                                               n_estimators=100,
                                                               n_jobs=-1,
                                                               num_leaves=31,
                                                               objective=None,
                                                               random_state=5...
                                                               subsample_freq=0),
                                     colsample_bytree=1.0,
                                     importance_type='split', learning_rate=0.1,
                                     max_depth=-1, min_child_samples=20,
                                     min_child_weight=0.001, min_split_gain=0.0,
                                     n_estimators=100, n_jobs=-1, num_leaves=31,
                                     objective=None,
                                     probability_threshold=0.21093753875806368,
                                     random_state=5411, reg_alpha=0.0,
                                     reg_lambda=0.0, subsample=1.0,
                                     subsample_for_bin=200000,
                                     subsample_freq=0)
2024-05-25 17:12:20,273:INFO:create_model() successfully completed......................................
2024-05-25 17:12:21,062:INFO:Threshold: 0.21093753875806368. Accuracy: 0.8698
2024-05-25 17:12:21,063:INFO:Initializing create_model()
2024-05-25 17:12:21,063:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5411, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.31640627136919813, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:12:21,063:INFO:Checking exceptions
2024-05-25 17:12:21,065:INFO:Importing libraries
2024-05-25 17:12:21,065:INFO:Copying training dataset
2024-05-25 17:12:21,105:INFO:Defining folds
2024-05-25 17:12:21,106:INFO:Declaring metric variables
2024-05-25 17:12:21,106:INFO:Importing untrained model
2024-05-25 17:12:21,106:INFO:Declaring custom model
2024-05-25 17:12:21,107:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-25 17:12:21,107:INFO:Starting cross validation
2024-05-25 17:12:21,111:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-25 17:12:26,561:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 587, in copy
    res._consolidate_inplace()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1750, in _consolidate_inplace
    self.blocks = _consolidate(self.blocks)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2217, in _consolidate
    merged_blocks, _ = _merge_blocks(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 2249, in _merge_blocks
    new_values = new_values[argsort]
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 31.5 MiB for an array with shape (51, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 26.0 MiB for an array with shape (42, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-25 17:12:26,561:INFO:Calculating mean and std
2024-05-25 17:12:26,562:INFO:Creating metrics dataframe
2024-05-25 17:12:26,565:INFO:Finalizing model
2024-05-25 17:13:00,974:INFO:Initializing create_model()
2024-05-25 17:13:00,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000261B8BBCC40>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-25 17:13:00,975:INFO:Checking exceptions
2024-05-25 17:13:00,995:INFO:Importing libraries
2024-05-25 17:13:00,995:INFO:Copying training dataset
2024-05-25 17:13:01,038:INFO:Defining folds
2024-05-25 17:13:01,038:INFO:Declaring metric variables
2024-05-25 17:13:01,042:INFO:Importing untrained model
2024-05-25 17:13:01,047:INFO:Gradient Boosting Classifier Imported successfully
2024-05-25 17:13:01,055:INFO:Starting cross validation
2024-05-25 17:13:01,060:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-26 20:11:23,063:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-26 20:11:23,064:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-26 20:11:23,064:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-26 20:11:23,064:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 12:45:08,645:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 12:45:08,654:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 12:45:08,654:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 12:45:08,654:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 12:46:54,409:INFO:PyCaret ClassificationExperiment
2024-05-27 12:46:54,410:INFO:Logging name: ml_codex
2024-05-27 12:46:54,410:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-27 12:46:54,410:INFO:version 3.3.2
2024-05-27 12:46:54,410:INFO:Initializing setup()
2024-05-27 12:46:54,410:INFO:self.USI: 9f1b
2024-05-27 12:46:54,410:INFO:self._variable_keys: {'memory', 'X_train', 'data', 'fold_shuffle_param', 'fold_generator', 'pipeline', 'y_test', 'X_test', 'X', 'gpu_param', 'seed', 'gpu_n_jobs_param', '_ml_usecase', 'html_param', 'logging_param', 'n_jobs_param', 'exp_id', 'idx', 'y', 'target_param', 'exp_name_log', 'y_train', 'USI', 'log_plots_param', 'fix_imbalance', 'is_multiclass', 'fold_groups_param', '_available_plots'}
2024-05-27 12:46:54,417:INFO:Checking environment
2024-05-27 12:46:54,417:INFO:python_version: 3.10.13
2024-05-27 12:46:54,417:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-27 12:46:54,417:INFO:machine: AMD64
2024-05-27 12:46:54,417:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-27 12:46:54,418:INFO:Memory: svmem(total=34267656192, available=22463954944, percent=34.4, used=11803701248, free=22463954944)
2024-05-27 12:46:54,418:INFO:Physical Core: 8
2024-05-27 12:46:54,418:INFO:Logical Core: 16
2024-05-27 12:46:54,418:INFO:Checking libraries
2024-05-27 12:46:54,418:INFO:System:
2024-05-27 12:46:54,418:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-27 12:46:54,418:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-27 12:46:54,418:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-27 12:46:54,418:INFO:PyCaret required dependencies:
2024-05-27 12:46:54,525:INFO:                 pip: 23.3
2024-05-27 12:46:54,525:INFO:          setuptools: 68.0.0
2024-05-27 12:46:54,525:INFO:             pycaret: 3.3.2
2024-05-27 12:46:54,525:INFO:             IPython: 8.24.0
2024-05-27 12:46:54,525:INFO:          ipywidgets: 8.1.2
2024-05-27 12:46:54,525:INFO:                tqdm: 4.66.4
2024-05-27 12:46:54,525:INFO:               numpy: 1.26.4
2024-05-27 12:46:54,525:INFO:              pandas: 2.1.4
2024-05-27 12:46:54,525:INFO:              jinja2: 3.1.4
2024-05-27 12:46:54,526:INFO:               scipy: 1.11.4
2024-05-27 12:46:54,526:INFO:              joblib: 1.3.2
2024-05-27 12:46:54,526:INFO:             sklearn: 1.4.2
2024-05-27 12:46:54,526:INFO:                pyod: 1.1.3
2024-05-27 12:46:54,526:INFO:            imblearn: 0.12.2
2024-05-27 12:46:54,526:INFO:   category_encoders: 2.6.3
2024-05-27 12:46:54,526:INFO:            lightgbm: 4.3.0
2024-05-27 12:46:54,526:INFO:               numba: 0.59.1
2024-05-27 12:46:54,526:INFO:            requests: 2.32.2
2024-05-27 12:46:54,526:INFO:          matplotlib: 3.7.5
2024-05-27 12:46:54,526:INFO:          scikitplot: 0.3.7
2024-05-27 12:46:54,527:INFO:         yellowbrick: 1.5
2024-05-27 12:46:54,527:INFO:              plotly: 5.22.0
2024-05-27 12:46:54,527:INFO:    plotly-resampler: Not installed
2024-05-27 12:46:54,527:INFO:             kaleido: 0.2.1
2024-05-27 12:46:54,527:INFO:           schemdraw: 0.15
2024-05-27 12:46:54,527:INFO:         statsmodels: 0.14.2
2024-05-27 12:46:54,527:INFO:              sktime: 0.26.0
2024-05-27 12:46:54,527:INFO:               tbats: 1.1.3
2024-05-27 12:46:54,527:INFO:            pmdarima: 2.0.4
2024-05-27 12:46:54,527:INFO:              psutil: 5.9.0
2024-05-27 12:46:54,527:INFO:          markupsafe: 2.1.5
2024-05-27 12:46:54,527:INFO:             pickle5: Not installed
2024-05-27 12:46:54,528:INFO:         cloudpickle: 3.0.0
2024-05-27 12:46:54,528:INFO:         deprecation: 2.1.0
2024-05-27 12:46:54,528:INFO:              xxhash: 3.4.1
2024-05-27 12:46:54,528:INFO:           wurlitzer: Not installed
2024-05-27 12:46:54,528:INFO:PyCaret optional dependencies:
2024-05-27 12:46:54,739:INFO:                shap: Not installed
2024-05-27 12:46:54,740:INFO:           interpret: Not installed
2024-05-27 12:46:54,740:INFO:                umap: Not installed
2024-05-27 12:46:54,740:INFO:     ydata_profiling: Not installed
2024-05-27 12:46:54,740:INFO:  explainerdashboard: Not installed
2024-05-27 12:46:54,740:INFO:             autoviz: Not installed
2024-05-27 12:46:54,740:INFO:           fairlearn: Not installed
2024-05-27 12:46:54,740:INFO:          deepchecks: Not installed
2024-05-27 12:46:54,740:INFO:             xgboost: 2.0.3
2024-05-27 12:46:54,740:INFO:            catboost: Not installed
2024-05-27 12:46:54,740:INFO:              kmodes: Not installed
2024-05-27 12:46:54,740:INFO:             mlxtend: Not installed
2024-05-27 12:46:54,741:INFO:       statsforecast: Not installed
2024-05-27 12:46:54,741:INFO:        tune_sklearn: Not installed
2024-05-27 12:46:54,741:INFO:                 ray: Not installed
2024-05-27 12:46:54,741:INFO:            hyperopt: Not installed
2024-05-27 12:46:54,741:INFO:              optuna: Not installed
2024-05-27 12:46:54,741:INFO:               skopt: Not installed
2024-05-27 12:46:54,741:INFO:              mlflow: 2.13.0
2024-05-27 12:46:54,741:INFO:              gradio: Not installed
2024-05-27 12:46:54,741:INFO:             fastapi: Not installed
2024-05-27 12:46:54,741:INFO:             uvicorn: Not installed
2024-05-27 12:46:54,741:INFO:              m2cgen: Not installed
2024-05-27 12:46:54,741:INFO:           evidently: Not installed
2024-05-27 12:46:54,742:INFO:               fugue: Not installed
2024-05-27 12:46:54,742:INFO:           streamlit: Not installed
2024-05-27 12:46:54,742:INFO:             prophet: Not installed
2024-05-27 12:46:54,742:INFO:None
2024-05-27 12:46:54,742:INFO:Set up data.
2024-05-27 12:46:55,137:INFO:Set up folding strategy.
2024-05-27 12:46:55,137:INFO:Set up train/test split.
2024-05-27 12:46:55,384:INFO:Set up index.
2024-05-27 12:46:55,389:INFO:Assigning column types.
2024-05-27 12:46:55,422:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-27 12:46:55,516:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 12:46:55,527:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 12:46:55,627:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 12:46:55,632:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:46:55,707:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 12:46:55,709:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 12:46:55,757:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 12:46:55,761:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:46:55,762:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-27 12:46:55,840:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 12:46:55,891:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 12:46:55,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:46:55,992:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 12:46:56,041:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 12:46:56,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:46:56,047:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-27 12:46:56,188:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 12:46:56,193:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:46:56,318:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 12:46:56,323:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:46:56,334:INFO:Preparing preprocessing pipeline...
2024-05-27 12:46:56,341:INFO:Set up simple imputation.
2024-05-27 12:46:56,383:INFO:Set up encoding of ordinal features.
2024-05-27 12:46:56,397:INFO:Set up encoding of categorical features.
2024-05-27 12:46:56,402:INFO:Set up column name cleaning.
2024-05-27 12:46:58,968:INFO:Finished creating preprocessing pipeline.
2024-05-27 12:46:59,004:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id',
                                                                    'seller_address.city.name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-05-27 12:46:59,004:INFO:Creating final display dataframe.
2024-05-27 12:47:00,915:INFO:Setup _display_container:                     Description            Value
0                    Session id             7066
1                        Target           target
2                   Target type           Binary
3           Original data shape     (100000, 19)
4        Transformed data shape     (100000, 57)
5   Transformed train set shape      (90000, 57)
6    Transformed test set shape      (10000, 57)
7              Numeric features                5
8          Categorical features                9
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Fold Generator  StratifiedKFold
16                  Fold Number               10
17                     CPU Jobs               -1
18                      Use GPU            False
19               Log Experiment     MlflowLogger
20              Experiment Name         ml_codex
21                          USI             9f1b
2024-05-27 12:47:01,043:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 12:47:01,048:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:47:01,168:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 12:47:01,173:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 12:47:01,175:INFO:Logging experiment in loggers
2024-05-27 12:47:01,744:INFO:SubProcess save_model() called ==================================
2024-05-27 12:47:01,806:INFO:Initializing save_model()
2024-05-27 12:47:01,806:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id',
                                                                    'seller_address.city.name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\Adm\AppData\Local\Temp\tmpu1emvgug\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id',
                                                                    'seller_address.city.name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-27 12:47:01,806:INFO:Adding model into prep_pipe
2024-05-27 12:47:01,806:WARNING:Only Model saved as it was a pipeline.
2024-05-27 12:47:01,839:INFO:C:\Users\Adm\AppData\Local\Temp\tmpu1emvgug\Transformation Pipeline.pkl saved in current working directory
2024-05-27 12:47:01,869:INFO:Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id',
                                                                    'seller_address.city.name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-05-27 12:47:01,869:INFO:save_model() successfully completed......................................
2024-05-27 12:47:02,822:INFO:SubProcess save_model() end ==================================
2024-05-27 12:47:02,864:INFO:setup() successfully completed in 6.82s...............
2024-05-27 12:47:02,864:INFO:Initializing compare_models()
2024-05-27 12:47:02,864:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144C1D7CD0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002144C1D7CD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-27 12:47:02,865:INFO:Checking exceptions
2024-05-27 12:47:02,886:INFO:Preparing display monitor
2024-05-27 12:47:02,923:INFO:Initializing Logistic Regression
2024-05-27 12:47:02,923:INFO:Total runtime is 0.0 minutes
2024-05-27 12:47:02,928:INFO:SubProcess create_model() called ==================================
2024-05-27 12:47:02,930:INFO:Initializing create_model()
2024-05-27 12:47:02,930:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144C1D7CD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021427056020>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:47:02,930:INFO:Checking exceptions
2024-05-27 12:47:02,930:INFO:Importing libraries
2024-05-27 12:47:02,931:INFO:Copying training dataset
2024-05-27 12:47:02,975:INFO:Defining folds
2024-05-27 12:47:02,975:INFO:Declaring metric variables
2024-05-27 12:47:02,980:INFO:Importing untrained model
2024-05-27 12:47:02,985:INFO:Logistic Regression Imported successfully
2024-05-27 12:47:02,995:INFO:Starting cross validation
2024-05-27 12:47:03,000:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:47:28,795:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-27 12:47:28,956:INFO:Calculating mean and std
2024-05-27 12:47:28,958:INFO:Creating metrics dataframe
2024-05-27 12:47:28,961:INFO:Uploading results into container
2024-05-27 12:47:28,962:INFO:Uploading model into container now
2024-05-27 12:47:28,963:INFO:_master_model_container: 1
2024-05-27 12:47:28,963:INFO:_display_container: 2
2024-05-27 12:47:28,964:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7066, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-27 12:47:28,964:INFO:create_model() successfully completed......................................
2024-05-27 12:47:29,817:INFO:SubProcess create_model() end ==================================
2024-05-27 12:47:29,817:INFO:Creating metrics dataframe
2024-05-27 12:47:29,825:INFO:Initializing K Neighbors Classifier
2024-05-27 12:47:29,826:INFO:Total runtime is 0.44839665095011394 minutes
2024-05-27 12:47:29,830:INFO:SubProcess create_model() called ==================================
2024-05-27 12:47:29,831:INFO:Initializing create_model()
2024-05-27 12:47:29,831:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144C1D7CD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021427056020>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:47:29,831:INFO:Checking exceptions
2024-05-27 12:47:29,831:INFO:Importing libraries
2024-05-27 12:47:29,832:INFO:Copying training dataset
2024-05-27 12:47:29,873:INFO:Defining folds
2024-05-27 12:47:29,873:INFO:Declaring metric variables
2024-05-27 12:47:29,878:INFO:Importing untrained model
2024-05-27 12:47:29,883:INFO:K Neighbors Classifier Imported successfully
2024-05-27 12:47:29,893:INFO:Starting cross validation
2024-05-27 12:47:29,898:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:47:55,838:INFO:Calculating mean and std
2024-05-27 12:47:55,840:INFO:Creating metrics dataframe
2024-05-27 12:47:55,842:INFO:Uploading results into container
2024-05-27 12:47:55,843:INFO:Uploading model into container now
2024-05-27 12:47:55,844:INFO:_master_model_container: 2
2024-05-27 12:47:55,844:INFO:_display_container: 2
2024-05-27 12:47:55,845:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-27 12:47:55,845:INFO:create_model() successfully completed......................................
2024-05-27 12:47:56,730:INFO:SubProcess create_model() end ==================================
2024-05-27 12:47:56,731:INFO:Creating metrics dataframe
2024-05-27 12:47:56,741:INFO:Initializing Naive Bayes
2024-05-27 12:47:56,742:INFO:Total runtime is 0.896989107131958 minutes
2024-05-27 12:47:56,747:INFO:SubProcess create_model() called ==================================
2024-05-27 12:47:56,747:INFO:Initializing create_model()
2024-05-27 12:47:56,747:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144C1D7CD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021427056020>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:47:56,747:INFO:Checking exceptions
2024-05-27 12:47:56,748:INFO:Importing libraries
2024-05-27 12:47:56,748:INFO:Copying training dataset
2024-05-27 12:47:56,791:INFO:Defining folds
2024-05-27 12:47:56,792:INFO:Declaring metric variables
2024-05-27 12:47:56,797:INFO:Importing untrained model
2024-05-27 12:47:56,802:INFO:Naive Bayes Imported successfully
2024-05-27 12:47:56,812:INFO:Starting cross validation
2024-05-27 12:47:56,817:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:48:00,503:INFO:Calculating mean and std
2024-05-27 12:48:00,505:INFO:Creating metrics dataframe
2024-05-27 12:48:00,508:INFO:Uploading results into container
2024-05-27 12:48:00,508:INFO:Uploading model into container now
2024-05-27 12:48:00,509:INFO:_master_model_container: 3
2024-05-27 12:48:00,509:INFO:_display_container: 2
2024-05-27 12:48:00,509:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-27 12:48:00,509:INFO:create_model() successfully completed......................................
2024-05-27 12:48:01,374:INFO:SubProcess create_model() end ==================================
2024-05-27 12:48:01,375:INFO:Creating metrics dataframe
2024-05-27 12:48:01,385:INFO:Initializing Decision Tree Classifier
2024-05-27 12:48:01,386:INFO:Total runtime is 0.9743911544481914 minutes
2024-05-27 12:48:01,390:INFO:SubProcess create_model() called ==================================
2024-05-27 12:48:01,390:INFO:Initializing create_model()
2024-05-27 12:48:01,391:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144C1D7CD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021427056020>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:48:01,391:INFO:Checking exceptions
2024-05-27 12:48:01,391:INFO:Importing libraries
2024-05-27 12:48:01,391:INFO:Copying training dataset
2024-05-27 12:48:01,433:INFO:Defining folds
2024-05-27 12:48:01,433:INFO:Declaring metric variables
2024-05-27 12:48:01,438:INFO:Importing untrained model
2024-05-27 12:48:01,443:INFO:Decision Tree Classifier Imported successfully
2024-05-27 12:48:01,453:INFO:Starting cross validation
2024-05-27 12:48:01,458:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:48:05,523:INFO:Calculating mean and std
2024-05-27 12:48:05,525:INFO:Creating metrics dataframe
2024-05-27 12:48:05,527:INFO:Uploading results into container
2024-05-27 12:48:05,528:INFO:Uploading model into container now
2024-05-27 12:48:05,529:INFO:_master_model_container: 4
2024-05-27 12:48:05,529:INFO:_display_container: 2
2024-05-27 12:48:05,530:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7066, splitter='best')
2024-05-27 12:48:05,530:INFO:create_model() successfully completed......................................
2024-05-27 12:48:06,375:INFO:SubProcess create_model() end ==================================
2024-05-27 12:48:06,375:INFO:Creating metrics dataframe
2024-05-27 12:48:06,386:INFO:Initializing SVM - Linear Kernel
2024-05-27 12:48:06,386:INFO:Total runtime is 1.0577259023984273 minutes
2024-05-27 12:48:06,391:INFO:SubProcess create_model() called ==================================
2024-05-27 12:48:06,391:INFO:Initializing create_model()
2024-05-27 12:48:06,391:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144C1D7CD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021427056020>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:48:06,392:INFO:Checking exceptions
2024-05-27 12:48:06,392:INFO:Importing libraries
2024-05-27 12:48:06,392:INFO:Copying training dataset
2024-05-27 12:48:06,435:INFO:Defining folds
2024-05-27 12:48:06,436:INFO:Declaring metric variables
2024-05-27 12:48:06,440:INFO:Importing untrained model
2024-05-27 12:48:06,446:INFO:SVM - Linear Kernel Imported successfully
2024-05-27 12:48:06,455:INFO:Starting cross validation
2024-05-27 12:48:06,460:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:48:10,240:INFO:Calculating mean and std
2024-05-27 12:48:10,242:INFO:Creating metrics dataframe
2024-05-27 12:48:10,245:INFO:Uploading results into container
2024-05-27 12:48:10,246:INFO:Uploading model into container now
2024-05-27 12:48:10,246:INFO:_master_model_container: 5
2024-05-27 12:48:10,246:INFO:_display_container: 2
2024-05-27 12:48:10,247:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7066, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-27 12:48:10,248:INFO:create_model() successfully completed......................................
2024-05-27 12:48:11,101:INFO:SubProcess create_model() end ==================================
2024-05-27 12:48:11,101:INFO:Creating metrics dataframe
2024-05-27 12:48:11,113:INFO:Initializing Ridge Classifier
2024-05-27 12:48:11,113:INFO:Total runtime is 1.1365092674891155 minutes
2024-05-27 12:48:11,118:INFO:SubProcess create_model() called ==================================
2024-05-27 12:48:11,118:INFO:Initializing create_model()
2024-05-27 12:48:11,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144C1D7CD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021427056020>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:48:11,118:INFO:Checking exceptions
2024-05-27 12:48:11,118:INFO:Importing libraries
2024-05-27 12:48:11,119:INFO:Copying training dataset
2024-05-27 12:48:11,161:INFO:Defining folds
2024-05-27 12:48:11,161:INFO:Declaring metric variables
2024-05-27 12:48:11,167:INFO:Importing untrained model
2024-05-27 12:48:11,172:INFO:Ridge Classifier Imported successfully
2024-05-27 12:48:11,181:INFO:Starting cross validation
2024-05-27 12:48:11,186:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:48:14,116:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.80749e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 12:48:14,117:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.80772e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 12:48:14,117:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.76653e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 12:48:14,193:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.80764e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 12:48:14,223:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.76651e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 12:48:14,257:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.80734e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 12:48:14,295:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.43608e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 12:48:14,309:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.81735e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 12:48:14,362:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.80785e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 12:48:14,390:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.80763e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 12:48:14,663:INFO:Calculating mean and std
2024-05-27 12:48:14,666:INFO:Creating metrics dataframe
2024-05-27 12:48:14,669:INFO:Uploading results into container
2024-05-27 12:48:14,670:INFO:Uploading model into container now
2024-05-27 12:48:14,671:INFO:_master_model_container: 6
2024-05-27 12:48:14,671:INFO:_display_container: 2
2024-05-27 12:48:14,672:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7066, solver='auto',
                tol=0.0001)
2024-05-27 12:48:14,672:INFO:create_model() successfully completed......................................
2024-05-27 12:48:15,517:INFO:SubProcess create_model() end ==================================
2024-05-27 12:48:15,517:INFO:Creating metrics dataframe
2024-05-27 12:48:15,529:INFO:Initializing Random Forest Classifier
2024-05-27 12:48:15,529:INFO:Total runtime is 1.2101092974344891 minutes
2024-05-27 12:48:15,534:INFO:SubProcess create_model() called ==================================
2024-05-27 12:48:15,534:INFO:Initializing create_model()
2024-05-27 12:48:15,535:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144C1D7CD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021427056020>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:48:15,535:INFO:Checking exceptions
2024-05-27 12:48:15,535:INFO:Importing libraries
2024-05-27 12:48:15,535:INFO:Copying training dataset
2024-05-27 12:48:15,577:INFO:Defining folds
2024-05-27 12:48:15,577:INFO:Declaring metric variables
2024-05-27 12:48:15,582:INFO:Importing untrained model
2024-05-27 12:48:15,587:INFO:Random Forest Classifier Imported successfully
2024-05-27 12:48:15,596:INFO:Starting cross validation
2024-05-27 12:48:15,602:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:48:33,776:INFO:Calculating mean and std
2024-05-27 12:48:33,778:INFO:Creating metrics dataframe
2024-05-27 12:48:33,781:INFO:Uploading results into container
2024-05-27 12:48:33,782:INFO:Uploading model into container now
2024-05-27 12:48:33,783:INFO:_master_model_container: 7
2024-05-27 12:48:33,783:INFO:_display_container: 2
2024-05-27 12:48:33,784:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=7066, verbose=0,
                       warm_start=False)
2024-05-27 12:48:33,784:INFO:create_model() successfully completed......................................
2024-05-27 12:48:34,665:INFO:SubProcess create_model() end ==================================
2024-05-27 12:48:34,665:INFO:Creating metrics dataframe
2024-05-27 12:48:34,678:INFO:Initializing Quadratic Discriminant Analysis
2024-05-27 12:48:34,678:INFO:Total runtime is 1.529259256521861 minutes
2024-05-27 12:48:34,691:INFO:SubProcess create_model() called ==================================
2024-05-27 12:48:34,692:INFO:Initializing create_model()
2024-05-27 12:48:34,692:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144C1D7CD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021427056020>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:48:34,692:INFO:Checking exceptions
2024-05-27 12:48:34,692:INFO:Importing libraries
2024-05-27 12:48:34,692:INFO:Copying training dataset
2024-05-27 12:48:34,734:INFO:Defining folds
2024-05-27 12:48:34,734:INFO:Declaring metric variables
2024-05-27 12:48:34,739:INFO:Importing untrained model
2024-05-27 12:48:34,744:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-27 12:48:34,753:INFO:Starting cross validation
2024-05-27 12:48:34,758:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:48:38,188:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 12:48:38,250:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 12:48:38,444:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 12:48:38,555:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 12:48:38,896:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 12:48:38,915:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 12:48:38,932:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 12:48:38,949:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 12:48:39,111:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 12:48:39,142:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 12:48:40,520:INFO:Calculating mean and std
2024-05-27 12:48:40,522:INFO:Creating metrics dataframe
2024-05-27 12:48:40,524:INFO:Uploading results into container
2024-05-27 12:48:40,525:INFO:Uploading model into container now
2024-05-27 12:48:40,525:INFO:_master_model_container: 8
2024-05-27 12:48:40,526:INFO:_display_container: 2
2024-05-27 12:48:40,526:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-27 12:48:40,526:INFO:create_model() successfully completed......................................
2024-05-27 12:48:41,350:INFO:SubProcess create_model() end ==================================
2024-05-27 12:48:41,350:INFO:Creating metrics dataframe
2024-05-27 12:48:41,363:INFO:Initializing Ada Boost Classifier
2024-05-27 12:48:41,363:INFO:Total runtime is 1.6406761050224308 minutes
2024-05-27 12:48:41,369:INFO:SubProcess create_model() called ==================================
2024-05-27 12:48:41,369:INFO:Initializing create_model()
2024-05-27 12:48:41,369:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144C1D7CD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021427056020>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:48:41,369:INFO:Checking exceptions
2024-05-27 12:48:41,369:INFO:Importing libraries
2024-05-27 12:48:41,370:INFO:Copying training dataset
2024-05-27 12:48:41,412:INFO:Defining folds
2024-05-27 12:48:41,412:INFO:Declaring metric variables
2024-05-27 12:48:41,418:INFO:Importing untrained model
2024-05-27 12:48:41,424:INFO:Ada Boost Classifier Imported successfully
2024-05-27 12:48:41,433:INFO:Starting cross validation
2024-05-27 12:48:41,438:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:48:43,760:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 12:48:43,950:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 12:48:43,967:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 12:48:44,124:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 12:48:44,148:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 12:48:44,160:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 12:48:44,174:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 12:48:44,204:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 12:48:44,349:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 12:48:44,422:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 12:48:52,901:INFO:Calculating mean and std
2024-05-27 12:48:52,903:INFO:Creating metrics dataframe
2024-05-27 12:48:52,905:INFO:Uploading results into container
2024-05-27 12:48:52,906:INFO:Uploading model into container now
2024-05-27 12:48:52,906:INFO:_master_model_container: 9
2024-05-27 12:48:52,907:INFO:_display_container: 2
2024-05-27 12:48:52,907:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=7066)
2024-05-27 12:48:52,907:INFO:create_model() successfully completed......................................
2024-05-27 12:48:53,763:INFO:SubProcess create_model() end ==================================
2024-05-27 12:48:53,764:INFO:Creating metrics dataframe
2024-05-27 12:48:53,777:INFO:Initializing Gradient Boosting Classifier
2024-05-27 12:48:53,777:INFO:Total runtime is 1.8475760857264205 minutes
2024-05-27 12:48:53,782:INFO:SubProcess create_model() called ==================================
2024-05-27 12:48:53,782:INFO:Initializing create_model()
2024-05-27 12:48:53,782:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144C1D7CD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021427056020>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:48:53,783:INFO:Checking exceptions
2024-05-27 12:48:53,783:INFO:Importing libraries
2024-05-27 12:48:53,783:INFO:Copying training dataset
2024-05-27 12:48:53,825:INFO:Defining folds
2024-05-27 12:48:53,825:INFO:Declaring metric variables
2024-05-27 12:48:53,830:INFO:Importing untrained model
2024-05-27 12:48:53,836:INFO:Gradient Boosting Classifier Imported successfully
2024-05-27 12:48:53,845:INFO:Starting cross validation
2024-05-27 12:48:53,850:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:49:17,971:INFO:Calculating mean and std
2024-05-27 12:49:17,973:INFO:Creating metrics dataframe
2024-05-27 12:49:17,975:INFO:Uploading results into container
2024-05-27 12:49:17,976:INFO:Uploading model into container now
2024-05-27 12:49:17,977:INFO:_master_model_container: 10
2024-05-27 12:49:17,977:INFO:_display_container: 2
2024-05-27 12:49:17,978:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7066, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-27 12:49:17,978:INFO:create_model() successfully completed......................................
2024-05-27 12:49:18,808:INFO:SubProcess create_model() end ==================================
2024-05-27 12:49:18,808:INFO:Creating metrics dataframe
2024-05-27 12:49:18,822:INFO:Initializing Linear Discriminant Analysis
2024-05-27 12:49:18,822:INFO:Total runtime is 2.264992753664653 minutes
2024-05-27 12:49:18,826:INFO:SubProcess create_model() called ==================================
2024-05-27 12:49:18,827:INFO:Initializing create_model()
2024-05-27 12:49:18,827:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144C1D7CD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021427056020>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:49:18,827:INFO:Checking exceptions
2024-05-27 12:49:18,827:INFO:Importing libraries
2024-05-27 12:49:18,827:INFO:Copying training dataset
2024-05-27 12:49:18,875:INFO:Defining folds
2024-05-27 12:49:18,876:INFO:Declaring metric variables
2024-05-27 12:49:18,881:INFO:Importing untrained model
2024-05-27 12:49:18,887:INFO:Linear Discriminant Analysis Imported successfully
2024-05-27 12:49:18,897:INFO:Starting cross validation
2024-05-27 12:49:18,904:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:49:24,709:INFO:Calculating mean and std
2024-05-27 12:49:24,711:INFO:Creating metrics dataframe
2024-05-27 12:49:24,713:INFO:Uploading results into container
2024-05-27 12:49:24,714:INFO:Uploading model into container now
2024-05-27 12:49:24,715:INFO:_master_model_container: 11
2024-05-27 12:49:24,715:INFO:_display_container: 2
2024-05-27 12:49:24,715:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-27 12:49:24,716:INFO:create_model() successfully completed......................................
2024-05-27 12:49:25,606:INFO:SubProcess create_model() end ==================================
2024-05-27 12:49:25,606:INFO:Creating metrics dataframe
2024-05-27 12:49:25,621:INFO:Initializing Extra Trees Classifier
2024-05-27 12:49:25,621:INFO:Total runtime is 2.3783095796902978 minutes
2024-05-27 12:49:25,626:INFO:SubProcess create_model() called ==================================
2024-05-27 12:49:25,626:INFO:Initializing create_model()
2024-05-27 12:49:25,626:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144C1D7CD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021427056020>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:49:25,626:INFO:Checking exceptions
2024-05-27 12:49:25,627:INFO:Importing libraries
2024-05-27 12:49:25,627:INFO:Copying training dataset
2024-05-27 12:49:25,669:INFO:Defining folds
2024-05-27 12:49:25,669:INFO:Declaring metric variables
2024-05-27 12:49:25,674:INFO:Importing untrained model
2024-05-27 12:49:25,680:INFO:Extra Trees Classifier Imported successfully
2024-05-27 12:49:25,689:INFO:Starting cross validation
2024-05-27 12:49:25,695:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:49:51,706:INFO:Calculating mean and std
2024-05-27 12:49:51,708:INFO:Creating metrics dataframe
2024-05-27 12:49:51,711:INFO:Uploading results into container
2024-05-27 12:49:51,711:INFO:Uploading model into container now
2024-05-27 12:49:51,712:INFO:_master_model_container: 12
2024-05-27 12:49:51,712:INFO:_display_container: 2
2024-05-27 12:49:51,713:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=7066, verbose=0,
                     warm_start=False)
2024-05-27 12:49:51,713:INFO:create_model() successfully completed......................................
2024-05-27 12:49:52,587:INFO:SubProcess create_model() end ==================================
2024-05-27 12:49:52,587:INFO:Creating metrics dataframe
2024-05-27 12:49:52,602:INFO:Initializing Extreme Gradient Boosting
2024-05-27 12:49:52,602:INFO:Total runtime is 2.8279942909876508 minutes
2024-05-27 12:49:52,607:INFO:SubProcess create_model() called ==================================
2024-05-27 12:49:52,607:INFO:Initializing create_model()
2024-05-27 12:49:52,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144C1D7CD0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021427056020>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:49:52,607:INFO:Checking exceptions
2024-05-27 12:49:52,607:INFO:Importing libraries
2024-05-27 12:49:52,608:INFO:Copying training dataset
2024-05-27 12:49:52,650:INFO:Defining folds
2024-05-27 12:49:52,650:INFO:Declaring metric variables
2024-05-27 12:49:52,655:INFO:Importing untrained model
2024-05-27 12:49:52,661:INFO:Extreme Gradient Boosting Imported successfully
2024-05-27 12:49:52,670:INFO:Starting cross validation
2024-05-27 12:49:52,676:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:49:59,475:INFO:Calculating mean and std
2024-05-27 12:49:59,477:INFO:Creating metrics dataframe
2024-05-27 12:49:59,479:INFO:Uploading results into container
2024-05-27 12:49:59,480:INFO:Uploading model into container now
2024-05-27 12:49:59,481:INFO:_master_model_container: 13
2024-05-27 12:49:59,481:INFO:_display_container: 2
2024-05-27 12:49:59,482:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-27 12:49:59,483:INFO:create_model() successfully completed......................................
2024-05-27 12:50:00,318:INFO:SubProcess create_model() end ==================================
2024-05-27 12:50:00,318:INFO:Creating metrics dataframe
2024-05-27 12:50:00,333:INFO:Initializing Light Gradient Boosting Machine
2024-05-27 12:50:00,333:INFO:Total runtime is 2.9568364063898724 minutes
2024-05-27 12:50:00,338:INFO:SubProcess create_model() called ==================================
2024-05-27 12:50:00,339:INFO:Initializing create_model()
2024-05-27 12:50:00,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144C1D7CD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021427056020>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:50:00,339:INFO:Checking exceptions
2024-05-27 12:50:00,339:INFO:Importing libraries
2024-05-27 12:50:00,339:INFO:Copying training dataset
2024-05-27 12:50:00,383:INFO:Defining folds
2024-05-27 12:50:00,383:INFO:Declaring metric variables
2024-05-27 12:50:00,388:INFO:Importing untrained model
2024-05-27 12:50:00,395:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 12:50:00,406:INFO:Starting cross validation
2024-05-27 12:50:00,411:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:50:06,514:INFO:Calculating mean and std
2024-05-27 12:50:06,516:INFO:Creating metrics dataframe
2024-05-27 12:50:06,519:INFO:Uploading results into container
2024-05-27 12:50:06,520:INFO:Uploading model into container now
2024-05-27 12:50:06,521:INFO:_master_model_container: 14
2024-05-27 12:50:06,521:INFO:_display_container: 2
2024-05-27 12:50:06,522:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7066, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-27 12:50:06,523:INFO:create_model() successfully completed......................................
2024-05-27 12:50:07,354:INFO:SubProcess create_model() end ==================================
2024-05-27 12:50:07,355:INFO:Creating metrics dataframe
2024-05-27 12:50:07,370:INFO:Initializing Dummy Classifier
2024-05-27 12:50:07,371:INFO:Total runtime is 3.0741369009017947 minutes
2024-05-27 12:50:07,375:INFO:SubProcess create_model() called ==================================
2024-05-27 12:50:07,376:INFO:Initializing create_model()
2024-05-27 12:50:07,376:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144C1D7CD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021427056020>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:50:07,376:INFO:Checking exceptions
2024-05-27 12:50:07,376:INFO:Importing libraries
2024-05-27 12:50:07,377:INFO:Copying training dataset
2024-05-27 12:50:07,418:INFO:Defining folds
2024-05-27 12:50:07,418:INFO:Declaring metric variables
2024-05-27 12:50:07,423:INFO:Importing untrained model
2024-05-27 12:50:07,428:INFO:Dummy Classifier Imported successfully
2024-05-27 12:50:07,437:INFO:Starting cross validation
2024-05-27 12:50:07,443:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 12:50:10,378:INFO:Calculating mean and std
2024-05-27 12:50:10,380:INFO:Creating metrics dataframe
2024-05-27 12:50:10,383:INFO:Uploading results into container
2024-05-27 12:50:10,384:INFO:Uploading model into container now
2024-05-27 12:50:10,384:INFO:_master_model_container: 15
2024-05-27 12:50:10,385:INFO:_display_container: 2
2024-05-27 12:50:10,385:INFO:DummyClassifier(constant=None, random_state=7066, strategy='prior')
2024-05-27 12:50:10,385:INFO:create_model() successfully completed......................................
2024-05-27 12:50:11,271:INFO:SubProcess create_model() end ==================================
2024-05-27 12:50:11,272:INFO:Creating metrics dataframe
2024-05-27 12:50:11,296:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-27 12:50:11,308:INFO:Initializing create_model()
2024-05-27 12:50:11,308:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144C1D7CD0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 12:50:11,309:INFO:Checking exceptions
2024-05-27 12:50:11,311:INFO:Importing libraries
2024-05-27 12:50:11,311:INFO:Copying training dataset
2024-05-27 12:50:11,353:INFO:Defining folds
2024-05-27 12:50:11,353:INFO:Declaring metric variables
2024-05-27 12:50:11,353:INFO:Importing untrained model
2024-05-27 12:50:11,353:INFO:Declaring custom model
2024-05-27 12:50:11,355:INFO:Extreme Gradient Boosting Imported successfully
2024-05-27 12:50:11,360:INFO:Cross validation set to False
2024-05-27 12:50:11,360:INFO:Fitting Model
2024-05-27 12:50:13,392:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-27 12:50:13,393:INFO:create_model() successfully completed......................................
2024-05-27 12:50:14,217:INFO:Creating Dashboard logs
2024-05-27 12:50:14,223:INFO:Model: Extreme Gradient Boosting
2024-05-27 12:50:14,307:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 7066, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2024-05-27 12:50:14,580:INFO:Initializing predict_model()
2024-05-27 12:50:14,580:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144C1D7CD0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002144C345EA0>)
2024-05-27 12:50:14,580:INFO:Checking exceptions
2024-05-27 12:50:14,580:INFO:Preloading libraries
2024-05-27 12:50:15,800:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2024-05-27 12:50:19,303:INFO:Creating Dashboard logs
2024-05-27 12:50:19,307:INFO:Model: Light Gradient Boosting Machine
2024-05-27 12:50:19,376:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 7066, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-05-27 12:50:20,527:INFO:Creating Dashboard logs
2024-05-27 12:50:20,532:INFO:Model: Gradient Boosting Classifier
2024-05-27 12:50:20,599:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 7066, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-27 12:50:21,734:INFO:Creating Dashboard logs
2024-05-27 12:50:21,739:INFO:Model: Random Forest Classifier
2024-05-27 12:50:21,805:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 7066, 'verbose': 0, 'warm_start': False}
2024-05-27 12:50:22,933:INFO:Creating Dashboard logs
2024-05-27 12:50:22,938:INFO:Model: Extra Trees Classifier
2024-05-27 12:50:23,006:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 7066, 'verbose': 0, 'warm_start': False}
2024-05-27 12:50:24,137:INFO:Creating Dashboard logs
2024-05-27 12:50:24,142:INFO:Model: Ada Boost Classifier
2024-05-27 12:50:24,210:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 7066}
2024-05-27 12:50:25,293:INFO:Creating Dashboard logs
2024-05-27 12:50:25,298:INFO:Model: Ridge Classifier
2024-05-27 12:50:25,365:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 7066, 'solver': 'auto', 'tol': 0.0001}
2024-05-27 12:50:26,473:INFO:Creating Dashboard logs
2024-05-27 12:50:26,478:INFO:Model: Linear Discriminant Analysis
2024-05-27 12:50:26,545:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-05-27 12:50:27,665:INFO:Creating Dashboard logs
2024-05-27 12:50:27,669:INFO:Model: Decision Tree Classifier
2024-05-27 12:50:27,738:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 7066, 'splitter': 'best'}
2024-05-27 12:50:28,845:INFO:Creating Dashboard logs
2024-05-27 12:50:28,849:INFO:Model: K Neighbors Classifier
2024-05-27 12:50:28,915:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2024-05-27 12:50:30,009:INFO:Creating Dashboard logs
2024-05-27 12:50:30,014:INFO:Model: Logistic Regression
2024-05-27 12:50:30,098:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 7066, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-05-27 12:50:31,212:INFO:Creating Dashboard logs
2024-05-27 12:50:31,216:INFO:Model: Quadratic Discriminant Analysis
2024-05-27 12:50:31,283:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2024-05-27 12:50:32,375:INFO:Creating Dashboard logs
2024-05-27 12:50:32,380:INFO:Model: Dummy Classifier
2024-05-27 12:50:32,447:INFO:Logged params: {'constant': None, 'random_state': 7066, 'strategy': 'prior'}
2024-05-27 12:50:33,527:INFO:Creating Dashboard logs
2024-05-27 12:50:33,531:INFO:Model: SVM - Linear Kernel
2024-05-27 12:50:33,599:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 7066, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-27 12:50:34,730:INFO:Creating Dashboard logs
2024-05-27 12:50:34,735:INFO:Model: Naive Bayes
2024-05-27 12:50:34,803:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-05-27 12:50:35,902:INFO:_master_model_container: 15
2024-05-27 12:50:35,902:INFO:_display_container: 2
2024-05-27 12:50:35,904:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-27 12:50:35,904:INFO:compare_models() successfully completed......................................
2024-05-27 13:01:31,774:INFO:PyCaret ClassificationExperiment
2024-05-27 13:01:31,774:INFO:Logging name: ml_codex
2024-05-27 13:01:31,774:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-27 13:01:31,774:INFO:version 3.3.2
2024-05-27 13:01:31,775:INFO:Initializing setup()
2024-05-27 13:01:31,775:INFO:self.USI: ee17
2024-05-27 13:01:31,775:INFO:self._variable_keys: {'memory', 'X_train', 'data', 'fold_shuffle_param', 'fold_generator', 'pipeline', 'y_test', 'X_test', 'X', 'gpu_param', 'seed', 'gpu_n_jobs_param', '_ml_usecase', 'html_param', 'logging_param', 'n_jobs_param', 'exp_id', 'idx', 'y', 'target_param', 'exp_name_log', 'y_train', 'USI', 'log_plots_param', 'fix_imbalance', 'is_multiclass', 'fold_groups_param', '_available_plots'}
2024-05-27 13:01:31,775:INFO:Checking environment
2024-05-27 13:01:31,775:INFO:python_version: 3.10.13
2024-05-27 13:01:31,775:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-27 13:01:31,775:INFO:machine: AMD64
2024-05-27 13:01:31,775:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-27 13:01:31,775:INFO:Memory: svmem(total=34267656192, available=21402144768, percent=37.5, used=12865511424, free=21402144768)
2024-05-27 13:01:31,775:INFO:Physical Core: 8
2024-05-27 13:01:31,776:INFO:Logical Core: 16
2024-05-27 13:01:31,776:INFO:Checking libraries
2024-05-27 13:01:31,776:INFO:System:
2024-05-27 13:01:31,776:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-27 13:01:31,776:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-27 13:01:31,776:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-27 13:01:31,776:INFO:PyCaret required dependencies:
2024-05-27 13:01:31,776:INFO:                 pip: 23.3
2024-05-27 13:01:31,776:INFO:          setuptools: 68.0.0
2024-05-27 13:01:31,777:INFO:             pycaret: 3.3.2
2024-05-27 13:01:31,777:INFO:             IPython: 8.24.0
2024-05-27 13:01:31,777:INFO:          ipywidgets: 8.1.2
2024-05-27 13:01:31,777:INFO:                tqdm: 4.66.4
2024-05-27 13:01:31,777:INFO:               numpy: 1.26.4
2024-05-27 13:01:31,777:INFO:              pandas: 2.1.4
2024-05-27 13:01:31,777:INFO:              jinja2: 3.1.4
2024-05-27 13:01:31,777:INFO:               scipy: 1.11.4
2024-05-27 13:01:31,777:INFO:              joblib: 1.3.2
2024-05-27 13:01:31,778:INFO:             sklearn: 1.4.2
2024-05-27 13:01:31,778:INFO:                pyod: 1.1.3
2024-05-27 13:01:31,778:INFO:            imblearn: 0.12.2
2024-05-27 13:01:31,778:INFO:   category_encoders: 2.6.3
2024-05-27 13:01:31,778:INFO:            lightgbm: 4.3.0
2024-05-27 13:01:31,778:INFO:               numba: 0.59.1
2024-05-27 13:01:31,778:INFO:            requests: 2.32.2
2024-05-27 13:01:31,778:INFO:          matplotlib: 3.7.5
2024-05-27 13:01:31,778:INFO:          scikitplot: 0.3.7
2024-05-27 13:01:31,778:INFO:         yellowbrick: 1.5
2024-05-27 13:01:31,779:INFO:              plotly: 5.22.0
2024-05-27 13:01:31,779:INFO:    plotly-resampler: Not installed
2024-05-27 13:01:31,779:INFO:             kaleido: 0.2.1
2024-05-27 13:01:31,779:INFO:           schemdraw: 0.15
2024-05-27 13:01:31,779:INFO:         statsmodels: 0.14.2
2024-05-27 13:01:31,779:INFO:              sktime: 0.26.0
2024-05-27 13:01:31,779:INFO:               tbats: 1.1.3
2024-05-27 13:01:31,779:INFO:            pmdarima: 2.0.4
2024-05-27 13:01:31,779:INFO:              psutil: 5.9.0
2024-05-27 13:01:31,779:INFO:          markupsafe: 2.1.5
2024-05-27 13:01:31,779:INFO:             pickle5: Not installed
2024-05-27 13:01:31,780:INFO:         cloudpickle: 3.0.0
2024-05-27 13:01:31,780:INFO:         deprecation: 2.1.0
2024-05-27 13:01:31,780:INFO:              xxhash: 3.4.1
2024-05-27 13:01:31,780:INFO:           wurlitzer: Not installed
2024-05-27 13:01:31,780:INFO:PyCaret optional dependencies:
2024-05-27 13:01:31,780:INFO:                shap: Not installed
2024-05-27 13:01:31,780:INFO:           interpret: Not installed
2024-05-27 13:01:31,789:INFO:                umap: Not installed
2024-05-27 13:01:31,789:INFO:     ydata_profiling: Not installed
2024-05-27 13:01:31,790:INFO:  explainerdashboard: Not installed
2024-05-27 13:01:31,790:INFO:             autoviz: Not installed
2024-05-27 13:01:31,790:INFO:           fairlearn: Not installed
2024-05-27 13:01:31,790:INFO:          deepchecks: Not installed
2024-05-27 13:01:31,790:INFO:             xgboost: 2.0.3
2024-05-27 13:01:31,790:INFO:            catboost: Not installed
2024-05-27 13:01:31,790:INFO:              kmodes: Not installed
2024-05-27 13:01:31,790:INFO:             mlxtend: Not installed
2024-05-27 13:01:31,790:INFO:       statsforecast: Not installed
2024-05-27 13:01:31,790:INFO:        tune_sklearn: Not installed
2024-05-27 13:01:31,790:INFO:                 ray: Not installed
2024-05-27 13:01:31,791:INFO:            hyperopt: Not installed
2024-05-27 13:01:31,791:INFO:              optuna: Not installed
2024-05-27 13:01:31,791:INFO:               skopt: Not installed
2024-05-27 13:01:31,791:INFO:              mlflow: 2.13.0
2024-05-27 13:01:31,791:INFO:              gradio: Not installed
2024-05-27 13:01:31,791:INFO:             fastapi: Not installed
2024-05-27 13:01:31,791:INFO:             uvicorn: Not installed
2024-05-27 13:01:31,791:INFO:              m2cgen: Not installed
2024-05-27 13:01:31,791:INFO:           evidently: Not installed
2024-05-27 13:01:31,792:INFO:               fugue: Not installed
2024-05-27 13:01:31,792:INFO:           streamlit: Not installed
2024-05-27 13:01:31,792:INFO:             prophet: Not installed
2024-05-27 13:01:31,792:INFO:None
2024-05-27 13:01:31,792:INFO:Set up data.
2024-05-27 13:01:33,144:INFO:Set up folding strategy.
2024-05-27 13:01:33,144:INFO:Set up train/test split.
2024-05-27 13:01:49,533:INFO:Set up index.
2024-05-27 13:01:49,549:INFO:Assigning column types.
2024-05-27 13:01:50,902:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-27 13:01:50,974:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 13:01:50,976:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 13:01:51,021:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 13:01:51,025:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 13:01:51,097:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 13:01:51,098:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 13:01:51,143:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 13:01:51,147:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 13:01:51,148:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-27 13:01:51,219:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 13:01:51,263:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 13:01:51,268:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 13:01:51,340:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 13:01:51,384:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 13:01:51,388:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 13:01:51,389:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-27 13:01:51,504:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 13:01:51,509:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 13:01:51,625:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 13:01:51,629:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 13:01:51,631:INFO:Preparing preprocessing pipeline...
2024-05-27 13:01:51,683:INFO:Set up simple imputation.
2024-05-27 13:01:51,732:INFO:Set up column name cleaning.
2024-05-27 13:02:15,392:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:02:21,259:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py:249: UserWarning: Persisting input arguments took 2.91s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2024-05-27 13:02:23,444:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:02:41,421:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py:256: UserWarning: Persisting input arguments took 2.06s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2024-05-27 13:03:16,794:INFO:Finished creating preprocessing pipeline.
2024-05-27 13:03:16,843:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity',
                                             'listing_type_id_bronze',
                                             'listing_type_id_free',
                                             'listing_type_id_gold',
                                             'listing_type_id_gold_premium',
                                             'listing_type_id_gold_pro'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-05-27 13:03:16,843:INFO:Creating final display dataframe.
2024-05-27 13:05:16,155:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py:289: UserWarning: Persisting input arguments took 2.22s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2024-05-27 13:05:24,184:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:05:35,147:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py:111: UserWarning: Persisting input arguments took 2.97s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2024-05-27 13:05:40,333:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py:289: UserWarning: Persisting input arguments took 2.21s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2024-05-27 13:06:14,216:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\classification\oop.py:916: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.
  if self.data.isna().sum().sum():

2024-05-27 13:06:14,270:INFO:Setup _display_container:                     Description            Value
0                    Session id             3360
1                        Target           target
2                   Target type           Binary
3           Original data shape   (100000, 3809)
4        Transformed data shape   (100000, 3809)
5   Transformed train set shape    (90000, 3809)
6    Transformed test set shape    (10000, 3809)
7              Numeric features             3804
8                    Preprocess             True
9               Imputation type           simple
10           Numeric imputation             mean
11       Categorical imputation             mode
12               Fold Generator  StratifiedKFold
13                  Fold Number               10
14                     CPU Jobs               -1
15                      Use GPU            False
16               Log Experiment     MlflowLogger
17              Experiment Name         ml_codex
18                          USI             ee17
2024-05-27 13:06:14,410:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 13:06:14,414:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 13:06:14,533:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 13:06:14,537:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 13:06:14,539:INFO:Logging experiment in loggers
2024-05-27 13:06:14,701:INFO:SubProcess save_model() called ==================================
2024-05-27 13:06:14,798:INFO:Initializing save_model()
2024-05-27 13:06:14,798:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity',
                                             'listing_type_id_bronze',
                                             'listing_type_id_free',
                                             'listing_type_id_gold',
                                             'listing_type_id_gold_premium',
                                             'listing_type_id_gold_pro'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\Adm\AppData\Local\Temp\tmpbnfiewvn\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity',
                                             'listing_type_id_bronze',
                                             'listing_type_id_free',
                                             'listing_type_id_gold',
                                             'listing_type_id_gold_premium',
                                             'listing_type_id_gold_pro'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-27 13:06:14,798:INFO:Adding model into prep_pipe
2024-05-27 13:06:14,798:WARNING:Only Model saved as it was a pipeline.
2024-05-27 13:06:14,928:INFO:C:\Users\Adm\AppData\Local\Temp\tmpbnfiewvn\Transformation Pipeline.pkl saved in current working directory
2024-05-27 13:06:14,976:INFO:Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity',
                                             'listing_type_id_bronze',
                                             'listing_type_id_free',
                                             'listing_type_id_gold',
                                             'listing_type_id_gold_premium',
                                             'listing_type_id_gold_pro'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-05-27 13:06:14,976:INFO:save_model() successfully completed......................................
2024-05-27 13:06:15,830:INFO:SubProcess save_model() end ==================================
2024-05-27 13:06:15,857:INFO:setup() successfully completed in 282.8s...............
2024-05-27 13:06:17,420:INFO:Initializing compare_models()
2024-05-27 13:06:17,420:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144BD50EB0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002144BD50EB0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-27 13:06:17,420:INFO:Checking exceptions
2024-05-27 13:06:28,602:INFO:Preparing display monitor
2024-05-27 13:06:28,634:INFO:Initializing Logistic Regression
2024-05-27 13:06:28,634:INFO:Total runtime is 1.6661485036214194e-05 minutes
2024-05-27 13:06:28,639:INFO:SubProcess create_model() called ==================================
2024-05-27 13:06:28,640:INFO:Initializing create_model()
2024-05-27 13:06:28,640:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144BD50EB0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002144787BF70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:06:28,640:INFO:Checking exceptions
2024-05-27 13:06:28,640:INFO:Importing libraries
2024-05-27 13:06:28,641:INFO:Copying training dataset
2024-05-27 13:07:01,669:INFO:Defining folds
2024-05-27 13:07:01,669:INFO:Declaring metric variables
2024-05-27 13:07:01,674:INFO:Importing untrained model
2024-05-27 13:07:01,679:INFO:Logistic Regression Imported successfully
2024-05-27 13:07:01,689:INFO:Starting cross validation
2024-05-27 13:07:01,720:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:07:26,602:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:07:27,108:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:07:27,704:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:07:28,541:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:07:28,896:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:07:29,316:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:07:30,106:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:07:31,336:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:07:31,912:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:07:32,447:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:07:33,385:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:07:34,459:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:07:36,551:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:07:37,404:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:08:24,980:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:08:33,246:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
9 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 3908, in __getitem__
    data = self._take_with_is_copy(indexer, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4088, in _take_with_is_copy
    result = self.take(indices=indices, axis=axis)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4068, in take
    new_data = self._mgr.take(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 877, in take
    return self.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 410, in fit
    X = self._validate_input(X, in_fit=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 1059, in check_array
    if np.may_share_memory(array, array_orig):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 192, in _prepare_df
    out = to_df(out, index=X.index, columns=columns)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 410, in fit
    X = self._validate_input(X, in_fit=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 997, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_array_api.py", line 521, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 549, in transform
    X = self._validate_input(X, in_fit=False)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 1059, in check_array
    if np.may_share_memory(array, array_orig):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-27 13:08:33,247:INFO:Calculating mean and std
2024-05-27 13:08:33,248:INFO:Creating metrics dataframe
2024-05-27 13:08:33,251:INFO:Uploading results into container
2024-05-27 13:08:33,252:INFO:Uploading model into container now
2024-05-27 13:08:33,253:INFO:_master_model_container: 1
2024-05-27 13:08:33,253:INFO:_display_container: 2
2024-05-27 13:08:33,254:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3360, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-27 13:08:33,254:INFO:create_model() successfully completed......................................
2024-05-27 13:08:34,160:WARNING:create_model() for LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3360, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-27 13:08:34,161:WARNING:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2024-05-27 13:08:34,161:INFO:Initializing create_model()
2024-05-27 13:08:34,161:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144BD50EB0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002144787BF70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:08:34,161:INFO:Checking exceptions
2024-05-27 13:08:34,162:INFO:Importing libraries
2024-05-27 13:08:34,162:INFO:Copying training dataset
2024-05-27 13:09:07,324:INFO:Defining folds
2024-05-27 13:09:07,324:INFO:Declaring metric variables
2024-05-27 13:09:07,329:INFO:Importing untrained model
2024-05-27 13:09:07,334:INFO:Logistic Regression Imported successfully
2024-05-27 13:09:07,344:INFO:Starting cross validation
2024-05-27 13:09:07,373:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:09:29,801:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:09:29,884:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:09:30,096:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:09:30,317:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:09:31,330:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:09:31,482:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:09:31,825:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:09:32,545:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:09:32,996:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:09:34,027:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:09:35,352:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:09:36,644:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:09:37,538:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:09:38,418:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:10:21,187:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:10:29,513:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
9 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 410, in fit
    X = self._validate_input(X, in_fit=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 1059, in check_array
    if np.may_share_memory(array, array_orig):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 410, in fit
    X = self._validate_input(X, in_fit=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 997, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_array_api.py", line 521, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 549, in transform
    X = self._validate_input(X, in_fit=False)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 1059, in check_array
    if np.may_share_memory(array, array_orig):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-27 13:10:29,514:INFO:Calculating mean and std
2024-05-27 13:10:29,516:INFO:Creating metrics dataframe
2024-05-27 13:10:29,519:INFO:Uploading results into container
2024-05-27 13:10:29,520:INFO:Uploading model into container now
2024-05-27 13:10:29,521:INFO:_master_model_container: 2
2024-05-27 13:10:29,521:INFO:_display_container: 2
2024-05-27 13:10:29,522:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3360, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-27 13:10:29,522:INFO:create_model() successfully completed......................................
2024-05-27 13:10:30,602:ERROR:create_model() for LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3360, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) raised an exception or returned all 0.0:
2024-05-27 13:10:30,602:ERROR:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2024-05-27 13:10:30,603:INFO:Initializing K Neighbors Classifier
2024-05-27 13:10:30,603:INFO:Total runtime is 4.032843577861786 minutes
2024-05-27 13:10:30,608:INFO:SubProcess create_model() called ==================================
2024-05-27 13:10:30,608:INFO:Initializing create_model()
2024-05-27 13:10:30,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144BD50EB0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002144787BF70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:10:30,609:INFO:Checking exceptions
2024-05-27 13:10:30,609:INFO:Importing libraries
2024-05-27 13:10:30,609:INFO:Copying training dataset
2024-05-27 13:11:03,245:INFO:Defining folds
2024-05-27 13:11:03,245:INFO:Declaring metric variables
2024-05-27 13:11:03,250:INFO:Importing untrained model
2024-05-27 13:11:03,255:INFO:K Neighbors Classifier Imported successfully
2024-05-27 13:11:03,266:INFO:Starting cross validation
2024-05-27 13:11:03,297:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:11:22,485:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:11:23,035:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:11:23,561:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:11:23,797:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:11:25,246:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:11:25,372:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:11:25,943:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:11:25,949:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:11:26,688:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:11:26,851:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:11:27,898:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:11:28,457:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:11:29,238:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:11:30,640:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:11:31,254:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:11:51,868:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:20:34,579:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
9 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 549, in transform
    X = self._validate_input(X, in_fit=False)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 997, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_array_api.py", line 521, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 410, in fit
    X = self._validate_input(X, in_fit=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 1059, in check_array
    if np.may_share_memory(array, array_orig):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 410, in fit
    X = self._validate_input(X, in_fit=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 997, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_array_api.py", line 521, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 549, in transform
    X = self._validate_input(X, in_fit=False)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 1059, in check_array
    if np.may_share_memory(array, array_orig):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-27 13:20:34,580:INFO:Calculating mean and std
2024-05-27 13:20:34,581:INFO:Creating metrics dataframe
2024-05-27 13:20:34,584:INFO:Uploading results into container
2024-05-27 13:20:34,585:INFO:Uploading model into container now
2024-05-27 13:20:34,586:INFO:_master_model_container: 3
2024-05-27 13:20:34,586:INFO:_display_container: 2
2024-05-27 13:20:34,587:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-27 13:20:34,587:INFO:create_model() successfully completed......................................
2024-05-27 13:20:35,503:WARNING:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-27 13:20:35,503:WARNING:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2024-05-27 13:20:35,503:INFO:Initializing create_model()
2024-05-27 13:20:35,503:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144BD50EB0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002144787BF70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:20:35,504:INFO:Checking exceptions
2024-05-27 13:20:35,504:INFO:Importing libraries
2024-05-27 13:20:35,504:INFO:Copying training dataset
2024-05-27 13:21:07,788:INFO:Defining folds
2024-05-27 13:21:07,788:INFO:Declaring metric variables
2024-05-27 13:21:07,793:INFO:Importing untrained model
2024-05-27 13:21:07,798:INFO:K Neighbors Classifier Imported successfully
2024-05-27 13:21:07,807:INFO:Starting cross validation
2024-05-27 13:21:07,835:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:21:26,847:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:21:32,402:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:21:32,564:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:21:32,683:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:21:33,059:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:21:33,558:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:21:34,408:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:21:34,800:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:21:35,233:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:21:35,901:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:21:36,235:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:21:38,292:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:21:39,044:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:21:40,542:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:22:01,442:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:30:41,658:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
9 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 410, in fit
    X = self._validate_input(X, in_fit=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 1059, in check_array
    if np.may_share_memory(array, array_orig):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 192, in _prepare_df
    out = to_df(out, index=X.index, columns=columns)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 410, in fit
    X = self._validate_input(X, in_fit=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 997, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_array_api.py", line 521, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-27 13:30:41,659:INFO:Calculating mean and std
2024-05-27 13:30:41,660:INFO:Creating metrics dataframe
2024-05-27 13:30:41,663:INFO:Uploading results into container
2024-05-27 13:30:41,664:INFO:Uploading model into container now
2024-05-27 13:30:41,665:INFO:_master_model_container: 4
2024-05-27 13:30:41,665:INFO:_display_container: 2
2024-05-27 13:30:41,666:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-27 13:30:41,666:INFO:create_model() successfully completed......................................
2024-05-27 13:30:42,602:ERROR:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0:
2024-05-27 13:30:42,602:ERROR:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2024-05-27 13:30:42,602:INFO:Initializing Naive Bayes
2024-05-27 13:30:42,603:INFO:Total runtime is 24.232835427920023 minutes
2024-05-27 13:30:42,607:INFO:SubProcess create_model() called ==================================
2024-05-27 13:30:42,607:INFO:Initializing create_model()
2024-05-27 13:30:42,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144BD50EB0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002144787BF70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:30:42,607:INFO:Checking exceptions
2024-05-27 13:30:42,608:INFO:Importing libraries
2024-05-27 13:30:42,608:INFO:Copying training dataset
2024-05-27 13:31:14,543:INFO:Defining folds
2024-05-27 13:31:14,544:INFO:Declaring metric variables
2024-05-27 13:31:14,548:INFO:Importing untrained model
2024-05-27 13:31:14,553:INFO:Naive Bayes Imported successfully
2024-05-27 13:31:14,562:INFO:Starting cross validation
2024-05-27 13:31:14,592:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:31:33,690:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:31:38,880:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:31:39,291:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:31:39,424:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:31:39,992:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:31:40,467:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:31:40,839:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:31:41,480:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:31:42,782:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:31:43,102:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:31:43,193:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:31:44,902:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:31:45,391:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:31:46,021:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:31:47,217:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:32:11,793:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:32:20,935:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
9 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 549, in transform
    X = self._validate_input(X, in_fit=False)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 1059, in check_array
    if np.may_share_memory(array, array_orig):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 410, in fit
    X = self._validate_input(X, in_fit=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 1059, in check_array
    if np.may_share_memory(array, array_orig):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 192, in _prepare_df
    out = to_df(out, index=X.index, columns=columns)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 410, in fit
    X = self._validate_input(X, in_fit=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 997, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_array_api.py", line 521, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-27 13:32:20,936:INFO:Calculating mean and std
2024-05-27 13:32:20,937:INFO:Creating metrics dataframe
2024-05-27 13:32:20,940:INFO:Uploading results into container
2024-05-27 13:32:20,941:INFO:Uploading model into container now
2024-05-27 13:32:20,942:INFO:_master_model_container: 5
2024-05-27 13:32:20,943:INFO:_display_container: 2
2024-05-27 13:32:20,943:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-27 13:32:20,943:INFO:create_model() successfully completed......................................
2024-05-27 13:32:21,847:WARNING:create_model() for GaussianNB(priors=None, var_smoothing=1e-09) raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-27 13:32:21,847:WARNING:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2024-05-27 13:32:21,848:INFO:Initializing create_model()
2024-05-27 13:32:21,848:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144BD50EB0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002144787BF70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:32:21,848:INFO:Checking exceptions
2024-05-27 13:32:21,848:INFO:Importing libraries
2024-05-27 13:32:21,848:INFO:Copying training dataset
2024-05-27 13:32:55,335:INFO:Defining folds
2024-05-27 13:32:55,335:INFO:Declaring metric variables
2024-05-27 13:32:55,340:INFO:Importing untrained model
2024-05-27 13:32:55,346:INFO:Naive Bayes Imported successfully
2024-05-27 13:32:55,356:INFO:Starting cross validation
2024-05-27 13:32:55,386:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:33:19,139:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:33:19,176:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:33:19,939:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:33:20,359:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:33:20,483:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:33:20,798:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:33:21,369:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:33:21,946:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:33:22,374:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:33:22,844:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:33:25,187:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:33:25,997:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:33:26,388:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:33:27,427:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:33:52,502:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:34:01,845:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
9 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 410, in fit
    X = self._validate_input(X, in_fit=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 1059, in check_array
    if np.may_share_memory(array, array_orig):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 549, in transform
    X = self._validate_input(X, in_fit=False)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 1059, in check_array
    if np.may_share_memory(array, array_orig):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 410, in fit
    X = self._validate_input(X, in_fit=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 997, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_array_api.py", line 521, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-27 13:34:01,846:INFO:Calculating mean and std
2024-05-27 13:34:01,849:INFO:Creating metrics dataframe
2024-05-27 13:34:01,858:INFO:Uploading results into container
2024-05-27 13:34:01,859:INFO:Uploading model into container now
2024-05-27 13:34:01,861:INFO:_master_model_container: 6
2024-05-27 13:34:01,861:INFO:_display_container: 2
2024-05-27 13:34:01,861:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-27 13:34:01,862:INFO:create_model() successfully completed......................................
2024-05-27 13:34:02,885:ERROR:create_model() for GaussianNB(priors=None, var_smoothing=1e-09) raised an exception or returned all 0.0:
2024-05-27 13:34:02,886:ERROR:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2024-05-27 13:34:02,886:INFO:Initializing Decision Tree Classifier
2024-05-27 13:34:02,886:INFO:Total runtime is 27.570883631706238 minutes
2024-05-27 13:34:02,892:INFO:SubProcess create_model() called ==================================
2024-05-27 13:34:02,893:INFO:Initializing create_model()
2024-05-27 13:34:02,893:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144BD50EB0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002144787BF70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:34:02,894:INFO:Checking exceptions
2024-05-27 13:34:02,894:INFO:Importing libraries
2024-05-27 13:34:02,894:INFO:Copying training dataset
2024-05-27 13:34:38,230:INFO:Defining folds
2024-05-27 13:34:38,230:INFO:Declaring metric variables
2024-05-27 13:34:38,235:INFO:Importing untrained model
2024-05-27 13:34:38,240:INFO:Decision Tree Classifier Imported successfully
2024-05-27 13:34:38,250:INFO:Starting cross validation
2024-05-27 13:34:38,279:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:35:01,360:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:35:01,741:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:35:02,089:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:35:03,379:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:35:04,086:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:35:04,833:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:35:05,378:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:35:05,612:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:35:06,282:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:35:06,735:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:35:07,623:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:35:08,279:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:35:10,134:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:35:10,779:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:35:10,980:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:35:21,638:WARNING:create_model() for dt raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-27 13:35:21,644:WARNING:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 549, in transform
    X = self._validate_input(X, in_fit=False)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 997, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_array_api.py", line 521, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 410, in fit
    X = self._validate_input(X, in_fit=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 1059, in check_array
    if np.may_share_memory(array, array_orig):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 410, in fit
    X = self._validate_input(X, in_fit=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 997, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_array_api.py", line 521, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 176, in _reorder_cols
    new_df = new_df.drop(new_df.filter(regex="__drop__$").columns, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5344, in drop
    return super().drop(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4711, in drop
    obj = obj._drop_axis(labels, axis, level=level, errors=errors)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4792, in _drop_axis
    new_mgr = self._mgr.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 192, in _prepare_df
    out = to_df(out, index=X.index, columns=columns)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64


2024-05-27 13:35:21,644:INFO:Initializing create_model()
2024-05-27 13:35:21,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144BD50EB0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002144787BF70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:35:21,645:INFO:Checking exceptions
2024-05-27 13:35:21,645:INFO:Importing libraries
2024-05-27 13:35:21,645:INFO:Copying training dataset
2024-05-27 13:35:55,123:INFO:Defining folds
2024-05-27 13:35:55,123:INFO:Declaring metric variables
2024-05-27 13:35:55,129:INFO:Importing untrained model
2024-05-27 13:35:55,134:INFO:Decision Tree Classifier Imported successfully
2024-05-27 13:35:55,143:INFO:Starting cross validation
2024-05-27 13:35:55,172:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:36:15,691:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:36:15,983:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:36:16,967:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:36:17,276:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:36:17,793:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:36:18,342:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:36:19,003:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:36:19,304:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:36:19,578:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:36:19,635:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:36:20,778:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:36:21,097:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:36:22,345:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:36:23,901:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:37:24,306:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.
  warnings.warn(

2024-05-27 13:37:32,541:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
9 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 549, in transform
    X = self._validate_input(X, in_fit=False)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 1059, in check_array
    if np.may_share_memory(array, array_orig):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 410, in fit
    X = self._validate_input(X, in_fit=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 1059, in check_array
    if np.may_share_memory(array, array_orig):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 410, in fit
    X = self._validate_input(X, in_fit=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 997, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_array_api.py", line 521, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-27 13:37:32,541:INFO:Calculating mean and std
2024-05-27 13:37:32,543:INFO:Creating metrics dataframe
2024-05-27 13:37:32,546:INFO:Uploading results into container
2024-05-27 13:37:32,547:INFO:Uploading model into container now
2024-05-27 13:37:32,547:INFO:_master_model_container: 7
2024-05-27 13:37:32,547:INFO:_display_container: 2
2024-05-27 13:37:32,548:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3360, splitter='best')
2024-05-27 13:37:32,548:INFO:create_model() successfully completed......................................
2024-05-27 13:37:33,457:ERROR:create_model() for DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3360, splitter='best') raised an exception or returned all 0.0:
2024-05-27 13:37:33,458:ERROR:Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 549, in transform
    X = self._validate_input(X, in_fit=False)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 997, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_array_api.py", line 521, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 410, in fit
    X = self._validate_input(X, in_fit=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 1059, in check_array
    if np.may_share_memory(array, array_orig):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 249, in _fit
    fitted_transformer = self._memory_fit(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 229, in fit
    self.transformer.fit(*args, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 410, in fit
    X = self._validate_input(X, in_fit=True)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\impute\_base.py", line 322, in _validate_input
    X = self._validate_data(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\validation.py", line 997, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_array_api.py", line 521, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 2083, in __array__
    values = self._values
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 1046, in _values
    return ensure_wrapped_if_datetimelike(self.values)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 12281, in values
    return self._mgr.as_array()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1656, in as_array
    arr = self._interleave(dtype=dtype, na_value=na_value)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 1689, in _interleave
    result = np.empty(self.shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 176, in _reorder_cols
    new_df = new_df.drop(new_df.filter(regex="__drop__$").columns, axis=1)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5344, in drop
    return super().drop(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4711, in drop
    obj = obj._drop_axis(labels, axis, level=level, errors=errors)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 4792, in _drop_axis
    new_mgr = self._mgr.reindex_indexer(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\array_algos\take.py", line 158, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 196, in _prepare_df
    return self._reorder_cols(out, X)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 169, in _reorder_cols
    new_df = df.merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 10487, in merge
    return merge(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 183, in merge
    return op.get_result(copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 885, in get_result
    result = self._reindex_and_concat(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\merge.py", line 876, in _reindex_and_concat
    result = concat([left, right], axis=1, copy=copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 393, in concat
    return op.get_result()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\reshape\concat.py", line 680, in get_result
    new_data = concatenate_managers(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 263, in transform
    new_X = self._prepare_df(X, output)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 192, in _prepare_df
    out = to_df(out, index=X.index, columns=columns)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\utils\generic.py", line 109, in to_df
    data = data.rename(columns=lambda col: str(col))
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\frame.py", line 5518, in rename
    return super()._rename(
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 1059, in _rename
    result = self if inplace else self.copy(deep=copy and not using_copy_on_write())
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\generic.py", line 6685, in copy
    data = self._mgr.copy(deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 576, in copy
    res = self.apply("copy", deep=deep)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\managers.py", line 354, in apply
    applied = getattr(b, f)(**kwargs)
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pandas\core\internals\blocks.py", line 645, in copy
    values = values.copy()
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.30 GiB for an array with shape (3804, 81000) and data type float64


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2024-05-27 13:37:33,465:INFO:Initializing SVM - Linear Kernel
2024-05-27 13:37:33,465:INFO:Total runtime is 31.080542866388956 minutes
2024-05-27 13:37:33,469:INFO:SubProcess create_model() called ==================================
2024-05-27 13:37:33,470:INFO:Initializing create_model()
2024-05-27 13:37:33,470:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144BD50EB0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002144787BF70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:37:33,470:INFO:Checking exceptions
2024-05-27 13:37:33,470:INFO:Importing libraries
2024-05-27 13:37:33,470:INFO:Copying training dataset
2024-05-27 13:38:18,844:INFO:PyCaret ClassificationExperiment
2024-05-27 13:38:18,845:INFO:Logging name: ml_codex
2024-05-27 13:38:18,845:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-27 13:38:18,845:INFO:version 3.3.2
2024-05-27 13:38:18,845:INFO:Initializing setup()
2024-05-27 13:38:18,845:INFO:self.USI: af58
2024-05-27 13:38:18,845:INFO:self._variable_keys: {'memory', 'X_train', 'data', 'fold_shuffle_param', 'fold_generator', 'pipeline', 'y_test', 'X_test', 'X', 'gpu_param', 'seed', 'gpu_n_jobs_param', '_ml_usecase', 'html_param', 'logging_param', 'n_jobs_param', 'exp_id', 'idx', 'y', 'target_param', 'exp_name_log', 'y_train', 'USI', 'log_plots_param', 'fix_imbalance', 'is_multiclass', 'fold_groups_param', '_available_plots'}
2024-05-27 13:38:18,845:INFO:Checking environment
2024-05-27 13:38:18,845:INFO:python_version: 3.10.13
2024-05-27 13:38:18,846:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-27 13:38:18,846:INFO:machine: AMD64
2024-05-27 13:38:18,846:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-27 13:38:18,846:INFO:Memory: svmem(total=34267656192, available=18490781696, percent=46.0, used=15776874496, free=18490781696)
2024-05-27 13:38:18,846:INFO:Physical Core: 8
2024-05-27 13:38:18,846:INFO:Logical Core: 16
2024-05-27 13:38:18,846:INFO:Checking libraries
2024-05-27 13:38:18,846:INFO:System:
2024-05-27 13:38:18,846:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-27 13:38:18,846:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-27 13:38:18,846:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-27 13:38:18,847:INFO:PyCaret required dependencies:
2024-05-27 13:38:18,847:INFO:                 pip: 23.3
2024-05-27 13:38:18,847:INFO:          setuptools: 68.0.0
2024-05-27 13:38:18,847:INFO:             pycaret: 3.3.2
2024-05-27 13:38:18,847:INFO:             IPython: 8.24.0
2024-05-27 13:38:18,847:INFO:          ipywidgets: 8.1.2
2024-05-27 13:38:18,847:INFO:                tqdm: 4.66.4
2024-05-27 13:38:18,847:INFO:               numpy: 1.26.4
2024-05-27 13:38:18,847:INFO:              pandas: 2.1.4
2024-05-27 13:38:18,847:INFO:              jinja2: 3.1.4
2024-05-27 13:38:18,847:INFO:               scipy: 1.11.4
2024-05-27 13:38:18,848:INFO:              joblib: 1.3.2
2024-05-27 13:38:18,848:INFO:             sklearn: 1.4.2
2024-05-27 13:38:18,848:INFO:                pyod: 1.1.3
2024-05-27 13:38:18,848:INFO:            imblearn: 0.12.2
2024-05-27 13:38:18,848:INFO:   category_encoders: 2.6.3
2024-05-27 13:38:18,848:INFO:            lightgbm: 4.3.0
2024-05-27 13:38:18,848:INFO:               numba: 0.59.1
2024-05-27 13:38:18,848:INFO:            requests: 2.32.2
2024-05-27 13:38:18,848:INFO:          matplotlib: 3.7.5
2024-05-27 13:38:18,848:INFO:          scikitplot: 0.3.7
2024-05-27 13:38:18,848:INFO:         yellowbrick: 1.5
2024-05-27 13:38:18,849:INFO:              plotly: 5.22.0
2024-05-27 13:38:18,849:INFO:    plotly-resampler: Not installed
2024-05-27 13:38:18,849:INFO:             kaleido: 0.2.1
2024-05-27 13:38:18,849:INFO:           schemdraw: 0.15
2024-05-27 13:38:18,849:INFO:         statsmodels: 0.14.2
2024-05-27 13:38:18,849:INFO:              sktime: 0.26.0
2024-05-27 13:38:18,849:INFO:               tbats: 1.1.3
2024-05-27 13:38:18,849:INFO:            pmdarima: 2.0.4
2024-05-27 13:38:18,849:INFO:              psutil: 5.9.0
2024-05-27 13:38:18,849:INFO:          markupsafe: 2.1.5
2024-05-27 13:38:18,849:INFO:             pickle5: Not installed
2024-05-27 13:38:18,849:INFO:         cloudpickle: 3.0.0
2024-05-27 13:38:18,850:INFO:         deprecation: 2.1.0
2024-05-27 13:38:18,850:INFO:              xxhash: 3.4.1
2024-05-27 13:38:18,850:INFO:           wurlitzer: Not installed
2024-05-27 13:38:18,850:INFO:PyCaret optional dependencies:
2024-05-27 13:38:18,850:INFO:                shap: Not installed
2024-05-27 13:38:18,850:INFO:           interpret: Not installed
2024-05-27 13:38:18,850:INFO:                umap: Not installed
2024-05-27 13:38:18,850:INFO:     ydata_profiling: Not installed
2024-05-27 13:38:18,850:INFO:  explainerdashboard: Not installed
2024-05-27 13:38:18,850:INFO:             autoviz: Not installed
2024-05-27 13:38:18,851:INFO:           fairlearn: Not installed
2024-05-27 13:38:18,851:INFO:          deepchecks: Not installed
2024-05-27 13:38:18,851:INFO:             xgboost: 2.0.3
2024-05-27 13:38:18,851:INFO:            catboost: Not installed
2024-05-27 13:38:18,851:INFO:              kmodes: Not installed
2024-05-27 13:38:18,851:INFO:             mlxtend: Not installed
2024-05-27 13:38:18,851:INFO:       statsforecast: Not installed
2024-05-27 13:38:18,851:INFO:        tune_sklearn: Not installed
2024-05-27 13:38:18,851:INFO:                 ray: Not installed
2024-05-27 13:38:18,851:INFO:            hyperopt: Not installed
2024-05-27 13:38:18,851:INFO:              optuna: Not installed
2024-05-27 13:38:18,851:INFO:               skopt: Not installed
2024-05-27 13:38:18,852:INFO:              mlflow: 2.13.0
2024-05-27 13:38:18,852:INFO:              gradio: Not installed
2024-05-27 13:38:18,852:INFO:             fastapi: Not installed
2024-05-27 13:38:18,852:INFO:             uvicorn: Not installed
2024-05-27 13:38:18,852:INFO:              m2cgen: Not installed
2024-05-27 13:38:18,852:INFO:           evidently: Not installed
2024-05-27 13:38:18,852:INFO:               fugue: Not installed
2024-05-27 13:38:18,852:INFO:           streamlit: Not installed
2024-05-27 13:38:18,852:INFO:             prophet: Not installed
2024-05-27 13:38:18,852:INFO:None
2024-05-27 13:38:18,853:INFO:Set up data.
2024-05-27 13:38:19,193:INFO:Set up folding strategy.
2024-05-27 13:38:19,194:INFO:Set up train/test split.
2024-05-27 13:38:19,248:INFO:Set up index.
2024-05-27 13:38:19,250:INFO:Assigning column types.
2024-05-27 13:38:19,270:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-27 13:38:19,342:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 13:38:19,343:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 13:38:19,388:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 13:38:19,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 13:38:19,464:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 13:38:19,465:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 13:38:19,510:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 13:38:19,514:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 13:38:19,515:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-27 13:38:19,587:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 13:38:19,632:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 13:38:19,636:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 13:38:19,709:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 13:38:19,753:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 13:38:19,757:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 13:38:19,758:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-27 13:38:19,875:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 13:38:19,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 13:38:20,010:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 13:38:20,016:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 13:38:20,018:INFO:Preparing preprocessing pipeline...
2024-05-27 13:38:20,023:INFO:Set up simple imputation.
2024-05-27 13:38:20,053:INFO:Set up encoding of ordinal features.
2024-05-27 13:38:20,062:INFO:Set up encoding of categorical features.
2024-05-27 13:38:20,066:INFO:Set up column name cleaning.
2024-05-27 13:38:22,343:INFO:Finished creating preprocessing pipeline.
2024-05-27 13:38:22,372:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id',
                                                                    'seller_address.city.name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-05-27 13:38:22,373:INFO:Creating final display dataframe.
2024-05-27 13:38:24,013:INFO:Setup _display_container:                     Description            Value
0                    Session id             6321
1                        Target           target
2                   Target type           Binary
3           Original data shape     (100000, 19)
4        Transformed data shape     (100000, 57)
5   Transformed train set shape      (90000, 57)
6    Transformed test set shape      (10000, 57)
7              Numeric features                5
8          Categorical features                9
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Fold Generator  StratifiedKFold
16                  Fold Number               10
17                     CPU Jobs               -1
18                      Use GPU            False
19               Log Experiment     MlflowLogger
20              Experiment Name         ml_codex
21                          USI             af58
2024-05-27 13:38:30,512:INFO:PyCaret ClassificationExperiment
2024-05-27 13:38:30,512:INFO:Logging name: ml_codex2
2024-05-27 13:38:30,512:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-27 13:38:30,512:INFO:version 3.3.2
2024-05-27 13:38:30,512:INFO:Initializing setup()
2024-05-27 13:38:30,513:INFO:self.USI: fcf1
2024-05-27 13:38:30,513:INFO:self._variable_keys: {'memory', 'X_train', 'data', 'fold_shuffle_param', 'fold_generator', 'pipeline', 'y_test', 'X_test', 'X', 'gpu_param', 'seed', 'gpu_n_jobs_param', '_ml_usecase', 'html_param', 'logging_param', 'n_jobs_param', 'exp_id', 'idx', 'y', 'target_param', 'exp_name_log', 'y_train', 'USI', 'log_plots_param', 'fix_imbalance', 'is_multiclass', 'fold_groups_param', '_available_plots'}
2024-05-27 13:38:30,513:INFO:Checking environment
2024-05-27 13:38:30,513:INFO:python_version: 3.10.13
2024-05-27 13:38:30,513:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-27 13:38:30,513:INFO:machine: AMD64
2024-05-27 13:38:30,513:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-27 13:38:30,513:INFO:Memory: svmem(total=34267656192, available=18234265600, percent=46.8, used=16033390592, free=18234265600)
2024-05-27 13:38:30,513:INFO:Physical Core: 8
2024-05-27 13:38:30,513:INFO:Logical Core: 16
2024-05-27 13:38:30,514:INFO:Checking libraries
2024-05-27 13:38:30,514:INFO:System:
2024-05-27 13:38:30,514:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-27 13:38:30,514:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-27 13:38:30,514:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-27 13:38:30,514:INFO:PyCaret required dependencies:
2024-05-27 13:38:30,514:INFO:                 pip: 23.3
2024-05-27 13:38:30,514:INFO:          setuptools: 68.0.0
2024-05-27 13:38:30,514:INFO:             pycaret: 3.3.2
2024-05-27 13:38:30,514:INFO:             IPython: 8.24.0
2024-05-27 13:38:30,515:INFO:          ipywidgets: 8.1.2
2024-05-27 13:38:30,515:INFO:                tqdm: 4.66.4
2024-05-27 13:38:30,515:INFO:               numpy: 1.26.4
2024-05-27 13:38:30,515:INFO:              pandas: 2.1.4
2024-05-27 13:38:30,515:INFO:              jinja2: 3.1.4
2024-05-27 13:38:30,515:INFO:               scipy: 1.11.4
2024-05-27 13:38:30,515:INFO:              joblib: 1.3.2
2024-05-27 13:38:30,515:INFO:             sklearn: 1.4.2
2024-05-27 13:38:30,515:INFO:                pyod: 1.1.3
2024-05-27 13:38:30,515:INFO:            imblearn: 0.12.2
2024-05-27 13:38:30,515:INFO:   category_encoders: 2.6.3
2024-05-27 13:38:30,515:INFO:            lightgbm: 4.3.0
2024-05-27 13:38:30,516:INFO:               numba: 0.59.1
2024-05-27 13:38:30,516:INFO:            requests: 2.32.2
2024-05-27 13:38:30,516:INFO:          matplotlib: 3.7.5
2024-05-27 13:38:30,516:INFO:          scikitplot: 0.3.7
2024-05-27 13:38:30,516:INFO:         yellowbrick: 1.5
2024-05-27 13:38:30,516:INFO:              plotly: 5.22.0
2024-05-27 13:38:30,516:INFO:    plotly-resampler: Not installed
2024-05-27 13:38:30,516:INFO:             kaleido: 0.2.1
2024-05-27 13:38:30,516:INFO:           schemdraw: 0.15
2024-05-27 13:38:30,516:INFO:         statsmodels: 0.14.2
2024-05-27 13:38:30,516:INFO:              sktime: 0.26.0
2024-05-27 13:38:30,517:INFO:               tbats: 1.1.3
2024-05-27 13:38:30,517:INFO:            pmdarima: 2.0.4
2024-05-27 13:38:30,517:INFO:              psutil: 5.9.0
2024-05-27 13:38:30,517:INFO:          markupsafe: 2.1.5
2024-05-27 13:38:30,517:INFO:             pickle5: Not installed
2024-05-27 13:38:30,517:INFO:         cloudpickle: 3.0.0
2024-05-27 13:38:30,517:INFO:         deprecation: 2.1.0
2024-05-27 13:38:30,517:INFO:              xxhash: 3.4.1
2024-05-27 13:38:30,517:INFO:           wurlitzer: Not installed
2024-05-27 13:38:30,517:INFO:PyCaret optional dependencies:
2024-05-27 13:38:30,518:INFO:                shap: Not installed
2024-05-27 13:38:30,518:INFO:           interpret: Not installed
2024-05-27 13:38:30,518:INFO:                umap: Not installed
2024-05-27 13:38:30,518:INFO:     ydata_profiling: Not installed
2024-05-27 13:38:30,518:INFO:  explainerdashboard: Not installed
2024-05-27 13:38:30,518:INFO:             autoviz: Not installed
2024-05-27 13:38:30,518:INFO:           fairlearn: Not installed
2024-05-27 13:38:30,518:INFO:          deepchecks: Not installed
2024-05-27 13:38:30,518:INFO:             xgboost: 2.0.3
2024-05-27 13:38:30,518:INFO:            catboost: Not installed
2024-05-27 13:38:30,518:INFO:              kmodes: Not installed
2024-05-27 13:38:30,519:INFO:             mlxtend: Not installed
2024-05-27 13:38:30,519:INFO:       statsforecast: Not installed
2024-05-27 13:38:30,519:INFO:        tune_sklearn: Not installed
2024-05-27 13:38:30,519:INFO:                 ray: Not installed
2024-05-27 13:38:30,519:INFO:            hyperopt: Not installed
2024-05-27 13:38:30,519:INFO:              optuna: Not installed
2024-05-27 13:38:30,519:INFO:               skopt: Not installed
2024-05-27 13:38:30,519:INFO:              mlflow: 2.13.0
2024-05-27 13:38:30,519:INFO:              gradio: Not installed
2024-05-27 13:38:30,519:INFO:             fastapi: Not installed
2024-05-27 13:38:30,519:INFO:             uvicorn: Not installed
2024-05-27 13:38:30,519:INFO:              m2cgen: Not installed
2024-05-27 13:38:30,520:INFO:           evidently: Not installed
2024-05-27 13:38:30,520:INFO:               fugue: Not installed
2024-05-27 13:38:30,520:INFO:           streamlit: Not installed
2024-05-27 13:38:30,520:INFO:             prophet: Not installed
2024-05-27 13:38:30,520:INFO:None
2024-05-27 13:38:30,520:INFO:Set up data.
2024-05-27 13:38:30,895:INFO:Set up folding strategy.
2024-05-27 13:38:30,895:INFO:Set up train/test split.
2024-05-27 13:38:30,955:INFO:Set up index.
2024-05-27 13:38:30,957:INFO:Assigning column types.
2024-05-27 13:38:30,979:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-27 13:38:31,053:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 13:38:31,054:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 13:38:31,099:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 13:38:31,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 13:38:31,176:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 13:38:31,178:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 13:38:31,224:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 13:38:31,229:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 13:38:31,230:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-27 13:38:31,312:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 13:38:31,405:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 13:38:31,409:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 13:38:31,496:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 13:38:31,542:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 13:38:31,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 13:38:31,547:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-27 13:38:31,666:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 13:38:31,671:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 13:38:31,789:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 13:38:31,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 13:38:31,795:INFO:Preparing preprocessing pipeline...
2024-05-27 13:38:31,800:INFO:Set up simple imputation.
2024-05-27 13:38:31,825:INFO:Set up encoding of ordinal features.
2024-05-27 13:38:31,833:INFO:Set up encoding of categorical features.
2024-05-27 13:38:31,836:INFO:Set up column name cleaning.
2024-05-27 13:38:33,990:INFO:Finished creating preprocessing pipeline.
2024-05-27 13:38:34,019:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id',
                                                                    'seller_address.city.name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-05-27 13:38:34,019:INFO:Creating final display dataframe.
2024-05-27 13:38:35,606:INFO:Setup _display_container:                     Description            Value
0                    Session id             6119
1                        Target           target
2                   Target type           Binary
3           Original data shape     (100000, 19)
4        Transformed data shape     (100000, 57)
5   Transformed train set shape      (90000, 57)
6    Transformed test set shape      (10000, 57)
7              Numeric features                5
8          Categorical features                9
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Fold Generator  StratifiedKFold
16                  Fold Number               10
17                     CPU Jobs               -1
18                      Use GPU            False
19               Log Experiment     MlflowLogger
20              Experiment Name        ml_codex2
21                          USI             fcf1
2024-05-27 13:38:35,733:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 13:38:35,737:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 13:38:35,855:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 13:38:35,859:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 13:38:35,861:INFO:Logging experiment in loggers
2024-05-27 13:38:36,008:INFO:SubProcess save_model() called ==================================
2024-05-27 13:38:36,064:INFO:Initializing save_model()
2024-05-27 13:38:36,065:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id',
                                                                    'seller_address.city.name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\Adm\AppData\Local\Temp\tmpcxdk3l07\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id',
                                                                    'seller_address.city.name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-27 13:38:36,065:INFO:Adding model into prep_pipe
2024-05-27 13:38:36,065:WARNING:Only Model saved as it was a pipeline.
2024-05-27 13:38:36,096:INFO:C:\Users\Adm\AppData\Local\Temp\tmpcxdk3l07\Transformation Pipeline.pkl saved in current working directory
2024-05-27 13:38:36,124:INFO:Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id',
                                                                    'seller_address.city.name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-05-27 13:38:36,124:INFO:save_model() successfully completed......................................
2024-05-27 13:38:37,109:INFO:SubProcess save_model() end ==================================
2024-05-27 13:38:37,138:INFO:setup() successfully completed in 5.37s...............
2024-05-27 13:38:37,172:INFO:Initializing compare_models()
2024-05-27 13:38:37,173:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458847E20>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021458847E20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-27 13:38:37,173:INFO:Checking exceptions
2024-05-27 13:38:37,198:INFO:Preparing display monitor
2024-05-27 13:38:37,227:INFO:Initializing Logistic Regression
2024-05-27 13:38:37,227:INFO:Total runtime is 1.6649564107259113e-05 minutes
2024-05-27 13:38:37,233:INFO:SubProcess create_model() called ==================================
2024-05-27 13:38:37,233:INFO:Initializing create_model()
2024-05-27 13:38:37,233:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458847E20>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214573BC250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:38:37,234:INFO:Checking exceptions
2024-05-27 13:38:37,234:INFO:Importing libraries
2024-05-27 13:38:37,234:INFO:Copying training dataset
2024-05-27 13:38:37,288:INFO:Defining folds
2024-05-27 13:38:37,288:INFO:Declaring metric variables
2024-05-27 13:38:37,296:INFO:Importing untrained model
2024-05-27 13:38:37,302:INFO:Logistic Regression Imported successfully
2024-05-27 13:38:37,322:INFO:Starting cross validation
2024-05-27 13:38:37,328:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:38:56,453:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-27 13:38:56,621:INFO:Calculating mean and std
2024-05-27 13:38:56,624:INFO:Creating metrics dataframe
2024-05-27 13:38:56,627:INFO:Uploading results into container
2024-05-27 13:38:56,628:INFO:Uploading model into container now
2024-05-27 13:38:56,629:INFO:_master_model_container: 1
2024-05-27 13:38:56,629:INFO:_display_container: 2
2024-05-27 13:38:56,630:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6119, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-27 13:38:56,630:INFO:create_model() successfully completed......................................
2024-05-27 13:38:57,566:INFO:SubProcess create_model() end ==================================
2024-05-27 13:38:57,566:INFO:Creating metrics dataframe
2024-05-27 13:38:57,576:INFO:Initializing K Neighbors Classifier
2024-05-27 13:38:57,576:INFO:Total runtime is 0.33916688362757363 minutes
2024-05-27 13:38:57,581:INFO:SubProcess create_model() called ==================================
2024-05-27 13:38:57,582:INFO:Initializing create_model()
2024-05-27 13:38:57,582:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458847E20>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214573BC250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:38:57,582:INFO:Checking exceptions
2024-05-27 13:38:57,582:INFO:Importing libraries
2024-05-27 13:38:57,583:INFO:Copying training dataset
2024-05-27 13:38:57,631:INFO:Defining folds
2024-05-27 13:38:57,631:INFO:Declaring metric variables
2024-05-27 13:38:57,637:INFO:Importing untrained model
2024-05-27 13:38:57,643:INFO:K Neighbors Classifier Imported successfully
2024-05-27 13:38:57,654:INFO:Starting cross validation
2024-05-27 13:38:57,658:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:39:21,158:INFO:Calculating mean and std
2024-05-27 13:39:21,160:INFO:Creating metrics dataframe
2024-05-27 13:39:21,163:INFO:Uploading results into container
2024-05-27 13:39:21,163:INFO:Uploading model into container now
2024-05-27 13:39:21,164:INFO:_master_model_container: 2
2024-05-27 13:39:21,164:INFO:_display_container: 2
2024-05-27 13:39:21,165:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-27 13:39:21,165:INFO:create_model() successfully completed......................................
2024-05-27 13:39:22,058:INFO:SubProcess create_model() end ==================================
2024-05-27 13:39:22,058:INFO:Creating metrics dataframe
2024-05-27 13:39:22,068:INFO:Initializing Naive Bayes
2024-05-27 13:39:22,068:INFO:Total runtime is 0.7473642786343893 minutes
2024-05-27 13:39:22,072:INFO:SubProcess create_model() called ==================================
2024-05-27 13:39:22,073:INFO:Initializing create_model()
2024-05-27 13:39:22,073:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458847E20>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214573BC250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:39:22,073:INFO:Checking exceptions
2024-05-27 13:39:22,073:INFO:Importing libraries
2024-05-27 13:39:22,073:INFO:Copying training dataset
2024-05-27 13:39:22,117:INFO:Defining folds
2024-05-27 13:39:22,117:INFO:Declaring metric variables
2024-05-27 13:39:22,123:INFO:Importing untrained model
2024-05-27 13:39:22,128:INFO:Naive Bayes Imported successfully
2024-05-27 13:39:22,137:INFO:Starting cross validation
2024-05-27 13:39:22,142:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:39:25,794:INFO:Calculating mean and std
2024-05-27 13:39:25,797:INFO:Creating metrics dataframe
2024-05-27 13:39:25,801:INFO:Uploading results into container
2024-05-27 13:39:25,802:INFO:Uploading model into container now
2024-05-27 13:39:25,802:INFO:_master_model_container: 3
2024-05-27 13:39:25,802:INFO:_display_container: 2
2024-05-27 13:39:25,803:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-27 13:39:25,803:INFO:create_model() successfully completed......................................
2024-05-27 13:39:26,855:INFO:SubProcess create_model() end ==================================
2024-05-27 13:39:26,855:INFO:Creating metrics dataframe
2024-05-27 13:39:26,866:INFO:Initializing Decision Tree Classifier
2024-05-27 13:39:26,866:INFO:Total runtime is 0.8273324251174927 minutes
2024-05-27 13:39:26,871:INFO:SubProcess create_model() called ==================================
2024-05-27 13:39:26,872:INFO:Initializing create_model()
2024-05-27 13:39:26,872:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458847E20>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214573BC250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:39:26,872:INFO:Checking exceptions
2024-05-27 13:39:26,872:INFO:Importing libraries
2024-05-27 13:39:26,872:INFO:Copying training dataset
2024-05-27 13:39:26,918:INFO:Defining folds
2024-05-27 13:39:26,918:INFO:Declaring metric variables
2024-05-27 13:39:26,923:INFO:Importing untrained model
2024-05-27 13:39:26,929:INFO:Decision Tree Classifier Imported successfully
2024-05-27 13:39:26,939:INFO:Starting cross validation
2024-05-27 13:39:26,944:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:39:31,232:INFO:Calculating mean and std
2024-05-27 13:39:31,234:INFO:Creating metrics dataframe
2024-05-27 13:39:31,237:INFO:Uploading results into container
2024-05-27 13:39:31,237:INFO:Uploading model into container now
2024-05-27 13:39:31,238:INFO:_master_model_container: 4
2024-05-27 13:39:31,238:INFO:_display_container: 2
2024-05-27 13:39:31,239:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=6119, splitter='best')
2024-05-27 13:39:31,239:INFO:create_model() successfully completed......................................
2024-05-27 13:39:32,157:INFO:SubProcess create_model() end ==================================
2024-05-27 13:39:32,157:INFO:Creating metrics dataframe
2024-05-27 13:39:32,168:INFO:Initializing SVM - Linear Kernel
2024-05-27 13:39:32,168:INFO:Total runtime is 0.9157058159510295 minutes
2024-05-27 13:39:32,173:INFO:SubProcess create_model() called ==================================
2024-05-27 13:39:32,173:INFO:Initializing create_model()
2024-05-27 13:39:32,173:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458847E20>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214573BC250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:39:32,173:INFO:Checking exceptions
2024-05-27 13:39:32,174:INFO:Importing libraries
2024-05-27 13:39:32,174:INFO:Copying training dataset
2024-05-27 13:39:32,217:INFO:Defining folds
2024-05-27 13:39:32,218:INFO:Declaring metric variables
2024-05-27 13:39:32,223:INFO:Importing untrained model
2024-05-27 13:39:32,228:INFO:SVM - Linear Kernel Imported successfully
2024-05-27 13:39:32,238:INFO:Starting cross validation
2024-05-27 13:39:32,243:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:39:36,388:INFO:Calculating mean and std
2024-05-27 13:39:36,389:INFO:Creating metrics dataframe
2024-05-27 13:39:36,392:INFO:Uploading results into container
2024-05-27 13:39:36,393:INFO:Uploading model into container now
2024-05-27 13:39:36,394:INFO:_master_model_container: 5
2024-05-27 13:39:36,394:INFO:_display_container: 2
2024-05-27 13:39:36,395:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6119, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-27 13:39:36,395:INFO:create_model() successfully completed......................................
2024-05-27 13:39:37,413:INFO:SubProcess create_model() end ==================================
2024-05-27 13:39:37,413:INFO:Creating metrics dataframe
2024-05-27 13:39:37,425:INFO:Initializing Ridge Classifier
2024-05-27 13:39:37,425:INFO:Total runtime is 1.00331715742747 minutes
2024-05-27 13:39:37,431:INFO:SubProcess create_model() called ==================================
2024-05-27 13:39:37,431:INFO:Initializing create_model()
2024-05-27 13:39:37,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458847E20>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214573BC250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:39:37,432:INFO:Checking exceptions
2024-05-27 13:39:37,432:INFO:Importing libraries
2024-05-27 13:39:37,432:INFO:Copying training dataset
2024-05-27 13:39:37,478:INFO:Defining folds
2024-05-27 13:39:37,478:INFO:Declaring metric variables
2024-05-27 13:39:37,484:INFO:Importing untrained model
2024-05-27 13:39:37,489:INFO:Ridge Classifier Imported successfully
2024-05-27 13:39:37,500:INFO:Starting cross validation
2024-05-27 13:39:37,505:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:39:40,313:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.80944e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 13:39:40,392:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.80938e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 13:39:40,409:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.80938e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 13:39:40,663:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.80906e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 13:39:40,688:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.80948e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 13:39:40,778:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.43771e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 13:39:40,818:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.78062e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 13:39:40,820:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.80939e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 13:39:40,839:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.80937e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 13:39:40,844:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.76926e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 13:39:41,143:INFO:Calculating mean and std
2024-05-27 13:39:41,145:INFO:Creating metrics dataframe
2024-05-27 13:39:41,148:INFO:Uploading results into container
2024-05-27 13:39:41,149:INFO:Uploading model into container now
2024-05-27 13:39:41,150:INFO:_master_model_container: 6
2024-05-27 13:39:41,150:INFO:_display_container: 2
2024-05-27 13:39:41,151:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6119, solver='auto',
                tol=0.0001)
2024-05-27 13:39:41,152:INFO:create_model() successfully completed......................................
2024-05-27 13:39:42,205:INFO:SubProcess create_model() end ==================================
2024-05-27 13:39:42,206:INFO:Creating metrics dataframe
2024-05-27 13:39:42,217:INFO:Initializing Random Forest Classifier
2024-05-27 13:39:42,218:INFO:Total runtime is 1.0832050760587058 minutes
2024-05-27 13:39:42,223:INFO:SubProcess create_model() called ==================================
2024-05-27 13:39:42,223:INFO:Initializing create_model()
2024-05-27 13:39:42,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458847E20>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214573BC250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:39:42,223:INFO:Checking exceptions
2024-05-27 13:39:42,224:INFO:Importing libraries
2024-05-27 13:39:42,224:INFO:Copying training dataset
2024-05-27 13:39:42,274:INFO:Defining folds
2024-05-27 13:39:42,274:INFO:Declaring metric variables
2024-05-27 13:39:42,279:INFO:Importing untrained model
2024-05-27 13:39:42,285:INFO:Random Forest Classifier Imported successfully
2024-05-27 13:39:42,295:INFO:Starting cross validation
2024-05-27 13:39:42,299:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:40:01,366:INFO:Calculating mean and std
2024-05-27 13:40:01,369:INFO:Creating metrics dataframe
2024-05-27 13:40:01,373:INFO:Uploading results into container
2024-05-27 13:40:01,375:INFO:Uploading model into container now
2024-05-27 13:40:01,376:INFO:_master_model_container: 7
2024-05-27 13:40:01,376:INFO:_display_container: 2
2024-05-27 13:40:01,377:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6119, verbose=0,
                       warm_start=False)
2024-05-27 13:40:01,378:INFO:create_model() successfully completed......................................
2024-05-27 13:40:02,945:INFO:SubProcess create_model() end ==================================
2024-05-27 13:40:02,945:INFO:Creating metrics dataframe
2024-05-27 13:40:02,965:INFO:Initializing Quadratic Discriminant Analysis
2024-05-27 13:40:02,965:INFO:Total runtime is 1.4289751768112184 minutes
2024-05-27 13:40:02,972:INFO:SubProcess create_model() called ==================================
2024-05-27 13:40:02,972:INFO:Initializing create_model()
2024-05-27 13:40:02,972:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458847E20>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214573BC250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:40:02,973:INFO:Checking exceptions
2024-05-27 13:40:02,973:INFO:Importing libraries
2024-05-27 13:40:02,973:INFO:Copying training dataset
2024-05-27 13:40:03,024:INFO:Defining folds
2024-05-27 13:40:03,025:INFO:Declaring metric variables
2024-05-27 13:40:03,033:INFO:Importing untrained model
2024-05-27 13:40:03,039:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-27 13:40:03,050:INFO:Starting cross validation
2024-05-27 13:40:03,055:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:40:06,906:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 13:40:06,995:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 13:40:07,075:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 13:40:07,094:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 13:40:07,115:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 13:40:07,121:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 13:40:07,183:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 13:40:07,414:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 13:40:07,468:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 13:40:09,141:INFO:Calculating mean and std
2024-05-27 13:40:09,143:INFO:Creating metrics dataframe
2024-05-27 13:40:09,146:INFO:Uploading results into container
2024-05-27 13:40:09,147:INFO:Uploading model into container now
2024-05-27 13:40:09,148:INFO:_master_model_container: 8
2024-05-27 13:40:09,148:INFO:_display_container: 2
2024-05-27 13:40:09,149:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-27 13:40:09,149:INFO:create_model() successfully completed......................................
2024-05-27 13:40:10,139:INFO:SubProcess create_model() end ==================================
2024-05-27 13:40:10,140:INFO:Creating metrics dataframe
2024-05-27 13:40:10,153:INFO:Initializing Ada Boost Classifier
2024-05-27 13:40:10,153:INFO:Total runtime is 1.548785456021627 minutes
2024-05-27 13:40:10,159:INFO:SubProcess create_model() called ==================================
2024-05-27 13:40:10,159:INFO:Initializing create_model()
2024-05-27 13:40:10,159:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458847E20>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214573BC250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:40:10,160:INFO:Checking exceptions
2024-05-27 13:40:10,160:INFO:Importing libraries
2024-05-27 13:40:10,160:INFO:Copying training dataset
2024-05-27 13:40:10,209:INFO:Defining folds
2024-05-27 13:40:10,210:INFO:Declaring metric variables
2024-05-27 13:40:10,216:INFO:Importing untrained model
2024-05-27 13:40:10,221:INFO:Ada Boost Classifier Imported successfully
2024-05-27 13:40:10,230:INFO:Starting cross validation
2024-05-27 13:40:10,235:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:40:12,983:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 13:40:13,023:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 13:40:13,114:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 13:40:13,123:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 13:40:13,144:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 13:40:13,169:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 13:40:13,327:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 13:40:13,329:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 13:40:13,386:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 13:40:13,404:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 13:40:23,129:INFO:Calculating mean and std
2024-05-27 13:40:23,131:INFO:Creating metrics dataframe
2024-05-27 13:40:23,134:INFO:Uploading results into container
2024-05-27 13:40:23,134:INFO:Uploading model into container now
2024-05-27 13:40:23,135:INFO:_master_model_container: 9
2024-05-27 13:40:23,135:INFO:_display_container: 2
2024-05-27 13:40:23,136:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=6119)
2024-05-27 13:40:23,136:INFO:create_model() successfully completed......................................
2024-05-27 13:40:24,078:INFO:SubProcess create_model() end ==================================
2024-05-27 13:40:24,078:INFO:Creating metrics dataframe
2024-05-27 13:40:24,091:INFO:Initializing Gradient Boosting Classifier
2024-05-27 13:40:24,092:INFO:Total runtime is 1.7810970743497214 minutes
2024-05-27 13:40:24,096:INFO:SubProcess create_model() called ==================================
2024-05-27 13:40:24,097:INFO:Initializing create_model()
2024-05-27 13:40:24,097:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458847E20>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214573BC250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:40:24,106:INFO:Checking exceptions
2024-05-27 13:40:24,107:INFO:Importing libraries
2024-05-27 13:40:24,107:INFO:Copying training dataset
2024-05-27 13:40:24,152:INFO:Defining folds
2024-05-27 13:40:24,153:INFO:Declaring metric variables
2024-05-27 13:40:24,158:INFO:Importing untrained model
2024-05-27 13:40:24,164:INFO:Gradient Boosting Classifier Imported successfully
2024-05-27 13:40:24,173:INFO:Starting cross validation
2024-05-27 13:40:24,178:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:40:50,709:INFO:Calculating mean and std
2024-05-27 13:40:50,711:INFO:Creating metrics dataframe
2024-05-27 13:40:50,714:INFO:Uploading results into container
2024-05-27 13:40:50,715:INFO:Uploading model into container now
2024-05-27 13:40:50,715:INFO:_master_model_container: 10
2024-05-27 13:40:50,716:INFO:_display_container: 2
2024-05-27 13:40:50,717:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6119, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-27 13:40:50,717:INFO:create_model() successfully completed......................................
2024-05-27 13:40:51,643:INFO:SubProcess create_model() end ==================================
2024-05-27 13:40:51,643:INFO:Creating metrics dataframe
2024-05-27 13:40:51,658:INFO:Initializing Linear Discriminant Analysis
2024-05-27 13:40:51,658:INFO:Total runtime is 2.2405240297317506 minutes
2024-05-27 13:40:51,663:INFO:SubProcess create_model() called ==================================
2024-05-27 13:40:51,663:INFO:Initializing create_model()
2024-05-27 13:40:51,664:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458847E20>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214573BC250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:40:51,664:INFO:Checking exceptions
2024-05-27 13:40:51,664:INFO:Importing libraries
2024-05-27 13:40:51,664:INFO:Copying training dataset
2024-05-27 13:40:51,711:INFO:Defining folds
2024-05-27 13:40:51,712:INFO:Declaring metric variables
2024-05-27 13:40:51,717:INFO:Importing untrained model
2024-05-27 13:40:51,722:INFO:Linear Discriminant Analysis Imported successfully
2024-05-27 13:40:51,734:INFO:Starting cross validation
2024-05-27 13:40:51,739:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:40:58,023:INFO:Calculating mean and std
2024-05-27 13:40:58,025:INFO:Creating metrics dataframe
2024-05-27 13:40:58,028:INFO:Uploading results into container
2024-05-27 13:40:58,029:INFO:Uploading model into container now
2024-05-27 13:40:58,029:INFO:_master_model_container: 11
2024-05-27 13:40:58,029:INFO:_display_container: 2
2024-05-27 13:40:58,030:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-27 13:40:58,030:INFO:create_model() successfully completed......................................
2024-05-27 13:40:59,057:INFO:SubProcess create_model() end ==================================
2024-05-27 13:40:59,058:INFO:Creating metrics dataframe
2024-05-27 13:40:59,072:INFO:Initializing Extra Trees Classifier
2024-05-27 13:40:59,072:INFO:Total runtime is 2.364097491900126 minutes
2024-05-27 13:40:59,077:INFO:SubProcess create_model() called ==================================
2024-05-27 13:40:59,077:INFO:Initializing create_model()
2024-05-27 13:40:59,077:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458847E20>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214573BC250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:40:59,078:INFO:Checking exceptions
2024-05-27 13:40:59,078:INFO:Importing libraries
2024-05-27 13:40:59,078:INFO:Copying training dataset
2024-05-27 13:40:59,123:INFO:Defining folds
2024-05-27 13:40:59,124:INFO:Declaring metric variables
2024-05-27 13:40:59,129:INFO:Importing untrained model
2024-05-27 13:40:59,134:INFO:Extra Trees Classifier Imported successfully
2024-05-27 13:40:59,145:INFO:Starting cross validation
2024-05-27 13:40:59,150:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:41:26,631:INFO:Calculating mean and std
2024-05-27 13:41:26,635:INFO:Creating metrics dataframe
2024-05-27 13:41:26,639:INFO:Uploading results into container
2024-05-27 13:41:26,640:INFO:Uploading model into container now
2024-05-27 13:41:26,641:INFO:_master_model_container: 12
2024-05-27 13:41:26,641:INFO:_display_container: 2
2024-05-27 13:41:26,642:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=6119, verbose=0,
                     warm_start=False)
2024-05-27 13:41:26,643:INFO:create_model() successfully completed......................................
2024-05-27 13:41:27,907:INFO:SubProcess create_model() end ==================================
2024-05-27 13:41:27,907:INFO:Creating metrics dataframe
2024-05-27 13:41:27,922:INFO:Initializing Extreme Gradient Boosting
2024-05-27 13:41:27,922:INFO:Total runtime is 2.8449323137601215 minutes
2024-05-27 13:41:27,927:INFO:SubProcess create_model() called ==================================
2024-05-27 13:41:27,927:INFO:Initializing create_model()
2024-05-27 13:41:27,928:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458847E20>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214573BC250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:41:27,928:INFO:Checking exceptions
2024-05-27 13:41:27,928:INFO:Importing libraries
2024-05-27 13:41:27,928:INFO:Copying training dataset
2024-05-27 13:41:27,972:INFO:Defining folds
2024-05-27 13:41:27,972:INFO:Declaring metric variables
2024-05-27 13:41:27,977:INFO:Importing untrained model
2024-05-27 13:41:27,982:INFO:Extreme Gradient Boosting Imported successfully
2024-05-27 13:41:27,992:INFO:Starting cross validation
2024-05-27 13:41:27,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:41:34,898:INFO:Calculating mean and std
2024-05-27 13:41:34,900:INFO:Creating metrics dataframe
2024-05-27 13:41:34,902:INFO:Uploading results into container
2024-05-27 13:41:34,903:INFO:Uploading model into container now
2024-05-27 13:41:34,904:INFO:_master_model_container: 13
2024-05-27 13:41:34,904:INFO:_display_container: 2
2024-05-27 13:41:34,906:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-27 13:41:34,906:INFO:create_model() successfully completed......................................
2024-05-27 13:41:35,824:INFO:SubProcess create_model() end ==================================
2024-05-27 13:41:35,824:INFO:Creating metrics dataframe
2024-05-27 13:41:35,840:INFO:Initializing Light Gradient Boosting Machine
2024-05-27 13:41:35,840:INFO:Total runtime is 2.976897056897481 minutes
2024-05-27 13:41:35,844:INFO:SubProcess create_model() called ==================================
2024-05-27 13:41:35,845:INFO:Initializing create_model()
2024-05-27 13:41:35,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458847E20>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214573BC250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:41:35,845:INFO:Checking exceptions
2024-05-27 13:41:35,845:INFO:Importing libraries
2024-05-27 13:41:35,846:INFO:Copying training dataset
2024-05-27 13:41:35,890:INFO:Defining folds
2024-05-27 13:41:35,890:INFO:Declaring metric variables
2024-05-27 13:41:35,895:INFO:Importing untrained model
2024-05-27 13:41:35,900:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 13:41:35,911:INFO:Starting cross validation
2024-05-27 13:41:35,916:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:41:42,295:INFO:Calculating mean and std
2024-05-27 13:41:42,297:INFO:Creating metrics dataframe
2024-05-27 13:41:42,300:INFO:Uploading results into container
2024-05-27 13:41:42,301:INFO:Uploading model into container now
2024-05-27 13:41:42,302:INFO:_master_model_container: 14
2024-05-27 13:41:42,303:INFO:_display_container: 2
2024-05-27 13:41:42,304:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6119, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-27 13:41:42,304:INFO:create_model() successfully completed......................................
2024-05-27 13:41:43,424:INFO:SubProcess create_model() end ==================================
2024-05-27 13:41:43,424:INFO:Creating metrics dataframe
2024-05-27 13:41:43,441:INFO:Initializing Dummy Classifier
2024-05-27 13:41:43,442:INFO:Total runtime is 3.1035984714825946 minutes
2024-05-27 13:41:43,447:INFO:SubProcess create_model() called ==================================
2024-05-27 13:41:43,447:INFO:Initializing create_model()
2024-05-27 13:41:43,447:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458847E20>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214573BC250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:41:43,447:INFO:Checking exceptions
2024-05-27 13:41:43,448:INFO:Importing libraries
2024-05-27 13:41:43,448:INFO:Copying training dataset
2024-05-27 13:41:43,493:INFO:Defining folds
2024-05-27 13:41:43,493:INFO:Declaring metric variables
2024-05-27 13:41:43,498:INFO:Importing untrained model
2024-05-27 13:41:43,503:INFO:Dummy Classifier Imported successfully
2024-05-27 13:41:43,512:INFO:Starting cross validation
2024-05-27 13:41:43,517:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 13:41:46,800:INFO:Calculating mean and std
2024-05-27 13:41:46,802:INFO:Creating metrics dataframe
2024-05-27 13:41:46,805:INFO:Uploading results into container
2024-05-27 13:41:46,806:INFO:Uploading model into container now
2024-05-27 13:41:46,806:INFO:_master_model_container: 15
2024-05-27 13:41:46,806:INFO:_display_container: 2
2024-05-27 13:41:46,807:INFO:DummyClassifier(constant=None, random_state=6119, strategy='prior')
2024-05-27 13:41:46,807:INFO:create_model() successfully completed......................................
2024-05-27 13:41:47,740:INFO:SubProcess create_model() end ==================================
2024-05-27 13:41:47,741:INFO:Creating metrics dataframe
2024-05-27 13:41:47,758:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-27 13:41:47,771:INFO:Initializing create_model()
2024-05-27 13:41:47,771:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458847E20>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 13:41:47,771:INFO:Checking exceptions
2024-05-27 13:41:47,774:INFO:Importing libraries
2024-05-27 13:41:47,774:INFO:Copying training dataset
2024-05-27 13:41:47,817:INFO:Defining folds
2024-05-27 13:41:47,817:INFO:Declaring metric variables
2024-05-27 13:41:47,818:INFO:Importing untrained model
2024-05-27 13:41:47,818:INFO:Declaring custom model
2024-05-27 13:41:47,820:INFO:Extreme Gradient Boosting Imported successfully
2024-05-27 13:41:47,824:INFO:Cross validation set to False
2024-05-27 13:41:47,824:INFO:Fitting Model
2024-05-27 13:41:49,903:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-27 13:41:49,903:INFO:create_model() successfully completed......................................
2024-05-27 13:41:50,854:INFO:Creating Dashboard logs
2024-05-27 13:41:50,859:INFO:Model: Extreme Gradient Boosting
2024-05-27 13:41:50,945:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 6119, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2024-05-27 13:41:51,207:INFO:Initializing predict_model()
2024-05-27 13:41:51,207:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021458847E20>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002144F3CACB0>)
2024-05-27 13:41:51,207:INFO:Checking exceptions
2024-05-27 13:41:51,207:INFO:Preloading libraries
2024-05-27 13:41:53,629:INFO:Creating Dashboard logs
2024-05-27 13:41:53,634:INFO:Model: Light Gradient Boosting Machine
2024-05-27 13:41:53,703:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 6119, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-05-27 13:41:54,963:INFO:Creating Dashboard logs
2024-05-27 13:41:54,967:INFO:Model: Gradient Boosting Classifier
2024-05-27 13:41:55,040:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 6119, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-27 13:41:56,306:INFO:Creating Dashboard logs
2024-05-27 13:41:56,311:INFO:Model: Random Forest Classifier
2024-05-27 13:41:56,385:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 6119, 'verbose': 0, 'warm_start': False}
2024-05-27 13:41:57,748:INFO:Creating Dashboard logs
2024-05-27 13:41:57,753:INFO:Model: Ada Boost Classifier
2024-05-27 13:41:57,821:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 6119}
2024-05-27 13:41:59,045:INFO:Creating Dashboard logs
2024-05-27 13:41:59,050:INFO:Model: Extra Trees Classifier
2024-05-27 13:41:59,118:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 6119, 'verbose': 0, 'warm_start': False}
2024-05-27 13:42:00,400:INFO:Creating Dashboard logs
2024-05-27 13:42:00,405:INFO:Model: Ridge Classifier
2024-05-27 13:42:00,473:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 6119, 'solver': 'auto', 'tol': 0.0001}
2024-05-27 13:42:01,767:INFO:Creating Dashboard logs
2024-05-27 13:42:01,772:INFO:Model: Linear Discriminant Analysis
2024-05-27 13:42:01,842:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-05-27 13:42:03,098:INFO:Creating Dashboard logs
2024-05-27 13:42:03,103:INFO:Model: Decision Tree Classifier
2024-05-27 13:42:03,173:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 6119, 'splitter': 'best'}
2024-05-27 13:42:04,418:INFO:Creating Dashboard logs
2024-05-27 13:42:04,423:INFO:Model: K Neighbors Classifier
2024-05-27 13:42:04,492:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2024-05-27 13:42:05,735:INFO:Creating Dashboard logs
2024-05-27 13:42:05,740:INFO:Model: Logistic Regression
2024-05-27 13:42:05,808:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 6119, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-05-27 13:42:07,041:INFO:Creating Dashboard logs
2024-05-27 13:42:07,046:INFO:Model: Quadratic Discriminant Analysis
2024-05-27 13:42:07,118:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2024-05-27 13:42:08,394:INFO:Creating Dashboard logs
2024-05-27 13:42:08,399:INFO:Model: Dummy Classifier
2024-05-27 13:42:08,468:INFO:Logged params: {'constant': None, 'random_state': 6119, 'strategy': 'prior'}
2024-05-27 13:42:09,670:INFO:Creating Dashboard logs
2024-05-27 13:42:09,674:INFO:Model: SVM - Linear Kernel
2024-05-27 13:42:09,742:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 6119, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-27 13:42:11,007:INFO:Creating Dashboard logs
2024-05-27 13:42:11,014:INFO:Model: Naive Bayes
2024-05-27 13:42:11,086:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-05-27 13:42:12,358:INFO:_master_model_container: 15
2024-05-27 13:42:12,359:INFO:_display_container: 2
2024-05-27 13:42:12,360:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-27 13:42:12,360:INFO:compare_models() successfully completed......................................
2024-05-27 14:07:37,392:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 14:07:37,393:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 14:07:37,393:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 14:07:37,393:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 14:08:31,749:INFO:PyCaret ClassificationExperiment
2024-05-27 14:08:31,749:INFO:Logging name: ml_codex3
2024-05-27 14:08:31,749:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-27 14:08:31,749:INFO:version 3.3.2
2024-05-27 14:08:31,749:INFO:Initializing setup()
2024-05-27 14:08:31,750:INFO:self.USI: 5386
2024-05-27 14:08:31,750:INFO:self._variable_keys: {'y', 'data', '_ml_usecase', 'gpu_param', '_available_plots', 'y_test', 'idx', 'fold_groups_param', 'X_train', 'fold_generator', 'html_param', 'is_multiclass', 'USI', 'fix_imbalance', 'exp_id', 'X_test', 'memory', 'seed', 'pipeline', 'exp_name_log', 'gpu_n_jobs_param', 'y_train', 'n_jobs_param', 'fold_shuffle_param', 'logging_param', 'log_plots_param', 'X', 'target_param'}
2024-05-27 14:08:31,750:INFO:Checking environment
2024-05-27 14:08:31,750:INFO:python_version: 3.10.13
2024-05-27 14:08:31,750:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-27 14:08:31,750:INFO:machine: AMD64
2024-05-27 14:08:31,750:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-27 14:08:31,750:INFO:Memory: svmem(total=34267656192, available=20375457792, percent=40.5, used=13892198400, free=20375457792)
2024-05-27 14:08:31,750:INFO:Physical Core: 8
2024-05-27 14:08:31,750:INFO:Logical Core: 16
2024-05-27 14:08:31,750:INFO:Checking libraries
2024-05-27 14:08:31,751:INFO:System:
2024-05-27 14:08:31,751:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-27 14:08:31,751:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-27 14:08:31,751:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-27 14:08:31,751:INFO:PyCaret required dependencies:
2024-05-27 14:08:31,790:INFO:                 pip: 23.3
2024-05-27 14:08:31,790:INFO:          setuptools: 68.0.0
2024-05-27 14:08:31,790:INFO:             pycaret: 3.3.2
2024-05-27 14:08:31,790:INFO:             IPython: 8.24.0
2024-05-27 14:08:31,790:INFO:          ipywidgets: 8.1.2
2024-05-27 14:08:31,790:INFO:                tqdm: 4.66.4
2024-05-27 14:08:31,790:INFO:               numpy: 1.26.4
2024-05-27 14:08:31,791:INFO:              pandas: 2.1.4
2024-05-27 14:08:31,791:INFO:              jinja2: 3.1.4
2024-05-27 14:08:31,791:INFO:               scipy: 1.11.4
2024-05-27 14:08:31,791:INFO:              joblib: 1.3.2
2024-05-27 14:08:31,791:INFO:             sklearn: 1.4.2
2024-05-27 14:08:31,791:INFO:                pyod: 1.1.3
2024-05-27 14:08:31,791:INFO:            imblearn: 0.12.2
2024-05-27 14:08:31,791:INFO:   category_encoders: 2.6.3
2024-05-27 14:08:31,791:INFO:            lightgbm: 4.3.0
2024-05-27 14:08:31,792:INFO:               numba: 0.59.1
2024-05-27 14:08:31,792:INFO:            requests: 2.32.2
2024-05-27 14:08:31,792:INFO:          matplotlib: 3.7.5
2024-05-27 14:08:31,792:INFO:          scikitplot: 0.3.7
2024-05-27 14:08:31,792:INFO:         yellowbrick: 1.5
2024-05-27 14:08:31,792:INFO:              plotly: 5.22.0
2024-05-27 14:08:31,792:INFO:    plotly-resampler: Not installed
2024-05-27 14:08:31,792:INFO:             kaleido: 0.2.1
2024-05-27 14:08:31,792:INFO:           schemdraw: 0.15
2024-05-27 14:08:31,792:INFO:         statsmodels: 0.14.2
2024-05-27 14:08:31,792:INFO:              sktime: 0.26.0
2024-05-27 14:08:31,792:INFO:               tbats: 1.1.3
2024-05-27 14:08:31,793:INFO:            pmdarima: 2.0.4
2024-05-27 14:08:31,793:INFO:              psutil: 5.9.0
2024-05-27 14:08:31,793:INFO:          markupsafe: 2.1.5
2024-05-27 14:08:31,793:INFO:             pickle5: Not installed
2024-05-27 14:08:31,793:INFO:         cloudpickle: 3.0.0
2024-05-27 14:08:31,793:INFO:         deprecation: 2.1.0
2024-05-27 14:08:31,793:INFO:              xxhash: 3.4.1
2024-05-27 14:08:31,793:INFO:           wurlitzer: Not installed
2024-05-27 14:08:31,793:INFO:PyCaret optional dependencies:
2024-05-27 14:08:31,855:INFO:                shap: Not installed
2024-05-27 14:08:31,855:INFO:           interpret: Not installed
2024-05-27 14:08:31,855:INFO:                umap: Not installed
2024-05-27 14:08:31,855:INFO:     ydata_profiling: Not installed
2024-05-27 14:08:31,855:INFO:  explainerdashboard: Not installed
2024-05-27 14:08:31,855:INFO:             autoviz: Not installed
2024-05-27 14:08:31,855:INFO:           fairlearn: Not installed
2024-05-27 14:08:31,855:INFO:          deepchecks: Not installed
2024-05-27 14:08:31,855:INFO:             xgboost: 2.0.3
2024-05-27 14:08:31,855:INFO:            catboost: Not installed
2024-05-27 14:08:31,856:INFO:              kmodes: Not installed
2024-05-27 14:08:31,856:INFO:             mlxtend: Not installed
2024-05-27 14:08:31,856:INFO:       statsforecast: Not installed
2024-05-27 14:08:31,856:INFO:        tune_sklearn: Not installed
2024-05-27 14:08:31,856:INFO:                 ray: Not installed
2024-05-27 14:08:31,856:INFO:            hyperopt: Not installed
2024-05-27 14:08:31,856:INFO:              optuna: Not installed
2024-05-27 14:08:31,856:INFO:               skopt: Not installed
2024-05-27 14:08:31,856:INFO:              mlflow: 2.13.0
2024-05-27 14:08:31,856:INFO:              gradio: Not installed
2024-05-27 14:08:31,856:INFO:             fastapi: Not installed
2024-05-27 14:08:31,856:INFO:             uvicorn: Not installed
2024-05-27 14:08:31,857:INFO:              m2cgen: Not installed
2024-05-27 14:08:31,857:INFO:           evidently: Not installed
2024-05-27 14:08:31,857:INFO:               fugue: Not installed
2024-05-27 14:08:31,857:INFO:           streamlit: Not installed
2024-05-27 14:08:31,857:INFO:             prophet: Not installed
2024-05-27 14:08:31,857:INFO:None
2024-05-27 14:08:31,857:INFO:Set up data.
2024-05-27 14:08:32,185:INFO:Set up folding strategy.
2024-05-27 14:08:32,185:INFO:Set up train/test split.
2024-05-27 14:08:32,242:INFO:Set up index.
2024-05-27 14:08:32,244:INFO:Assigning column types.
2024-05-27 14:08:32,264:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-27 14:08:32,337:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 14:08:32,342:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 14:08:32,399:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 14:08:32,404:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 14:08:32,477:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 14:08:32,478:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 14:08:32,524:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 14:08:32,528:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 14:08:32,529:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-27 14:08:32,603:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 14:08:32,649:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 14:08:32,653:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 14:08:32,728:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 14:08:32,774:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 14:08:32,778:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 14:08:32,778:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-27 14:08:32,898:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 14:08:32,902:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 14:08:33,024:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 14:08:33,028:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 14:08:33,032:INFO:Preparing preprocessing pipeline...
2024-05-27 14:08:33,036:INFO:Set up simple imputation.
2024-05-27 14:08:33,061:INFO:Set up encoding of ordinal features.
2024-05-27 14:08:33,070:INFO:Set up encoding of categorical features.
2024-05-27 14:08:33,073:INFO:Set up column name cleaning.
2024-05-27 14:08:35,520:INFO:Finished creating preprocessing pipeline.
2024-05-27 14:08:35,552:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id',
                                                                    'seller_address.city.name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-05-27 14:08:35,552:INFO:Creating final display dataframe.
2024-05-27 14:08:37,219:INFO:Setup _display_container:                     Description            Value
0                    Session id             2990
1                        Target           target
2                   Target type           Binary
3           Original data shape     (100000, 19)
4        Transformed data shape     (100000, 56)
5   Transformed train set shape      (90000, 56)
6    Transformed test set shape      (10000, 56)
7              Numeric features                5
8          Categorical features                9
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Fold Generator  StratifiedKFold
16                  Fold Number               10
17                     CPU Jobs               -1
18                      Use GPU            False
19               Log Experiment     MlflowLogger
20              Experiment Name        ml_codex3
21                          USI             5386
2024-05-27 14:08:37,351:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 14:08:37,356:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 14:08:37,476:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 14:08:37,480:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 14:08:37,482:INFO:Logging experiment in loggers
2024-05-27 14:08:37,903:INFO:SubProcess save_model() called ==================================
2024-05-27 14:08:37,960:INFO:Initializing save_model()
2024-05-27 14:08:37,960:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id',
                                                                    'seller_address.city.name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\Adm\AppData\Local\Temp\tmp980oy6t3\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id',
                                                                    'seller_address.city.name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-27 14:08:37,960:INFO:Adding model into prep_pipe
2024-05-27 14:08:37,960:WARNING:Only Model saved as it was a pipeline.
2024-05-27 14:08:37,994:INFO:C:\Users\Adm\AppData\Local\Temp\tmp980oy6t3\Transformation Pipeline.pkl saved in current working directory
2024-05-27 14:08:38,023:INFO:Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id',
                                                                    'seller_address.city.name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-05-27 14:08:38,023:INFO:save_model() successfully completed......................................
2024-05-27 14:08:38,729:INFO:SubProcess save_model() end ==================================
2024-05-27 14:08:38,797:INFO:setup() successfully completed in 5.76s...............
2024-05-27 14:08:48,087:INFO:Initializing compare_models()
2024-05-27 14:08:48,087:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-27 14:08:48,087:INFO:Checking exceptions
2024-05-27 14:08:48,115:INFO:Preparing display monitor
2024-05-27 14:08:48,187:INFO:Initializing Logistic Regression
2024-05-27 14:08:48,189:INFO:Total runtime is 3.331899642944336e-05 minutes
2024-05-27 14:08:48,195:INFO:SubProcess create_model() called ==================================
2024-05-27 14:08:48,196:INFO:Initializing create_model()
2024-05-27 14:08:48,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025DA9CCC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 14:08:48,196:INFO:Checking exceptions
2024-05-27 14:08:48,197:INFO:Importing libraries
2024-05-27 14:08:48,197:INFO:Copying training dataset
2024-05-27 14:08:48,248:INFO:Defining folds
2024-05-27 14:08:48,248:INFO:Declaring metric variables
2024-05-27 14:08:48,253:INFO:Importing untrained model
2024-05-27 14:08:48,258:INFO:Logistic Regression Imported successfully
2024-05-27 14:08:48,266:INFO:Starting cross validation
2024-05-27 14:08:48,271:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 14:09:13,795:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-27 14:09:13,950:INFO:Calculating mean and std
2024-05-27 14:09:13,952:INFO:Creating metrics dataframe
2024-05-27 14:09:13,955:INFO:Uploading results into container
2024-05-27 14:09:13,956:INFO:Uploading model into container now
2024-05-27 14:09:13,956:INFO:_master_model_container: 1
2024-05-27 14:09:13,957:INFO:_display_container: 2
2024-05-27 14:09:13,957:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2990, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-27 14:09:13,958:INFO:create_model() successfully completed......................................
2024-05-27 14:09:14,654:INFO:SubProcess create_model() end ==================================
2024-05-27 14:09:14,654:INFO:Creating metrics dataframe
2024-05-27 14:09:14,663:INFO:Initializing K Neighbors Classifier
2024-05-27 14:09:14,663:INFO:Total runtime is 0.44126248757044473 minutes
2024-05-27 14:09:14,668:INFO:SubProcess create_model() called ==================================
2024-05-27 14:09:14,668:INFO:Initializing create_model()
2024-05-27 14:09:14,668:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025DA9CCC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 14:09:14,669:INFO:Checking exceptions
2024-05-27 14:09:14,669:INFO:Importing libraries
2024-05-27 14:09:14,669:INFO:Copying training dataset
2024-05-27 14:09:14,712:INFO:Defining folds
2024-05-27 14:09:14,712:INFO:Declaring metric variables
2024-05-27 14:09:14,719:INFO:Importing untrained model
2024-05-27 14:09:14,725:INFO:K Neighbors Classifier Imported successfully
2024-05-27 14:09:14,734:INFO:Starting cross validation
2024-05-27 14:09:14,739:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 14:09:41,607:INFO:Calculating mean and std
2024-05-27 14:09:41,609:INFO:Creating metrics dataframe
2024-05-27 14:09:41,612:INFO:Uploading results into container
2024-05-27 14:09:41,613:INFO:Uploading model into container now
2024-05-27 14:09:41,614:INFO:_master_model_container: 2
2024-05-27 14:09:41,614:INFO:_display_container: 2
2024-05-27 14:09:41,615:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-27 14:09:41,615:INFO:create_model() successfully completed......................................
2024-05-27 14:09:42,460:INFO:SubProcess create_model() end ==================================
2024-05-27 14:09:42,460:INFO:Creating metrics dataframe
2024-05-27 14:09:42,470:INFO:Initializing Naive Bayes
2024-05-27 14:09:42,471:INFO:Total runtime is 0.9047353704770407 minutes
2024-05-27 14:09:42,476:INFO:SubProcess create_model() called ==================================
2024-05-27 14:09:42,476:INFO:Initializing create_model()
2024-05-27 14:09:42,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025DA9CCC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 14:09:42,477:INFO:Checking exceptions
2024-05-27 14:09:42,477:INFO:Importing libraries
2024-05-27 14:09:42,477:INFO:Copying training dataset
2024-05-27 14:09:42,523:INFO:Defining folds
2024-05-27 14:09:42,523:INFO:Declaring metric variables
2024-05-27 14:09:42,529:INFO:Importing untrained model
2024-05-27 14:09:42,536:INFO:Naive Bayes Imported successfully
2024-05-27 14:09:42,548:INFO:Starting cross validation
2024-05-27 14:09:42,554:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 14:09:46,537:INFO:Calculating mean and std
2024-05-27 14:09:46,539:INFO:Creating metrics dataframe
2024-05-27 14:09:46,546:INFO:Uploading results into container
2024-05-27 14:09:46,547:INFO:Uploading model into container now
2024-05-27 14:09:46,549:INFO:_master_model_container: 3
2024-05-27 14:09:46,549:INFO:_display_container: 2
2024-05-27 14:09:46,550:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-27 14:09:46,550:INFO:create_model() successfully completed......................................
2024-05-27 14:09:47,429:INFO:SubProcess create_model() end ==================================
2024-05-27 14:09:47,430:INFO:Creating metrics dataframe
2024-05-27 14:09:47,439:INFO:Initializing Decision Tree Classifier
2024-05-27 14:09:47,440:INFO:Total runtime is 0.9875522216161092 minutes
2024-05-27 14:09:47,444:INFO:SubProcess create_model() called ==================================
2024-05-27 14:09:47,445:INFO:Initializing create_model()
2024-05-27 14:09:47,445:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025DA9CCC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 14:09:47,445:INFO:Checking exceptions
2024-05-27 14:09:47,446:INFO:Importing libraries
2024-05-27 14:09:47,446:INFO:Copying training dataset
2024-05-27 14:09:47,490:INFO:Defining folds
2024-05-27 14:09:47,490:INFO:Declaring metric variables
2024-05-27 14:09:47,496:INFO:Importing untrained model
2024-05-27 14:09:47,501:INFO:Decision Tree Classifier Imported successfully
2024-05-27 14:09:47,511:INFO:Starting cross validation
2024-05-27 14:09:47,516:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 14:09:51,895:INFO:Calculating mean and std
2024-05-27 14:09:51,897:INFO:Creating metrics dataframe
2024-05-27 14:09:51,899:INFO:Uploading results into container
2024-05-27 14:09:51,900:INFO:Uploading model into container now
2024-05-27 14:09:51,901:INFO:_master_model_container: 4
2024-05-27 14:09:51,901:INFO:_display_container: 2
2024-05-27 14:09:51,901:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2990, splitter='best')
2024-05-27 14:09:51,902:INFO:create_model() successfully completed......................................
2024-05-27 14:09:52,605:INFO:SubProcess create_model() end ==================================
2024-05-27 14:09:52,606:INFO:Creating metrics dataframe
2024-05-27 14:09:52,617:INFO:Initializing SVM - Linear Kernel
2024-05-27 14:09:52,617:INFO:Total runtime is 1.073836898803711 minutes
2024-05-27 14:09:52,621:INFO:SubProcess create_model() called ==================================
2024-05-27 14:09:52,622:INFO:Initializing create_model()
2024-05-27 14:09:52,622:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025DA9CCC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 14:09:52,622:INFO:Checking exceptions
2024-05-27 14:09:52,622:INFO:Importing libraries
2024-05-27 14:09:52,622:INFO:Copying training dataset
2024-05-27 14:09:52,665:INFO:Defining folds
2024-05-27 14:09:52,666:INFO:Declaring metric variables
2024-05-27 14:09:52,670:INFO:Importing untrained model
2024-05-27 14:09:52,676:INFO:SVM - Linear Kernel Imported successfully
2024-05-27 14:09:52,685:INFO:Starting cross validation
2024-05-27 14:09:52,691:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 14:09:56,731:INFO:Calculating mean and std
2024-05-27 14:09:56,733:INFO:Creating metrics dataframe
2024-05-27 14:09:56,736:INFO:Uploading results into container
2024-05-27 14:09:56,737:INFO:Uploading model into container now
2024-05-27 14:09:56,738:INFO:_master_model_container: 5
2024-05-27 14:09:56,739:INFO:_display_container: 2
2024-05-27 14:09:56,740:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2990, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-27 14:09:56,741:INFO:create_model() successfully completed......................................
2024-05-27 14:09:57,545:INFO:SubProcess create_model() end ==================================
2024-05-27 14:09:57,545:INFO:Creating metrics dataframe
2024-05-27 14:09:57,557:INFO:Initializing Ridge Classifier
2024-05-27 14:09:57,557:INFO:Total runtime is 1.1561745246251425 minutes
2024-05-27 14:09:57,564:INFO:SubProcess create_model() called ==================================
2024-05-27 14:09:57,564:INFO:Initializing create_model()
2024-05-27 14:09:57,565:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025DA9CCC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 14:09:57,565:INFO:Checking exceptions
2024-05-27 14:09:57,565:INFO:Importing libraries
2024-05-27 14:09:57,565:INFO:Copying training dataset
2024-05-27 14:09:57,611:INFO:Defining folds
2024-05-27 14:09:57,612:INFO:Declaring metric variables
2024-05-27 14:09:57,617:INFO:Importing untrained model
2024-05-27 14:09:57,623:INFO:Ridge Classifier Imported successfully
2024-05-27 14:09:57,634:INFO:Starting cross validation
2024-05-27 14:09:57,638:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 14:10:00,782:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.76678e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 14:10:00,867:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.7691e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 14:10:00,888:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.75521e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 14:10:00,975:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.75512e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 14:10:01,015:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.75515e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 14:10:01,101:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.75525e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 14:10:01,105:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.75495e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 14:10:01,123:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.7552e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 14:10:01,141:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=7.18572e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 14:10:01,159:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.8259e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 14:10:01,553:INFO:Calculating mean and std
2024-05-27 14:10:01,555:INFO:Creating metrics dataframe
2024-05-27 14:10:01,558:INFO:Uploading results into container
2024-05-27 14:10:01,559:INFO:Uploading model into container now
2024-05-27 14:10:01,560:INFO:_master_model_container: 6
2024-05-27 14:10:01,560:INFO:_display_container: 2
2024-05-27 14:10:01,562:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2990, solver='auto',
                tol=0.0001)
2024-05-27 14:10:01,562:INFO:create_model() successfully completed......................................
2024-05-27 14:10:02,550:INFO:SubProcess create_model() end ==================================
2024-05-27 14:10:02,551:INFO:Creating metrics dataframe
2024-05-27 14:10:02,564:INFO:Initializing Random Forest Classifier
2024-05-27 14:10:02,564:INFO:Total runtime is 1.2396094719568889 minutes
2024-05-27 14:10:02,568:INFO:SubProcess create_model() called ==================================
2024-05-27 14:10:02,569:INFO:Initializing create_model()
2024-05-27 14:10:02,569:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025DA9CCC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 14:10:02,569:INFO:Checking exceptions
2024-05-27 14:10:02,569:INFO:Importing libraries
2024-05-27 14:10:02,569:INFO:Copying training dataset
2024-05-27 14:10:02,612:INFO:Defining folds
2024-05-27 14:10:02,612:INFO:Declaring metric variables
2024-05-27 14:10:02,617:INFO:Importing untrained model
2024-05-27 14:10:02,621:INFO:Random Forest Classifier Imported successfully
2024-05-27 14:10:02,631:INFO:Starting cross validation
2024-05-27 14:10:02,635:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 14:10:22,814:INFO:Calculating mean and std
2024-05-27 14:10:22,815:INFO:Creating metrics dataframe
2024-05-27 14:10:22,819:INFO:Uploading results into container
2024-05-27 14:10:22,819:INFO:Uploading model into container now
2024-05-27 14:10:22,820:INFO:_master_model_container: 7
2024-05-27 14:10:22,821:INFO:_display_container: 2
2024-05-27 14:10:22,822:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2990, verbose=0,
                       warm_start=False)
2024-05-27 14:10:22,822:INFO:create_model() successfully completed......................................
2024-05-27 14:10:23,646:INFO:SubProcess create_model() end ==================================
2024-05-27 14:10:23,646:INFO:Creating metrics dataframe
2024-05-27 14:10:23,659:INFO:Initializing Quadratic Discriminant Analysis
2024-05-27 14:10:23,659:INFO:Total runtime is 1.5911970416704815 minutes
2024-05-27 14:10:23,664:INFO:SubProcess create_model() called ==================================
2024-05-27 14:10:23,665:INFO:Initializing create_model()
2024-05-27 14:10:23,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025DA9CCC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 14:10:23,665:INFO:Checking exceptions
2024-05-27 14:10:23,665:INFO:Importing libraries
2024-05-27 14:10:23,665:INFO:Copying training dataset
2024-05-27 14:10:23,708:INFO:Defining folds
2024-05-27 14:10:23,708:INFO:Declaring metric variables
2024-05-27 14:10:23,713:INFO:Importing untrained model
2024-05-27 14:10:23,721:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-27 14:10:23,735:INFO:Starting cross validation
2024-05-27 14:10:23,741:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 14:10:27,204:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 14:10:27,455:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 14:10:27,608:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 14:10:27,886:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 14:10:27,926:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 14:10:27,952:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 14:10:28,110:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 14:10:28,134:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 14:10:28,211:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 14:10:28,317:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 14:10:29,643:INFO:Calculating mean and std
2024-05-27 14:10:29,645:INFO:Creating metrics dataframe
2024-05-27 14:10:29,648:INFO:Uploading results into container
2024-05-27 14:10:29,648:INFO:Uploading model into container now
2024-05-27 14:10:29,649:INFO:_master_model_container: 8
2024-05-27 14:10:29,649:INFO:_display_container: 2
2024-05-27 14:10:29,650:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-27 14:10:29,650:INFO:create_model() successfully completed......................................
2024-05-27 14:10:30,413:INFO:SubProcess create_model() end ==================================
2024-05-27 14:10:30,413:INFO:Creating metrics dataframe
2024-05-27 14:10:30,426:INFO:Initializing Ada Boost Classifier
2024-05-27 14:10:30,426:INFO:Total runtime is 1.7039802749951682 minutes
2024-05-27 14:10:30,431:INFO:SubProcess create_model() called ==================================
2024-05-27 14:10:30,431:INFO:Initializing create_model()
2024-05-27 14:10:30,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025DA9CCC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 14:10:30,432:INFO:Checking exceptions
2024-05-27 14:10:30,432:INFO:Importing libraries
2024-05-27 14:10:30,432:INFO:Copying training dataset
2024-05-27 14:10:30,474:INFO:Defining folds
2024-05-27 14:10:30,475:INFO:Declaring metric variables
2024-05-27 14:10:30,480:INFO:Importing untrained model
2024-05-27 14:10:30,485:INFO:Ada Boost Classifier Imported successfully
2024-05-27 14:10:30,494:INFO:Starting cross validation
2024-05-27 14:10:30,497:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 14:10:32,968:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 14:10:33,136:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 14:10:33,152:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 14:10:33,214:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 14:10:33,347:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 14:10:33,402:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 14:10:33,406:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 14:10:33,431:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 14:10:33,486:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 14:10:33,497:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 14:10:42,542:INFO:Calculating mean and std
2024-05-27 14:10:42,544:INFO:Creating metrics dataframe
2024-05-27 14:10:42,547:INFO:Uploading results into container
2024-05-27 14:10:42,548:INFO:Uploading model into container now
2024-05-27 14:10:42,548:INFO:_master_model_container: 9
2024-05-27 14:10:42,548:INFO:_display_container: 2
2024-05-27 14:10:42,549:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2990)
2024-05-27 14:10:42,549:INFO:create_model() successfully completed......................................
2024-05-27 14:10:43,287:INFO:SubProcess create_model() end ==================================
2024-05-27 14:10:43,287:INFO:Creating metrics dataframe
2024-05-27 14:10:43,301:INFO:Initializing Gradient Boosting Classifier
2024-05-27 14:10:43,301:INFO:Total runtime is 1.918564041455587 minutes
2024-05-27 14:10:43,305:INFO:SubProcess create_model() called ==================================
2024-05-27 14:10:43,306:INFO:Initializing create_model()
2024-05-27 14:10:43,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025DA9CCC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 14:10:43,306:INFO:Checking exceptions
2024-05-27 14:10:43,306:INFO:Importing libraries
2024-05-27 14:10:43,306:INFO:Copying training dataset
2024-05-27 14:10:43,348:INFO:Defining folds
2024-05-27 14:10:43,349:INFO:Declaring metric variables
2024-05-27 14:10:43,354:INFO:Importing untrained model
2024-05-27 14:10:43,360:INFO:Gradient Boosting Classifier Imported successfully
2024-05-27 14:10:43,369:INFO:Starting cross validation
2024-05-27 14:10:43,373:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 14:11:08,849:INFO:Calculating mean and std
2024-05-27 14:11:08,851:INFO:Creating metrics dataframe
2024-05-27 14:11:08,854:INFO:Uploading results into container
2024-05-27 14:11:08,854:INFO:Uploading model into container now
2024-05-27 14:11:08,855:INFO:_master_model_container: 10
2024-05-27 14:11:08,855:INFO:_display_container: 2
2024-05-27 14:11:08,856:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2990, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-27 14:11:08,856:INFO:create_model() successfully completed......................................
2024-05-27 14:11:09,576:INFO:SubProcess create_model() end ==================================
2024-05-27 14:11:09,576:INFO:Creating metrics dataframe
2024-05-27 14:11:09,591:INFO:Initializing Linear Discriminant Analysis
2024-05-27 14:11:09,591:INFO:Total runtime is 2.3567397832870487 minutes
2024-05-27 14:11:09,596:INFO:SubProcess create_model() called ==================================
2024-05-27 14:11:09,597:INFO:Initializing create_model()
2024-05-27 14:11:09,597:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025DA9CCC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 14:11:09,597:INFO:Checking exceptions
2024-05-27 14:11:09,597:INFO:Importing libraries
2024-05-27 14:11:09,598:INFO:Copying training dataset
2024-05-27 14:11:09,641:INFO:Defining folds
2024-05-27 14:11:09,642:INFO:Declaring metric variables
2024-05-27 14:11:09,647:INFO:Importing untrained model
2024-05-27 14:11:09,652:INFO:Linear Discriminant Analysis Imported successfully
2024-05-27 14:11:09,661:INFO:Starting cross validation
2024-05-27 14:11:09,666:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 14:11:15,860:INFO:Calculating mean and std
2024-05-27 14:11:15,863:INFO:Creating metrics dataframe
2024-05-27 14:11:15,867:INFO:Uploading results into container
2024-05-27 14:11:15,868:INFO:Uploading model into container now
2024-05-27 14:11:15,869:INFO:_master_model_container: 11
2024-05-27 14:11:15,869:INFO:_display_container: 2
2024-05-27 14:11:15,869:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-27 14:11:15,870:INFO:create_model() successfully completed......................................
2024-05-27 14:11:16,748:INFO:SubProcess create_model() end ==================================
2024-05-27 14:11:16,748:INFO:Creating metrics dataframe
2024-05-27 14:11:16,764:INFO:Initializing Extra Trees Classifier
2024-05-27 14:11:16,764:INFO:Total runtime is 2.4762786030769353 minutes
2024-05-27 14:11:16,769:INFO:SubProcess create_model() called ==================================
2024-05-27 14:11:16,770:INFO:Initializing create_model()
2024-05-27 14:11:16,770:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025DA9CCC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 14:11:16,770:INFO:Checking exceptions
2024-05-27 14:11:16,770:INFO:Importing libraries
2024-05-27 14:11:16,770:INFO:Copying training dataset
2024-05-27 14:11:16,813:INFO:Defining folds
2024-05-27 14:11:16,814:INFO:Declaring metric variables
2024-05-27 14:11:16,820:INFO:Importing untrained model
2024-05-27 14:11:16,826:INFO:Extra Trees Classifier Imported successfully
2024-05-27 14:11:16,837:INFO:Starting cross validation
2024-05-27 14:11:16,841:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 14:11:43,996:INFO:Calculating mean and std
2024-05-27 14:11:43,998:INFO:Creating metrics dataframe
2024-05-27 14:11:44,002:INFO:Uploading results into container
2024-05-27 14:11:44,002:INFO:Uploading model into container now
2024-05-27 14:11:44,003:INFO:_master_model_container: 12
2024-05-27 14:11:44,003:INFO:_display_container: 2
2024-05-27 14:11:44,004:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2990, verbose=0,
                     warm_start=False)
2024-05-27 14:11:44,004:INFO:create_model() successfully completed......................................
2024-05-27 14:11:44,833:INFO:SubProcess create_model() end ==================================
2024-05-27 14:11:44,834:INFO:Creating metrics dataframe
2024-05-27 14:11:44,849:INFO:Initializing Extreme Gradient Boosting
2024-05-27 14:11:44,849:INFO:Total runtime is 2.9443675120671595 minutes
2024-05-27 14:11:44,854:INFO:SubProcess create_model() called ==================================
2024-05-27 14:11:44,854:INFO:Initializing create_model()
2024-05-27 14:11:44,854:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025DA9CCC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 14:11:44,854:INFO:Checking exceptions
2024-05-27 14:11:44,855:INFO:Importing libraries
2024-05-27 14:11:44,855:INFO:Copying training dataset
2024-05-27 14:11:44,897:INFO:Defining folds
2024-05-27 14:11:44,898:INFO:Declaring metric variables
2024-05-27 14:11:44,902:INFO:Importing untrained model
2024-05-27 14:11:44,907:INFO:Extreme Gradient Boosting Imported successfully
2024-05-27 14:11:44,917:INFO:Starting cross validation
2024-05-27 14:11:44,922:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 14:11:51,620:INFO:Calculating mean and std
2024-05-27 14:11:51,622:INFO:Creating metrics dataframe
2024-05-27 14:11:51,624:INFO:Uploading results into container
2024-05-27 14:11:51,625:INFO:Uploading model into container now
2024-05-27 14:11:51,626:INFO:_master_model_container: 13
2024-05-27 14:11:51,626:INFO:_display_container: 2
2024-05-27 14:11:51,627:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-27 14:11:51,627:INFO:create_model() successfully completed......................................
2024-05-27 14:11:52,361:INFO:SubProcess create_model() end ==================================
2024-05-27 14:11:52,361:INFO:Creating metrics dataframe
2024-05-27 14:11:52,377:INFO:Initializing Light Gradient Boosting Machine
2024-05-27 14:11:52,377:INFO:Total runtime is 3.0698273261388147 minutes
2024-05-27 14:11:52,381:INFO:SubProcess create_model() called ==================================
2024-05-27 14:11:52,382:INFO:Initializing create_model()
2024-05-27 14:11:52,382:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025DA9CCC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 14:11:52,382:INFO:Checking exceptions
2024-05-27 14:11:52,382:INFO:Importing libraries
2024-05-27 14:11:52,383:INFO:Copying training dataset
2024-05-27 14:11:52,424:INFO:Defining folds
2024-05-27 14:11:52,425:INFO:Declaring metric variables
2024-05-27 14:11:52,430:INFO:Importing untrained model
2024-05-27 14:11:52,436:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 14:11:52,445:INFO:Starting cross validation
2024-05-27 14:11:52,449:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 14:11:58,442:INFO:Calculating mean and std
2024-05-27 14:11:58,444:INFO:Creating metrics dataframe
2024-05-27 14:11:58,448:INFO:Uploading results into container
2024-05-27 14:11:58,450:INFO:Uploading model into container now
2024-05-27 14:11:58,451:INFO:_master_model_container: 14
2024-05-27 14:11:58,451:INFO:_display_container: 2
2024-05-27 14:11:58,452:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2990, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-27 14:11:58,452:INFO:create_model() successfully completed......................................
2024-05-27 14:11:59,193:INFO:SubProcess create_model() end ==================================
2024-05-27 14:11:59,193:INFO:Creating metrics dataframe
2024-05-27 14:11:59,209:INFO:Initializing Dummy Classifier
2024-05-27 14:11:59,210:INFO:Total runtime is 3.183709291617076 minutes
2024-05-27 14:11:59,215:INFO:SubProcess create_model() called ==================================
2024-05-27 14:11:59,215:INFO:Initializing create_model()
2024-05-27 14:11:59,215:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025DA9CCC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 14:11:59,215:INFO:Checking exceptions
2024-05-27 14:11:59,216:INFO:Importing libraries
2024-05-27 14:11:59,216:INFO:Copying training dataset
2024-05-27 14:11:59,259:INFO:Defining folds
2024-05-27 14:11:59,259:INFO:Declaring metric variables
2024-05-27 14:11:59,264:INFO:Importing untrained model
2024-05-27 14:11:59,269:INFO:Dummy Classifier Imported successfully
2024-05-27 14:11:59,277:INFO:Starting cross validation
2024-05-27 14:11:59,283:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 14:12:02,431:INFO:Calculating mean and std
2024-05-27 14:12:02,433:INFO:Creating metrics dataframe
2024-05-27 14:12:02,436:INFO:Uploading results into container
2024-05-27 14:12:02,436:INFO:Uploading model into container now
2024-05-27 14:12:02,436:INFO:_master_model_container: 15
2024-05-27 14:12:02,436:INFO:_display_container: 2
2024-05-27 14:12:02,437:INFO:DummyClassifier(constant=None, random_state=2990, strategy='prior')
2024-05-27 14:12:02,437:INFO:create_model() successfully completed......................................
2024-05-27 14:12:03,175:INFO:SubProcess create_model() end ==================================
2024-05-27 14:12:03,175:INFO:Creating metrics dataframe
2024-05-27 14:12:03,195:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-27 14:12:03,208:INFO:Initializing create_model()
2024-05-27 14:12:03,208:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 14:12:03,208:INFO:Checking exceptions
2024-05-27 14:12:03,210:INFO:Importing libraries
2024-05-27 14:12:03,211:INFO:Copying training dataset
2024-05-27 14:12:03,253:INFO:Defining folds
2024-05-27 14:12:03,253:INFO:Declaring metric variables
2024-05-27 14:12:03,253:INFO:Importing untrained model
2024-05-27 14:12:03,254:INFO:Declaring custom model
2024-05-27 14:12:03,256:INFO:Extreme Gradient Boosting Imported successfully
2024-05-27 14:12:03,260:INFO:Cross validation set to False
2024-05-27 14:12:03,260:INFO:Fitting Model
2024-05-27 14:12:05,348:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-27 14:12:05,348:INFO:create_model() successfully completed......................................
2024-05-27 14:12:06,088:INFO:Creating Dashboard logs
2024-05-27 14:12:06,094:INFO:Model: Extreme Gradient Boosting
2024-05-27 14:12:06,182:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 2990, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2024-05-27 14:12:06,459:INFO:Initializing predict_model()
2024-05-27 14:12:06,459:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025DAC9CE680>)
2024-05-27 14:12:06,459:INFO:Checking exceptions
2024-05-27 14:12:06,459:INFO:Preloading libraries
2024-05-27 14:12:07,541:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2024-05-27 14:12:10,230:INFO:Creating Dashboard logs
2024-05-27 14:12:10,235:INFO:Model: Light Gradient Boosting Machine
2024-05-27 14:12:10,312:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 2990, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-05-27 14:12:11,370:INFO:Creating Dashboard logs
2024-05-27 14:12:11,375:INFO:Model: Gradient Boosting Classifier
2024-05-27 14:12:11,452:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 2990, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-27 14:12:12,547:INFO:Creating Dashboard logs
2024-05-27 14:12:12,552:INFO:Model: Random Forest Classifier
2024-05-27 14:12:12,627:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 2990, 'verbose': 0, 'warm_start': False}
2024-05-27 14:12:13,678:INFO:Creating Dashboard logs
2024-05-27 14:12:13,683:INFO:Model: Extra Trees Classifier
2024-05-27 14:12:13,759:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 2990, 'verbose': 0, 'warm_start': False}
2024-05-27 14:12:14,803:INFO:Creating Dashboard logs
2024-05-27 14:12:14,807:INFO:Model: Ada Boost Classifier
2024-05-27 14:12:14,883:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 2990}
2024-05-27 14:12:15,910:INFO:Creating Dashboard logs
2024-05-27 14:12:15,915:INFO:Model: Ridge Classifier
2024-05-27 14:12:15,992:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 2990, 'solver': 'auto', 'tol': 0.0001}
2024-05-27 14:12:17,058:INFO:Creating Dashboard logs
2024-05-27 14:12:17,063:INFO:Model: Linear Discriminant Analysis
2024-05-27 14:12:17,138:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-05-27 14:12:18,181:INFO:Creating Dashboard logs
2024-05-27 14:12:18,185:INFO:Model: Decision Tree Classifier
2024-05-27 14:12:18,260:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 2990, 'splitter': 'best'}
2024-05-27 14:12:19,284:INFO:Creating Dashboard logs
2024-05-27 14:12:19,288:INFO:Model: K Neighbors Classifier
2024-05-27 14:12:19,364:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2024-05-27 14:12:20,368:INFO:Creating Dashboard logs
2024-05-27 14:12:20,373:INFO:Model: Logistic Regression
2024-05-27 14:12:20,448:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 2990, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-05-27 14:12:21,497:INFO:Creating Dashboard logs
2024-05-27 14:12:21,502:INFO:Model: Quadratic Discriminant Analysis
2024-05-27 14:12:21,577:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2024-05-27 14:12:22,668:INFO:Creating Dashboard logs
2024-05-27 14:12:22,672:INFO:Model: Dummy Classifier
2024-05-27 14:12:22,748:INFO:Logged params: {'constant': None, 'random_state': 2990, 'strategy': 'prior'}
2024-05-27 14:12:23,757:INFO:Creating Dashboard logs
2024-05-27 14:12:23,761:INFO:Model: SVM - Linear Kernel
2024-05-27 14:12:23,837:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 2990, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-27 14:12:24,884:INFO:Creating Dashboard logs
2024-05-27 14:12:24,889:INFO:Model: Naive Bayes
2024-05-27 14:12:24,962:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-05-27 14:12:25,974:INFO:_master_model_container: 15
2024-05-27 14:12:25,975:INFO:_display_container: 2
2024-05-27 14:12:25,976:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-27 14:12:25,976:INFO:compare_models() successfully completed......................................
2024-05-27 14:12:26,067:INFO:Initializing finalize_model()
2024-05-27 14:12:26,067:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-05-27 14:12:26,068:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-27 14:12:26,086:INFO:Initializing create_model()
2024-05-27 14:12:26,086:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 14:12:26,086:INFO:Checking exceptions
2024-05-27 14:12:26,089:INFO:Importing libraries
2024-05-27 14:12:26,089:INFO:Copying training dataset
2024-05-27 14:12:26,092:INFO:Defining folds
2024-05-27 14:12:26,092:INFO:Declaring metric variables
2024-05-27 14:12:26,092:INFO:Importing untrained model
2024-05-27 14:12:26,092:INFO:Declaring custom model
2024-05-27 14:12:26,094:INFO:Extreme Gradient Boosting Imported successfully
2024-05-27 14:12:26,099:INFO:Cross validation set to False
2024-05-27 14:12:26,099:INFO:Fitting Model
2024-05-27 14:12:28,496:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transf...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2024-05-27 14:12:28,496:INFO:create_model() successfully completed......................................
2024-05-27 14:12:29,193:INFO:Creating Dashboard logs
2024-05-27 14:12:29,195:INFO:Model: Extreme Gradient Boosting
2024-05-27 14:12:29,271:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 2990, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2024-05-27 14:12:30,359:INFO:_master_model_container: 15
2024-05-27 14:12:30,359:INFO:_display_container: 2
2024-05-27 14:12:30,392:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transf...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2024-05-27 14:12:30,392:INFO:finalize_model() successfully completed......................................
2024-05-27 14:12:31,294:INFO:Initializing evaluate_model()
2024-05-27 14:12:31,294:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-27 14:12:31,331:INFO:Initializing plot_model()
2024-05-27 14:12:31,332:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, system=True)
2024-05-27 14:12:31,332:INFO:Checking exceptions
2024-05-27 14:12:31,349:INFO:Preloading libraries
2024-05-27 14:12:31,358:INFO:Copying training dataset
2024-05-27 14:12:31,358:INFO:Plot type: pipeline
2024-05-27 14:12:31,905:INFO:Visual Rendered Successfully
2024-05-27 14:12:32,614:INFO:plot_model() successfully completed......................................
2024-05-27 14:15:28,501:INFO:Initializing plot_model()
2024-05-27 14:15:28,501:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, system=True)
2024-05-27 14:15:28,502:INFO:Checking exceptions
2024-05-27 14:15:28,519:INFO:Preloading libraries
2024-05-27 14:15:28,526:INFO:Copying training dataset
2024-05-27 14:15:28,527:INFO:Plot type: threshold
2024-05-27 14:15:28,942:INFO:Fitting Model
2024-05-27 14:16:28,639:INFO:Scoring test/hold-out set
2024-05-27 14:16:29,326:INFO:Visual Rendered Successfully
2024-05-27 14:16:30,028:INFO:plot_model() successfully completed......................................
2024-05-27 14:16:30,218:INFO:Initializing plot_model()
2024-05-27 14:16:30,218:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, system=True)
2024-05-27 14:16:30,219:INFO:Checking exceptions
2024-05-27 14:16:30,238:INFO:Preloading libraries
2024-05-27 14:16:30,246:INFO:Copying training dataset
2024-05-27 14:16:30,246:INFO:Plot type: auc
2024-05-27 14:16:30,685:INFO:Fitting Model
2024-05-27 14:16:30,688:INFO:Scoring test/hold-out set
2024-05-27 14:16:31,122:INFO:Visual Rendered Successfully
2024-05-27 14:16:31,827:INFO:plot_model() successfully completed......................................
2024-05-27 14:16:38,883:INFO:Initializing plot_model()
2024-05-27 14:16:38,883:INFO:plot_model(plot=rfe, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, system=True)
2024-05-27 14:16:38,884:INFO:Checking exceptions
2024-05-27 14:16:38,901:INFO:Preloading libraries
2024-05-27 14:16:38,909:INFO:Copying training dataset
2024-05-27 14:16:38,909:INFO:Plot type: rfe
2024-05-27 14:16:39,389:INFO:Fitting Model
2024-05-27 14:28:18,028:WARNING:Exception ignored on calling ctypes callback function: <bound method DataIter._next_wrapper of <xgboost.data.SingleBatchInternalIter object at 0x0000025DB0B4F790>>
2024-05-27 14:28:18,029:WARNING:Traceback (most recent call last):
2024-05-27 14:28:18,029:WARNING:  File "c:\Users\Adm\.conda\envs\python310\lib\site-packages\xgboost\core.py", line 589, in _next_wrapper
2024-05-27 14:28:18,030:WARNING:    def _next_wrapper(self, this: None) -> int:  # pylint: disable=unused-argument
2024-05-27 14:28:18,030:WARNING:KeyboardInterrupt: 
2024-05-27 14:28:42,309:INFO:Initializing evaluate_model()
2024-05-27 14:28:42,310:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-27 14:28:42,353:INFO:Initializing plot_model()
2024-05-27 14:28:42,353:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, system=True)
2024-05-27 14:28:42,354:INFO:Checking exceptions
2024-05-27 14:28:42,382:INFO:Preloading libraries
2024-05-27 14:28:42,390:INFO:Copying training dataset
2024-05-27 14:28:42,390:INFO:Plot type: pipeline
2024-05-27 14:28:42,705:INFO:Visual Rendered Successfully
2024-05-27 14:28:43,514:INFO:plot_model() successfully completed......................................
2024-05-27 14:28:43,529:INFO:Initializing evaluate_model()
2024-05-27 14:28:43,529:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-27 14:28:43,559:INFO:Initializing plot_model()
2024-05-27 14:28:43,560:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, system=True)
2024-05-27 14:28:43,560:INFO:Checking exceptions
2024-05-27 14:28:43,578:INFO:Preloading libraries
2024-05-27 14:28:43,586:INFO:Copying training dataset
2024-05-27 14:28:43,586:INFO:Plot type: pipeline
2024-05-27 14:28:43,889:INFO:Visual Rendered Successfully
2024-05-27 14:28:44,793:INFO:plot_model() successfully completed......................................
2024-05-27 14:28:46,193:INFO:Initializing evaluate_model()
2024-05-27 14:28:46,194:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-27 14:28:46,223:INFO:Initializing plot_model()
2024-05-27 14:28:46,224:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, system=True)
2024-05-27 14:28:46,224:INFO:Checking exceptions
2024-05-27 14:28:46,242:INFO:Preloading libraries
2024-05-27 14:28:46,250:INFO:Copying training dataset
2024-05-27 14:28:46,250:INFO:Plot type: pipeline
2024-05-27 14:28:46,553:INFO:Visual Rendered Successfully
2024-05-27 14:28:47,312:INFO:plot_model() successfully completed......................................
2024-05-27 14:28:51,540:INFO:Initializing plot_model()
2024-05-27 14:28:51,540:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, system=True)
2024-05-27 14:28:51,541:INFO:Checking exceptions
2024-05-27 14:28:51,557:INFO:Preloading libraries
2024-05-27 14:28:51,565:INFO:Copying training dataset
2024-05-27 14:28:51,566:INFO:Plot type: parameter
2024-05-27 14:28:51,575:INFO:Visual Rendered Successfully
2024-05-27 14:28:52,350:INFO:plot_model() successfully completed......................................
2024-05-27 14:28:57,094:INFO:Initializing plot_model()
2024-05-27 14:28:57,094:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, system=True)
2024-05-27 14:28:57,095:INFO:Checking exceptions
2024-05-27 14:28:57,112:INFO:Preloading libraries
2024-05-27 14:28:57,120:INFO:Copying training dataset
2024-05-27 14:28:57,120:INFO:Plot type: auc
2024-05-27 14:28:57,558:INFO:Fitting Model
2024-05-27 14:28:57,562:INFO:Scoring test/hold-out set
2024-05-27 14:28:58,013:INFO:Visual Rendered Successfully
2024-05-27 14:28:58,766:INFO:plot_model() successfully completed......................................
2024-05-27 14:29:02,177:INFO:Initializing plot_model()
2024-05-27 14:29:02,177:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, system=True)
2024-05-27 14:29:02,177:INFO:Checking exceptions
2024-05-27 14:29:02,195:INFO:Preloading libraries
2024-05-27 14:29:02,202:INFO:Copying training dataset
2024-05-27 14:29:02,203:INFO:Plot type: confusion_matrix
2024-05-27 14:29:02,659:INFO:Fitting Model
2024-05-27 14:29:02,662:INFO:Scoring test/hold-out set
2024-05-27 14:29:02,969:INFO:Visual Rendered Successfully
2024-05-27 14:29:03,701:INFO:plot_model() successfully completed......................................
2024-05-27 14:29:05,550:INFO:Initializing plot_model()
2024-05-27 14:29:05,550:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, system=True)
2024-05-27 14:29:05,550:INFO:Checking exceptions
2024-05-27 14:29:05,567:INFO:Preloading libraries
2024-05-27 14:29:05,575:INFO:Copying training dataset
2024-05-27 14:29:05,575:INFO:Plot type: threshold
2024-05-27 14:29:06,003:INFO:Fitting Model
2024-05-27 14:29:50,804:INFO:Initializing evaluate_model()
2024-05-27 14:29:50,804:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-27 14:29:50,834:INFO:Initializing plot_model()
2024-05-27 14:29:50,834:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, system=True)
2024-05-27 14:29:50,835:INFO:Checking exceptions
2024-05-27 14:29:50,853:INFO:Preloading libraries
2024-05-27 14:29:50,861:INFO:Copying training dataset
2024-05-27 14:29:50,862:INFO:Plot type: pipeline
2024-05-27 14:29:51,142:INFO:Visual Rendered Successfully
2024-05-27 14:29:51,953:INFO:plot_model() successfully completed......................................
2024-05-27 14:29:51,970:INFO:Initializing plot_model()
2024-05-27 14:29:51,970:INFO:plot_model(plot=error, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, system=True)
2024-05-27 14:29:51,970:INFO:Checking exceptions
2024-05-27 14:29:51,987:INFO:Preloading libraries
2024-05-27 14:29:51,994:INFO:Copying training dataset
2024-05-27 14:29:51,994:INFO:Plot type: error
2024-05-27 14:29:52,452:INFO:Fitting Model
2024-05-27 14:29:52,454:INFO:Scoring test/hold-out set
2024-05-27 14:29:52,884:INFO:Visual Rendered Successfully
2024-05-27 14:29:53,611:INFO:plot_model() successfully completed......................................
2024-05-27 14:29:55,077:INFO:Initializing plot_model()
2024-05-27 14:29:55,077:INFO:plot_model(plot=rfe, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, system=True)
2024-05-27 14:29:55,077:INFO:Checking exceptions
2024-05-27 14:29:55,103:INFO:Preloading libraries
2024-05-27 14:29:55,112:INFO:Copying training dataset
2024-05-27 14:29:55,113:INFO:Plot type: rfe
2024-05-27 14:29:55,588:INFO:Fitting Model
2024-05-27 14:44:19,396:INFO:Initializing finalize_model()
2024-05-27 14:44:19,396:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-05-27 14:44:19,398:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-27 14:44:19,420:INFO:Initializing create_model()
2024-05-27 14:44:19,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D4BFFE7A0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 14:44:19,420:INFO:Checking exceptions
2024-05-27 14:44:19,423:INFO:Importing libraries
2024-05-27 14:44:19,423:INFO:Copying training dataset
2024-05-27 14:44:19,427:INFO:Defining folds
2024-05-27 14:44:19,427:INFO:Declaring metric variables
2024-05-27 14:44:19,427:INFO:Importing untrained model
2024-05-27 14:44:19,428:INFO:Declaring custom model
2024-05-27 14:44:19,430:INFO:Extreme Gradient Boosting Imported successfully
2024-05-27 14:44:19,434:INFO:Cross validation set to False
2024-05-27 14:44:19,434:INFO:Fitting Model
2024-05-27 14:44:22,075:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transf...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2024-05-27 14:44:22,075:INFO:create_model() successfully completed......................................
2024-05-27 14:44:22,905:INFO:Creating Dashboard logs
2024-05-27 14:44:22,907:INFO:Model: Extreme Gradient Boosting
2024-05-27 14:44:22,994:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 2990, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2024-05-27 14:44:24,141:INFO:_master_model_container: 15
2024-05-27 14:44:24,141:INFO:_display_container: 2
2024-05-27 14:44:24,175:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transf...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2024-05-27 14:44:24,176:INFO:finalize_model() successfully completed......................................
2024-05-27 15:40:09,553:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 15:40:09,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 15:40:09,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 15:40:09,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 15:56:47,395:INFO:PyCaret ClassificationExperiment
2024-05-27 15:56:47,395:INFO:Logging name: no_onehot
2024-05-27 15:56:47,395:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-27 15:56:47,395:INFO:version 3.3.2
2024-05-27 15:56:47,395:INFO:Initializing setup()
2024-05-27 15:56:47,396:INFO:self.USI: 4a2c
2024-05-27 15:56:47,396:INFO:self._variable_keys: {'X_train', 'data', 'html_param', '_ml_usecase', 'is_multiclass', 'memory', 'fold_shuffle_param', 'fix_imbalance', 'target_param', 'n_jobs_param', 'exp_id', 'X', 'fold_generator', 'exp_name_log', 'gpu_param', 'fold_groups_param', 'X_test', 'pipeline', 'USI', 'log_plots_param', 'seed', 'idx', 'y_test', 'gpu_n_jobs_param', 'y_train', 'logging_param', 'y', '_available_plots'}
2024-05-27 15:56:47,396:INFO:Checking environment
2024-05-27 15:56:47,396:INFO:python_version: 3.10.13
2024-05-27 15:56:47,396:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-27 15:56:47,396:INFO:machine: AMD64
2024-05-27 15:56:47,396:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-27 15:56:47,396:INFO:Memory: svmem(total=34267656192, available=23512268800, percent=31.4, used=10755387392, free=23512268800)
2024-05-27 15:56:47,396:INFO:Physical Core: 8
2024-05-27 15:56:47,396:INFO:Logical Core: 16
2024-05-27 15:56:47,396:INFO:Checking libraries
2024-05-27 15:56:47,397:INFO:System:
2024-05-27 15:56:47,397:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-27 15:56:47,397:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-27 15:56:47,397:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-27 15:56:47,397:INFO:PyCaret required dependencies:
2024-05-27 15:56:47,438:INFO:                 pip: 23.3
2024-05-27 15:56:47,438:INFO:          setuptools: 68.0.0
2024-05-27 15:56:47,438:INFO:             pycaret: 3.3.2
2024-05-27 15:56:47,438:INFO:             IPython: 8.24.0
2024-05-27 15:56:47,438:INFO:          ipywidgets: 8.1.2
2024-05-27 15:56:47,438:INFO:                tqdm: 4.66.4
2024-05-27 15:56:47,438:INFO:               numpy: 1.26.4
2024-05-27 15:56:47,439:INFO:              pandas: 2.1.4
2024-05-27 15:56:47,439:INFO:              jinja2: 3.1.4
2024-05-27 15:56:47,439:INFO:               scipy: 1.11.4
2024-05-27 15:56:47,439:INFO:              joblib: 1.3.2
2024-05-27 15:56:47,439:INFO:             sklearn: 1.4.2
2024-05-27 15:56:47,439:INFO:                pyod: 1.1.3
2024-05-27 15:56:47,439:INFO:            imblearn: 0.12.2
2024-05-27 15:56:47,439:INFO:   category_encoders: 2.6.3
2024-05-27 15:56:47,439:INFO:            lightgbm: 4.3.0
2024-05-27 15:56:47,439:INFO:               numba: 0.59.1
2024-05-27 15:56:47,440:INFO:            requests: 2.32.2
2024-05-27 15:56:47,440:INFO:          matplotlib: 3.7.5
2024-05-27 15:56:47,440:INFO:          scikitplot: 0.3.7
2024-05-27 15:56:47,440:INFO:         yellowbrick: 1.5
2024-05-27 15:56:47,440:INFO:              plotly: 5.22.0
2024-05-27 15:56:47,440:INFO:    plotly-resampler: Not installed
2024-05-27 15:56:47,440:INFO:             kaleido: 0.2.1
2024-05-27 15:56:47,440:INFO:           schemdraw: 0.15
2024-05-27 15:56:47,441:INFO:         statsmodels: 0.14.2
2024-05-27 15:56:47,441:INFO:              sktime: 0.26.0
2024-05-27 15:56:47,441:INFO:               tbats: 1.1.3
2024-05-27 15:56:47,441:INFO:            pmdarima: 2.0.4
2024-05-27 15:56:47,441:INFO:              psutil: 5.9.0
2024-05-27 15:56:47,441:INFO:          markupsafe: 2.1.5
2024-05-27 15:56:47,441:INFO:             pickle5: Not installed
2024-05-27 15:56:47,441:INFO:         cloudpickle: 3.0.0
2024-05-27 15:56:47,441:INFO:         deprecation: 2.1.0
2024-05-27 15:56:47,442:INFO:              xxhash: 3.4.1
2024-05-27 15:56:47,442:INFO:           wurlitzer: Not installed
2024-05-27 15:56:47,442:INFO:PyCaret optional dependencies:
2024-05-27 15:56:47,511:INFO:                shap: Not installed
2024-05-27 15:56:47,511:INFO:           interpret: Not installed
2024-05-27 15:56:47,511:INFO:                umap: Not installed
2024-05-27 15:56:47,512:INFO:     ydata_profiling: Not installed
2024-05-27 15:56:47,512:INFO:  explainerdashboard: Not installed
2024-05-27 15:56:47,512:INFO:             autoviz: Not installed
2024-05-27 15:56:47,512:INFO:           fairlearn: Not installed
2024-05-27 15:56:47,512:INFO:          deepchecks: Not installed
2024-05-27 15:56:47,512:INFO:             xgboost: 2.0.3
2024-05-27 15:56:47,512:INFO:            catboost: Not installed
2024-05-27 15:56:47,512:INFO:              kmodes: Not installed
2024-05-27 15:56:47,512:INFO:             mlxtend: Not installed
2024-05-27 15:56:47,512:INFO:       statsforecast: Not installed
2024-05-27 15:56:47,512:INFO:        tune_sklearn: Not installed
2024-05-27 15:56:47,512:INFO:                 ray: Not installed
2024-05-27 15:56:47,513:INFO:            hyperopt: Not installed
2024-05-27 15:56:47,513:INFO:              optuna: Not installed
2024-05-27 15:56:47,513:INFO:               skopt: Not installed
2024-05-27 15:56:47,513:INFO:              mlflow: 2.13.0
2024-05-27 15:56:47,513:INFO:              gradio: Not installed
2024-05-27 15:56:47,513:INFO:             fastapi: Not installed
2024-05-27 15:56:47,513:INFO:             uvicorn: Not installed
2024-05-27 15:56:47,513:INFO:              m2cgen: Not installed
2024-05-27 15:56:47,513:INFO:           evidently: Not installed
2024-05-27 15:56:47,513:INFO:               fugue: Not installed
2024-05-27 15:56:47,513:INFO:           streamlit: Not installed
2024-05-27 15:56:47,513:INFO:             prophet: Not installed
2024-05-27 15:56:47,513:INFO:None
2024-05-27 15:56:47,514:INFO:Set up data.
2024-05-27 15:56:47,891:INFO:Set up folding strategy.
2024-05-27 15:56:47,891:INFO:Set up train/test split.
2024-05-27 15:56:47,949:INFO:Set up index.
2024-05-27 15:56:47,951:INFO:Assigning column types.
2024-05-27 15:56:47,972:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-27 15:56:48,044:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 15:56:48,050:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 15:56:48,103:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 15:56:48,107:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 15:56:48,179:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-27 15:56:48,180:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 15:56:48,227:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 15:56:48,231:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 15:56:48,231:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-27 15:56:48,303:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 15:56:48,348:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 15:56:48,353:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 15:56:48,429:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-27 15:56:48,475:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 15:56:48,479:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 15:56:48,480:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-27 15:56:48,597:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 15:56:48,601:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 15:56:48,718:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 15:56:48,722:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 15:56:48,726:INFO:Preparing preprocessing pipeline...
2024-05-27 15:56:48,730:INFO:Set up simple imputation.
2024-05-27 15:56:48,755:INFO:Set up encoding of ordinal features.
2024-05-27 15:56:48,763:INFO:Set up encoding of categorical features.
2024-05-27 15:56:48,766:INFO:Set up column name cleaning.
2024-05-27 15:56:51,119:INFO:Finished creating preprocessing pipeline.
2024-05-27 15:56:51,149:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id',
                                                                    'seller_address.city.name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-05-27 15:56:51,149:INFO:Creating final display dataframe.
2024-05-27 15:56:52,764:INFO:Setup _display_container:                     Description            Value
0                    Session id              408
1                        Target        condition
2                   Target type           Binary
3           Original data shape     (100000, 19)
4        Transformed data shape     (100000, 57)
5   Transformed train set shape      (90000, 57)
6    Transformed test set shape      (10000, 57)
7              Numeric features                5
8          Categorical features                9
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Fold Generator  StratifiedKFold
16                  Fold Number               10
17                     CPU Jobs               -1
18                      Use GPU            False
19               Log Experiment     MlflowLogger
20              Experiment Name        no_onehot
21                          USI             4a2c
2024-05-27 15:56:52,892:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 15:56:52,896:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 15:56:53,015:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-27 15:56:53,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-27 15:56:53,022:INFO:Logging experiment in loggers
2024-05-27 15:56:53,426:INFO:SubProcess save_model() called ==================================
2024-05-27 15:56:53,481:INFO:Initializing save_model()
2024-05-27 15:56:53,482:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id',
                                                                    'seller_address.city.name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\Adm\AppData\Local\Temp\tmpegtefb5w\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id',
                                                                    'seller_address.city.name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-27 15:56:53,482:INFO:Adding model into prep_pipe
2024-05-27 15:56:53,482:WARNING:Only Model saved as it was a pipeline.
2024-05-27 15:56:53,515:INFO:C:\Users\Adm\AppData\Local\Temp\tmpegtefb5w\Transformation Pipeline.pkl saved in current working directory
2024-05-27 15:56:53,542:INFO:Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                    transformer=TargetEncoder(cols=['seller_id',
                                                                    'category_id',
                                                                    'seller_address.city.name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-05-27 15:56:53,542:INFO:save_model() successfully completed......................................
2024-05-27 15:56:54,245:INFO:SubProcess save_model() end ==================================
2024-05-27 15:56:54,268:INFO:setup() successfully completed in 5.65s...............
2024-05-27 15:56:54,278:INFO:Initializing compare_models()
2024-05-27 15:56:54,278:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-27 15:56:54,278:INFO:Checking exceptions
2024-05-27 15:56:54,313:INFO:Preparing display monitor
2024-05-27 15:56:54,352:INFO:Initializing Logistic Regression
2024-05-27 15:56:54,352:INFO:Total runtime is 0.0 minutes
2024-05-27 15:56:54,357:INFO:SubProcess create_model() called ==================================
2024-05-27 15:56:54,358:INFO:Initializing create_model()
2024-05-27 15:56:54,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000239A8379180>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 15:56:54,358:INFO:Checking exceptions
2024-05-27 15:56:54,359:INFO:Importing libraries
2024-05-27 15:56:54,359:INFO:Copying training dataset
2024-05-27 15:56:54,407:INFO:Defining folds
2024-05-27 15:56:54,407:INFO:Declaring metric variables
2024-05-27 15:56:54,412:INFO:Importing untrained model
2024-05-27 15:56:54,417:INFO:Logistic Regression Imported successfully
2024-05-27 15:56:54,427:INFO:Starting cross validation
2024-05-27 15:56:54,432:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 15:57:17,643:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-27 15:57:17,823:INFO:Calculating mean and std
2024-05-27 15:57:17,825:INFO:Creating metrics dataframe
2024-05-27 15:57:17,829:INFO:Uploading results into container
2024-05-27 15:57:17,829:INFO:Uploading model into container now
2024-05-27 15:57:17,830:INFO:_master_model_container: 1
2024-05-27 15:57:17,830:INFO:_display_container: 2
2024-05-27 15:57:17,831:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=408, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-27 15:57:17,831:INFO:create_model() successfully completed......................................
2024-05-27 15:57:18,597:INFO:SubProcess create_model() end ==================================
2024-05-27 15:57:18,598:INFO:Creating metrics dataframe
2024-05-27 15:57:18,607:INFO:Initializing K Neighbors Classifier
2024-05-27 15:57:18,607:INFO:Total runtime is 0.4042500774065653 minutes
2024-05-27 15:57:18,611:INFO:SubProcess create_model() called ==================================
2024-05-27 15:57:18,612:INFO:Initializing create_model()
2024-05-27 15:57:18,612:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000239A8379180>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 15:57:18,613:INFO:Checking exceptions
2024-05-27 15:57:18,613:INFO:Importing libraries
2024-05-27 15:57:18,613:INFO:Copying training dataset
2024-05-27 15:57:18,654:INFO:Defining folds
2024-05-27 15:57:18,655:INFO:Declaring metric variables
2024-05-27 15:57:18,659:INFO:Importing untrained model
2024-05-27 15:57:18,664:INFO:K Neighbors Classifier Imported successfully
2024-05-27 15:57:18,672:INFO:Starting cross validation
2024-05-27 15:57:18,677:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 15:57:45,558:INFO:Calculating mean and std
2024-05-27 15:57:45,560:INFO:Creating metrics dataframe
2024-05-27 15:57:45,562:INFO:Uploading results into container
2024-05-27 15:57:45,563:INFO:Uploading model into container now
2024-05-27 15:57:45,564:INFO:_master_model_container: 2
2024-05-27 15:57:45,564:INFO:_display_container: 2
2024-05-27 15:57:45,565:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-27 15:57:45,565:INFO:create_model() successfully completed......................................
2024-05-27 15:57:46,273:INFO:SubProcess create_model() end ==================================
2024-05-27 15:57:46,273:INFO:Creating metrics dataframe
2024-05-27 15:57:46,283:INFO:Initializing Naive Bayes
2024-05-27 15:57:46,283:INFO:Total runtime is 0.8655296127001444 minutes
2024-05-27 15:57:46,287:INFO:SubProcess create_model() called ==================================
2024-05-27 15:57:46,287:INFO:Initializing create_model()
2024-05-27 15:57:46,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000239A8379180>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 15:57:46,288:INFO:Checking exceptions
2024-05-27 15:57:46,288:INFO:Importing libraries
2024-05-27 15:57:46,288:INFO:Copying training dataset
2024-05-27 15:57:46,329:INFO:Defining folds
2024-05-27 15:57:46,329:INFO:Declaring metric variables
2024-05-27 15:57:46,334:INFO:Importing untrained model
2024-05-27 15:57:46,338:INFO:Naive Bayes Imported successfully
2024-05-27 15:57:46,347:INFO:Starting cross validation
2024-05-27 15:57:46,352:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 15:57:49,937:INFO:Calculating mean and std
2024-05-27 15:57:49,940:INFO:Creating metrics dataframe
2024-05-27 15:57:49,944:INFO:Uploading results into container
2024-05-27 15:57:49,945:INFO:Uploading model into container now
2024-05-27 15:57:49,946:INFO:_master_model_container: 3
2024-05-27 15:57:49,947:INFO:_display_container: 2
2024-05-27 15:57:49,947:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-27 15:57:49,948:INFO:create_model() successfully completed......................................
2024-05-27 15:57:50,837:INFO:SubProcess create_model() end ==================================
2024-05-27 15:57:50,837:INFO:Creating metrics dataframe
2024-05-27 15:57:50,848:INFO:Initializing Decision Tree Classifier
2024-05-27 15:57:50,848:INFO:Total runtime is 0.941603934764862 minutes
2024-05-27 15:57:50,853:INFO:SubProcess create_model() called ==================================
2024-05-27 15:57:50,853:INFO:Initializing create_model()
2024-05-27 15:57:50,853:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000239A8379180>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 15:57:50,854:INFO:Checking exceptions
2024-05-27 15:57:50,854:INFO:Importing libraries
2024-05-27 15:57:50,854:INFO:Copying training dataset
2024-05-27 15:57:50,896:INFO:Defining folds
2024-05-27 15:57:50,896:INFO:Declaring metric variables
2024-05-27 15:57:50,901:INFO:Importing untrained model
2024-05-27 15:57:50,906:INFO:Decision Tree Classifier Imported successfully
2024-05-27 15:57:50,916:INFO:Starting cross validation
2024-05-27 15:57:50,921:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 15:57:55,487:INFO:Calculating mean and std
2024-05-27 15:57:55,488:INFO:Creating metrics dataframe
2024-05-27 15:57:55,491:INFO:Uploading results into container
2024-05-27 15:57:55,492:INFO:Uploading model into container now
2024-05-27 15:57:55,493:INFO:_master_model_container: 4
2024-05-27 15:57:55,493:INFO:_display_container: 2
2024-05-27 15:57:55,494:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=408, splitter='best')
2024-05-27 15:57:55,494:INFO:create_model() successfully completed......................................
2024-05-27 15:57:56,243:INFO:SubProcess create_model() end ==================================
2024-05-27 15:57:56,244:INFO:Creating metrics dataframe
2024-05-27 15:57:56,254:INFO:Initializing SVM - Linear Kernel
2024-05-27 15:57:56,255:INFO:Total runtime is 1.0317294438680014 minutes
2024-05-27 15:57:56,259:INFO:SubProcess create_model() called ==================================
2024-05-27 15:57:56,260:INFO:Initializing create_model()
2024-05-27 15:57:56,260:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000239A8379180>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 15:57:56,260:INFO:Checking exceptions
2024-05-27 15:57:56,261:INFO:Importing libraries
2024-05-27 15:57:56,261:INFO:Copying training dataset
2024-05-27 15:57:56,302:INFO:Defining folds
2024-05-27 15:57:56,302:INFO:Declaring metric variables
2024-05-27 15:57:56,307:INFO:Importing untrained model
2024-05-27 15:57:56,312:INFO:SVM - Linear Kernel Imported successfully
2024-05-27 15:57:56,321:INFO:Starting cross validation
2024-05-27 15:57:56,326:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 15:58:00,880:INFO:Calculating mean and std
2024-05-27 15:58:00,882:INFO:Creating metrics dataframe
2024-05-27 15:58:00,884:INFO:Uploading results into container
2024-05-27 15:58:00,885:INFO:Uploading model into container now
2024-05-27 15:58:00,886:INFO:_master_model_container: 5
2024-05-27 15:58:00,886:INFO:_display_container: 2
2024-05-27 15:58:00,887:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=408, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-27 15:58:00,887:INFO:create_model() successfully completed......................................
2024-05-27 15:58:01,697:INFO:SubProcess create_model() end ==================================
2024-05-27 15:58:01,697:INFO:Creating metrics dataframe
2024-05-27 15:58:01,708:INFO:Initializing Ridge Classifier
2024-05-27 15:58:01,708:INFO:Total runtime is 1.1226027727127075 minutes
2024-05-27 15:58:01,714:INFO:SubProcess create_model() called ==================================
2024-05-27 15:58:01,714:INFO:Initializing create_model()
2024-05-27 15:58:01,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000239A8379180>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 15:58:01,714:INFO:Checking exceptions
2024-05-27 15:58:01,715:INFO:Importing libraries
2024-05-27 15:58:01,715:INFO:Copying training dataset
2024-05-27 15:58:01,757:INFO:Defining folds
2024-05-27 15:58:01,757:INFO:Declaring metric variables
2024-05-27 15:58:01,763:INFO:Importing untrained model
2024-05-27 15:58:01,767:INFO:Ridge Classifier Imported successfully
2024-05-27 15:58:01,777:INFO:Starting cross validation
2024-05-27 15:58:01,783:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 15:58:04,839:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.80964e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 15:58:04,856:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.43774e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 15:58:04,875:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.80917e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 15:58:04,888:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.80956e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 15:58:04,944:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.8094e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 15:58:04,987:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.76916e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 15:58:05,032:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.81772e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 15:58:05,160:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.76943e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 15:58:05,245:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.80939e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 15:58:05,257:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.80939e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-27 15:58:05,533:INFO:Calculating mean and std
2024-05-27 15:58:05,535:INFO:Creating metrics dataframe
2024-05-27 15:58:05,538:INFO:Uploading results into container
2024-05-27 15:58:05,539:INFO:Uploading model into container now
2024-05-27 15:58:05,539:INFO:_master_model_container: 6
2024-05-27 15:58:05,540:INFO:_display_container: 2
2024-05-27 15:58:05,540:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=408, solver='auto',
                tol=0.0001)
2024-05-27 15:58:05,540:INFO:create_model() successfully completed......................................
2024-05-27 15:58:06,287:INFO:SubProcess create_model() end ==================================
2024-05-27 15:58:06,287:INFO:Creating metrics dataframe
2024-05-27 15:58:06,299:INFO:Initializing Random Forest Classifier
2024-05-27 15:58:06,300:INFO:Total runtime is 1.1991451263427735 minutes
2024-05-27 15:58:06,304:INFO:SubProcess create_model() called ==================================
2024-05-27 15:58:06,305:INFO:Initializing create_model()
2024-05-27 15:58:06,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000239A8379180>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 15:58:06,305:INFO:Checking exceptions
2024-05-27 15:58:06,305:INFO:Importing libraries
2024-05-27 15:58:06,305:INFO:Copying training dataset
2024-05-27 15:58:06,346:INFO:Defining folds
2024-05-27 15:58:06,346:INFO:Declaring metric variables
2024-05-27 15:58:06,350:INFO:Importing untrained model
2024-05-27 15:58:06,355:INFO:Random Forest Classifier Imported successfully
2024-05-27 15:58:06,364:INFO:Starting cross validation
2024-05-27 15:58:06,369:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 15:58:25,237:INFO:Calculating mean and std
2024-05-27 15:58:25,239:INFO:Creating metrics dataframe
2024-05-27 15:58:25,242:INFO:Uploading results into container
2024-05-27 15:58:25,243:INFO:Uploading model into container now
2024-05-27 15:58:25,244:INFO:_master_model_container: 7
2024-05-27 15:58:25,244:INFO:_display_container: 2
2024-05-27 15:58:25,245:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=408, verbose=0,
                       warm_start=False)
2024-05-27 15:58:25,246:INFO:create_model() successfully completed......................................
2024-05-27 15:58:26,189:INFO:SubProcess create_model() end ==================================
2024-05-27 15:58:26,189:INFO:Creating metrics dataframe
2024-05-27 15:58:26,217:INFO:Initializing Quadratic Discriminant Analysis
2024-05-27 15:58:26,218:INFO:Total runtime is 1.5311059594154357 minutes
2024-05-27 15:58:26,226:INFO:SubProcess create_model() called ==================================
2024-05-27 15:58:26,227:INFO:Initializing create_model()
2024-05-27 15:58:26,227:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000239A8379180>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 15:58:26,227:INFO:Checking exceptions
2024-05-27 15:58:26,227:INFO:Importing libraries
2024-05-27 15:58:26,228:INFO:Copying training dataset
2024-05-27 15:58:26,278:INFO:Defining folds
2024-05-27 15:58:26,278:INFO:Declaring metric variables
2024-05-27 15:58:26,284:INFO:Importing untrained model
2024-05-27 15:58:26,290:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-27 15:58:26,303:INFO:Starting cross validation
2024-05-27 15:58:26,309:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 15:58:29,876:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 15:58:30,203:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 15:58:30,286:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 15:58:30,361:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 15:58:30,369:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 15:58:30,397:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 15:58:30,465:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 15:58:30,511:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 15:58:30,565:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 15:58:30,722:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-27 15:58:32,348:INFO:Calculating mean and std
2024-05-27 15:58:32,351:INFO:Creating metrics dataframe
2024-05-27 15:58:32,355:INFO:Uploading results into container
2024-05-27 15:58:32,357:INFO:Uploading model into container now
2024-05-27 15:58:32,358:INFO:_master_model_container: 8
2024-05-27 15:58:32,358:INFO:_display_container: 2
2024-05-27 15:58:32,359:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-27 15:58:32,359:INFO:create_model() successfully completed......................................
2024-05-27 15:58:33,130:INFO:SubProcess create_model() end ==================================
2024-05-27 15:58:33,131:INFO:Creating metrics dataframe
2024-05-27 15:58:33,143:INFO:Initializing Ada Boost Classifier
2024-05-27 15:58:33,144:INFO:Total runtime is 1.6465458353360494 minutes
2024-05-27 15:58:33,149:INFO:SubProcess create_model() called ==================================
2024-05-27 15:58:33,149:INFO:Initializing create_model()
2024-05-27 15:58:33,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000239A8379180>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 15:58:33,149:INFO:Checking exceptions
2024-05-27 15:58:33,150:INFO:Importing libraries
2024-05-27 15:58:33,150:INFO:Copying training dataset
2024-05-27 15:58:33,193:INFO:Defining folds
2024-05-27 15:58:33,193:INFO:Declaring metric variables
2024-05-27 15:58:33,198:INFO:Importing untrained model
2024-05-27 15:58:33,204:INFO:Ada Boost Classifier Imported successfully
2024-05-27 15:58:33,215:INFO:Starting cross validation
2024-05-27 15:58:33,219:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 15:58:35,909:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 15:58:35,938:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 15:58:35,940:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 15:58:36,002:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 15:58:36,064:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 15:58:36,113:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 15:58:36,197:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 15:58:36,226:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 15:58:36,318:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 15:58:36,383:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-27 15:58:45,657:INFO:Calculating mean and std
2024-05-27 15:58:45,659:INFO:Creating metrics dataframe
2024-05-27 15:58:45,662:INFO:Uploading results into container
2024-05-27 15:58:45,663:INFO:Uploading model into container now
2024-05-27 15:58:45,663:INFO:_master_model_container: 9
2024-05-27 15:58:45,663:INFO:_display_container: 2
2024-05-27 15:58:45,664:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=408)
2024-05-27 15:58:45,664:INFO:create_model() successfully completed......................................
2024-05-27 15:58:46,436:INFO:SubProcess create_model() end ==================================
2024-05-27 15:58:46,436:INFO:Creating metrics dataframe
2024-05-27 15:58:46,451:INFO:Initializing Gradient Boosting Classifier
2024-05-27 15:58:46,451:INFO:Total runtime is 1.868326731522878 minutes
2024-05-27 15:58:46,456:INFO:SubProcess create_model() called ==================================
2024-05-27 15:58:46,456:INFO:Initializing create_model()
2024-05-27 15:58:46,456:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000239A8379180>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 15:58:46,456:INFO:Checking exceptions
2024-05-27 15:58:46,456:INFO:Importing libraries
2024-05-27 15:58:46,457:INFO:Copying training dataset
2024-05-27 15:58:46,504:INFO:Defining folds
2024-05-27 15:58:46,504:INFO:Declaring metric variables
2024-05-27 15:58:46,510:INFO:Importing untrained model
2024-05-27 15:58:46,516:INFO:Gradient Boosting Classifier Imported successfully
2024-05-27 15:58:46,526:INFO:Starting cross validation
2024-05-27 15:58:46,531:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 15:59:12,012:INFO:Calculating mean and std
2024-05-27 15:59:12,015:INFO:Creating metrics dataframe
2024-05-27 15:59:12,019:INFO:Uploading results into container
2024-05-27 15:59:12,020:INFO:Uploading model into container now
2024-05-27 15:59:12,021:INFO:_master_model_container: 10
2024-05-27 15:59:12,021:INFO:_display_container: 2
2024-05-27 15:59:12,022:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=408, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-27 15:59:12,023:INFO:create_model() successfully completed......................................
2024-05-27 15:59:12,736:INFO:SubProcess create_model() end ==================================
2024-05-27 15:59:12,737:INFO:Creating metrics dataframe
2024-05-27 15:59:12,751:INFO:Initializing Linear Discriminant Analysis
2024-05-27 15:59:12,751:INFO:Total runtime is 2.3066583116849264 minutes
2024-05-27 15:59:12,756:INFO:SubProcess create_model() called ==================================
2024-05-27 15:59:12,756:INFO:Initializing create_model()
2024-05-27 15:59:12,756:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000239A8379180>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 15:59:12,756:INFO:Checking exceptions
2024-05-27 15:59:12,756:INFO:Importing libraries
2024-05-27 15:59:12,757:INFO:Copying training dataset
2024-05-27 15:59:12,798:INFO:Defining folds
2024-05-27 15:59:12,798:INFO:Declaring metric variables
2024-05-27 15:59:12,802:INFO:Importing untrained model
2024-05-27 15:59:12,807:INFO:Linear Discriminant Analysis Imported successfully
2024-05-27 15:59:12,816:INFO:Starting cross validation
2024-05-27 15:59:12,821:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 15:59:18,885:INFO:Calculating mean and std
2024-05-27 15:59:18,887:INFO:Creating metrics dataframe
2024-05-27 15:59:18,890:INFO:Uploading results into container
2024-05-27 15:59:18,890:INFO:Uploading model into container now
2024-05-27 15:59:18,891:INFO:_master_model_container: 11
2024-05-27 15:59:18,891:INFO:_display_container: 2
2024-05-27 15:59:18,892:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-27 15:59:18,892:INFO:create_model() successfully completed......................................
2024-05-27 15:59:19,722:INFO:SubProcess create_model() end ==================================
2024-05-27 15:59:19,722:INFO:Creating metrics dataframe
2024-05-27 15:59:19,738:INFO:Initializing Extra Trees Classifier
2024-05-27 15:59:19,738:INFO:Total runtime is 2.423106853167216 minutes
2024-05-27 15:59:19,742:INFO:SubProcess create_model() called ==================================
2024-05-27 15:59:19,743:INFO:Initializing create_model()
2024-05-27 15:59:19,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000239A8379180>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 15:59:19,743:INFO:Checking exceptions
2024-05-27 15:59:19,744:INFO:Importing libraries
2024-05-27 15:59:19,744:INFO:Copying training dataset
2024-05-27 15:59:19,787:INFO:Defining folds
2024-05-27 15:59:19,788:INFO:Declaring metric variables
2024-05-27 15:59:19,792:INFO:Importing untrained model
2024-05-27 15:59:19,798:INFO:Extra Trees Classifier Imported successfully
2024-05-27 15:59:19,807:INFO:Starting cross validation
2024-05-27 15:59:19,812:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 15:59:46,295:INFO:Calculating mean and std
2024-05-27 15:59:46,297:INFO:Creating metrics dataframe
2024-05-27 15:59:46,300:INFO:Uploading results into container
2024-05-27 15:59:46,300:INFO:Uploading model into container now
2024-05-27 15:59:46,301:INFO:_master_model_container: 12
2024-05-27 15:59:46,301:INFO:_display_container: 2
2024-05-27 15:59:46,302:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=408, verbose=0,
                     warm_start=False)
2024-05-27 15:59:46,303:INFO:create_model() successfully completed......................................
2024-05-27 15:59:47,183:INFO:SubProcess create_model() end ==================================
2024-05-27 15:59:47,183:INFO:Creating metrics dataframe
2024-05-27 15:59:47,199:INFO:Initializing Extreme Gradient Boosting
2024-05-27 15:59:47,199:INFO:Total runtime is 2.8807839830716455 minutes
2024-05-27 15:59:47,204:INFO:SubProcess create_model() called ==================================
2024-05-27 15:59:47,204:INFO:Initializing create_model()
2024-05-27 15:59:47,204:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000239A8379180>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 15:59:47,205:INFO:Checking exceptions
2024-05-27 15:59:47,205:INFO:Importing libraries
2024-05-27 15:59:47,205:INFO:Copying training dataset
2024-05-27 15:59:47,247:INFO:Defining folds
2024-05-27 15:59:47,247:INFO:Declaring metric variables
2024-05-27 15:59:47,252:INFO:Importing untrained model
2024-05-27 15:59:47,257:INFO:Extreme Gradient Boosting Imported successfully
2024-05-27 15:59:47,268:INFO:Starting cross validation
2024-05-27 15:59:47,274:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 15:59:53,961:INFO:Calculating mean and std
2024-05-27 15:59:53,963:INFO:Creating metrics dataframe
2024-05-27 15:59:53,965:INFO:Uploading results into container
2024-05-27 15:59:53,966:INFO:Uploading model into container now
2024-05-27 15:59:53,967:INFO:_master_model_container: 13
2024-05-27 15:59:53,967:INFO:_display_container: 2
2024-05-27 15:59:53,968:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-27 15:59:53,968:INFO:create_model() successfully completed......................................
2024-05-27 15:59:54,704:INFO:SubProcess create_model() end ==================================
2024-05-27 15:59:54,705:INFO:Creating metrics dataframe
2024-05-27 15:59:54,720:INFO:Initializing Light Gradient Boosting Machine
2024-05-27 15:59:54,721:INFO:Total runtime is 3.006162516276042 minutes
2024-05-27 15:59:54,725:INFO:SubProcess create_model() called ==================================
2024-05-27 15:59:54,726:INFO:Initializing create_model()
2024-05-27 15:59:54,726:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000239A8379180>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 15:59:54,726:INFO:Checking exceptions
2024-05-27 15:59:54,726:INFO:Importing libraries
2024-05-27 15:59:54,726:INFO:Copying training dataset
2024-05-27 15:59:54,767:INFO:Defining folds
2024-05-27 15:59:54,767:INFO:Declaring metric variables
2024-05-27 15:59:54,772:INFO:Importing untrained model
2024-05-27 15:59:54,777:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-27 15:59:54,786:INFO:Starting cross validation
2024-05-27 15:59:54,791:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 16:00:01,390:INFO:Calculating mean and std
2024-05-27 16:00:01,392:INFO:Creating metrics dataframe
2024-05-27 16:00:01,395:INFO:Uploading results into container
2024-05-27 16:00:01,397:INFO:Uploading model into container now
2024-05-27 16:00:01,397:INFO:_master_model_container: 14
2024-05-27 16:00:01,398:INFO:_display_container: 2
2024-05-27 16:00:01,398:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=408, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-27 16:00:01,399:INFO:create_model() successfully completed......................................
2024-05-27 16:00:02,228:INFO:SubProcess create_model() end ==================================
2024-05-27 16:00:02,229:INFO:Creating metrics dataframe
2024-05-27 16:00:02,246:INFO:Initializing Dummy Classifier
2024-05-27 16:00:02,246:INFO:Total runtime is 3.1315711855888373 minutes
2024-05-27 16:00:02,251:INFO:SubProcess create_model() called ==================================
2024-05-27 16:00:02,251:INFO:Initializing create_model()
2024-05-27 16:00:02,251:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000239A8379180>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 16:00:02,251:INFO:Checking exceptions
2024-05-27 16:00:02,252:INFO:Importing libraries
2024-05-27 16:00:02,252:INFO:Copying training dataset
2024-05-27 16:00:02,293:INFO:Defining folds
2024-05-27 16:00:02,294:INFO:Declaring metric variables
2024-05-27 16:00:02,299:INFO:Importing untrained model
2024-05-27 16:00:02,304:INFO:Dummy Classifier Imported successfully
2024-05-27 16:00:02,312:INFO:Starting cross validation
2024-05-27 16:00:02,317:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-27 16:00:05,667:INFO:Calculating mean and std
2024-05-27 16:00:05,669:INFO:Creating metrics dataframe
2024-05-27 16:00:05,674:INFO:Uploading results into container
2024-05-27 16:00:05,676:INFO:Uploading model into container now
2024-05-27 16:00:05,677:INFO:_master_model_container: 15
2024-05-27 16:00:05,677:INFO:_display_container: 2
2024-05-27 16:00:05,678:INFO:DummyClassifier(constant=None, random_state=408, strategy='prior')
2024-05-27 16:00:05,678:INFO:create_model() successfully completed......................................
2024-05-27 16:00:06,469:INFO:SubProcess create_model() end ==================================
2024-05-27 16:00:06,470:INFO:Creating metrics dataframe
2024-05-27 16:00:06,489:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-27 16:00:06,502:INFO:Initializing create_model()
2024-05-27 16:00:06,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 16:00:06,502:INFO:Checking exceptions
2024-05-27 16:00:06,505:INFO:Importing libraries
2024-05-27 16:00:06,505:INFO:Copying training dataset
2024-05-27 16:00:06,546:INFO:Defining folds
2024-05-27 16:00:06,546:INFO:Declaring metric variables
2024-05-27 16:00:06,547:INFO:Importing untrained model
2024-05-27 16:00:06,547:INFO:Declaring custom model
2024-05-27 16:00:06,549:INFO:Extreme Gradient Boosting Imported successfully
2024-05-27 16:00:06,553:INFO:Cross validation set to False
2024-05-27 16:00:06,553:INFO:Fitting Model
2024-05-27 16:00:08,788:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-27 16:00:08,788:INFO:create_model() successfully completed......................................
2024-05-27 16:00:09,627:INFO:Creating Dashboard logs
2024-05-27 16:00:09,633:INFO:Model: Extreme Gradient Boosting
2024-05-27 16:00:09,750:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 408, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2024-05-27 16:00:10,046:INFO:Initializing predict_model()
2024-05-27 16:00:10,047:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000239ADDF1000>)
2024-05-27 16:00:10,047:INFO:Checking exceptions
2024-05-27 16:00:10,047:INFO:Preloading libraries
2024-05-27 16:00:11,166:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2024-05-27 16:00:13,387:INFO:Creating Dashboard logs
2024-05-27 16:00:13,392:INFO:Model: Light Gradient Boosting Machine
2024-05-27 16:00:13,469:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 408, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-05-27 16:00:14,469:INFO:Creating Dashboard logs
2024-05-27 16:00:14,474:INFO:Model: Gradient Boosting Classifier
2024-05-27 16:00:14,549:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 408, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-27 16:00:15,544:INFO:Creating Dashboard logs
2024-05-27 16:00:15,548:INFO:Model: Random Forest Classifier
2024-05-27 16:00:15,623:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 408, 'verbose': 0, 'warm_start': False}
2024-05-27 16:00:16,633:INFO:Creating Dashboard logs
2024-05-27 16:00:16,637:INFO:Model: Ada Boost Classifier
2024-05-27 16:00:16,716:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 408}
2024-05-27 16:00:17,720:INFO:Creating Dashboard logs
2024-05-27 16:00:17,724:INFO:Model: Extra Trees Classifier
2024-05-27 16:00:17,801:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 408, 'verbose': 0, 'warm_start': False}
2024-05-27 16:00:18,815:INFO:Creating Dashboard logs
2024-05-27 16:00:18,820:INFO:Model: Ridge Classifier
2024-05-27 16:00:18,898:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 408, 'solver': 'auto', 'tol': 0.0001}
2024-05-27 16:00:19,878:INFO:Creating Dashboard logs
2024-05-27 16:00:19,882:INFO:Model: Linear Discriminant Analysis
2024-05-27 16:00:19,960:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-05-27 16:00:20,936:INFO:Creating Dashboard logs
2024-05-27 16:00:20,940:INFO:Model: Decision Tree Classifier
2024-05-27 16:00:21,017:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 408, 'splitter': 'best'}
2024-05-27 16:00:22,059:INFO:Creating Dashboard logs
2024-05-27 16:00:22,063:INFO:Model: K Neighbors Classifier
2024-05-27 16:00:22,139:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2024-05-27 16:00:23,153:INFO:Creating Dashboard logs
2024-05-27 16:00:23,157:INFO:Model: Logistic Regression
2024-05-27 16:00:23,234:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 408, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-05-27 16:00:24,245:INFO:Creating Dashboard logs
2024-05-27 16:00:24,249:INFO:Model: Quadratic Discriminant Analysis
2024-05-27 16:00:24,326:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2024-05-27 16:00:25,340:INFO:Creating Dashboard logs
2024-05-27 16:00:25,345:INFO:Model: Dummy Classifier
2024-05-27 16:00:25,424:INFO:Logged params: {'constant': None, 'random_state': 408, 'strategy': 'prior'}
2024-05-27 16:00:26,508:INFO:Creating Dashboard logs
2024-05-27 16:00:26,513:INFO:Model: SVM - Linear Kernel
2024-05-27 16:00:26,595:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 408, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-27 16:00:27,636:INFO:Creating Dashboard logs
2024-05-27 16:00:27,641:INFO:Model: Naive Bayes
2024-05-27 16:00:27,718:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-05-27 16:00:28,714:INFO:_master_model_container: 15
2024-05-27 16:00:28,714:INFO:_display_container: 2
2024-05-27 16:00:28,716:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-27 16:00:28,716:INFO:compare_models() successfully completed......................................
2024-05-27 16:00:28,730:INFO:Initializing finalize_model()
2024-05-27 16:00:28,730:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-05-27 16:00:28,731:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-27 16:00:28,749:INFO:Initializing create_model()
2024-05-27 16:00:28,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-05-27 16:00:28,749:INFO:Checking exceptions
2024-05-27 16:00:28,752:INFO:Importing libraries
2024-05-27 16:00:28,752:INFO:Copying training dataset
2024-05-27 16:00:28,754:INFO:Defining folds
2024-05-27 16:00:28,754:INFO:Declaring metric variables
2024-05-27 16:00:28,755:INFO:Importing untrained model
2024-05-27 16:00:28,755:INFO:Declaring custom model
2024-05-27 16:00:28,757:INFO:Extreme Gradient Boosting Imported successfully
2024-05-27 16:00:28,761:INFO:Cross validation set to False
2024-05-27 16:00:28,761:INFO:Fitting Model
2024-05-27 16:00:31,168:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transf...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2024-05-27 16:00:31,168:INFO:create_model() successfully completed......................................
2024-05-27 16:00:31,948:INFO:Creating Dashboard logs
2024-05-27 16:00:31,950:INFO:Model: Extreme Gradient Boosting
2024-05-27 16:00:32,034:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 408, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2024-05-27 16:00:33,173:INFO:_master_model_container: 15
2024-05-27 16:00:33,173:INFO:_display_container: 2
2024-05-27 16:00:33,207:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['base_price', 'price',
                                             'initial_quantity',
                                             'sold_quantity',
                                             'available_quantity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transf...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2024-05-27 16:00:33,207:INFO:finalize_model() successfully completed......................................
2024-05-27 16:00:34,150:INFO:Initializing evaluate_model()
2024-05-27 16:00:34,151:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-27 16:00:34,187:INFO:Initializing plot_model()
2024-05-27 16:00:34,187:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, system=True)
2024-05-27 16:00:34,187:INFO:Checking exceptions
2024-05-27 16:00:34,204:INFO:Preloading libraries
2024-05-27 16:00:34,212:INFO:Copying training dataset
2024-05-27 16:00:34,212:INFO:Plot type: pipeline
2024-05-27 16:00:34,567:INFO:Visual Rendered Successfully
2024-05-27 16:00:35,311:INFO:plot_model() successfully completed......................................
2024-05-27 16:03:38,978:INFO:Initializing plot_model()
2024-05-27 16:03:38,978:INFO:plot_model(plot=rfe, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239A8379C90>, system=True)
2024-05-27 16:03:38,978:INFO:Checking exceptions
2024-05-27 16:03:38,995:INFO:Preloading libraries
2024-05-27 16:03:39,003:INFO:Copying training dataset
2024-05-27 16:03:39,004:INFO:Plot type: rfe
2024-05-27 16:03:39,426:INFO:Fitting Model
2024-05-27 17:16:10,451:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 17:16:10,451:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 17:16:10,451:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 17:16:10,451:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 17:46:30,754:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 17:46:30,755:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 17:46:30,755:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-27 17:46:30,755:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-29 02:45:53,008:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-29 02:45:53,008:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-29 02:45:53,008:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-29 02:45:53,008:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-29 02:46:04,468:INFO:PyCaret ClassificationExperiment
2024-05-29 02:46:04,468:INFO:Logging name: codex
2024-05-29 02:46:04,468:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 02:46:04,468:INFO:version 3.3.2
2024-05-29 02:46:04,468:INFO:Initializing setup()
2024-05-29 02:46:04,468:INFO:self.USI: 05f8
2024-05-29 02:46:04,468:INFO:self._variable_keys: {'y_train', 'seed', 'target_param', 'X_train', 'memory', 'USI', 'data', 'is_multiclass', '_available_plots', 'fold_shuffle_param', 'pipeline', 'fold_generator', 'X_test', 'fix_imbalance', 'fold_groups_param', 'gpu_param', 'log_plots_param', 'exp_name_log', 'X', 'html_param', 'idx', 'logging_param', '_ml_usecase', 'y', 'gpu_n_jobs_param', 'exp_id', 'y_test', 'n_jobs_param'}
2024-05-29 02:46:04,468:INFO:Checking environment
2024-05-29 02:46:04,468:INFO:python_version: 3.10.13
2024-05-29 02:46:04,469:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 02:46:04,469:INFO:machine: AMD64
2024-05-29 02:46:04,469:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 02:46:04,469:INFO:Memory: svmem(total=34267656192, available=18675982336, percent=45.5, used=15591673856, free=18675982336)
2024-05-29 02:46:04,469:INFO:Physical Core: 8
2024-05-29 02:46:04,469:INFO:Logical Core: 16
2024-05-29 02:46:04,469:INFO:Checking libraries
2024-05-29 02:46:04,469:INFO:System:
2024-05-29 02:46:04,469:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 02:46:04,469:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 02:46:04,470:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 02:46:04,470:INFO:PyCaret required dependencies:
2024-05-29 02:46:04,525:INFO:                 pip: 23.3
2024-05-29 02:46:04,525:INFO:          setuptools: 68.0.0
2024-05-29 02:46:04,525:INFO:             pycaret: 3.3.2
2024-05-29 02:46:04,525:INFO:             IPython: 8.24.0
2024-05-29 02:46:04,525:INFO:          ipywidgets: 8.1.2
2024-05-29 02:46:04,525:INFO:                tqdm: 4.66.4
2024-05-29 02:46:04,525:INFO:               numpy: 1.26.4
2024-05-29 02:46:04,525:INFO:              pandas: 2.1.4
2024-05-29 02:46:04,525:INFO:              jinja2: 3.1.4
2024-05-29 02:46:04,526:INFO:               scipy: 1.11.4
2024-05-29 02:46:04,526:INFO:              joblib: 1.3.2
2024-05-29 02:46:04,526:INFO:             sklearn: 1.4.2
2024-05-29 02:46:04,526:INFO:                pyod: 1.1.3
2024-05-29 02:46:04,526:INFO:            imblearn: 0.12.2
2024-05-29 02:46:04,526:INFO:   category_encoders: 2.6.3
2024-05-29 02:46:04,526:INFO:            lightgbm: 4.3.0
2024-05-29 02:46:04,526:INFO:               numba: 0.59.1
2024-05-29 02:46:04,526:INFO:            requests: 2.32.2
2024-05-29 02:46:04,526:INFO:          matplotlib: 3.7.5
2024-05-29 02:46:04,526:INFO:          scikitplot: 0.3.7
2024-05-29 02:46:04,526:INFO:         yellowbrick: 1.5
2024-05-29 02:46:04,527:INFO:              plotly: 5.22.0
2024-05-29 02:46:04,527:INFO:    plotly-resampler: Not installed
2024-05-29 02:46:04,527:INFO:             kaleido: 0.2.1
2024-05-29 02:46:04,527:INFO:           schemdraw: 0.15
2024-05-29 02:46:04,527:INFO:         statsmodels: 0.14.2
2024-05-29 02:46:04,527:INFO:              sktime: 0.26.0
2024-05-29 02:46:04,527:INFO:               tbats: 1.1.3
2024-05-29 02:46:04,527:INFO:            pmdarima: 2.0.4
2024-05-29 02:46:04,527:INFO:              psutil: 5.9.0
2024-05-29 02:46:04,527:INFO:          markupsafe: 2.1.5
2024-05-29 02:46:04,527:INFO:             pickle5: Not installed
2024-05-29 02:46:04,527:INFO:         cloudpickle: 3.0.0
2024-05-29 02:46:04,528:INFO:         deprecation: 2.1.0
2024-05-29 02:46:04,528:INFO:              xxhash: 3.4.1
2024-05-29 02:46:04,528:INFO:           wurlitzer: Not installed
2024-05-29 02:46:04,528:INFO:PyCaret optional dependencies:
2024-05-29 02:46:04,553:INFO:                shap: Not installed
2024-05-29 02:46:04,553:INFO:           interpret: Not installed
2024-05-29 02:46:04,553:INFO:                umap: Not installed
2024-05-29 02:46:04,553:INFO:     ydata_profiling: Not installed
2024-05-29 02:46:04,554:INFO:  explainerdashboard: Not installed
2024-05-29 02:46:04,554:INFO:             autoviz: Not installed
2024-05-29 02:46:04,554:INFO:           fairlearn: Not installed
2024-05-29 02:46:04,554:INFO:          deepchecks: Not installed
2024-05-29 02:46:04,554:INFO:             xgboost: 2.0.3
2024-05-29 02:46:04,554:INFO:            catboost: Not installed
2024-05-29 02:46:04,554:INFO:              kmodes: Not installed
2024-05-29 02:46:04,554:INFO:             mlxtend: Not installed
2024-05-29 02:46:04,554:INFO:       statsforecast: Not installed
2024-05-29 02:46:04,554:INFO:        tune_sklearn: Not installed
2024-05-29 02:46:04,554:INFO:                 ray: Not installed
2024-05-29 02:46:04,554:INFO:            hyperopt: Not installed
2024-05-29 02:46:04,555:INFO:              optuna: Not installed
2024-05-29 02:46:04,555:INFO:               skopt: Not installed
2024-05-29 02:46:04,555:INFO:              mlflow: 2.13.0
2024-05-29 02:46:04,555:INFO:              gradio: Not installed
2024-05-29 02:46:04,555:INFO:             fastapi: Not installed
2024-05-29 02:46:04,555:INFO:             uvicorn: Not installed
2024-05-29 02:46:04,555:INFO:              m2cgen: Not installed
2024-05-29 02:46:04,555:INFO:           evidently: Not installed
2024-05-29 02:46:04,555:INFO:               fugue: Not installed
2024-05-29 02:46:04,555:INFO:           streamlit: Not installed
2024-05-29 02:46:04,555:INFO:             prophet: Not installed
2024-05-29 02:46:04,555:INFO:None
2024-05-29 02:46:04,556:INFO:Set up data.
2024-05-29 02:46:04,585:INFO:Set up folding strategy.
2024-05-29 02:46:04,585:INFO:Set up train/test split.
2024-05-29 02:46:04,643:INFO:Set up index.
2024-05-29 02:46:04,645:INFO:Assigning column types.
2024-05-29 02:46:04,678:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 02:46:04,748:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 02:46:04,758:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 02:46:04,825:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:46:04,829:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:46:04,899:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 02:46:04,900:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 02:46:04,945:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:46:04,949:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:46:04,949:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 02:46:05,023:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 02:46:05,068:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:46:05,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:46:05,143:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 02:46:05,187:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:46:05,191:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:46:05,192:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 02:46:05,307:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:46:05,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:46:05,426:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:46:05,430:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:46:05,433:INFO:Preparing preprocessing pipeline...
2024-05-29 02:46:05,440:INFO:Set up simple imputation.
2024-05-29 02:46:05,537:INFO:Finished creating preprocessing pipeline.
2024-05-29 02:46:05,543:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'featu...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-05-29 02:46:05,543:INFO:Creating final display dataframe.
2024-05-29 02:46:05,801:INFO:Setup _display_container:                     Description            Value
0                    Session id             8262
1                        Target           target
2                   Target type           Binary
3           Original data shape      (90000, 18)
4        Transformed data shape      (90000, 18)
5   Transformed train set shape      (72000, 18)
6    Transformed test set shape      (18000, 18)
7              Numeric features               17
8                    Preprocess             True
9               Imputation type           simple
10           Numeric imputation             mean
11       Categorical imputation             mode
12               Fold Generator  StratifiedKFold
13                  Fold Number               10
14                     CPU Jobs               -1
15                      Use GPU            False
16               Log Experiment     MlflowLogger
17              Experiment Name            codex
18                          USI             05f8
2024-05-29 02:46:05,926:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:46:05,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:46:06,046:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:46:06,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:46:06,052:INFO:Logging experiment in loggers
2024-05-29 02:46:06,630:INFO:SubProcess save_model() called ==================================
2024-05-29 02:46:06,641:INFO:Initializing save_model()
2024-05-29 02:46:06,641:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'featu...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), model_name=C:\Users\Adm\AppData\Local\Temp\tmpkknfyx3q\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'featu...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-29 02:46:06,641:INFO:Adding model into prep_pipe
2024-05-29 02:46:06,641:WARNING:Only Model saved as it was a pipeline.
2024-05-29 02:46:06,648:INFO:C:\Users\Adm\AppData\Local\Temp\tmpkknfyx3q\Transformation Pipeline.pkl saved in current working directory
2024-05-29 02:46:06,654:INFO:Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'featu...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-05-29 02:46:06,654:INFO:save_model() successfully completed......................................
2024-05-29 02:46:07,799:INFO:SubProcess save_model() end ==================================
2024-05-29 02:46:07,825:INFO:setup() successfully completed in 1.63s...............
2024-05-29 02:48:56,523:INFO:PyCaret ClassificationExperiment
2024-05-29 02:48:56,523:INFO:Logging name: codex
2024-05-29 02:48:56,523:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 02:48:56,523:INFO:version 3.3.2
2024-05-29 02:48:56,523:INFO:Initializing setup()
2024-05-29 02:48:56,524:INFO:self.USI: fefe
2024-05-29 02:48:56,524:INFO:self._variable_keys: {'y_train', 'seed', 'target_param', 'X_train', 'memory', 'USI', 'data', 'is_multiclass', '_available_plots', 'fold_shuffle_param', 'pipeline', 'fold_generator', 'X_test', 'fix_imbalance', 'fold_groups_param', 'gpu_param', 'log_plots_param', 'exp_name_log', 'X', 'html_param', 'idx', 'logging_param', '_ml_usecase', 'y', 'gpu_n_jobs_param', 'exp_id', 'y_test', 'n_jobs_param'}
2024-05-29 02:48:56,524:INFO:Checking environment
2024-05-29 02:48:56,524:INFO:python_version: 3.10.13
2024-05-29 02:48:56,524:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 02:48:56,524:INFO:machine: AMD64
2024-05-29 02:48:56,524:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 02:48:56,524:INFO:Memory: svmem(total=34267656192, available=18724495360, percent=45.4, used=15543160832, free=18724495360)
2024-05-29 02:48:56,524:INFO:Physical Core: 8
2024-05-29 02:48:56,525:INFO:Logical Core: 16
2024-05-29 02:48:56,525:INFO:Checking libraries
2024-05-29 02:48:56,525:INFO:System:
2024-05-29 02:48:56,525:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 02:48:56,525:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 02:48:56,525:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 02:48:56,525:INFO:PyCaret required dependencies:
2024-05-29 02:48:56,525:INFO:                 pip: 23.3
2024-05-29 02:48:56,525:INFO:          setuptools: 68.0.0
2024-05-29 02:48:56,525:INFO:             pycaret: 3.3.2
2024-05-29 02:48:56,526:INFO:             IPython: 8.24.0
2024-05-29 02:48:56,526:INFO:          ipywidgets: 8.1.2
2024-05-29 02:48:56,526:INFO:                tqdm: 4.66.4
2024-05-29 02:48:56,526:INFO:               numpy: 1.26.4
2024-05-29 02:48:56,526:INFO:              pandas: 2.1.4
2024-05-29 02:48:56,526:INFO:              jinja2: 3.1.4
2024-05-29 02:48:56,526:INFO:               scipy: 1.11.4
2024-05-29 02:48:56,526:INFO:              joblib: 1.3.2
2024-05-29 02:48:56,526:INFO:             sklearn: 1.4.2
2024-05-29 02:48:56,526:INFO:                pyod: 1.1.3
2024-05-29 02:48:56,526:INFO:            imblearn: 0.12.2
2024-05-29 02:48:56,527:INFO:   category_encoders: 2.6.3
2024-05-29 02:48:56,527:INFO:            lightgbm: 4.3.0
2024-05-29 02:48:56,527:INFO:               numba: 0.59.1
2024-05-29 02:48:56,527:INFO:            requests: 2.32.2
2024-05-29 02:48:56,527:INFO:          matplotlib: 3.7.5
2024-05-29 02:48:56,527:INFO:          scikitplot: 0.3.7
2024-05-29 02:48:56,527:INFO:         yellowbrick: 1.5
2024-05-29 02:48:56,527:INFO:              plotly: 5.22.0
2024-05-29 02:48:56,527:INFO:    plotly-resampler: Not installed
2024-05-29 02:48:56,527:INFO:             kaleido: 0.2.1
2024-05-29 02:48:56,527:INFO:           schemdraw: 0.15
2024-05-29 02:48:56,527:INFO:         statsmodels: 0.14.2
2024-05-29 02:48:56,528:INFO:              sktime: 0.26.0
2024-05-29 02:48:56,528:INFO:               tbats: 1.1.3
2024-05-29 02:48:56,528:INFO:            pmdarima: 2.0.4
2024-05-29 02:48:56,528:INFO:              psutil: 5.9.0
2024-05-29 02:48:56,528:INFO:          markupsafe: 2.1.5
2024-05-29 02:48:56,528:INFO:             pickle5: Not installed
2024-05-29 02:48:56,528:INFO:         cloudpickle: 3.0.0
2024-05-29 02:48:56,528:INFO:         deprecation: 2.1.0
2024-05-29 02:48:56,528:INFO:              xxhash: 3.4.1
2024-05-29 02:48:56,528:INFO:           wurlitzer: Not installed
2024-05-29 02:48:56,528:INFO:PyCaret optional dependencies:
2024-05-29 02:48:56,528:INFO:                shap: Not installed
2024-05-29 02:48:56,529:INFO:           interpret: Not installed
2024-05-29 02:48:56,529:INFO:                umap: Not installed
2024-05-29 02:48:56,529:INFO:     ydata_profiling: Not installed
2024-05-29 02:48:56,529:INFO:  explainerdashboard: Not installed
2024-05-29 02:48:56,529:INFO:             autoviz: Not installed
2024-05-29 02:48:56,529:INFO:           fairlearn: Not installed
2024-05-29 02:48:56,529:INFO:          deepchecks: Not installed
2024-05-29 02:48:56,529:INFO:             xgboost: 2.0.3
2024-05-29 02:48:56,529:INFO:            catboost: Not installed
2024-05-29 02:48:56,529:INFO:              kmodes: Not installed
2024-05-29 02:48:56,529:INFO:             mlxtend: Not installed
2024-05-29 02:48:56,529:INFO:       statsforecast: Not installed
2024-05-29 02:48:56,530:INFO:        tune_sklearn: Not installed
2024-05-29 02:48:56,530:INFO:                 ray: Not installed
2024-05-29 02:48:56,530:INFO:            hyperopt: Not installed
2024-05-29 02:48:56,530:INFO:              optuna: Not installed
2024-05-29 02:48:56,530:INFO:               skopt: Not installed
2024-05-29 02:48:56,530:INFO:              mlflow: 2.13.0
2024-05-29 02:48:56,530:INFO:              gradio: Not installed
2024-05-29 02:48:56,530:INFO:             fastapi: Not installed
2024-05-29 02:48:56,530:INFO:             uvicorn: Not installed
2024-05-29 02:48:56,530:INFO:              m2cgen: Not installed
2024-05-29 02:48:56,530:INFO:           evidently: Not installed
2024-05-29 02:48:56,530:INFO:               fugue: Not installed
2024-05-29 02:48:56,531:INFO:           streamlit: Not installed
2024-05-29 02:48:56,531:INFO:             prophet: Not installed
2024-05-29 02:48:56,531:INFO:None
2024-05-29 02:48:56,531:INFO:Set up data.
2024-05-29 02:48:56,560:INFO:Set up folding strategy.
2024-05-29 02:48:56,560:INFO:Set up train/test split.
2024-05-29 02:48:56,617:INFO:Set up index.
2024-05-29 02:48:56,619:INFO:Assigning column types.
2024-05-29 02:48:56,651:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 02:48:56,722:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 02:48:56,724:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 02:48:56,768:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:48:56,773:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:48:56,843:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 02:48:56,844:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 02:48:56,889:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:48:56,893:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:48:56,893:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 02:48:56,965:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 02:48:57,009:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:48:57,013:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:48:57,088:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 02:48:57,132:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:48:57,136:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:48:57,137:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 02:48:57,252:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:48:57,256:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:48:57,371:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:48:57,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:48:57,377:INFO:Preparing preprocessing pipeline...
2024-05-29 02:48:57,383:INFO:Set up simple imputation.
2024-05-29 02:48:57,474:INFO:Finished creating preprocessing pipeline.
2024-05-29 02:48:57,480:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'featu...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-05-29 02:48:57,480:INFO:Creating final display dataframe.
2024-05-29 02:48:57,738:INFO:Setup _display_container:                     Description            Value
0                    Session id             7831
1                        Target           target
2                   Target type           Binary
3           Original data shape      (90000, 18)
4        Transformed data shape      (90000, 18)
5   Transformed train set shape      (72000, 18)
6    Transformed test set shape      (18000, 18)
7              Numeric features               17
8                    Preprocess             True
9               Imputation type           simple
10           Numeric imputation             mean
11       Categorical imputation             mode
12               Fold Generator  StratifiedKFold
13                  Fold Number               10
14                     CPU Jobs               -1
15                      Use GPU            False
16               Log Experiment     MlflowLogger
17              Experiment Name            codex
18                          USI             fefe
2024-05-29 02:48:57,863:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:48:57,867:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:48:57,983:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:48:57,987:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:48:57,989:INFO:Logging experiment in loggers
2024-05-29 02:48:58,153:INFO:SubProcess save_model() called ==================================
2024-05-29 02:48:58,164:INFO:Initializing save_model()
2024-05-29 02:48:58,164:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'featu...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), model_name=C:\Users\Adm\AppData\Local\Temp\tmpo6ebz7o3\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'featu...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-29 02:48:58,165:INFO:Adding model into prep_pipe
2024-05-29 02:48:58,165:WARNING:Only Model saved as it was a pipeline.
2024-05-29 02:48:58,172:INFO:C:\Users\Adm\AppData\Local\Temp\tmpo6ebz7o3\Transformation Pipeline.pkl saved in current working directory
2024-05-29 02:48:58,178:INFO:Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'featu...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-05-29 02:48:58,178:INFO:save_model() successfully completed......................................
2024-05-29 02:48:59,211:INFO:SubProcess save_model() end ==================================
2024-05-29 02:48:59,237:INFO:setup() successfully completed in 1.5s...............
2024-05-29 02:50:11,223:INFO:PyCaret ClassificationExperiment
2024-05-29 02:50:11,223:INFO:Logging name: codex
2024-05-29 02:50:11,223:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 02:50:11,223:INFO:version 3.3.2
2024-05-29 02:50:11,223:INFO:Initializing setup()
2024-05-29 02:50:11,223:INFO:self.USI: 42ea
2024-05-29 02:50:11,223:INFO:self._variable_keys: {'y_train', 'seed', 'target_param', 'X_train', 'memory', 'USI', 'data', 'is_multiclass', '_available_plots', 'fold_shuffle_param', 'pipeline', 'fold_generator', 'X_test', 'fix_imbalance', 'fold_groups_param', 'gpu_param', 'log_plots_param', 'exp_name_log', 'X', 'html_param', 'idx', 'logging_param', '_ml_usecase', 'y', 'gpu_n_jobs_param', 'exp_id', 'y_test', 'n_jobs_param'}
2024-05-29 02:50:11,223:INFO:Checking environment
2024-05-29 02:50:11,223:INFO:python_version: 3.10.13
2024-05-29 02:50:11,224:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 02:50:11,224:INFO:machine: AMD64
2024-05-29 02:50:11,224:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 02:50:11,224:INFO:Memory: svmem(total=34267656192, available=18650312704, percent=45.6, used=15617343488, free=18650312704)
2024-05-29 02:50:11,224:INFO:Physical Core: 8
2024-05-29 02:50:11,224:INFO:Logical Core: 16
2024-05-29 02:50:11,224:INFO:Checking libraries
2024-05-29 02:50:11,224:INFO:System:
2024-05-29 02:50:11,224:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 02:50:11,224:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 02:50:11,225:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 02:50:11,225:INFO:PyCaret required dependencies:
2024-05-29 02:50:11,225:INFO:                 pip: 23.3
2024-05-29 02:50:11,225:INFO:          setuptools: 68.0.0
2024-05-29 02:50:11,225:INFO:             pycaret: 3.3.2
2024-05-29 02:50:11,225:INFO:             IPython: 8.24.0
2024-05-29 02:50:11,225:INFO:          ipywidgets: 8.1.2
2024-05-29 02:50:11,225:INFO:                tqdm: 4.66.4
2024-05-29 02:50:11,225:INFO:               numpy: 1.26.4
2024-05-29 02:50:11,225:INFO:              pandas: 2.1.4
2024-05-29 02:50:11,225:INFO:              jinja2: 3.1.4
2024-05-29 02:50:11,226:INFO:               scipy: 1.11.4
2024-05-29 02:50:11,226:INFO:              joblib: 1.3.2
2024-05-29 02:50:11,226:INFO:             sklearn: 1.4.2
2024-05-29 02:50:11,226:INFO:                pyod: 1.1.3
2024-05-29 02:50:11,226:INFO:            imblearn: 0.12.2
2024-05-29 02:50:11,226:INFO:   category_encoders: 2.6.3
2024-05-29 02:50:11,226:INFO:            lightgbm: 4.3.0
2024-05-29 02:50:11,226:INFO:               numba: 0.59.1
2024-05-29 02:50:11,226:INFO:            requests: 2.32.2
2024-05-29 02:50:11,226:INFO:          matplotlib: 3.7.5
2024-05-29 02:50:11,227:INFO:          scikitplot: 0.3.7
2024-05-29 02:50:11,227:INFO:         yellowbrick: 1.5
2024-05-29 02:50:11,227:INFO:              plotly: 5.22.0
2024-05-29 02:50:11,227:INFO:    plotly-resampler: Not installed
2024-05-29 02:50:11,227:INFO:             kaleido: 0.2.1
2024-05-29 02:50:11,227:INFO:           schemdraw: 0.15
2024-05-29 02:50:11,227:INFO:         statsmodels: 0.14.2
2024-05-29 02:50:11,227:INFO:              sktime: 0.26.0
2024-05-29 02:50:11,227:INFO:               tbats: 1.1.3
2024-05-29 02:50:11,227:INFO:            pmdarima: 2.0.4
2024-05-29 02:50:11,227:INFO:              psutil: 5.9.0
2024-05-29 02:50:11,228:INFO:          markupsafe: 2.1.5
2024-05-29 02:50:11,228:INFO:             pickle5: Not installed
2024-05-29 02:50:11,228:INFO:         cloudpickle: 3.0.0
2024-05-29 02:50:11,228:INFO:         deprecation: 2.1.0
2024-05-29 02:50:11,228:INFO:              xxhash: 3.4.1
2024-05-29 02:50:11,228:INFO:           wurlitzer: Not installed
2024-05-29 02:50:11,228:INFO:PyCaret optional dependencies:
2024-05-29 02:50:11,228:INFO:                shap: Not installed
2024-05-29 02:50:11,228:INFO:           interpret: Not installed
2024-05-29 02:50:11,228:INFO:                umap: Not installed
2024-05-29 02:50:11,229:INFO:     ydata_profiling: Not installed
2024-05-29 02:50:11,229:INFO:  explainerdashboard: Not installed
2024-05-29 02:50:11,229:INFO:             autoviz: Not installed
2024-05-29 02:50:11,229:INFO:           fairlearn: Not installed
2024-05-29 02:50:11,229:INFO:          deepchecks: Not installed
2024-05-29 02:50:11,229:INFO:             xgboost: 2.0.3
2024-05-29 02:50:11,229:INFO:            catboost: Not installed
2024-05-29 02:50:11,229:INFO:              kmodes: Not installed
2024-05-29 02:50:11,230:INFO:             mlxtend: Not installed
2024-05-29 02:50:11,230:INFO:       statsforecast: Not installed
2024-05-29 02:50:11,230:INFO:        tune_sklearn: Not installed
2024-05-29 02:50:11,230:INFO:                 ray: Not installed
2024-05-29 02:50:11,230:INFO:            hyperopt: Not installed
2024-05-29 02:50:11,230:INFO:              optuna: Not installed
2024-05-29 02:50:11,230:INFO:               skopt: Not installed
2024-05-29 02:50:11,230:INFO:              mlflow: 2.13.0
2024-05-29 02:50:11,230:INFO:              gradio: Not installed
2024-05-29 02:50:11,230:INFO:             fastapi: Not installed
2024-05-29 02:50:11,230:INFO:             uvicorn: Not installed
2024-05-29 02:50:11,231:INFO:              m2cgen: Not installed
2024-05-29 02:50:11,231:INFO:           evidently: Not installed
2024-05-29 02:50:11,231:INFO:               fugue: Not installed
2024-05-29 02:50:11,231:INFO:           streamlit: Not installed
2024-05-29 02:50:11,231:INFO:             prophet: Not installed
2024-05-29 02:50:11,231:INFO:None
2024-05-29 02:50:11,231:INFO:Set up data.
2024-05-29 02:50:11,260:INFO:Set up folding strategy.
2024-05-29 02:50:11,260:INFO:Set up train/test split.
2024-05-29 02:50:11,313:INFO:Set up index.
2024-05-29 02:50:11,315:INFO:Assigning column types.
2024-05-29 02:50:11,347:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 02:50:11,417:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 02:50:11,419:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 02:50:11,463:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:50:11,467:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:50:11,538:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 02:50:11,539:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 02:50:11,583:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:50:11,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:50:11,588:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 02:50:11,659:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 02:50:11,703:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:50:11,708:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:50:11,779:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 02:50:11,823:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:50:11,827:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:50:11,828:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 02:50:11,943:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:50:11,947:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:50:12,063:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:50:12,067:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:50:12,069:INFO:Preparing preprocessing pipeline...
2024-05-29 02:50:12,075:INFO:Set up simple imputation.
2024-05-29 02:50:12,161:INFO:Finished creating preprocessing pipeline.
2024-05-29 02:50:12,167:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'featu...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-05-29 02:50:12,167:INFO:Creating final display dataframe.
2024-05-29 02:50:12,423:INFO:Setup _display_container:                     Description            Value
0                    Session id             6389
1                        Target           target
2                   Target type           Binary
3           Original data shape      (90000, 18)
4        Transformed data shape      (90000, 18)
5   Transformed train set shape      (72000, 18)
6    Transformed test set shape      (18000, 18)
7              Numeric features               17
8                    Preprocess             True
9               Imputation type           simple
10           Numeric imputation             mean
11       Categorical imputation             mode
12               Fold Generator  StratifiedKFold
13                  Fold Number               10
14                     CPU Jobs               -1
15                      Use GPU            False
16               Log Experiment     MlflowLogger
17              Experiment Name            codex
18                          USI             42ea
2024-05-29 02:50:12,599:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:50:12,604:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:50:12,719:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 02:50:12,724:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 02:50:12,725:INFO:Logging experiment in loggers
2024-05-29 02:50:12,876:INFO:SubProcess save_model() called ==================================
2024-05-29 02:50:12,888:INFO:Initializing save_model()
2024-05-29 02:50:12,888:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'featu...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), model_name=C:\Users\Adm\AppData\Local\Temp\tmpdxaqiisj\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'featu...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-29 02:50:12,889:INFO:Adding model into prep_pipe
2024-05-29 02:50:12,889:WARNING:Only Model saved as it was a pipeline.
2024-05-29 02:50:12,896:INFO:C:\Users\Adm\AppData\Local\Temp\tmpdxaqiisj\Transformation Pipeline.pkl saved in current working directory
2024-05-29 02:50:12,902:INFO:Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'featu...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-05-29 02:50:12,902:INFO:save_model() successfully completed......................................
2024-05-29 02:50:13,892:INFO:SubProcess save_model() end ==================================
2024-05-29 02:50:13,919:INFO:setup() successfully completed in 1.53s...............
2024-05-29 02:50:13,955:INFO:Initializing compare_models()
2024-05-29 02:50:13,956:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7B828D6F0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E7B828D6F0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-29 02:50:13,956:INFO:Checking exceptions
2024-05-29 02:50:13,982:INFO:Preparing display monitor
2024-05-29 02:50:14,012:INFO:Initializing Logistic Regression
2024-05-29 02:50:14,012:INFO:Total runtime is 0.0 minutes
2024-05-29 02:50:14,016:INFO:SubProcess create_model() called ==================================
2024-05-29 02:50:14,016:INFO:Initializing create_model()
2024-05-29 02:50:14,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7B828D6F0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7ACF748B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 02:50:14,016:INFO:Checking exceptions
2024-05-29 02:50:14,017:INFO:Importing libraries
2024-05-29 02:50:14,017:INFO:Copying training dataset
2024-05-29 02:50:14,063:INFO:Defining folds
2024-05-29 02:50:14,063:INFO:Declaring metric variables
2024-05-29 02:50:14,067:INFO:Importing untrained model
2024-05-29 02:50:14,072:INFO:Logistic Regression Imported successfully
2024-05-29 02:50:14,080:INFO:Starting cross validation
2024-05-29 02:50:14,081:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 02:50:21,044:INFO:Calculating mean and std
2024-05-29 02:50:21,046:INFO:Creating metrics dataframe
2024-05-29 02:50:21,049:INFO:Uploading results into container
2024-05-29 02:50:21,050:INFO:Uploading model into container now
2024-05-29 02:50:21,050:INFO:_master_model_container: 1
2024-05-29 02:50:21,050:INFO:_display_container: 2
2024-05-29 02:50:21,051:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6389, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-29 02:50:21,052:INFO:create_model() successfully completed......................................
2024-05-29 02:50:22,099:INFO:SubProcess create_model() end ==================================
2024-05-29 02:50:22,100:INFO:Creating metrics dataframe
2024-05-29 02:50:22,115:INFO:Initializing K Neighbors Classifier
2024-05-29 02:50:22,115:INFO:Total runtime is 0.1350500464439392 minutes
2024-05-29 02:50:22,120:INFO:SubProcess create_model() called ==================================
2024-05-29 02:50:22,120:INFO:Initializing create_model()
2024-05-29 02:50:22,121:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7B828D6F0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7ACF748B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 02:50:22,121:INFO:Checking exceptions
2024-05-29 02:50:22,121:INFO:Importing libraries
2024-05-29 02:50:22,121:INFO:Copying training dataset
2024-05-29 02:50:22,174:INFO:Defining folds
2024-05-29 02:50:22,174:INFO:Declaring metric variables
2024-05-29 02:50:22,178:INFO:Importing untrained model
2024-05-29 02:50:22,183:INFO:K Neighbors Classifier Imported successfully
2024-05-29 02:50:22,192:INFO:Starting cross validation
2024-05-29 02:50:22,194:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 02:50:35,560:INFO:Calculating mean and std
2024-05-29 02:50:35,562:INFO:Creating metrics dataframe
2024-05-29 02:50:35,565:INFO:Uploading results into container
2024-05-29 02:50:35,566:INFO:Uploading model into container now
2024-05-29 02:50:35,567:INFO:_master_model_container: 2
2024-05-29 02:50:35,567:INFO:_display_container: 2
2024-05-29 02:50:35,567:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-29 02:50:35,567:INFO:create_model() successfully completed......................................
2024-05-29 02:50:36,579:INFO:SubProcess create_model() end ==================================
2024-05-29 02:50:36,579:INFO:Creating metrics dataframe
2024-05-29 02:50:36,589:INFO:Initializing Naive Bayes
2024-05-29 02:50:36,589:INFO:Total runtime is 0.37628747224807735 minutes
2024-05-29 02:50:36,594:INFO:SubProcess create_model() called ==================================
2024-05-29 02:50:36,594:INFO:Initializing create_model()
2024-05-29 02:50:36,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7B828D6F0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7ACF748B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 02:50:36,594:INFO:Checking exceptions
2024-05-29 02:50:36,595:INFO:Importing libraries
2024-05-29 02:50:36,595:INFO:Copying training dataset
2024-05-29 02:50:36,641:INFO:Defining folds
2024-05-29 02:50:36,642:INFO:Declaring metric variables
2024-05-29 02:50:36,646:INFO:Importing untrained model
2024-05-29 02:50:36,650:INFO:Naive Bayes Imported successfully
2024-05-29 02:50:36,658:INFO:Starting cross validation
2024-05-29 02:50:36,660:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 02:50:37,040:INFO:Calculating mean and std
2024-05-29 02:50:37,042:INFO:Creating metrics dataframe
2024-05-29 02:50:37,044:INFO:Uploading results into container
2024-05-29 02:50:37,045:INFO:Uploading model into container now
2024-05-29 02:50:37,045:INFO:_master_model_container: 3
2024-05-29 02:50:37,045:INFO:_display_container: 2
2024-05-29 02:50:37,046:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-29 02:50:37,046:INFO:create_model() successfully completed......................................
2024-05-29 02:50:38,052:INFO:SubProcess create_model() end ==================================
2024-05-29 02:50:38,052:INFO:Creating metrics dataframe
2024-05-29 02:50:38,063:INFO:Initializing Decision Tree Classifier
2024-05-29 02:50:38,063:INFO:Total runtime is 0.4008541266123453 minutes
2024-05-29 02:50:38,067:INFO:SubProcess create_model() called ==================================
2024-05-29 02:50:38,068:INFO:Initializing create_model()
2024-05-29 02:50:38,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7B828D6F0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7ACF748B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 02:50:38,068:INFO:Checking exceptions
2024-05-29 02:50:38,068:INFO:Importing libraries
2024-05-29 02:50:38,069:INFO:Copying training dataset
2024-05-29 02:50:38,115:INFO:Defining folds
2024-05-29 02:50:38,116:INFO:Declaring metric variables
2024-05-29 02:50:38,121:INFO:Importing untrained model
2024-05-29 02:50:38,126:INFO:Decision Tree Classifier Imported successfully
2024-05-29 02:50:38,134:INFO:Starting cross validation
2024-05-29 02:50:38,135:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 02:50:38,913:INFO:Calculating mean and std
2024-05-29 02:50:38,916:INFO:Creating metrics dataframe
2024-05-29 02:50:38,918:INFO:Uploading results into container
2024-05-29 02:50:38,920:INFO:Uploading model into container now
2024-05-29 02:50:38,920:INFO:_master_model_container: 4
2024-05-29 02:50:38,921:INFO:_display_container: 2
2024-05-29 02:50:38,921:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=6389, splitter='best')
2024-05-29 02:50:38,921:INFO:create_model() successfully completed......................................
2024-05-29 02:50:39,945:INFO:SubProcess create_model() end ==================================
2024-05-29 02:50:39,945:INFO:Creating metrics dataframe
2024-05-29 02:50:39,956:INFO:Initializing SVM - Linear Kernel
2024-05-29 02:50:39,956:INFO:Total runtime is 0.4324041684468587 minutes
2024-05-29 02:50:39,960:INFO:SubProcess create_model() called ==================================
2024-05-29 02:50:39,961:INFO:Initializing create_model()
2024-05-29 02:50:39,961:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7B828D6F0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7ACF748B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 02:50:39,961:INFO:Checking exceptions
2024-05-29 02:50:39,961:INFO:Importing libraries
2024-05-29 02:50:39,962:INFO:Copying training dataset
2024-05-29 02:50:40,008:INFO:Defining folds
2024-05-29 02:50:40,008:INFO:Declaring metric variables
2024-05-29 02:50:40,012:INFO:Importing untrained model
2024-05-29 02:50:40,017:INFO:SVM - Linear Kernel Imported successfully
2024-05-29 02:50:40,025:INFO:Starting cross validation
2024-05-29 02:50:40,026:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 02:50:40,590:INFO:Calculating mean and std
2024-05-29 02:50:40,592:INFO:Creating metrics dataframe
2024-05-29 02:50:40,594:INFO:Uploading results into container
2024-05-29 02:50:40,595:INFO:Uploading model into container now
2024-05-29 02:50:40,596:INFO:_master_model_container: 5
2024-05-29 02:50:40,596:INFO:_display_container: 2
2024-05-29 02:50:40,597:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6389, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-29 02:50:40,597:INFO:create_model() successfully completed......................................
2024-05-29 02:50:41,593:INFO:SubProcess create_model() end ==================================
2024-05-29 02:50:41,593:INFO:Creating metrics dataframe
2024-05-29 02:50:41,604:INFO:Initializing Ridge Classifier
2024-05-29 02:50:41,604:INFO:Total runtime is 0.4598708073298136 minutes
2024-05-29 02:50:41,609:INFO:SubProcess create_model() called ==================================
2024-05-29 02:50:41,609:INFO:Initializing create_model()
2024-05-29 02:50:41,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7B828D6F0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7ACF748B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 02:50:41,609:INFO:Checking exceptions
2024-05-29 02:50:41,610:INFO:Importing libraries
2024-05-29 02:50:41,610:INFO:Copying training dataset
2024-05-29 02:50:41,655:INFO:Defining folds
2024-05-29 02:50:41,656:INFO:Declaring metric variables
2024-05-29 02:50:41,660:INFO:Importing untrained model
2024-05-29 02:50:41,664:INFO:Ridge Classifier Imported successfully
2024-05-29 02:50:41,672:INFO:Starting cross validation
2024-05-29 02:50:41,674:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 02:50:42,037:INFO:Calculating mean and std
2024-05-29 02:50:42,039:INFO:Creating metrics dataframe
2024-05-29 02:50:42,041:INFO:Uploading results into container
2024-05-29 02:50:42,042:INFO:Uploading model into container now
2024-05-29 02:50:42,043:INFO:_master_model_container: 6
2024-05-29 02:50:42,043:INFO:_display_container: 2
2024-05-29 02:50:42,043:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6389, solver='auto',
                tol=0.0001)
2024-05-29 02:50:42,044:INFO:create_model() successfully completed......................................
2024-05-29 02:50:43,116:INFO:SubProcess create_model() end ==================================
2024-05-29 02:50:43,116:INFO:Creating metrics dataframe
2024-05-29 02:50:43,128:INFO:Initializing Random Forest Classifier
2024-05-29 02:50:43,128:INFO:Total runtime is 0.4852707942326863 minutes
2024-05-29 02:50:43,132:INFO:SubProcess create_model() called ==================================
2024-05-29 02:50:43,133:INFO:Initializing create_model()
2024-05-29 02:50:43,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7B828D6F0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7ACF748B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 02:50:43,133:INFO:Checking exceptions
2024-05-29 02:50:43,133:INFO:Importing libraries
2024-05-29 02:50:43,134:INFO:Copying training dataset
2024-05-29 02:50:43,180:INFO:Defining folds
2024-05-29 02:50:43,180:INFO:Declaring metric variables
2024-05-29 02:50:43,184:INFO:Importing untrained model
2024-05-29 02:50:43,189:INFO:Random Forest Classifier Imported successfully
2024-05-29 02:50:43,197:INFO:Starting cross validation
2024-05-29 02:50:43,198:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 02:50:52,457:INFO:Calculating mean and std
2024-05-29 02:50:52,461:INFO:Creating metrics dataframe
2024-05-29 02:50:52,466:INFO:Uploading results into container
2024-05-29 02:50:52,468:INFO:Uploading model into container now
2024-05-29 02:50:52,469:INFO:_master_model_container: 7
2024-05-29 02:50:52,469:INFO:_display_container: 2
2024-05-29 02:50:52,471:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6389, verbose=0,
                       warm_start=False)
2024-05-29 02:50:52,471:INFO:create_model() successfully completed......................................
2024-05-29 02:50:53,544:INFO:SubProcess create_model() end ==================================
2024-05-29 02:50:53,544:INFO:Creating metrics dataframe
2024-05-29 02:50:53,557:INFO:Initializing Quadratic Discriminant Analysis
2024-05-29 02:50:53,557:INFO:Total runtime is 0.6590945363044738 minutes
2024-05-29 02:50:53,562:INFO:SubProcess create_model() called ==================================
2024-05-29 02:50:53,562:INFO:Initializing create_model()
2024-05-29 02:50:53,563:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7B828D6F0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7ACF748B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 02:50:53,563:INFO:Checking exceptions
2024-05-29 02:50:53,563:INFO:Importing libraries
2024-05-29 02:50:53,563:INFO:Copying training dataset
2024-05-29 02:50:53,610:INFO:Defining folds
2024-05-29 02:50:53,610:INFO:Declaring metric variables
2024-05-29 02:50:53,615:INFO:Importing untrained model
2024-05-29 02:50:53,619:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-29 02:50:53,627:INFO:Starting cross validation
2024-05-29 02:50:53,628:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 02:50:53,829:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-29 02:50:53,837:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-29 02:50:53,890:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-29 02:50:53,918:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-29 02:50:53,928:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-29 02:50:53,957:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-29 02:50:54,001:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-29 02:50:54,009:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-29 02:50:54,010:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-29 02:50:54,034:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-29 02:50:54,080:INFO:Calculating mean and std
2024-05-29 02:50:54,082:INFO:Creating metrics dataframe
2024-05-29 02:50:54,084:INFO:Uploading results into container
2024-05-29 02:50:54,085:INFO:Uploading model into container now
2024-05-29 02:50:54,086:INFO:_master_model_container: 8
2024-05-29 02:50:54,086:INFO:_display_container: 2
2024-05-29 02:50:54,086:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-29 02:50:54,086:INFO:create_model() successfully completed......................................
2024-05-29 02:50:55,072:INFO:SubProcess create_model() end ==================================
2024-05-29 02:50:55,072:INFO:Creating metrics dataframe
2024-05-29 02:50:55,085:INFO:Initializing Ada Boost Classifier
2024-05-29 02:50:55,085:INFO:Total runtime is 0.6845611770947774 minutes
2024-05-29 02:50:55,089:INFO:SubProcess create_model() called ==================================
2024-05-29 02:50:55,090:INFO:Initializing create_model()
2024-05-29 02:50:55,090:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7B828D6F0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7ACF748B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 02:50:55,090:INFO:Checking exceptions
2024-05-29 02:50:55,090:INFO:Importing libraries
2024-05-29 02:50:55,090:INFO:Copying training dataset
2024-05-29 02:50:55,137:INFO:Defining folds
2024-05-29 02:50:55,137:INFO:Declaring metric variables
2024-05-29 02:50:55,142:INFO:Importing untrained model
2024-05-29 02:50:55,146:INFO:Ada Boost Classifier Imported successfully
2024-05-29 02:50:55,154:INFO:Starting cross validation
2024-05-29 02:50:55,155:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 02:50:55,261:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 02:50:55,280:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 02:50:55,302:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 02:50:55,316:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 02:50:55,356:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 02:50:55,370:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 02:50:55,395:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 02:50:55,429:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 02:50:55,461:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 02:50:55,497:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 02:50:58,698:INFO:Calculating mean and std
2024-05-29 02:50:58,700:INFO:Creating metrics dataframe
2024-05-29 02:50:58,703:INFO:Uploading results into container
2024-05-29 02:50:58,704:INFO:Uploading model into container now
2024-05-29 02:50:58,704:INFO:_master_model_container: 9
2024-05-29 02:50:58,704:INFO:_display_container: 2
2024-05-29 02:50:58,705:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=6389)
2024-05-29 02:50:58,705:INFO:create_model() successfully completed......................................
2024-05-29 02:50:59,838:INFO:SubProcess create_model() end ==================================
2024-05-29 02:50:59,838:INFO:Creating metrics dataframe
2024-05-29 02:50:59,855:INFO:Initializing Gradient Boosting Classifier
2024-05-29 02:50:59,856:INFO:Total runtime is 0.764066755771637 minutes
2024-05-29 02:50:59,863:INFO:SubProcess create_model() called ==================================
2024-05-29 02:50:59,864:INFO:Initializing create_model()
2024-05-29 02:50:59,864:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7B828D6F0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7ACF748B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 02:50:59,865:INFO:Checking exceptions
2024-05-29 02:50:59,865:INFO:Importing libraries
2024-05-29 02:50:59,865:INFO:Copying training dataset
2024-05-29 02:50:59,928:INFO:Defining folds
2024-05-29 02:50:59,929:INFO:Declaring metric variables
2024-05-29 02:50:59,936:INFO:Importing untrained model
2024-05-29 02:50:59,943:INFO:Gradient Boosting Classifier Imported successfully
2024-05-29 02:50:59,956:INFO:Starting cross validation
2024-05-29 02:50:59,957:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 02:51:11,555:INFO:Calculating mean and std
2024-05-29 02:51:11,558:INFO:Creating metrics dataframe
2024-05-29 02:51:11,561:INFO:Uploading results into container
2024-05-29 02:51:11,562:INFO:Uploading model into container now
2024-05-29 02:51:11,563:INFO:_master_model_container: 10
2024-05-29 02:51:11,563:INFO:_display_container: 2
2024-05-29 02:51:11,563:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6389, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-29 02:51:11,564:INFO:create_model() successfully completed......................................
2024-05-29 02:51:12,692:INFO:SubProcess create_model() end ==================================
2024-05-29 02:51:12,692:INFO:Creating metrics dataframe
2024-05-29 02:51:12,708:INFO:Initializing Linear Discriminant Analysis
2024-05-29 02:51:12,709:INFO:Total runtime is 0.9782872398694357 minutes
2024-05-29 02:51:12,714:INFO:SubProcess create_model() called ==================================
2024-05-29 02:51:12,715:INFO:Initializing create_model()
2024-05-29 02:51:12,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7B828D6F0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7ACF748B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 02:51:12,715:INFO:Checking exceptions
2024-05-29 02:51:12,715:INFO:Importing libraries
2024-05-29 02:51:12,716:INFO:Copying training dataset
2024-05-29 02:51:12,773:INFO:Defining folds
2024-05-29 02:51:12,773:INFO:Declaring metric variables
2024-05-29 02:51:12,780:INFO:Importing untrained model
2024-05-29 02:51:12,785:INFO:Linear Discriminant Analysis Imported successfully
2024-05-29 02:51:12,796:INFO:Starting cross validation
2024-05-29 02:51:12,797:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 02:51:13,339:INFO:Calculating mean and std
2024-05-29 02:51:13,342:INFO:Creating metrics dataframe
2024-05-29 02:51:13,347:INFO:Uploading results into container
2024-05-29 02:51:13,348:INFO:Uploading model into container now
2024-05-29 02:51:13,349:INFO:_master_model_container: 11
2024-05-29 02:51:13,349:INFO:_display_container: 2
2024-05-29 02:51:13,350:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-29 02:51:13,350:INFO:create_model() successfully completed......................................
2024-05-29 02:51:14,497:INFO:SubProcess create_model() end ==================================
2024-05-29 02:51:14,497:INFO:Creating metrics dataframe
2024-05-29 02:51:14,513:INFO:Initializing Extra Trees Classifier
2024-05-29 02:51:14,513:INFO:Total runtime is 1.008353833357493 minutes
2024-05-29 02:51:14,518:INFO:SubProcess create_model() called ==================================
2024-05-29 02:51:14,518:INFO:Initializing create_model()
2024-05-29 02:51:14,518:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7B828D6F0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7ACF748B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 02:51:14,519:INFO:Checking exceptions
2024-05-29 02:51:14,519:INFO:Importing libraries
2024-05-29 02:51:14,519:INFO:Copying training dataset
2024-05-29 02:51:14,567:INFO:Defining folds
2024-05-29 02:51:14,567:INFO:Declaring metric variables
2024-05-29 02:51:14,573:INFO:Importing untrained model
2024-05-29 02:51:14,578:INFO:Extra Trees Classifier Imported successfully
2024-05-29 02:51:14,587:INFO:Starting cross validation
2024-05-29 02:51:14,588:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 02:51:23,937:INFO:Calculating mean and std
2024-05-29 02:51:23,939:INFO:Creating metrics dataframe
2024-05-29 02:51:23,943:INFO:Uploading results into container
2024-05-29 02:51:23,944:INFO:Uploading model into container now
2024-05-29 02:51:23,945:INFO:_master_model_container: 12
2024-05-29 02:51:23,945:INFO:_display_container: 2
2024-05-29 02:51:23,946:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=6389, verbose=0,
                     warm_start=False)
2024-05-29 02:51:23,946:INFO:create_model() successfully completed......................................
2024-05-29 02:51:24,961:INFO:SubProcess create_model() end ==================================
2024-05-29 02:51:24,962:INFO:Creating metrics dataframe
2024-05-29 02:51:24,977:INFO:Initializing Extreme Gradient Boosting
2024-05-29 02:51:24,977:INFO:Total runtime is 1.1827565670013427 minutes
2024-05-29 02:51:24,981:INFO:SubProcess create_model() called ==================================
2024-05-29 02:51:24,982:INFO:Initializing create_model()
2024-05-29 02:51:24,982:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7B828D6F0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7ACF748B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 02:51:24,982:INFO:Checking exceptions
2024-05-29 02:51:24,982:INFO:Importing libraries
2024-05-29 02:51:24,982:INFO:Copying training dataset
2024-05-29 02:51:25,043:INFO:Defining folds
2024-05-29 02:51:25,043:INFO:Declaring metric variables
2024-05-29 02:51:25,051:INFO:Importing untrained model
2024-05-29 02:51:25,060:INFO:Extreme Gradient Boosting Imported successfully
2024-05-29 02:51:25,073:INFO:Starting cross validation
2024-05-29 02:51:25,075:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 02:51:26,767:INFO:Calculating mean and std
2024-05-29 02:51:26,769:INFO:Creating metrics dataframe
2024-05-29 02:51:26,772:INFO:Uploading results into container
2024-05-29 02:51:26,773:INFO:Uploading model into container now
2024-05-29 02:51:26,774:INFO:_master_model_container: 13
2024-05-29 02:51:26,774:INFO:_display_container: 2
2024-05-29 02:51:26,775:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-29 02:51:26,776:INFO:create_model() successfully completed......................................
2024-05-29 02:51:27,915:INFO:SubProcess create_model() end ==================================
2024-05-29 02:51:27,916:INFO:Creating metrics dataframe
2024-05-29 02:51:27,940:INFO:Initializing Light Gradient Boosting Machine
2024-05-29 02:51:27,940:INFO:Total runtime is 1.2321380694707234 minutes
2024-05-29 02:51:27,946:INFO:SubProcess create_model() called ==================================
2024-05-29 02:51:27,946:INFO:Initializing create_model()
2024-05-29 02:51:27,947:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7B828D6F0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7ACF748B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 02:51:27,947:INFO:Checking exceptions
2024-05-29 02:51:27,947:INFO:Importing libraries
2024-05-29 02:51:27,947:INFO:Copying training dataset
2024-05-29 02:51:28,007:INFO:Defining folds
2024-05-29 02:51:28,007:INFO:Declaring metric variables
2024-05-29 02:51:28,014:INFO:Importing untrained model
2024-05-29 02:51:28,023:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-29 02:51:28,036:INFO:Starting cross validation
2024-05-29 02:51:28,037:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 02:51:30,763:INFO:Calculating mean and std
2024-05-29 02:51:30,765:INFO:Creating metrics dataframe
2024-05-29 02:51:30,768:INFO:Uploading results into container
2024-05-29 02:51:30,769:INFO:Uploading model into container now
2024-05-29 02:51:30,770:INFO:_master_model_container: 14
2024-05-29 02:51:30,770:INFO:_display_container: 2
2024-05-29 02:51:30,771:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6389, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-29 02:51:30,771:INFO:create_model() successfully completed......................................
2024-05-29 02:51:31,887:INFO:SubProcess create_model() end ==================================
2024-05-29 02:51:31,887:INFO:Creating metrics dataframe
2024-05-29 02:51:31,903:INFO:Initializing Dummy Classifier
2024-05-29 02:51:31,903:INFO:Total runtime is 1.2981932838757833 minutes
2024-05-29 02:51:31,908:INFO:SubProcess create_model() called ==================================
2024-05-29 02:51:31,909:INFO:Initializing create_model()
2024-05-29 02:51:31,909:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7B828D6F0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7ACF748B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 02:51:31,909:INFO:Checking exceptions
2024-05-29 02:51:31,909:INFO:Importing libraries
2024-05-29 02:51:31,909:INFO:Copying training dataset
2024-05-29 02:51:31,956:INFO:Defining folds
2024-05-29 02:51:31,957:INFO:Declaring metric variables
2024-05-29 02:51:31,961:INFO:Importing untrained model
2024-05-29 02:51:31,965:INFO:Dummy Classifier Imported successfully
2024-05-29 02:51:31,973:INFO:Starting cross validation
2024-05-29 02:51:31,974:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 02:51:32,121:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 02:51:32,139:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 02:51:32,149:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 02:51:32,186:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 02:51:32,202:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 02:51:32,224:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 02:51:32,246:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 02:51:32,263:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 02:51:32,280:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 02:51:32,293:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 02:51:32,312:INFO:Calculating mean and std
2024-05-29 02:51:32,314:INFO:Creating metrics dataframe
2024-05-29 02:51:32,317:INFO:Uploading results into container
2024-05-29 02:51:32,317:INFO:Uploading model into container now
2024-05-29 02:51:32,318:INFO:_master_model_container: 15
2024-05-29 02:51:32,318:INFO:_display_container: 2
2024-05-29 02:51:32,319:INFO:DummyClassifier(constant=None, random_state=6389, strategy='prior')
2024-05-29 02:51:32,319:INFO:create_model() successfully completed......................................
2024-05-29 02:51:33,475:INFO:SubProcess create_model() end ==================================
2024-05-29 02:51:33,475:INFO:Creating metrics dataframe
2024-05-29 02:51:33,503:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-29 02:51:33,517:INFO:Initializing create_model()
2024-05-29 02:51:33,518:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7B828D6F0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 02:51:33,518:INFO:Checking exceptions
2024-05-29 02:51:33,520:INFO:Importing libraries
2024-05-29 02:51:33,521:INFO:Copying training dataset
2024-05-29 02:51:33,570:INFO:Defining folds
2024-05-29 02:51:33,570:INFO:Declaring metric variables
2024-05-29 02:51:33,570:INFO:Importing untrained model
2024-05-29 02:51:33,570:INFO:Declaring custom model
2024-05-29 02:51:33,573:INFO:Extreme Gradient Boosting Imported successfully
2024-05-29 02:51:33,574:INFO:Cross validation set to False
2024-05-29 02:51:33,574:INFO:Fitting Model
2024-05-29 02:51:33,980:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-29 02:51:33,980:INFO:create_model() successfully completed......................................
2024-05-29 02:51:35,192:INFO:Creating Dashboard logs
2024-05-29 02:51:35,200:INFO:Model: Extreme Gradient Boosting
2024-05-29 02:51:35,288:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 6389, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2024-05-29 02:51:35,616:INFO:Initializing predict_model()
2024-05-29 02:51:35,616:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7B828D6F0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E7AE5800D0>)
2024-05-29 02:51:35,616:INFO:Checking exceptions
2024-05-29 02:51:35,616:INFO:Preloading libraries
2024-05-29 02:51:36,910:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2024-05-29 02:51:40,548:INFO:Creating Dashboard logs
2024-05-29 02:51:40,556:INFO:Model: Light Gradient Boosting Machine
2024-05-29 02:51:40,644:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 6389, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-05-29 02:51:42,038:INFO:Creating Dashboard logs
2024-05-29 02:51:42,043:INFO:Model: Random Forest Classifier
2024-05-29 02:51:42,127:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 6389, 'verbose': 0, 'warm_start': False}
2024-05-29 02:51:43,499:INFO:Creating Dashboard logs
2024-05-29 02:51:43,503:INFO:Model: Gradient Boosting Classifier
2024-05-29 02:51:43,590:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 6389, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-29 02:51:44,934:INFO:Creating Dashboard logs
2024-05-29 02:51:44,938:INFO:Model: Ada Boost Classifier
2024-05-29 02:51:45,027:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 6389}
2024-05-29 02:51:46,410:INFO:Creating Dashboard logs
2024-05-29 02:51:46,415:INFO:Model: Extra Trees Classifier
2024-05-29 02:51:46,500:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 6389, 'verbose': 0, 'warm_start': False}
2024-05-29 02:51:47,860:INFO:Creating Dashboard logs
2024-05-29 02:51:47,864:INFO:Model: Logistic Regression
2024-05-29 02:51:47,947:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 6389, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-05-29 02:51:49,253:INFO:Creating Dashboard logs
2024-05-29 02:51:49,258:INFO:Model: SVM - Linear Kernel
2024-05-29 02:51:49,345:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 6389, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-29 02:51:50,691:INFO:Creating Dashboard logs
2024-05-29 02:51:50,695:INFO:Model: Ridge Classifier
2024-05-29 02:51:50,779:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 6389, 'solver': 'auto', 'tol': 0.0001}
2024-05-29 02:51:52,080:INFO:Creating Dashboard logs
2024-05-29 02:51:52,085:INFO:Model: Linear Discriminant Analysis
2024-05-29 02:51:52,171:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-05-29 02:51:53,511:INFO:Creating Dashboard logs
2024-05-29 02:51:53,516:INFO:Model: K Neighbors Classifier
2024-05-29 02:51:53,598:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2024-05-29 02:51:54,980:INFO:Creating Dashboard logs
2024-05-29 02:51:54,985:INFO:Model: Decision Tree Classifier
2024-05-29 02:51:55,070:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 6389, 'splitter': 'best'}
2024-05-29 02:51:56,537:INFO:Creating Dashboard logs
2024-05-29 02:51:56,545:INFO:Model: Naive Bayes
2024-05-29 02:51:56,631:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-05-29 02:51:58,129:INFO:Creating Dashboard logs
2024-05-29 02:51:58,135:INFO:Model: Quadratic Discriminant Analysis
2024-05-29 02:51:58,279:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2024-05-29 02:51:59,730:INFO:Creating Dashboard logs
2024-05-29 02:51:59,735:INFO:Model: Dummy Classifier
2024-05-29 02:51:59,819:INFO:Logged params: {'constant': None, 'random_state': 6389, 'strategy': 'prior'}
2024-05-29 02:52:01,163:INFO:_master_model_container: 15
2024-05-29 02:52:01,164:INFO:_display_container: 2
2024-05-29 02:52:01,165:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-29 02:52:01,165:INFO:compare_models() successfully completed......................................
2024-05-29 03:51:32,517:INFO:PyCaret ClassificationExperiment
2024-05-29 03:51:32,517:INFO:Logging name: codex
2024-05-29 03:51:32,517:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 03:51:32,517:INFO:version 3.3.2
2024-05-29 03:51:32,517:INFO:Initializing setup()
2024-05-29 03:51:32,517:INFO:self.USI: cb47
2024-05-29 03:51:32,518:INFO:self._variable_keys: {'y_train', 'seed', 'target_param', 'X_train', 'memory', 'USI', 'data', 'is_multiclass', '_available_plots', 'fold_shuffle_param', 'pipeline', 'fold_generator', 'X_test', 'fix_imbalance', 'fold_groups_param', 'gpu_param', 'log_plots_param', 'exp_name_log', 'X', 'html_param', 'idx', 'logging_param', '_ml_usecase', 'y', 'gpu_n_jobs_param', 'exp_id', 'y_test', 'n_jobs_param'}
2024-05-29 03:51:32,518:INFO:Checking environment
2024-05-29 03:51:32,518:INFO:python_version: 3.10.13
2024-05-29 03:51:32,518:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 03:51:32,518:INFO:machine: AMD64
2024-05-29 03:51:32,518:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 03:51:32,518:INFO:Memory: svmem(total=34267656192, available=18125115392, percent=47.1, used=16142540800, free=18125115392)
2024-05-29 03:51:32,518:INFO:Physical Core: 8
2024-05-29 03:51:32,518:INFO:Logical Core: 16
2024-05-29 03:51:32,519:INFO:Checking libraries
2024-05-29 03:51:32,519:INFO:System:
2024-05-29 03:51:32,519:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 03:51:32,519:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 03:51:32,519:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 03:51:32,519:INFO:PyCaret required dependencies:
2024-05-29 03:51:32,519:INFO:                 pip: 23.3
2024-05-29 03:51:32,519:INFO:          setuptools: 68.0.0
2024-05-29 03:51:32,519:INFO:             pycaret: 3.3.2
2024-05-29 03:51:32,519:INFO:             IPython: 8.24.0
2024-05-29 03:51:32,520:INFO:          ipywidgets: 8.1.2
2024-05-29 03:51:32,520:INFO:                tqdm: 4.66.4
2024-05-29 03:51:32,520:INFO:               numpy: 1.26.4
2024-05-29 03:51:32,520:INFO:              pandas: 2.1.4
2024-05-29 03:51:32,520:INFO:              jinja2: 3.1.4
2024-05-29 03:51:32,520:INFO:               scipy: 1.11.4
2024-05-29 03:51:32,520:INFO:              joblib: 1.3.2
2024-05-29 03:51:32,520:INFO:             sklearn: 1.4.2
2024-05-29 03:51:32,520:INFO:                pyod: 1.1.3
2024-05-29 03:51:32,520:INFO:            imblearn: 0.12.2
2024-05-29 03:51:32,520:INFO:   category_encoders: 2.6.3
2024-05-29 03:51:32,520:INFO:            lightgbm: 4.3.0
2024-05-29 03:51:32,521:INFO:               numba: 0.59.1
2024-05-29 03:51:32,521:INFO:            requests: 2.32.2
2024-05-29 03:51:32,521:INFO:          matplotlib: 3.7.5
2024-05-29 03:51:32,521:INFO:          scikitplot: 0.3.7
2024-05-29 03:51:32,521:INFO:         yellowbrick: 1.5
2024-05-29 03:51:32,521:INFO:              plotly: 5.22.0
2024-05-29 03:51:32,521:INFO:    plotly-resampler: Not installed
2024-05-29 03:51:32,521:INFO:             kaleido: 0.2.1
2024-05-29 03:51:32,521:INFO:           schemdraw: 0.15
2024-05-29 03:51:32,521:INFO:         statsmodels: 0.14.2
2024-05-29 03:51:32,521:INFO:              sktime: 0.26.0
2024-05-29 03:51:32,521:INFO:               tbats: 1.1.3
2024-05-29 03:51:32,522:INFO:            pmdarima: 2.0.4
2024-05-29 03:51:32,522:INFO:              psutil: 5.9.0
2024-05-29 03:51:32,522:INFO:          markupsafe: 2.1.5
2024-05-29 03:51:32,522:INFO:             pickle5: Not installed
2024-05-29 03:51:32,522:INFO:         cloudpickle: 3.0.0
2024-05-29 03:51:32,522:INFO:         deprecation: 2.1.0
2024-05-29 03:51:32,522:INFO:              xxhash: 3.4.1
2024-05-29 03:51:32,522:INFO:           wurlitzer: Not installed
2024-05-29 03:51:32,522:INFO:PyCaret optional dependencies:
2024-05-29 03:51:32,523:INFO:                shap: Not installed
2024-05-29 03:51:32,523:INFO:           interpret: Not installed
2024-05-29 03:51:32,523:INFO:                umap: Not installed
2024-05-29 03:51:32,523:INFO:     ydata_profiling: Not installed
2024-05-29 03:51:32,523:INFO:  explainerdashboard: Not installed
2024-05-29 03:51:32,523:INFO:             autoviz: Not installed
2024-05-29 03:51:32,523:INFO:           fairlearn: Not installed
2024-05-29 03:51:32,523:INFO:          deepchecks: Not installed
2024-05-29 03:51:32,523:INFO:             xgboost: 2.0.3
2024-05-29 03:51:32,523:INFO:            catboost: Not installed
2024-05-29 03:51:32,524:INFO:              kmodes: Not installed
2024-05-29 03:51:32,524:INFO:             mlxtend: Not installed
2024-05-29 03:51:32,524:INFO:       statsforecast: Not installed
2024-05-29 03:51:32,524:INFO:        tune_sklearn: Not installed
2024-05-29 03:51:32,524:INFO:                 ray: Not installed
2024-05-29 03:51:32,524:INFO:            hyperopt: Not installed
2024-05-29 03:51:32,524:INFO:              optuna: Not installed
2024-05-29 03:51:32,524:INFO:               skopt: Not installed
2024-05-29 03:51:32,524:INFO:              mlflow: 2.13.0
2024-05-29 03:51:32,524:INFO:              gradio: Not installed
2024-05-29 03:51:32,524:INFO:             fastapi: Not installed
2024-05-29 03:51:32,524:INFO:             uvicorn: Not installed
2024-05-29 03:51:32,525:INFO:              m2cgen: Not installed
2024-05-29 03:51:32,525:INFO:           evidently: Not installed
2024-05-29 03:51:32,525:INFO:               fugue: Not installed
2024-05-29 03:51:32,525:INFO:           streamlit: Not installed
2024-05-29 03:51:32,525:INFO:             prophet: Not installed
2024-05-29 03:51:32,525:INFO:None
2024-05-29 03:51:32,525:INFO:Set up data.
2024-05-29 03:51:32,554:INFO:Set up folding strategy.
2024-05-29 03:51:32,554:INFO:Set up train/test split.
2024-05-29 03:51:32,611:INFO:Set up index.
2024-05-29 03:51:32,613:INFO:Assigning column types.
2024-05-29 03:51:32,647:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 03:51:32,716:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 03:51:32,718:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 03:51:32,762:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 03:51:32,766:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 03:51:32,836:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 03:51:32,837:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 03:51:32,881:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 03:51:32,886:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 03:51:32,886:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 03:51:32,957:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 03:51:33,001:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 03:51:33,005:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 03:51:33,077:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 03:51:33,121:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 03:51:33,125:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 03:51:33,125:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 03:51:33,241:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 03:51:33,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 03:51:33,367:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 03:51:33,374:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 03:51:33,378:INFO:Preparing preprocessing pipeline...
2024-05-29 03:51:33,390:INFO:Set up simple imputation.
2024-05-29 03:51:33,495:INFO:Finished creating preprocessing pipeline.
2024-05-29 03:51:33,500:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'featu...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-05-29 03:51:33,501:INFO:Creating final display dataframe.
2024-05-29 03:51:33,785:INFO:Setup _display_container:                     Description            Value
0                    Session id             2036
1                        Target           target
2                   Target type           Binary
3           Original data shape      (90000, 18)
4        Transformed data shape      (90000, 18)
5   Transformed train set shape      (72000, 18)
6    Transformed test set shape      (18000, 18)
7              Numeric features               17
8                    Preprocess             True
9               Imputation type           simple
10           Numeric imputation             mean
11       Categorical imputation             mode
12               Fold Generator  StratifiedKFold
13                  Fold Number               10
14                     CPU Jobs               -1
15                      Use GPU            False
16               Log Experiment     MlflowLogger
17              Experiment Name            codex
18                          USI             cb47
2024-05-29 03:51:33,933:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 03:51:33,938:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 03:51:34,076:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 03:51:34,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 03:51:34,082:INFO:Logging experiment in loggers
2024-05-29 03:51:34,241:INFO:SubProcess save_model() called ==================================
2024-05-29 03:51:34,253:INFO:Initializing save_model()
2024-05-29 03:51:34,253:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'featu...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), model_name=C:\Users\Adm\AppData\Local\Temp\tmp20ftqi1u\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'featu...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-29 03:51:34,253:INFO:Adding model into prep_pipe
2024-05-29 03:51:34,253:WARNING:Only Model saved as it was a pipeline.
2024-05-29 03:51:34,260:INFO:C:\Users\Adm\AppData\Local\Temp\tmp20ftqi1u\Transformation Pipeline.pkl saved in current working directory
2024-05-29 03:51:34,266:INFO:Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'featu...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-05-29 03:51:34,266:INFO:save_model() successfully completed......................................
2024-05-29 03:51:35,269:INFO:SubProcess save_model() end ==================================
2024-05-29 03:51:35,296:INFO:setup() successfully completed in 1.61s...............
2024-05-29 03:51:35,334:INFO:Initializing compare_models()
2024-05-29 03:51:35,334:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7AE1A7D00>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E7AE1A7D00>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-29 03:51:35,334:INFO:Checking exceptions
2024-05-29 03:51:35,362:INFO:Preparing display monitor
2024-05-29 03:51:35,388:INFO:Initializing Logistic Regression
2024-05-29 03:51:35,388:INFO:Total runtime is 0.0 minutes
2024-05-29 03:51:35,392:INFO:SubProcess create_model() called ==================================
2024-05-29 03:51:35,392:INFO:Initializing create_model()
2024-05-29 03:51:35,393:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7AE1A7D00>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7B82BDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 03:51:35,393:INFO:Checking exceptions
2024-05-29 03:51:35,393:INFO:Importing libraries
2024-05-29 03:51:35,393:INFO:Copying training dataset
2024-05-29 03:51:35,440:INFO:Defining folds
2024-05-29 03:51:35,441:INFO:Declaring metric variables
2024-05-29 03:51:35,445:INFO:Importing untrained model
2024-05-29 03:51:35,449:INFO:Logistic Regression Imported successfully
2024-05-29 03:51:35,457:INFO:Starting cross validation
2024-05-29 03:51:35,458:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 03:51:42,070:INFO:Calculating mean and std
2024-05-29 03:51:42,072:INFO:Creating metrics dataframe
2024-05-29 03:51:42,076:INFO:Uploading results into container
2024-05-29 03:51:42,077:INFO:Uploading model into container now
2024-05-29 03:51:42,078:INFO:_master_model_container: 1
2024-05-29 03:51:42,079:INFO:_display_container: 2
2024-05-29 03:51:42,079:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2036, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-29 03:51:42,080:INFO:create_model() successfully completed......................................
2024-05-29 03:51:43,117:INFO:SubProcess create_model() end ==================================
2024-05-29 03:51:43,117:INFO:Creating metrics dataframe
2024-05-29 03:51:43,128:INFO:Initializing K Neighbors Classifier
2024-05-29 03:51:43,128:INFO:Total runtime is 0.12900002797444662 minutes
2024-05-29 03:51:43,133:INFO:SubProcess create_model() called ==================================
2024-05-29 03:51:43,134:INFO:Initializing create_model()
2024-05-29 03:51:43,134:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7AE1A7D00>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7B82BDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 03:51:43,134:INFO:Checking exceptions
2024-05-29 03:51:43,134:INFO:Importing libraries
2024-05-29 03:51:43,135:INFO:Copying training dataset
2024-05-29 03:51:43,184:INFO:Defining folds
2024-05-29 03:51:43,184:INFO:Declaring metric variables
2024-05-29 03:51:43,189:INFO:Importing untrained model
2024-05-29 03:51:43,194:INFO:K Neighbors Classifier Imported successfully
2024-05-29 03:51:43,202:INFO:Starting cross validation
2024-05-29 03:51:43,204:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 03:51:57,077:INFO:Calculating mean and std
2024-05-29 03:51:57,079:INFO:Creating metrics dataframe
2024-05-29 03:51:57,083:INFO:Uploading results into container
2024-05-29 03:51:57,084:INFO:Uploading model into container now
2024-05-29 03:51:57,084:INFO:_master_model_container: 2
2024-05-29 03:51:57,085:INFO:_display_container: 2
2024-05-29 03:51:57,085:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-29 03:51:57,086:INFO:create_model() successfully completed......................................
2024-05-29 03:51:58,104:INFO:SubProcess create_model() end ==================================
2024-05-29 03:51:58,104:INFO:Creating metrics dataframe
2024-05-29 03:51:58,114:INFO:Initializing Naive Bayes
2024-05-29 03:51:58,114:INFO:Total runtime is 0.37876165707906084 minutes
2024-05-29 03:51:58,119:INFO:SubProcess create_model() called ==================================
2024-05-29 03:51:58,120:INFO:Initializing create_model()
2024-05-29 03:51:58,120:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7AE1A7D00>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7B82BDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 03:51:58,120:INFO:Checking exceptions
2024-05-29 03:51:58,120:INFO:Importing libraries
2024-05-29 03:51:58,120:INFO:Copying training dataset
2024-05-29 03:51:58,167:INFO:Defining folds
2024-05-29 03:51:58,167:INFO:Declaring metric variables
2024-05-29 03:51:58,171:INFO:Importing untrained model
2024-05-29 03:51:58,176:INFO:Naive Bayes Imported successfully
2024-05-29 03:51:58,184:INFO:Starting cross validation
2024-05-29 03:51:58,185:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 03:51:58,571:INFO:Calculating mean and std
2024-05-29 03:51:58,573:INFO:Creating metrics dataframe
2024-05-29 03:51:58,575:INFO:Uploading results into container
2024-05-29 03:51:58,576:INFO:Uploading model into container now
2024-05-29 03:51:58,576:INFO:_master_model_container: 3
2024-05-29 03:51:58,576:INFO:_display_container: 2
2024-05-29 03:51:58,577:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-29 03:51:58,577:INFO:create_model() successfully completed......................................
2024-05-29 03:51:59,636:INFO:SubProcess create_model() end ==================================
2024-05-29 03:51:59,637:INFO:Creating metrics dataframe
2024-05-29 03:51:59,649:INFO:Initializing Decision Tree Classifier
2024-05-29 03:51:59,649:INFO:Total runtime is 0.4043370405832926 minutes
2024-05-29 03:51:59,654:INFO:SubProcess create_model() called ==================================
2024-05-29 03:51:59,654:INFO:Initializing create_model()
2024-05-29 03:51:59,654:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7AE1A7D00>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7B82BDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 03:51:59,655:INFO:Checking exceptions
2024-05-29 03:51:59,655:INFO:Importing libraries
2024-05-29 03:51:59,655:INFO:Copying training dataset
2024-05-29 03:51:59,708:INFO:Defining folds
2024-05-29 03:51:59,709:INFO:Declaring metric variables
2024-05-29 03:51:59,715:INFO:Importing untrained model
2024-05-29 03:51:59,720:INFO:Decision Tree Classifier Imported successfully
2024-05-29 03:51:59,729:INFO:Starting cross validation
2024-05-29 03:51:59,731:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 03:52:00,443:INFO:Calculating mean and std
2024-05-29 03:52:00,445:INFO:Creating metrics dataframe
2024-05-29 03:52:00,447:INFO:Uploading results into container
2024-05-29 03:52:00,448:INFO:Uploading model into container now
2024-05-29 03:52:00,448:INFO:_master_model_container: 4
2024-05-29 03:52:00,449:INFO:_display_container: 2
2024-05-29 03:52:00,449:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2036, splitter='best')
2024-05-29 03:52:00,449:INFO:create_model() successfully completed......................................
2024-05-29 03:52:01,465:INFO:SubProcess create_model() end ==================================
2024-05-29 03:52:01,465:INFO:Creating metrics dataframe
2024-05-29 03:52:01,476:INFO:Initializing SVM - Linear Kernel
2024-05-29 03:52:01,476:INFO:Total runtime is 0.43478702306747435 minutes
2024-05-29 03:52:01,480:INFO:SubProcess create_model() called ==================================
2024-05-29 03:52:01,481:INFO:Initializing create_model()
2024-05-29 03:52:01,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7AE1A7D00>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7B82BDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 03:52:01,481:INFO:Checking exceptions
2024-05-29 03:52:01,481:INFO:Importing libraries
2024-05-29 03:52:01,482:INFO:Copying training dataset
2024-05-29 03:52:01,529:INFO:Defining folds
2024-05-29 03:52:01,529:INFO:Declaring metric variables
2024-05-29 03:52:01,533:INFO:Importing untrained model
2024-05-29 03:52:01,538:INFO:SVM - Linear Kernel Imported successfully
2024-05-29 03:52:01,546:INFO:Starting cross validation
2024-05-29 03:52:01,547:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 03:52:02,067:INFO:Calculating mean and std
2024-05-29 03:52:02,069:INFO:Creating metrics dataframe
2024-05-29 03:52:02,071:INFO:Uploading results into container
2024-05-29 03:52:02,072:INFO:Uploading model into container now
2024-05-29 03:52:02,072:INFO:_master_model_container: 5
2024-05-29 03:52:02,072:INFO:_display_container: 2
2024-05-29 03:52:02,073:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2036, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-29 03:52:02,073:INFO:create_model() successfully completed......................................
2024-05-29 03:52:03,087:INFO:SubProcess create_model() end ==================================
2024-05-29 03:52:03,088:INFO:Creating metrics dataframe
2024-05-29 03:52:03,100:INFO:Initializing Ridge Classifier
2024-05-29 03:52:03,100:INFO:Total runtime is 0.46185372273127234 minutes
2024-05-29 03:52:03,105:INFO:SubProcess create_model() called ==================================
2024-05-29 03:52:03,105:INFO:Initializing create_model()
2024-05-29 03:52:03,105:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7AE1A7D00>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7B82BDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 03:52:03,106:INFO:Checking exceptions
2024-05-29 03:52:03,106:INFO:Importing libraries
2024-05-29 03:52:03,106:INFO:Copying training dataset
2024-05-29 03:52:03,157:INFO:Defining folds
2024-05-29 03:52:03,157:INFO:Declaring metric variables
2024-05-29 03:52:03,162:INFO:Importing untrained model
2024-05-29 03:52:03,167:INFO:Ridge Classifier Imported successfully
2024-05-29 03:52:03,175:INFO:Starting cross validation
2024-05-29 03:52:03,176:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 03:52:03,546:INFO:Calculating mean and std
2024-05-29 03:52:03,548:INFO:Creating metrics dataframe
2024-05-29 03:52:03,550:INFO:Uploading results into container
2024-05-29 03:52:03,551:INFO:Uploading model into container now
2024-05-29 03:52:03,551:INFO:_master_model_container: 6
2024-05-29 03:52:03,551:INFO:_display_container: 2
2024-05-29 03:52:03,552:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2036, solver='auto',
                tol=0.0001)
2024-05-29 03:52:03,552:INFO:create_model() successfully completed......................................
2024-05-29 03:52:04,550:INFO:SubProcess create_model() end ==================================
2024-05-29 03:52:04,550:INFO:Creating metrics dataframe
2024-05-29 03:52:04,561:INFO:Initializing Random Forest Classifier
2024-05-29 03:52:04,561:INFO:Total runtime is 0.48620374600092564 minutes
2024-05-29 03:52:04,566:INFO:SubProcess create_model() called ==================================
2024-05-29 03:52:04,566:INFO:Initializing create_model()
2024-05-29 03:52:04,567:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7AE1A7D00>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7B82BDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 03:52:04,567:INFO:Checking exceptions
2024-05-29 03:52:04,567:INFO:Importing libraries
2024-05-29 03:52:04,567:INFO:Copying training dataset
2024-05-29 03:52:04,614:INFO:Defining folds
2024-05-29 03:52:04,614:INFO:Declaring metric variables
2024-05-29 03:52:04,619:INFO:Importing untrained model
2024-05-29 03:52:04,623:INFO:Random Forest Classifier Imported successfully
2024-05-29 03:52:04,631:INFO:Starting cross validation
2024-05-29 03:52:04,633:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 03:52:13,073:INFO:Calculating mean and std
2024-05-29 03:52:13,075:INFO:Creating metrics dataframe
2024-05-29 03:52:13,078:INFO:Uploading results into container
2024-05-29 03:52:13,079:INFO:Uploading model into container now
2024-05-29 03:52:13,080:INFO:_master_model_container: 7
2024-05-29 03:52:13,080:INFO:_display_container: 2
2024-05-29 03:52:13,081:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2036, verbose=0,
                       warm_start=False)
2024-05-29 03:52:13,081:INFO:create_model() successfully completed......................................
2024-05-29 03:52:14,122:INFO:SubProcess create_model() end ==================================
2024-05-29 03:52:14,122:INFO:Creating metrics dataframe
2024-05-29 03:52:14,136:INFO:Initializing Quadratic Discriminant Analysis
2024-05-29 03:52:14,137:INFO:Total runtime is 0.6458055774370829 minutes
2024-05-29 03:52:14,142:INFO:SubProcess create_model() called ==================================
2024-05-29 03:52:14,143:INFO:Initializing create_model()
2024-05-29 03:52:14,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7AE1A7D00>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7B82BDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 03:52:14,143:INFO:Checking exceptions
2024-05-29 03:52:14,143:INFO:Importing libraries
2024-05-29 03:52:14,143:INFO:Copying training dataset
2024-05-29 03:52:14,191:INFO:Defining folds
2024-05-29 03:52:14,191:INFO:Declaring metric variables
2024-05-29 03:52:14,196:INFO:Importing untrained model
2024-05-29 03:52:14,201:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-29 03:52:14,210:INFO:Starting cross validation
2024-05-29 03:52:14,211:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 03:52:14,698:INFO:Calculating mean and std
2024-05-29 03:52:14,700:INFO:Creating metrics dataframe
2024-05-29 03:52:14,703:INFO:Uploading results into container
2024-05-29 03:52:14,704:INFO:Uploading model into container now
2024-05-29 03:52:14,704:INFO:_master_model_container: 8
2024-05-29 03:52:14,705:INFO:_display_container: 2
2024-05-29 03:52:14,705:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-29 03:52:14,705:INFO:create_model() successfully completed......................................
2024-05-29 03:52:15,710:INFO:SubProcess create_model() end ==================================
2024-05-29 03:52:15,710:INFO:Creating metrics dataframe
2024-05-29 03:52:15,723:INFO:Initializing Ada Boost Classifier
2024-05-29 03:52:15,723:INFO:Total runtime is 0.6722432812054951 minutes
2024-05-29 03:52:15,727:INFO:SubProcess create_model() called ==================================
2024-05-29 03:52:15,728:INFO:Initializing create_model()
2024-05-29 03:52:15,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7AE1A7D00>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7B82BDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 03:52:15,728:INFO:Checking exceptions
2024-05-29 03:52:15,729:INFO:Importing libraries
2024-05-29 03:52:15,729:INFO:Copying training dataset
2024-05-29 03:52:15,776:INFO:Defining folds
2024-05-29 03:52:15,776:INFO:Declaring metric variables
2024-05-29 03:52:15,781:INFO:Importing untrained model
2024-05-29 03:52:15,785:INFO:Ada Boost Classifier Imported successfully
2024-05-29 03:52:15,793:INFO:Starting cross validation
2024-05-29 03:52:15,794:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 03:52:15,896:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 03:52:15,920:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 03:52:15,947:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 03:52:15,961:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 03:52:15,977:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 03:52:16,009:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 03:52:16,051:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 03:52:16,074:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 03:52:16,086:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 03:52:16,104:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 03:52:19,072:INFO:Calculating mean and std
2024-05-29 03:52:19,074:INFO:Creating metrics dataframe
2024-05-29 03:52:19,076:INFO:Uploading results into container
2024-05-29 03:52:19,077:INFO:Uploading model into container now
2024-05-29 03:52:19,078:INFO:_master_model_container: 9
2024-05-29 03:52:19,078:INFO:_display_container: 2
2024-05-29 03:52:19,079:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2036)
2024-05-29 03:52:19,079:INFO:create_model() successfully completed......................................
2024-05-29 03:52:20,139:INFO:SubProcess create_model() end ==================================
2024-05-29 03:52:20,139:INFO:Creating metrics dataframe
2024-05-29 03:52:20,153:INFO:Initializing Gradient Boosting Classifier
2024-05-29 03:52:20,153:INFO:Total runtime is 0.7460806965827942 minutes
2024-05-29 03:52:20,158:INFO:SubProcess create_model() called ==================================
2024-05-29 03:52:20,159:INFO:Initializing create_model()
2024-05-29 03:52:20,159:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7AE1A7D00>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7B82BDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 03:52:20,159:INFO:Checking exceptions
2024-05-29 03:52:20,159:INFO:Importing libraries
2024-05-29 03:52:20,159:INFO:Copying training dataset
2024-05-29 03:52:20,210:INFO:Defining folds
2024-05-29 03:52:20,210:INFO:Declaring metric variables
2024-05-29 03:52:20,216:INFO:Importing untrained model
2024-05-29 03:52:20,221:INFO:Gradient Boosting Classifier Imported successfully
2024-05-29 03:52:20,229:INFO:Starting cross validation
2024-05-29 03:52:20,231:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 03:52:30,253:INFO:Calculating mean and std
2024-05-29 03:52:30,255:INFO:Creating metrics dataframe
2024-05-29 03:52:30,257:INFO:Uploading results into container
2024-05-29 03:52:30,258:INFO:Uploading model into container now
2024-05-29 03:52:30,258:INFO:_master_model_container: 10
2024-05-29 03:52:30,258:INFO:_display_container: 2
2024-05-29 03:52:30,259:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2036, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-29 03:52:30,259:INFO:create_model() successfully completed......................................
2024-05-29 03:52:31,262:INFO:SubProcess create_model() end ==================================
2024-05-29 03:52:31,262:INFO:Creating metrics dataframe
2024-05-29 03:52:31,276:INFO:Initializing Linear Discriminant Analysis
2024-05-29 03:52:31,277:INFO:Total runtime is 0.9314718246459961 minutes
2024-05-29 03:52:31,281:INFO:SubProcess create_model() called ==================================
2024-05-29 03:52:31,281:INFO:Initializing create_model()
2024-05-29 03:52:31,282:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7AE1A7D00>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7B82BDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 03:52:31,282:INFO:Checking exceptions
2024-05-29 03:52:31,282:INFO:Importing libraries
2024-05-29 03:52:31,282:INFO:Copying training dataset
2024-05-29 03:52:31,329:INFO:Defining folds
2024-05-29 03:52:31,330:INFO:Declaring metric variables
2024-05-29 03:52:31,334:INFO:Importing untrained model
2024-05-29 03:52:31,338:INFO:Linear Discriminant Analysis Imported successfully
2024-05-29 03:52:31,347:INFO:Starting cross validation
2024-05-29 03:52:31,348:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 03:52:31,788:INFO:Calculating mean and std
2024-05-29 03:52:31,790:INFO:Creating metrics dataframe
2024-05-29 03:52:31,792:INFO:Uploading results into container
2024-05-29 03:52:31,793:INFO:Uploading model into container now
2024-05-29 03:52:31,793:INFO:_master_model_container: 11
2024-05-29 03:52:31,793:INFO:_display_container: 2
2024-05-29 03:52:31,794:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-29 03:52:31,794:INFO:create_model() successfully completed......................................
2024-05-29 03:52:32,807:INFO:SubProcess create_model() end ==================================
2024-05-29 03:52:32,807:INFO:Creating metrics dataframe
2024-05-29 03:52:32,822:INFO:Initializing Extra Trees Classifier
2024-05-29 03:52:32,822:INFO:Total runtime is 0.9572334130605061 minutes
2024-05-29 03:52:32,826:INFO:SubProcess create_model() called ==================================
2024-05-29 03:52:32,827:INFO:Initializing create_model()
2024-05-29 03:52:32,827:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7AE1A7D00>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7B82BDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 03:52:32,827:INFO:Checking exceptions
2024-05-29 03:52:32,827:INFO:Importing libraries
2024-05-29 03:52:32,827:INFO:Copying training dataset
2024-05-29 03:52:32,874:INFO:Defining folds
2024-05-29 03:52:32,875:INFO:Declaring metric variables
2024-05-29 03:52:32,879:INFO:Importing untrained model
2024-05-29 03:52:32,884:INFO:Extra Trees Classifier Imported successfully
2024-05-29 03:52:32,892:INFO:Starting cross validation
2024-05-29 03:52:32,893:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 03:52:42,132:INFO:Calculating mean and std
2024-05-29 03:52:42,134:INFO:Creating metrics dataframe
2024-05-29 03:52:42,138:INFO:Uploading results into container
2024-05-29 03:52:42,139:INFO:Uploading model into container now
2024-05-29 03:52:42,139:INFO:_master_model_container: 12
2024-05-29 03:52:42,140:INFO:_display_container: 2
2024-05-29 03:52:42,141:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2036, verbose=0,
                     warm_start=False)
2024-05-29 03:52:42,141:INFO:create_model() successfully completed......................................
2024-05-29 03:52:43,182:INFO:SubProcess create_model() end ==================================
2024-05-29 03:52:43,182:INFO:Creating metrics dataframe
2024-05-29 03:52:43,197:INFO:Initializing Extreme Gradient Boosting
2024-05-29 03:52:43,197:INFO:Total runtime is 1.1301459074020386 minutes
2024-05-29 03:52:43,202:INFO:SubProcess create_model() called ==================================
2024-05-29 03:52:43,202:INFO:Initializing create_model()
2024-05-29 03:52:43,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7AE1A7D00>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7B82BDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 03:52:43,203:INFO:Checking exceptions
2024-05-29 03:52:43,203:INFO:Importing libraries
2024-05-29 03:52:43,203:INFO:Copying training dataset
2024-05-29 03:52:43,251:INFO:Defining folds
2024-05-29 03:52:43,251:INFO:Declaring metric variables
2024-05-29 03:52:43,256:INFO:Importing untrained model
2024-05-29 03:52:43,262:INFO:Extreme Gradient Boosting Imported successfully
2024-05-29 03:52:43,270:INFO:Starting cross validation
2024-05-29 03:52:43,271:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 03:52:44,862:INFO:Calculating mean and std
2024-05-29 03:52:44,864:INFO:Creating metrics dataframe
2024-05-29 03:52:44,866:INFO:Uploading results into container
2024-05-29 03:52:44,867:INFO:Uploading model into container now
2024-05-29 03:52:44,867:INFO:_master_model_container: 13
2024-05-29 03:52:44,867:INFO:_display_container: 2
2024-05-29 03:52:44,869:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-29 03:52:44,869:INFO:create_model() successfully completed......................................
2024-05-29 03:52:45,978:INFO:SubProcess create_model() end ==================================
2024-05-29 03:52:45,979:INFO:Creating metrics dataframe
2024-05-29 03:52:45,994:INFO:Initializing Light Gradient Boosting Machine
2024-05-29 03:52:45,995:INFO:Total runtime is 1.1767788648605346 minutes
2024-05-29 03:52:45,999:INFO:SubProcess create_model() called ==================================
2024-05-29 03:52:46,000:INFO:Initializing create_model()
2024-05-29 03:52:46,000:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7AE1A7D00>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7B82BDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 03:52:46,000:INFO:Checking exceptions
2024-05-29 03:52:46,000:INFO:Importing libraries
2024-05-29 03:52:46,000:INFO:Copying training dataset
2024-05-29 03:52:46,048:INFO:Defining folds
2024-05-29 03:52:46,049:INFO:Declaring metric variables
2024-05-29 03:52:46,053:INFO:Importing untrained model
2024-05-29 03:52:46,058:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-29 03:52:46,066:INFO:Starting cross validation
2024-05-29 03:52:46,067:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 03:52:48,651:INFO:Calculating mean and std
2024-05-29 03:52:48,653:INFO:Creating metrics dataframe
2024-05-29 03:52:48,656:INFO:Uploading results into container
2024-05-29 03:52:48,657:INFO:Uploading model into container now
2024-05-29 03:52:48,658:INFO:_master_model_container: 14
2024-05-29 03:52:48,658:INFO:_display_container: 2
2024-05-29 03:52:48,659:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2036, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-29 03:52:48,659:INFO:create_model() successfully completed......................................
2024-05-29 03:52:49,729:INFO:SubProcess create_model() end ==================================
2024-05-29 03:52:49,729:INFO:Creating metrics dataframe
2024-05-29 03:52:49,745:INFO:Initializing Dummy Classifier
2024-05-29 03:52:49,746:INFO:Total runtime is 1.239295502503713 minutes
2024-05-29 03:52:49,750:INFO:SubProcess create_model() called ==================================
2024-05-29 03:52:49,751:INFO:Initializing create_model()
2024-05-29 03:52:49,751:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7AE1A7D00>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E7B82BDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 03:52:49,751:INFO:Checking exceptions
2024-05-29 03:52:49,752:INFO:Importing libraries
2024-05-29 03:52:49,752:INFO:Copying training dataset
2024-05-29 03:52:49,799:INFO:Defining folds
2024-05-29 03:52:49,800:INFO:Declaring metric variables
2024-05-29 03:52:49,804:INFO:Importing untrained model
2024-05-29 03:52:49,809:INFO:Dummy Classifier Imported successfully
2024-05-29 03:52:49,819:INFO:Starting cross validation
2024-05-29 03:52:49,820:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 03:52:49,966:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 03:52:49,999:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 03:52:50,005:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 03:52:50,045:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 03:52:50,068:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 03:52:50,095:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 03:52:50,109:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 03:52:50,131:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 03:52:50,146:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 03:52:50,161:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 03:52:50,177:INFO:Calculating mean and std
2024-05-29 03:52:50,179:INFO:Creating metrics dataframe
2024-05-29 03:52:50,181:INFO:Uploading results into container
2024-05-29 03:52:50,182:INFO:Uploading model into container now
2024-05-29 03:52:50,183:INFO:_master_model_container: 15
2024-05-29 03:52:50,183:INFO:_display_container: 2
2024-05-29 03:52:50,183:INFO:DummyClassifier(constant=None, random_state=2036, strategy='prior')
2024-05-29 03:52:50,183:INFO:create_model() successfully completed......................................
2024-05-29 03:52:51,220:INFO:SubProcess create_model() end ==================================
2024-05-29 03:52:51,221:INFO:Creating metrics dataframe
2024-05-29 03:52:51,238:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-29 03:52:51,249:INFO:Initializing create_model()
2024-05-29 03:52:51,249:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7AE1A7D00>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 03:52:51,249:INFO:Checking exceptions
2024-05-29 03:52:51,252:INFO:Importing libraries
2024-05-29 03:52:51,252:INFO:Copying training dataset
2024-05-29 03:52:51,298:INFO:Defining folds
2024-05-29 03:52:51,298:INFO:Declaring metric variables
2024-05-29 03:52:51,298:INFO:Importing untrained model
2024-05-29 03:52:51,298:INFO:Declaring custom model
2024-05-29 03:52:51,300:INFO:Extreme Gradient Boosting Imported successfully
2024-05-29 03:52:51,301:INFO:Cross validation set to False
2024-05-29 03:52:51,302:INFO:Fitting Model
2024-05-29 03:52:51,602:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-29 03:52:51,602:INFO:create_model() successfully completed......................................
2024-05-29 03:52:52,682:INFO:Creating Dashboard logs
2024-05-29 03:52:52,688:INFO:Model: Extreme Gradient Boosting
2024-05-29 03:52:52,795:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 2036, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2024-05-29 03:52:53,104:INFO:Initializing predict_model()
2024-05-29 03:52:53,104:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E7AE1A7D00>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E7ACFA3F40>)
2024-05-29 03:52:53,104:INFO:Checking exceptions
2024-05-29 03:52:53,104:INFO:Preloading libraries
2024-05-29 03:52:55,633:INFO:Creating Dashboard logs
2024-05-29 03:52:55,637:INFO:Model: Light Gradient Boosting Machine
2024-05-29 03:52:55,725:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 2036, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-05-29 03:52:57,159:INFO:Creating Dashboard logs
2024-05-29 03:52:57,163:INFO:Model: Random Forest Classifier
2024-05-29 03:52:57,247:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 2036, 'verbose': 0, 'warm_start': False}
2024-05-29 03:52:58,594:INFO:Creating Dashboard logs
2024-05-29 03:52:58,599:INFO:Model: Gradient Boosting Classifier
2024-05-29 03:52:58,684:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 2036, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-29 03:53:00,022:INFO:Creating Dashboard logs
2024-05-29 03:53:00,026:INFO:Model: Ada Boost Classifier
2024-05-29 03:53:00,110:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 2036}
2024-05-29 03:53:01,451:INFO:Creating Dashboard logs
2024-05-29 03:53:01,455:INFO:Model: Extra Trees Classifier
2024-05-29 03:53:01,540:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 2036, 'verbose': 0, 'warm_start': False}
2024-05-29 03:53:02,888:INFO:Creating Dashboard logs
2024-05-29 03:53:02,892:INFO:Model: Logistic Regression
2024-05-29 03:53:02,981:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 2036, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-05-29 03:53:04,337:INFO:Creating Dashboard logs
2024-05-29 03:53:04,342:INFO:Model: K Neighbors Classifier
2024-05-29 03:53:04,433:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2024-05-29 03:53:05,795:INFO:Creating Dashboard logs
2024-05-29 03:53:05,800:INFO:Model: SVM - Linear Kernel
2024-05-29 03:53:05,886:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 2036, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-29 03:53:07,244:INFO:Creating Dashboard logs
2024-05-29 03:53:07,249:INFO:Model: Ridge Classifier
2024-05-29 03:53:07,334:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 2036, 'solver': 'auto', 'tol': 0.0001}
2024-05-29 03:53:08,659:INFO:Creating Dashboard logs
2024-05-29 03:53:08,663:INFO:Model: Linear Discriminant Analysis
2024-05-29 03:53:08,751:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-05-29 03:53:10,066:INFO:Creating Dashboard logs
2024-05-29 03:53:10,071:INFO:Model: Quadratic Discriminant Analysis
2024-05-29 03:53:10,160:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2024-05-29 03:53:11,455:INFO:Creating Dashboard logs
2024-05-29 03:53:11,460:INFO:Model: Decision Tree Classifier
2024-05-29 03:53:11,545:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 2036, 'splitter': 'best'}
2024-05-29 03:53:12,871:INFO:Creating Dashboard logs
2024-05-29 03:53:12,875:INFO:Model: Naive Bayes
2024-05-29 03:53:12,959:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-05-29 03:53:14,262:INFO:Creating Dashboard logs
2024-05-29 03:53:14,267:INFO:Model: Dummy Classifier
2024-05-29 03:53:14,354:INFO:Logged params: {'constant': None, 'random_state': 2036, 'strategy': 'prior'}
2024-05-29 03:53:15,769:INFO:_master_model_container: 15
2024-05-29 03:53:15,769:INFO:_display_container: 2
2024-05-29 03:53:15,770:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-29 03:53:15,771:INFO:compare_models() successfully completed......................................
2024-05-29 09:57:07,935:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-29 09:57:07,947:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-29 09:57:07,948:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-29 09:57:07,948:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-29 10:02:46,966:INFO:PyCaret ClassificationExperiment
2024-05-29 10:02:46,966:INFO:Logging name: codex
2024-05-29 10:02:46,966:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:02:46,966:INFO:version 3.3.2
2024-05-29 10:02:46,966:INFO:Initializing setup()
2024-05-29 10:02:46,966:INFO:self.USI: d149
2024-05-29 10:02:46,966:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:02:46,966:INFO:Checking environment
2024-05-29 10:02:46,966:INFO:python_version: 3.10.13
2024-05-29 10:02:46,967:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:02:46,967:INFO:machine: AMD64
2024-05-29 10:02:46,967:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:02:46,968:INFO:Memory: svmem(total=34267656192, available=20018872320, percent=41.6, used=14248783872, free=20018872320)
2024-05-29 10:02:46,968:INFO:Physical Core: 8
2024-05-29 10:02:46,968:INFO:Logical Core: 16
2024-05-29 10:02:46,968:INFO:Checking libraries
2024-05-29 10:02:46,969:INFO:System:
2024-05-29 10:02:46,969:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:02:46,969:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:02:46,969:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:02:46,969:INFO:PyCaret required dependencies:
2024-05-29 10:02:47,017:INFO:                 pip: 23.3
2024-05-29 10:02:47,017:INFO:          setuptools: 68.0.0
2024-05-29 10:02:47,017:INFO:             pycaret: 3.3.2
2024-05-29 10:02:47,017:INFO:             IPython: 8.24.0
2024-05-29 10:02:47,017:INFO:          ipywidgets: 8.1.2
2024-05-29 10:02:47,017:INFO:                tqdm: 4.66.4
2024-05-29 10:02:47,017:INFO:               numpy: 1.26.4
2024-05-29 10:02:47,018:INFO:              pandas: 2.1.4
2024-05-29 10:02:47,018:INFO:              jinja2: 3.1.4
2024-05-29 10:02:47,018:INFO:               scipy: 1.11.4
2024-05-29 10:02:47,018:INFO:              joblib: 1.3.2
2024-05-29 10:02:47,018:INFO:             sklearn: 1.4.2
2024-05-29 10:02:47,018:INFO:                pyod: 1.1.3
2024-05-29 10:02:47,018:INFO:            imblearn: 0.12.2
2024-05-29 10:02:47,018:INFO:   category_encoders: 2.6.3
2024-05-29 10:02:47,018:INFO:            lightgbm: 4.3.0
2024-05-29 10:02:47,018:INFO:               numba: 0.59.1
2024-05-29 10:02:47,018:INFO:            requests: 2.32.2
2024-05-29 10:02:47,018:INFO:          matplotlib: 3.7.5
2024-05-29 10:02:47,018:INFO:          scikitplot: 0.3.7
2024-05-29 10:02:47,019:INFO:         yellowbrick: 1.5
2024-05-29 10:02:47,019:INFO:              plotly: 5.22.0
2024-05-29 10:02:47,019:INFO:    plotly-resampler: Not installed
2024-05-29 10:02:47,019:INFO:             kaleido: 0.2.1
2024-05-29 10:02:47,019:INFO:           schemdraw: 0.15
2024-05-29 10:02:47,019:INFO:         statsmodels: 0.14.2
2024-05-29 10:02:47,019:INFO:              sktime: 0.26.0
2024-05-29 10:02:47,019:INFO:               tbats: 1.1.3
2024-05-29 10:02:47,019:INFO:            pmdarima: 2.0.4
2024-05-29 10:02:47,019:INFO:              psutil: 5.9.0
2024-05-29 10:02:47,019:INFO:          markupsafe: 2.1.5
2024-05-29 10:02:47,019:INFO:             pickle5: Not installed
2024-05-29 10:02:47,020:INFO:         cloudpickle: 3.0.0
2024-05-29 10:02:47,020:INFO:         deprecation: 2.1.0
2024-05-29 10:02:47,020:INFO:              xxhash: 3.4.1
2024-05-29 10:02:47,020:INFO:           wurlitzer: Not installed
2024-05-29 10:02:47,020:INFO:PyCaret optional dependencies:
2024-05-29 10:02:47,045:INFO:                shap: Not installed
2024-05-29 10:02:47,045:INFO:           interpret: Not installed
2024-05-29 10:02:47,045:INFO:                umap: Not installed
2024-05-29 10:02:47,045:INFO:     ydata_profiling: Not installed
2024-05-29 10:02:47,045:INFO:  explainerdashboard: Not installed
2024-05-29 10:02:47,045:INFO:             autoviz: Not installed
2024-05-29 10:02:47,045:INFO:           fairlearn: Not installed
2024-05-29 10:02:47,045:INFO:          deepchecks: Not installed
2024-05-29 10:02:47,046:INFO:             xgboost: 2.0.3
2024-05-29 10:02:47,046:INFO:            catboost: Not installed
2024-05-29 10:02:47,046:INFO:              kmodes: Not installed
2024-05-29 10:02:47,046:INFO:             mlxtend: Not installed
2024-05-29 10:02:47,046:INFO:       statsforecast: Not installed
2024-05-29 10:02:47,046:INFO:        tune_sklearn: Not installed
2024-05-29 10:02:47,046:INFO:                 ray: Not installed
2024-05-29 10:02:47,046:INFO:            hyperopt: Not installed
2024-05-29 10:02:47,046:INFO:              optuna: Not installed
2024-05-29 10:02:47,046:INFO:               skopt: Not installed
2024-05-29 10:02:47,046:INFO:              mlflow: 2.13.0
2024-05-29 10:02:47,046:INFO:              gradio: Not installed
2024-05-29 10:02:47,047:INFO:             fastapi: Not installed
2024-05-29 10:02:47,047:INFO:             uvicorn: Not installed
2024-05-29 10:02:47,047:INFO:              m2cgen: Not installed
2024-05-29 10:02:47,047:INFO:           evidently: Not installed
2024-05-29 10:02:47,047:INFO:               fugue: Not installed
2024-05-29 10:02:47,047:INFO:           streamlit: Not installed
2024-05-29 10:02:47,047:INFO:             prophet: Not installed
2024-05-29 10:02:47,047:INFO:None
2024-05-29 10:02:47,047:INFO:Set up data.
2024-05-29 10:02:47,075:INFO:Set up folding strategy.
2024-05-29 10:02:47,075:INFO:Set up train/test split.
2024-05-29 10:02:47,136:INFO:Set up index.
2024-05-29 10:02:47,138:INFO:Assigning column types.
2024-05-29 10:02:47,170:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:02:47,242:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:02:47,248:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:02:47,308:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:02:47,312:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:02:47,384:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:02:47,386:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:02:47,431:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:02:47,435:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:02:47,436:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:02:47,509:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:02:47,554:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:02:47,559:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:02:47,632:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:02:47,677:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:02:47,682:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:02:47,682:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:02:47,801:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:02:47,805:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:02:47,923:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:02:47,928:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:02:47,931:INFO:Preparing preprocessing pipeline...
2024-05-29 10:02:47,937:INFO:Set up simple imputation.
2024-05-29 10:17:02,292:INFO:PyCaret ClassificationExperiment
2024-05-29 10:17:02,293:INFO:Logging name: codex
2024-05-29 10:17:02,293:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:17:02,293:INFO:version 3.3.2
2024-05-29 10:17:02,293:INFO:Initializing setup()
2024-05-29 10:17:02,293:INFO:self.USI: fc1c
2024-05-29 10:17:02,293:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:17:02,293:INFO:Checking environment
2024-05-29 10:17:02,293:INFO:python_version: 3.10.13
2024-05-29 10:17:02,294:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:17:02,294:INFO:machine: AMD64
2024-05-29 10:17:02,294:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:17:02,294:INFO:Memory: svmem(total=34267656192, available=19414585344, percent=43.3, used=14853070848, free=19414585344)
2024-05-29 10:17:02,294:INFO:Physical Core: 8
2024-05-29 10:17:02,294:INFO:Logical Core: 16
2024-05-29 10:17:02,294:INFO:Checking libraries
2024-05-29 10:17:02,294:INFO:System:
2024-05-29 10:17:02,294:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:17:02,294:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:17:02,294:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:17:02,295:INFO:PyCaret required dependencies:
2024-05-29 10:17:02,295:INFO:                 pip: 23.3
2024-05-29 10:17:02,295:INFO:          setuptools: 68.0.0
2024-05-29 10:17:02,295:INFO:             pycaret: 3.3.2
2024-05-29 10:17:02,295:INFO:             IPython: 8.24.0
2024-05-29 10:17:02,295:INFO:          ipywidgets: 8.1.2
2024-05-29 10:17:02,295:INFO:                tqdm: 4.66.4
2024-05-29 10:17:02,295:INFO:               numpy: 1.26.4
2024-05-29 10:17:02,295:INFO:              pandas: 2.1.4
2024-05-29 10:17:02,295:INFO:              jinja2: 3.1.4
2024-05-29 10:17:02,296:INFO:               scipy: 1.11.4
2024-05-29 10:17:02,296:INFO:              joblib: 1.3.2
2024-05-29 10:17:02,296:INFO:             sklearn: 1.4.2
2024-05-29 10:17:02,296:INFO:                pyod: 1.1.3
2024-05-29 10:17:02,296:INFO:            imblearn: 0.12.2
2024-05-29 10:17:02,296:INFO:   category_encoders: 2.6.3
2024-05-29 10:17:02,296:INFO:            lightgbm: 4.3.0
2024-05-29 10:17:02,296:INFO:               numba: 0.59.1
2024-05-29 10:17:02,296:INFO:            requests: 2.32.2
2024-05-29 10:17:02,296:INFO:          matplotlib: 3.7.5
2024-05-29 10:17:02,296:INFO:          scikitplot: 0.3.7
2024-05-29 10:17:02,297:INFO:         yellowbrick: 1.5
2024-05-29 10:17:02,297:INFO:              plotly: 5.22.0
2024-05-29 10:17:02,297:INFO:    plotly-resampler: Not installed
2024-05-29 10:17:02,297:INFO:             kaleido: 0.2.1
2024-05-29 10:17:02,297:INFO:           schemdraw: 0.15
2024-05-29 10:17:02,297:INFO:         statsmodels: 0.14.2
2024-05-29 10:17:02,297:INFO:              sktime: 0.26.0
2024-05-29 10:17:02,297:INFO:               tbats: 1.1.3
2024-05-29 10:17:02,297:INFO:            pmdarima: 2.0.4
2024-05-29 10:17:02,297:INFO:              psutil: 5.9.0
2024-05-29 10:17:02,297:INFO:          markupsafe: 2.1.5
2024-05-29 10:17:02,297:INFO:             pickle5: Not installed
2024-05-29 10:17:02,298:INFO:         cloudpickle: 3.0.0
2024-05-29 10:17:02,298:INFO:         deprecation: 2.1.0
2024-05-29 10:17:02,298:INFO:              xxhash: 3.4.1
2024-05-29 10:17:02,298:INFO:           wurlitzer: Not installed
2024-05-29 10:17:02,298:INFO:PyCaret optional dependencies:
2024-05-29 10:17:02,298:INFO:                shap: Not installed
2024-05-29 10:17:02,298:INFO:           interpret: Not installed
2024-05-29 10:17:02,298:INFO:                umap: Not installed
2024-05-29 10:17:02,298:INFO:     ydata_profiling: Not installed
2024-05-29 10:17:02,298:INFO:  explainerdashboard: Not installed
2024-05-29 10:17:02,298:INFO:             autoviz: Not installed
2024-05-29 10:17:02,299:INFO:           fairlearn: Not installed
2024-05-29 10:17:02,299:INFO:          deepchecks: Not installed
2024-05-29 10:17:02,299:INFO:             xgboost: 2.0.3
2024-05-29 10:17:02,299:INFO:            catboost: Not installed
2024-05-29 10:17:02,299:INFO:              kmodes: Not installed
2024-05-29 10:17:02,299:INFO:             mlxtend: Not installed
2024-05-29 10:17:02,299:INFO:       statsforecast: Not installed
2024-05-29 10:17:02,299:INFO:        tune_sklearn: Not installed
2024-05-29 10:17:02,299:INFO:                 ray: Not installed
2024-05-29 10:17:02,300:INFO:            hyperopt: Not installed
2024-05-29 10:17:02,300:INFO:              optuna: Not installed
2024-05-29 10:17:02,300:INFO:               skopt: Not installed
2024-05-29 10:17:02,300:INFO:              mlflow: 2.13.0
2024-05-29 10:17:02,300:INFO:              gradio: Not installed
2024-05-29 10:17:02,300:INFO:             fastapi: Not installed
2024-05-29 10:17:02,300:INFO:             uvicorn: Not installed
2024-05-29 10:17:02,300:INFO:              m2cgen: Not installed
2024-05-29 10:17:02,300:INFO:           evidently: Not installed
2024-05-29 10:17:02,300:INFO:               fugue: Not installed
2024-05-29 10:17:02,301:INFO:           streamlit: Not installed
2024-05-29 10:17:02,301:INFO:             prophet: Not installed
2024-05-29 10:17:02,301:INFO:None
2024-05-29 10:17:02,301:INFO:Set up data.
2024-05-29 10:17:02,333:INFO:Set up folding strategy.
2024-05-29 10:17:02,334:INFO:Set up train/test split.
2024-05-29 10:17:02,393:INFO:Set up index.
2024-05-29 10:17:02,395:INFO:Assigning column types.
2024-05-29 10:17:02,429:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:17:02,502:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:17:02,504:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:17:02,549:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:17:02,554:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:17:02,627:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:17:02,629:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:17:02,674:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:17:02,679:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:17:02,679:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:17:02,754:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:17:02,799:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:17:02,804:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:17:02,879:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:17:02,924:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:17:02,929:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:17:02,929:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:17:03,048:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:17:03,052:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:17:03,172:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:17:03,176:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:17:03,179:INFO:Preparing preprocessing pipeline...
2024-05-29 10:17:03,185:INFO:Set up simple imputation.
2024-05-29 10:18:35,366:INFO:gpu_param set to False
2024-05-29 10:18:35,507:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:18:35,512:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:18:35,637:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:18:35,641:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:19:18,169:INFO:gpu_param set to False
2024-05-29 10:19:18,320:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:19:18,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:19:18,460:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:19:18,464:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:19:32,753:INFO:gpu_param set to False
2024-05-29 10:19:32,874:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:19:32,878:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:19:32,999:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:19:33,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:20:38,083:INFO:PyCaret ClassificationExperiment
2024-05-29 10:20:38,083:INFO:Logging name: codex
2024-05-29 10:20:38,084:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:20:38,084:INFO:version 3.3.2
2024-05-29 10:20:38,084:INFO:Initializing setup()
2024-05-29 10:20:38,084:INFO:self.USI: ce99
2024-05-29 10:20:38,084:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:20:38,084:INFO:Checking environment
2024-05-29 10:20:38,084:INFO:python_version: 3.10.13
2024-05-29 10:20:38,084:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:20:38,084:INFO:machine: AMD64
2024-05-29 10:20:38,084:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:20:38,085:INFO:Memory: svmem(total=34267656192, available=19366350848, percent=43.5, used=14901305344, free=19366350848)
2024-05-29 10:20:38,085:INFO:Physical Core: 8
2024-05-29 10:20:38,085:INFO:Logical Core: 16
2024-05-29 10:20:38,085:INFO:Checking libraries
2024-05-29 10:20:38,085:INFO:System:
2024-05-29 10:20:38,085:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:20:38,085:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:20:38,085:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:20:38,085:INFO:PyCaret required dependencies:
2024-05-29 10:20:38,085:INFO:                 pip: 23.3
2024-05-29 10:20:38,085:INFO:          setuptools: 68.0.0
2024-05-29 10:20:38,086:INFO:             pycaret: 3.3.2
2024-05-29 10:20:38,086:INFO:             IPython: 8.24.0
2024-05-29 10:20:38,086:INFO:          ipywidgets: 8.1.2
2024-05-29 10:20:38,086:INFO:                tqdm: 4.66.4
2024-05-29 10:20:38,086:INFO:               numpy: 1.26.4
2024-05-29 10:20:38,086:INFO:              pandas: 2.1.4
2024-05-29 10:20:38,086:INFO:              jinja2: 3.1.4
2024-05-29 10:20:38,086:INFO:               scipy: 1.11.4
2024-05-29 10:20:38,086:INFO:              joblib: 1.3.2
2024-05-29 10:20:38,086:INFO:             sklearn: 1.4.2
2024-05-29 10:20:38,087:INFO:                pyod: 1.1.3
2024-05-29 10:20:38,087:INFO:            imblearn: 0.12.2
2024-05-29 10:20:38,087:INFO:   category_encoders: 2.6.3
2024-05-29 10:20:38,087:INFO:            lightgbm: 4.3.0
2024-05-29 10:20:38,087:INFO:               numba: 0.59.1
2024-05-29 10:20:38,087:INFO:            requests: 2.32.2
2024-05-29 10:20:38,087:INFO:          matplotlib: 3.7.5
2024-05-29 10:20:38,087:INFO:          scikitplot: 0.3.7
2024-05-29 10:20:38,087:INFO:         yellowbrick: 1.5
2024-05-29 10:20:38,087:INFO:              plotly: 5.22.0
2024-05-29 10:20:38,087:INFO:    plotly-resampler: Not installed
2024-05-29 10:20:38,087:INFO:             kaleido: 0.2.1
2024-05-29 10:20:38,088:INFO:           schemdraw: 0.15
2024-05-29 10:20:38,088:INFO:         statsmodels: 0.14.2
2024-05-29 10:20:38,088:INFO:              sktime: 0.26.0
2024-05-29 10:20:38,088:INFO:               tbats: 1.1.3
2024-05-29 10:20:38,088:INFO:            pmdarima: 2.0.4
2024-05-29 10:20:38,088:INFO:              psutil: 5.9.0
2024-05-29 10:20:38,088:INFO:          markupsafe: 2.1.5
2024-05-29 10:20:38,088:INFO:             pickle5: Not installed
2024-05-29 10:20:38,088:INFO:         cloudpickle: 3.0.0
2024-05-29 10:20:38,088:INFO:         deprecation: 2.1.0
2024-05-29 10:20:38,088:INFO:              xxhash: 3.4.1
2024-05-29 10:20:38,088:INFO:           wurlitzer: Not installed
2024-05-29 10:20:38,089:INFO:PyCaret optional dependencies:
2024-05-29 10:20:38,089:INFO:                shap: Not installed
2024-05-29 10:20:38,089:INFO:           interpret: Not installed
2024-05-29 10:20:38,089:INFO:                umap: Not installed
2024-05-29 10:20:38,089:INFO:     ydata_profiling: Not installed
2024-05-29 10:20:38,089:INFO:  explainerdashboard: Not installed
2024-05-29 10:20:38,089:INFO:             autoviz: Not installed
2024-05-29 10:20:38,089:INFO:           fairlearn: Not installed
2024-05-29 10:20:38,089:INFO:          deepchecks: Not installed
2024-05-29 10:20:38,089:INFO:             xgboost: 2.0.3
2024-05-29 10:20:38,089:INFO:            catboost: Not installed
2024-05-29 10:20:38,090:INFO:              kmodes: Not installed
2024-05-29 10:20:38,090:INFO:             mlxtend: Not installed
2024-05-29 10:20:38,090:INFO:       statsforecast: Not installed
2024-05-29 10:20:38,090:INFO:        tune_sklearn: Not installed
2024-05-29 10:20:38,090:INFO:                 ray: Not installed
2024-05-29 10:20:38,090:INFO:            hyperopt: Not installed
2024-05-29 10:20:38,090:INFO:              optuna: Not installed
2024-05-29 10:20:38,090:INFO:               skopt: Not installed
2024-05-29 10:20:38,090:INFO:              mlflow: 2.13.0
2024-05-29 10:20:38,090:INFO:              gradio: Not installed
2024-05-29 10:20:38,090:INFO:             fastapi: Not installed
2024-05-29 10:20:38,090:INFO:             uvicorn: Not installed
2024-05-29 10:20:38,091:INFO:              m2cgen: Not installed
2024-05-29 10:20:38,091:INFO:           evidently: Not installed
2024-05-29 10:20:38,091:INFO:               fugue: Not installed
2024-05-29 10:20:38,091:INFO:           streamlit: Not installed
2024-05-29 10:20:38,091:INFO:             prophet: Not installed
2024-05-29 10:20:38,091:INFO:None
2024-05-29 10:20:38,091:INFO:Set up data.
2024-05-29 10:20:38,124:INFO:Set up folding strategy.
2024-05-29 10:20:38,125:INFO:Set up train/test split.
2024-05-29 10:20:38,181:INFO:Set up index.
2024-05-29 10:20:38,183:INFO:Assigning column types.
2024-05-29 10:20:38,215:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:20:38,288:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:20:38,289:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:20:38,335:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:20:38,339:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:20:38,413:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:20:38,414:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:20:38,460:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:20:38,464:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:20:38,465:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:20:38,538:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:20:38,584:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:20:38,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:20:38,662:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:20:38,707:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:20:38,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:20:38,712:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:20:38,829:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:20:38,834:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:20:38,952:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:20:38,956:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:20:38,958:INFO:Preparing preprocessing pipeline...
2024-05-29 10:20:38,964:INFO:Set up simple imputation.
2024-05-29 10:21:10,320:INFO:PyCaret ClassificationExperiment
2024-05-29 10:21:10,320:INFO:Logging name: codex
2024-05-29 10:21:10,320:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:21:10,320:INFO:version 3.3.2
2024-05-29 10:21:10,320:INFO:Initializing setup()
2024-05-29 10:21:10,320:INFO:self.USI: 8117
2024-05-29 10:21:10,320:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:21:10,320:INFO:Checking environment
2024-05-29 10:21:10,320:INFO:python_version: 3.10.13
2024-05-29 10:21:10,321:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:21:10,321:INFO:machine: AMD64
2024-05-29 10:21:10,321:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:21:10,321:INFO:Memory: svmem(total=34267656192, available=19433361408, percent=43.3, used=14834294784, free=19433361408)
2024-05-29 10:21:10,321:INFO:Physical Core: 8
2024-05-29 10:21:10,321:INFO:Logical Core: 16
2024-05-29 10:21:10,321:INFO:Checking libraries
2024-05-29 10:21:10,321:INFO:System:
2024-05-29 10:21:10,321:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:21:10,322:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:21:10,322:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:21:10,322:INFO:PyCaret required dependencies:
2024-05-29 10:21:10,322:INFO:                 pip: 23.3
2024-05-29 10:21:10,322:INFO:          setuptools: 68.0.0
2024-05-29 10:21:10,322:INFO:             pycaret: 3.3.2
2024-05-29 10:21:10,322:INFO:             IPython: 8.24.0
2024-05-29 10:21:10,322:INFO:          ipywidgets: 8.1.2
2024-05-29 10:21:10,322:INFO:                tqdm: 4.66.4
2024-05-29 10:21:10,323:INFO:               numpy: 1.26.4
2024-05-29 10:21:10,323:INFO:              pandas: 2.1.4
2024-05-29 10:21:10,323:INFO:              jinja2: 3.1.4
2024-05-29 10:21:10,323:INFO:               scipy: 1.11.4
2024-05-29 10:21:10,323:INFO:              joblib: 1.3.2
2024-05-29 10:21:10,323:INFO:             sklearn: 1.4.2
2024-05-29 10:21:10,323:INFO:                pyod: 1.1.3
2024-05-29 10:21:10,323:INFO:            imblearn: 0.12.2
2024-05-29 10:21:10,323:INFO:   category_encoders: 2.6.3
2024-05-29 10:21:10,323:INFO:            lightgbm: 4.3.0
2024-05-29 10:21:10,323:INFO:               numba: 0.59.1
2024-05-29 10:21:10,324:INFO:            requests: 2.32.2
2024-05-29 10:21:10,324:INFO:          matplotlib: 3.7.5
2024-05-29 10:21:10,324:INFO:          scikitplot: 0.3.7
2024-05-29 10:21:10,324:INFO:         yellowbrick: 1.5
2024-05-29 10:21:10,324:INFO:              plotly: 5.22.0
2024-05-29 10:21:10,324:INFO:    plotly-resampler: Not installed
2024-05-29 10:21:10,324:INFO:             kaleido: 0.2.1
2024-05-29 10:21:10,324:INFO:           schemdraw: 0.15
2024-05-29 10:21:10,324:INFO:         statsmodels: 0.14.2
2024-05-29 10:21:10,324:INFO:              sktime: 0.26.0
2024-05-29 10:21:10,325:INFO:               tbats: 1.1.3
2024-05-29 10:21:10,325:INFO:            pmdarima: 2.0.4
2024-05-29 10:21:10,325:INFO:              psutil: 5.9.0
2024-05-29 10:21:10,325:INFO:          markupsafe: 2.1.5
2024-05-29 10:21:10,325:INFO:             pickle5: Not installed
2024-05-29 10:21:10,325:INFO:         cloudpickle: 3.0.0
2024-05-29 10:21:10,325:INFO:         deprecation: 2.1.0
2024-05-29 10:21:10,325:INFO:              xxhash: 3.4.1
2024-05-29 10:21:10,325:INFO:           wurlitzer: Not installed
2024-05-29 10:21:10,325:INFO:PyCaret optional dependencies:
2024-05-29 10:21:10,325:INFO:                shap: Not installed
2024-05-29 10:21:10,326:INFO:           interpret: Not installed
2024-05-29 10:21:10,326:INFO:                umap: Not installed
2024-05-29 10:21:10,326:INFO:     ydata_profiling: Not installed
2024-05-29 10:21:10,326:INFO:  explainerdashboard: Not installed
2024-05-29 10:21:10,326:INFO:             autoviz: Not installed
2024-05-29 10:21:10,326:INFO:           fairlearn: Not installed
2024-05-29 10:21:10,326:INFO:          deepchecks: Not installed
2024-05-29 10:21:10,326:INFO:             xgboost: 2.0.3
2024-05-29 10:21:10,326:INFO:            catboost: Not installed
2024-05-29 10:21:10,326:INFO:              kmodes: Not installed
2024-05-29 10:21:10,326:INFO:             mlxtend: Not installed
2024-05-29 10:21:10,327:INFO:       statsforecast: Not installed
2024-05-29 10:21:10,327:INFO:        tune_sklearn: Not installed
2024-05-29 10:21:10,327:INFO:                 ray: Not installed
2024-05-29 10:21:10,327:INFO:            hyperopt: Not installed
2024-05-29 10:21:10,327:INFO:              optuna: Not installed
2024-05-29 10:21:10,327:INFO:               skopt: Not installed
2024-05-29 10:21:10,327:INFO:              mlflow: 2.13.0
2024-05-29 10:21:10,327:INFO:              gradio: Not installed
2024-05-29 10:21:10,327:INFO:             fastapi: Not installed
2024-05-29 10:21:10,328:INFO:             uvicorn: Not installed
2024-05-29 10:21:10,328:INFO:              m2cgen: Not installed
2024-05-29 10:21:10,328:INFO:           evidently: Not installed
2024-05-29 10:21:10,328:INFO:               fugue: Not installed
2024-05-29 10:21:10,328:INFO:           streamlit: Not installed
2024-05-29 10:21:10,328:INFO:             prophet: Not installed
2024-05-29 10:21:10,328:INFO:None
2024-05-29 10:21:10,328:INFO:Set up data.
2024-05-29 10:21:10,356:INFO:Set up folding strategy.
2024-05-29 10:21:10,356:INFO:Set up train/test split.
2024-05-29 10:21:10,415:INFO:Set up index.
2024-05-29 10:21:10,416:INFO:Assigning column types.
2024-05-29 10:21:10,450:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:21:10,523:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:21:10,524:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:21:10,569:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:10,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:10,646:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:21:10,647:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:21:10,693:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:10,697:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:10,698:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:21:10,771:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:21:10,817:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:10,821:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:10,895:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:21:10,942:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:10,946:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:10,947:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:21:11,065:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:11,069:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:11,187:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:11,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:11,193:INFO:Preparing preprocessing pipeline...
2024-05-29 10:21:11,199:INFO:Set up simple imputation.
2024-05-29 10:21:25,560:INFO:PyCaret ClassificationExperiment
2024-05-29 10:21:25,561:INFO:Logging name: codex
2024-05-29 10:21:25,561:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:21:25,561:INFO:version 3.3.2
2024-05-29 10:21:25,561:INFO:Initializing setup()
2024-05-29 10:21:25,561:INFO:self.USI: 1224
2024-05-29 10:21:25,561:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:21:25,561:INFO:Checking environment
2024-05-29 10:21:25,561:INFO:python_version: 3.10.13
2024-05-29 10:21:25,562:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:21:25,562:INFO:machine: AMD64
2024-05-29 10:21:25,562:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:21:25,562:INFO:Memory: svmem(total=34267656192, available=19430871040, percent=43.3, used=14836785152, free=19430871040)
2024-05-29 10:21:25,562:INFO:Physical Core: 8
2024-05-29 10:21:25,562:INFO:Logical Core: 16
2024-05-29 10:21:25,562:INFO:Checking libraries
2024-05-29 10:21:25,562:INFO:System:
2024-05-29 10:21:25,562:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:21:25,563:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:21:25,563:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:21:25,563:INFO:PyCaret required dependencies:
2024-05-29 10:21:25,563:INFO:                 pip: 23.3
2024-05-29 10:21:25,563:INFO:          setuptools: 68.0.0
2024-05-29 10:21:25,563:INFO:             pycaret: 3.3.2
2024-05-29 10:21:25,563:INFO:             IPython: 8.24.0
2024-05-29 10:21:25,563:INFO:          ipywidgets: 8.1.2
2024-05-29 10:21:25,563:INFO:                tqdm: 4.66.4
2024-05-29 10:21:25,563:INFO:               numpy: 1.26.4
2024-05-29 10:21:25,564:INFO:              pandas: 2.1.4
2024-05-29 10:21:25,564:INFO:              jinja2: 3.1.4
2024-05-29 10:21:25,564:INFO:               scipy: 1.11.4
2024-05-29 10:21:25,564:INFO:              joblib: 1.3.2
2024-05-29 10:21:25,564:INFO:             sklearn: 1.4.2
2024-05-29 10:21:25,564:INFO:                pyod: 1.1.3
2024-05-29 10:21:25,564:INFO:            imblearn: 0.12.2
2024-05-29 10:21:25,564:INFO:   category_encoders: 2.6.3
2024-05-29 10:21:25,564:INFO:            lightgbm: 4.3.0
2024-05-29 10:21:25,564:INFO:               numba: 0.59.1
2024-05-29 10:21:25,564:INFO:            requests: 2.32.2
2024-05-29 10:21:25,565:INFO:          matplotlib: 3.7.5
2024-05-29 10:21:25,565:INFO:          scikitplot: 0.3.7
2024-05-29 10:21:25,565:INFO:         yellowbrick: 1.5
2024-05-29 10:21:25,565:INFO:              plotly: 5.22.0
2024-05-29 10:21:25,565:INFO:    plotly-resampler: Not installed
2024-05-29 10:21:25,565:INFO:             kaleido: 0.2.1
2024-05-29 10:21:25,565:INFO:           schemdraw: 0.15
2024-05-29 10:21:25,565:INFO:         statsmodels: 0.14.2
2024-05-29 10:21:25,565:INFO:              sktime: 0.26.0
2024-05-29 10:21:25,565:INFO:               tbats: 1.1.3
2024-05-29 10:21:25,565:INFO:            pmdarima: 2.0.4
2024-05-29 10:21:25,565:INFO:              psutil: 5.9.0
2024-05-29 10:21:25,566:INFO:          markupsafe: 2.1.5
2024-05-29 10:21:25,566:INFO:             pickle5: Not installed
2024-05-29 10:21:25,566:INFO:         cloudpickle: 3.0.0
2024-05-29 10:21:25,566:INFO:         deprecation: 2.1.0
2024-05-29 10:21:25,566:INFO:              xxhash: 3.4.1
2024-05-29 10:21:25,566:INFO:           wurlitzer: Not installed
2024-05-29 10:21:25,566:INFO:PyCaret optional dependencies:
2024-05-29 10:21:25,566:INFO:                shap: Not installed
2024-05-29 10:21:25,566:INFO:           interpret: Not installed
2024-05-29 10:21:25,566:INFO:                umap: Not installed
2024-05-29 10:21:25,566:INFO:     ydata_profiling: Not installed
2024-05-29 10:21:25,567:INFO:  explainerdashboard: Not installed
2024-05-29 10:21:25,567:INFO:             autoviz: Not installed
2024-05-29 10:21:25,567:INFO:           fairlearn: Not installed
2024-05-29 10:21:25,567:INFO:          deepchecks: Not installed
2024-05-29 10:21:25,567:INFO:             xgboost: 2.0.3
2024-05-29 10:21:25,567:INFO:            catboost: Not installed
2024-05-29 10:21:25,567:INFO:              kmodes: Not installed
2024-05-29 10:21:25,567:INFO:             mlxtend: Not installed
2024-05-29 10:21:25,567:INFO:       statsforecast: Not installed
2024-05-29 10:21:25,567:INFO:        tune_sklearn: Not installed
2024-05-29 10:21:25,567:INFO:                 ray: Not installed
2024-05-29 10:21:25,567:INFO:            hyperopt: Not installed
2024-05-29 10:21:25,568:INFO:              optuna: Not installed
2024-05-29 10:21:25,568:INFO:               skopt: Not installed
2024-05-29 10:21:25,568:INFO:              mlflow: 2.13.0
2024-05-29 10:21:25,568:INFO:              gradio: Not installed
2024-05-29 10:21:25,568:INFO:             fastapi: Not installed
2024-05-29 10:21:25,568:INFO:             uvicorn: Not installed
2024-05-29 10:21:25,568:INFO:              m2cgen: Not installed
2024-05-29 10:21:25,568:INFO:           evidently: Not installed
2024-05-29 10:21:25,568:INFO:               fugue: Not installed
2024-05-29 10:21:25,568:INFO:           streamlit: Not installed
2024-05-29 10:21:25,569:INFO:             prophet: Not installed
2024-05-29 10:21:25,569:INFO:None
2024-05-29 10:21:25,569:INFO:Set up data.
2024-05-29 10:21:25,597:INFO:Set up folding strategy.
2024-05-29 10:21:25,597:INFO:Set up train/test split.
2024-05-29 10:21:25,655:INFO:Set up index.
2024-05-29 10:21:25,657:INFO:Assigning column types.
2024-05-29 10:21:25,689:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:21:25,762:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:21:25,763:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:21:25,808:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:25,812:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:25,885:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:21:25,886:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:21:25,932:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:25,936:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:25,937:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:21:26,010:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:21:26,056:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:26,060:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:26,134:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:21:26,179:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:26,183:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:26,184:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:21:26,302:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:26,307:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:26,426:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:26,430:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:26,432:INFO:Preparing preprocessing pipeline...
2024-05-29 10:21:26,438:INFO:Set up simple imputation.
2024-05-29 10:21:33,979:INFO:PyCaret ClassificationExperiment
2024-05-29 10:21:33,979:INFO:Logging name: clf-default-name
2024-05-29 10:21:33,980:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:21:33,980:INFO:version 3.3.2
2024-05-29 10:21:33,980:INFO:Initializing setup()
2024-05-29 10:21:33,980:INFO:self.USI: d0e2
2024-05-29 10:21:33,980:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:21:33,980:INFO:Checking environment
2024-05-29 10:21:33,980:INFO:python_version: 3.10.13
2024-05-29 10:21:33,980:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:21:33,980:INFO:machine: AMD64
2024-05-29 10:21:33,980:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:21:33,981:INFO:Memory: svmem(total=34267656192, available=19354005504, percent=43.5, used=14913650688, free=19354005504)
2024-05-29 10:21:33,981:INFO:Physical Core: 8
2024-05-29 10:21:33,981:INFO:Logical Core: 16
2024-05-29 10:21:33,981:INFO:Checking libraries
2024-05-29 10:21:33,981:INFO:System:
2024-05-29 10:21:33,981:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:21:33,981:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:21:33,981:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:21:33,982:INFO:PyCaret required dependencies:
2024-05-29 10:21:33,982:INFO:                 pip: 23.3
2024-05-29 10:21:33,982:INFO:          setuptools: 68.0.0
2024-05-29 10:21:33,982:INFO:             pycaret: 3.3.2
2024-05-29 10:21:33,982:INFO:             IPython: 8.24.0
2024-05-29 10:21:33,982:INFO:          ipywidgets: 8.1.2
2024-05-29 10:21:33,982:INFO:                tqdm: 4.66.4
2024-05-29 10:21:33,982:INFO:               numpy: 1.26.4
2024-05-29 10:21:33,982:INFO:              pandas: 2.1.4
2024-05-29 10:21:33,982:INFO:              jinja2: 3.1.4
2024-05-29 10:21:33,983:INFO:               scipy: 1.11.4
2024-05-29 10:21:33,983:INFO:              joblib: 1.3.2
2024-05-29 10:21:33,983:INFO:             sklearn: 1.4.2
2024-05-29 10:21:33,983:INFO:                pyod: 1.1.3
2024-05-29 10:21:33,983:INFO:            imblearn: 0.12.2
2024-05-29 10:21:33,983:INFO:   category_encoders: 2.6.3
2024-05-29 10:21:33,983:INFO:            lightgbm: 4.3.0
2024-05-29 10:21:33,983:INFO:               numba: 0.59.1
2024-05-29 10:21:33,983:INFO:            requests: 2.32.2
2024-05-29 10:21:33,983:INFO:          matplotlib: 3.7.5
2024-05-29 10:21:33,984:INFO:          scikitplot: 0.3.7
2024-05-29 10:21:33,984:INFO:         yellowbrick: 1.5
2024-05-29 10:21:33,984:INFO:              plotly: 5.22.0
2024-05-29 10:21:33,984:INFO:    plotly-resampler: Not installed
2024-05-29 10:21:33,984:INFO:             kaleido: 0.2.1
2024-05-29 10:21:33,984:INFO:           schemdraw: 0.15
2024-05-29 10:21:33,984:INFO:         statsmodels: 0.14.2
2024-05-29 10:21:33,984:INFO:              sktime: 0.26.0
2024-05-29 10:21:33,984:INFO:               tbats: 1.1.3
2024-05-29 10:21:33,984:INFO:            pmdarima: 2.0.4
2024-05-29 10:21:33,984:INFO:              psutil: 5.9.0
2024-05-29 10:21:33,985:INFO:          markupsafe: 2.1.5
2024-05-29 10:21:33,985:INFO:             pickle5: Not installed
2024-05-29 10:21:33,985:INFO:         cloudpickle: 3.0.0
2024-05-29 10:21:33,985:INFO:         deprecation: 2.1.0
2024-05-29 10:21:33,985:INFO:              xxhash: 3.4.1
2024-05-29 10:21:33,985:INFO:           wurlitzer: Not installed
2024-05-29 10:21:33,985:INFO:PyCaret optional dependencies:
2024-05-29 10:21:33,985:INFO:                shap: Not installed
2024-05-29 10:21:33,985:INFO:           interpret: Not installed
2024-05-29 10:21:33,985:INFO:                umap: Not installed
2024-05-29 10:21:33,986:INFO:     ydata_profiling: Not installed
2024-05-29 10:21:33,986:INFO:  explainerdashboard: Not installed
2024-05-29 10:21:33,986:INFO:             autoviz: Not installed
2024-05-29 10:21:33,986:INFO:           fairlearn: Not installed
2024-05-29 10:21:33,986:INFO:          deepchecks: Not installed
2024-05-29 10:21:33,986:INFO:             xgboost: 2.0.3
2024-05-29 10:21:33,986:INFO:            catboost: Not installed
2024-05-29 10:21:33,986:INFO:              kmodes: Not installed
2024-05-29 10:21:33,986:INFO:             mlxtend: Not installed
2024-05-29 10:21:33,986:INFO:       statsforecast: Not installed
2024-05-29 10:21:33,986:INFO:        tune_sklearn: Not installed
2024-05-29 10:21:33,987:INFO:                 ray: Not installed
2024-05-29 10:21:33,987:INFO:            hyperopt: Not installed
2024-05-29 10:21:33,987:INFO:              optuna: Not installed
2024-05-29 10:21:33,987:INFO:               skopt: Not installed
2024-05-29 10:21:33,987:INFO:              mlflow: 2.13.0
2024-05-29 10:21:33,987:INFO:              gradio: Not installed
2024-05-29 10:21:33,987:INFO:             fastapi: Not installed
2024-05-29 10:21:33,987:INFO:             uvicorn: Not installed
2024-05-29 10:21:33,987:INFO:              m2cgen: Not installed
2024-05-29 10:21:33,987:INFO:           evidently: Not installed
2024-05-29 10:21:33,987:INFO:               fugue: Not installed
2024-05-29 10:21:33,988:INFO:           streamlit: Not installed
2024-05-29 10:21:33,988:INFO:             prophet: Not installed
2024-05-29 10:21:33,988:INFO:None
2024-05-29 10:21:33,988:INFO:Set up data.
2024-05-29 10:21:34,018:INFO:Set up folding strategy.
2024-05-29 10:21:34,019:INFO:Set up train/test split.
2024-05-29 10:21:34,077:INFO:Set up index.
2024-05-29 10:21:34,080:INFO:Assigning column types.
2024-05-29 10:21:34,113:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:21:34,186:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:21:34,187:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:21:34,232:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:34,237:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:34,310:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:21:34,311:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:21:34,375:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:34,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:34,381:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:21:34,455:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:21:34,500:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:34,505:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:34,579:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:21:34,624:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:34,628:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:34,629:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:21:34,749:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:34,754:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:34,873:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:34,877:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:34,879:INFO:Preparing preprocessing pipeline...
2024-05-29 10:21:34,885:INFO:Set up simple imputation.
2024-05-29 10:21:39,350:INFO:PyCaret ClassificationExperiment
2024-05-29 10:21:39,350:INFO:Logging name: codex
2024-05-29 10:21:39,350:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:21:39,350:INFO:version 3.3.2
2024-05-29 10:21:39,350:INFO:Initializing setup()
2024-05-29 10:21:39,350:INFO:self.USI: 4908
2024-05-29 10:21:39,350:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:21:39,350:INFO:Checking environment
2024-05-29 10:21:39,350:INFO:python_version: 3.10.13
2024-05-29 10:21:39,351:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:21:39,351:INFO:machine: AMD64
2024-05-29 10:21:39,351:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:21:39,351:INFO:Memory: svmem(total=34267656192, available=19325202432, percent=43.6, used=14942453760, free=19325202432)
2024-05-29 10:21:39,351:INFO:Physical Core: 8
2024-05-29 10:21:39,351:INFO:Logical Core: 16
2024-05-29 10:21:39,351:INFO:Checking libraries
2024-05-29 10:21:39,351:INFO:System:
2024-05-29 10:21:39,351:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:21:39,351:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:21:39,352:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:21:39,352:INFO:PyCaret required dependencies:
2024-05-29 10:21:39,352:INFO:                 pip: 23.3
2024-05-29 10:21:39,352:INFO:          setuptools: 68.0.0
2024-05-29 10:21:39,352:INFO:             pycaret: 3.3.2
2024-05-29 10:21:39,352:INFO:             IPython: 8.24.0
2024-05-29 10:21:39,352:INFO:          ipywidgets: 8.1.2
2024-05-29 10:21:39,352:INFO:                tqdm: 4.66.4
2024-05-29 10:21:39,352:INFO:               numpy: 1.26.4
2024-05-29 10:21:39,352:INFO:              pandas: 2.1.4
2024-05-29 10:21:39,353:INFO:              jinja2: 3.1.4
2024-05-29 10:21:39,353:INFO:               scipy: 1.11.4
2024-05-29 10:21:39,353:INFO:              joblib: 1.3.2
2024-05-29 10:21:39,353:INFO:             sklearn: 1.4.2
2024-05-29 10:21:39,353:INFO:                pyod: 1.1.3
2024-05-29 10:21:39,353:INFO:            imblearn: 0.12.2
2024-05-29 10:21:39,353:INFO:   category_encoders: 2.6.3
2024-05-29 10:21:39,353:INFO:            lightgbm: 4.3.0
2024-05-29 10:21:39,353:INFO:               numba: 0.59.1
2024-05-29 10:21:39,353:INFO:            requests: 2.32.2
2024-05-29 10:21:39,353:INFO:          matplotlib: 3.7.5
2024-05-29 10:21:39,354:INFO:          scikitplot: 0.3.7
2024-05-29 10:21:39,354:INFO:         yellowbrick: 1.5
2024-05-29 10:21:39,354:INFO:              plotly: 5.22.0
2024-05-29 10:21:39,354:INFO:    plotly-resampler: Not installed
2024-05-29 10:21:39,354:INFO:             kaleido: 0.2.1
2024-05-29 10:21:39,354:INFO:           schemdraw: 0.15
2024-05-29 10:21:39,354:INFO:         statsmodels: 0.14.2
2024-05-29 10:21:39,354:INFO:              sktime: 0.26.0
2024-05-29 10:21:39,354:INFO:               tbats: 1.1.3
2024-05-29 10:21:39,354:INFO:            pmdarima: 2.0.4
2024-05-29 10:21:39,354:INFO:              psutil: 5.9.0
2024-05-29 10:21:39,354:INFO:          markupsafe: 2.1.5
2024-05-29 10:21:39,355:INFO:             pickle5: Not installed
2024-05-29 10:21:39,355:INFO:         cloudpickle: 3.0.0
2024-05-29 10:21:39,355:INFO:         deprecation: 2.1.0
2024-05-29 10:21:39,355:INFO:              xxhash: 3.4.1
2024-05-29 10:21:39,355:INFO:           wurlitzer: Not installed
2024-05-29 10:21:39,355:INFO:PyCaret optional dependencies:
2024-05-29 10:21:39,355:INFO:                shap: Not installed
2024-05-29 10:21:39,355:INFO:           interpret: Not installed
2024-05-29 10:21:39,356:INFO:                umap: Not installed
2024-05-29 10:21:39,356:INFO:     ydata_profiling: Not installed
2024-05-29 10:21:39,356:INFO:  explainerdashboard: Not installed
2024-05-29 10:21:39,356:INFO:             autoviz: Not installed
2024-05-29 10:21:39,356:INFO:           fairlearn: Not installed
2024-05-29 10:21:39,356:INFO:          deepchecks: Not installed
2024-05-29 10:21:39,356:INFO:             xgboost: 2.0.3
2024-05-29 10:21:39,356:INFO:            catboost: Not installed
2024-05-29 10:21:39,356:INFO:              kmodes: Not installed
2024-05-29 10:21:39,356:INFO:             mlxtend: Not installed
2024-05-29 10:21:39,356:INFO:       statsforecast: Not installed
2024-05-29 10:21:39,357:INFO:        tune_sklearn: Not installed
2024-05-29 10:21:39,357:INFO:                 ray: Not installed
2024-05-29 10:21:39,357:INFO:            hyperopt: Not installed
2024-05-29 10:21:39,357:INFO:              optuna: Not installed
2024-05-29 10:21:39,357:INFO:               skopt: Not installed
2024-05-29 10:21:39,357:INFO:              mlflow: 2.13.0
2024-05-29 10:21:39,357:INFO:              gradio: Not installed
2024-05-29 10:21:39,357:INFO:             fastapi: Not installed
2024-05-29 10:21:39,357:INFO:             uvicorn: Not installed
2024-05-29 10:21:39,357:INFO:              m2cgen: Not installed
2024-05-29 10:21:39,357:INFO:           evidently: Not installed
2024-05-29 10:21:39,358:INFO:               fugue: Not installed
2024-05-29 10:21:39,358:INFO:           streamlit: Not installed
2024-05-29 10:21:39,358:INFO:             prophet: Not installed
2024-05-29 10:21:39,358:INFO:None
2024-05-29 10:21:39,358:INFO:Set up data.
2024-05-29 10:21:39,387:INFO:Set up folding strategy.
2024-05-29 10:21:39,387:INFO:Set up train/test split.
2024-05-29 10:21:39,449:INFO:Set up index.
2024-05-29 10:21:39,451:INFO:Assigning column types.
2024-05-29 10:21:39,485:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:21:39,558:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:21:39,560:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:21:39,605:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:39,609:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:39,683:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:21:39,684:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:21:39,730:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:39,735:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:39,735:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:21:39,809:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:21:39,854:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:39,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:39,931:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:21:39,975:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:39,980:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:39,980:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:21:40,099:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:40,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:40,220:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:21:40,224:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:21:40,226:INFO:Preparing preprocessing pipeline...
2024-05-29 10:21:40,232:INFO:Set up simple imputation.
2024-05-29 10:22:17,782:INFO:PyCaret ClassificationExperiment
2024-05-29 10:22:17,782:INFO:Logging name: codex
2024-05-29 10:22:17,782:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:22:17,782:INFO:version 3.3.2
2024-05-29 10:22:17,782:INFO:Initializing setup()
2024-05-29 10:22:17,782:INFO:self.USI: 14b3
2024-05-29 10:22:17,782:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:22:17,783:INFO:Checking environment
2024-05-29 10:22:17,783:INFO:python_version: 3.10.13
2024-05-29 10:22:17,783:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:22:17,783:INFO:machine: AMD64
2024-05-29 10:22:17,783:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:22:17,783:INFO:Memory: svmem(total=34267656192, available=19404079104, percent=43.4, used=14863577088, free=19404079104)
2024-05-29 10:22:17,783:INFO:Physical Core: 8
2024-05-29 10:22:17,783:INFO:Logical Core: 16
2024-05-29 10:22:17,783:INFO:Checking libraries
2024-05-29 10:22:17,784:INFO:System:
2024-05-29 10:22:17,784:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:22:17,784:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:22:17,784:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:22:17,784:INFO:PyCaret required dependencies:
2024-05-29 10:22:17,784:INFO:                 pip: 23.3
2024-05-29 10:22:17,784:INFO:          setuptools: 68.0.0
2024-05-29 10:22:17,784:INFO:             pycaret: 3.3.2
2024-05-29 10:22:17,784:INFO:             IPython: 8.24.0
2024-05-29 10:22:17,784:INFO:          ipywidgets: 8.1.2
2024-05-29 10:22:17,784:INFO:                tqdm: 4.66.4
2024-05-29 10:22:17,785:INFO:               numpy: 1.26.4
2024-05-29 10:22:17,785:INFO:              pandas: 2.1.4
2024-05-29 10:22:17,785:INFO:              jinja2: 3.1.4
2024-05-29 10:22:17,785:INFO:               scipy: 1.11.4
2024-05-29 10:22:17,785:INFO:              joblib: 1.3.2
2024-05-29 10:22:17,785:INFO:             sklearn: 1.4.2
2024-05-29 10:22:17,785:INFO:                pyod: 1.1.3
2024-05-29 10:22:17,785:INFO:            imblearn: 0.12.2
2024-05-29 10:22:17,785:INFO:   category_encoders: 2.6.3
2024-05-29 10:22:17,786:INFO:            lightgbm: 4.3.0
2024-05-29 10:22:17,786:INFO:               numba: 0.59.1
2024-05-29 10:22:17,786:INFO:            requests: 2.32.2
2024-05-29 10:22:17,786:INFO:          matplotlib: 3.7.5
2024-05-29 10:22:17,786:INFO:          scikitplot: 0.3.7
2024-05-29 10:22:17,786:INFO:         yellowbrick: 1.5
2024-05-29 10:22:17,786:INFO:              plotly: 5.22.0
2024-05-29 10:22:17,786:INFO:    plotly-resampler: Not installed
2024-05-29 10:22:17,786:INFO:             kaleido: 0.2.1
2024-05-29 10:22:17,786:INFO:           schemdraw: 0.15
2024-05-29 10:22:17,787:INFO:         statsmodels: 0.14.2
2024-05-29 10:22:17,787:INFO:              sktime: 0.26.0
2024-05-29 10:22:17,787:INFO:               tbats: 1.1.3
2024-05-29 10:22:17,787:INFO:            pmdarima: 2.0.4
2024-05-29 10:22:17,787:INFO:              psutil: 5.9.0
2024-05-29 10:22:17,787:INFO:          markupsafe: 2.1.5
2024-05-29 10:22:17,787:INFO:             pickle5: Not installed
2024-05-29 10:22:17,787:INFO:         cloudpickle: 3.0.0
2024-05-29 10:22:17,787:INFO:         deprecation: 2.1.0
2024-05-29 10:22:17,787:INFO:              xxhash: 3.4.1
2024-05-29 10:22:17,787:INFO:           wurlitzer: Not installed
2024-05-29 10:22:17,787:INFO:PyCaret optional dependencies:
2024-05-29 10:22:17,788:INFO:                shap: Not installed
2024-05-29 10:22:17,788:INFO:           interpret: Not installed
2024-05-29 10:22:17,788:INFO:                umap: Not installed
2024-05-29 10:22:17,788:INFO:     ydata_profiling: Not installed
2024-05-29 10:22:17,788:INFO:  explainerdashboard: Not installed
2024-05-29 10:22:17,788:INFO:             autoviz: Not installed
2024-05-29 10:22:17,788:INFO:           fairlearn: Not installed
2024-05-29 10:22:17,788:INFO:          deepchecks: Not installed
2024-05-29 10:22:17,788:INFO:             xgboost: 2.0.3
2024-05-29 10:22:17,788:INFO:            catboost: Not installed
2024-05-29 10:22:17,788:INFO:              kmodes: Not installed
2024-05-29 10:22:17,789:INFO:             mlxtend: Not installed
2024-05-29 10:22:17,789:INFO:       statsforecast: Not installed
2024-05-29 10:22:17,789:INFO:        tune_sklearn: Not installed
2024-05-29 10:22:17,789:INFO:                 ray: Not installed
2024-05-29 10:22:17,789:INFO:            hyperopt: Not installed
2024-05-29 10:22:17,789:INFO:              optuna: Not installed
2024-05-29 10:22:17,789:INFO:               skopt: Not installed
2024-05-29 10:22:17,789:INFO:              mlflow: 2.13.0
2024-05-29 10:22:17,789:INFO:              gradio: Not installed
2024-05-29 10:22:17,789:INFO:             fastapi: Not installed
2024-05-29 10:22:17,789:INFO:             uvicorn: Not installed
2024-05-29 10:22:17,789:INFO:              m2cgen: Not installed
2024-05-29 10:22:17,790:INFO:           evidently: Not installed
2024-05-29 10:22:17,790:INFO:               fugue: Not installed
2024-05-29 10:22:17,790:INFO:           streamlit: Not installed
2024-05-29 10:22:17,790:INFO:             prophet: Not installed
2024-05-29 10:22:17,790:INFO:None
2024-05-29 10:22:17,790:INFO:Set up data.
2024-05-29 10:22:17,819:INFO:Set up folding strategy.
2024-05-29 10:22:17,819:INFO:Set up train/test split.
2024-05-29 10:22:17,877:INFO:Set up index.
2024-05-29 10:22:17,879:INFO:Assigning column types.
2024-05-29 10:22:17,913:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:22:17,984:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:22:17,985:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:22:18,029:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:22:18,034:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:22:18,105:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:22:18,106:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:22:18,151:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:22:18,156:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:22:18,156:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:22:18,229:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:22:18,273:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:22:18,277:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:22:18,350:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:22:18,394:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:22:18,398:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:22:18,399:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:22:18,515:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:22:18,520:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:22:18,639:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:22:18,644:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:22:18,646:INFO:Preparing preprocessing pipeline...
2024-05-29 10:22:18,653:INFO:Set up simple imputation.
2024-05-29 10:22:42,222:INFO:PyCaret ClassificationExperiment
2024-05-29 10:22:42,222:INFO:Logging name: codex
2024-05-29 10:22:42,222:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:22:42,222:INFO:version 3.3.2
2024-05-29 10:22:42,222:INFO:Initializing setup()
2024-05-29 10:22:42,222:INFO:self.USI: ef6f
2024-05-29 10:22:42,222:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:22:42,222:INFO:Checking environment
2024-05-29 10:22:42,223:INFO:python_version: 3.10.13
2024-05-29 10:22:42,223:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:22:42,223:INFO:machine: AMD64
2024-05-29 10:22:42,223:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:22:42,223:INFO:Memory: svmem(total=34267656192, available=19309150208, percent=43.7, used=14958505984, free=19309150208)
2024-05-29 10:22:42,223:INFO:Physical Core: 8
2024-05-29 10:22:42,223:INFO:Logical Core: 16
2024-05-29 10:22:42,223:INFO:Checking libraries
2024-05-29 10:22:42,223:INFO:System:
2024-05-29 10:22:42,224:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:22:42,224:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:22:42,224:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:22:42,224:INFO:PyCaret required dependencies:
2024-05-29 10:22:42,224:INFO:                 pip: 23.3
2024-05-29 10:22:42,224:INFO:          setuptools: 68.0.0
2024-05-29 10:22:42,224:INFO:             pycaret: 3.3.2
2024-05-29 10:22:42,224:INFO:             IPython: 8.24.0
2024-05-29 10:22:42,224:INFO:          ipywidgets: 8.1.2
2024-05-29 10:22:42,224:INFO:                tqdm: 4.66.4
2024-05-29 10:22:42,224:INFO:               numpy: 1.26.4
2024-05-29 10:22:42,225:INFO:              pandas: 2.1.4
2024-05-29 10:22:42,225:INFO:              jinja2: 3.1.4
2024-05-29 10:22:42,225:INFO:               scipy: 1.11.4
2024-05-29 10:22:42,225:INFO:              joblib: 1.3.2
2024-05-29 10:22:42,225:INFO:             sklearn: 1.4.2
2024-05-29 10:22:42,225:INFO:                pyod: 1.1.3
2024-05-29 10:22:42,225:INFO:            imblearn: 0.12.2
2024-05-29 10:22:42,225:INFO:   category_encoders: 2.6.3
2024-05-29 10:22:42,226:INFO:            lightgbm: 4.3.0
2024-05-29 10:22:42,226:INFO:               numba: 0.59.1
2024-05-29 10:22:42,226:INFO:            requests: 2.32.2
2024-05-29 10:22:42,226:INFO:          matplotlib: 3.7.5
2024-05-29 10:22:42,226:INFO:          scikitplot: 0.3.7
2024-05-29 10:22:42,226:INFO:         yellowbrick: 1.5
2024-05-29 10:22:42,226:INFO:              plotly: 5.22.0
2024-05-29 10:22:42,226:INFO:    plotly-resampler: Not installed
2024-05-29 10:22:42,226:INFO:             kaleido: 0.2.1
2024-05-29 10:22:42,226:INFO:           schemdraw: 0.15
2024-05-29 10:22:42,226:INFO:         statsmodels: 0.14.2
2024-05-29 10:22:42,227:INFO:              sktime: 0.26.0
2024-05-29 10:22:42,227:INFO:               tbats: 1.1.3
2024-05-29 10:22:42,227:INFO:            pmdarima: 2.0.4
2024-05-29 10:22:42,227:INFO:              psutil: 5.9.0
2024-05-29 10:22:42,227:INFO:          markupsafe: 2.1.5
2024-05-29 10:22:42,227:INFO:             pickle5: Not installed
2024-05-29 10:22:42,227:INFO:         cloudpickle: 3.0.0
2024-05-29 10:22:42,227:INFO:         deprecation: 2.1.0
2024-05-29 10:22:42,227:INFO:              xxhash: 3.4.1
2024-05-29 10:22:42,227:INFO:           wurlitzer: Not installed
2024-05-29 10:22:42,227:INFO:PyCaret optional dependencies:
2024-05-29 10:22:42,228:INFO:                shap: Not installed
2024-05-29 10:22:42,228:INFO:           interpret: Not installed
2024-05-29 10:22:42,228:INFO:                umap: Not installed
2024-05-29 10:22:42,228:INFO:     ydata_profiling: Not installed
2024-05-29 10:22:42,228:INFO:  explainerdashboard: Not installed
2024-05-29 10:22:42,228:INFO:             autoviz: Not installed
2024-05-29 10:22:42,228:INFO:           fairlearn: Not installed
2024-05-29 10:22:42,228:INFO:          deepchecks: Not installed
2024-05-29 10:22:42,228:INFO:             xgboost: 2.0.3
2024-05-29 10:22:42,228:INFO:            catboost: Not installed
2024-05-29 10:22:42,228:INFO:              kmodes: Not installed
2024-05-29 10:22:42,228:INFO:             mlxtend: Not installed
2024-05-29 10:22:42,229:INFO:       statsforecast: Not installed
2024-05-29 10:22:42,229:INFO:        tune_sklearn: Not installed
2024-05-29 10:22:42,229:INFO:                 ray: Not installed
2024-05-29 10:22:42,229:INFO:            hyperopt: Not installed
2024-05-29 10:22:42,229:INFO:              optuna: Not installed
2024-05-29 10:22:42,229:INFO:               skopt: Not installed
2024-05-29 10:22:42,229:INFO:              mlflow: 2.13.0
2024-05-29 10:22:42,229:INFO:              gradio: Not installed
2024-05-29 10:22:42,229:INFO:             fastapi: Not installed
2024-05-29 10:22:42,229:INFO:             uvicorn: Not installed
2024-05-29 10:22:42,229:INFO:              m2cgen: Not installed
2024-05-29 10:22:42,229:INFO:           evidently: Not installed
2024-05-29 10:22:42,230:INFO:               fugue: Not installed
2024-05-29 10:22:42,230:INFO:           streamlit: Not installed
2024-05-29 10:22:42,230:INFO:             prophet: Not installed
2024-05-29 10:22:42,230:INFO:None
2024-05-29 10:22:42,230:INFO:Set up data.
2024-05-29 10:22:42,260:INFO:Set up folding strategy.
2024-05-29 10:22:42,261:INFO:Set up train/test split.
2024-05-29 10:22:42,319:INFO:Set up index.
2024-05-29 10:22:42,321:INFO:Assigning column types.
2024-05-29 10:22:42,361:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:22:42,432:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:22:42,434:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:22:42,478:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:22:42,482:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:22:42,553:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:22:42,554:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:22:42,599:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:22:42,603:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:22:42,604:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:22:42,675:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:22:42,720:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:22:42,724:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:22:42,797:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:22:42,841:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:22:42,845:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:22:42,845:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:22:42,961:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:22:42,965:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:22:43,081:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:22:43,085:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:22:43,087:INFO:Preparing preprocessing pipeline...
2024-05-29 10:22:43,093:INFO:Set up simple imputation.
2024-05-29 10:29:32,905:INFO:PyCaret ClassificationExperiment
2024-05-29 10:29:32,905:INFO:Logging name: codex
2024-05-29 10:29:32,905:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:29:32,905:INFO:version 3.3.2
2024-05-29 10:29:32,905:INFO:Initializing setup()
2024-05-29 10:29:32,906:INFO:self.USI: 2426
2024-05-29 10:29:32,906:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:29:32,906:INFO:Checking environment
2024-05-29 10:29:32,906:INFO:python_version: 3.10.13
2024-05-29 10:29:32,906:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:29:32,906:INFO:machine: AMD64
2024-05-29 10:29:32,906:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:29:32,906:INFO:Memory: svmem(total=34267656192, available=18808832000, percent=45.1, used=15458824192, free=18808832000)
2024-05-29 10:29:32,906:INFO:Physical Core: 8
2024-05-29 10:29:32,906:INFO:Logical Core: 16
2024-05-29 10:29:32,906:INFO:Checking libraries
2024-05-29 10:29:32,907:INFO:System:
2024-05-29 10:29:32,907:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:29:32,907:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:29:32,907:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:29:32,907:INFO:PyCaret required dependencies:
2024-05-29 10:29:32,907:INFO:                 pip: 23.3
2024-05-29 10:29:32,907:INFO:          setuptools: 68.0.0
2024-05-29 10:29:32,907:INFO:             pycaret: 3.3.2
2024-05-29 10:29:32,908:INFO:             IPython: 8.24.0
2024-05-29 10:29:32,908:INFO:          ipywidgets: 8.1.2
2024-05-29 10:29:32,908:INFO:                tqdm: 4.66.4
2024-05-29 10:29:32,908:INFO:               numpy: 1.26.4
2024-05-29 10:29:32,908:INFO:              pandas: 2.1.4
2024-05-29 10:29:32,908:INFO:              jinja2: 3.1.4
2024-05-29 10:29:32,908:INFO:               scipy: 1.11.4
2024-05-29 10:29:32,908:INFO:              joblib: 1.3.2
2024-05-29 10:29:32,908:INFO:             sklearn: 1.4.2
2024-05-29 10:29:32,909:INFO:                pyod: 1.1.3
2024-05-29 10:29:32,909:INFO:            imblearn: 0.12.2
2024-05-29 10:29:32,909:INFO:   category_encoders: 2.6.3
2024-05-29 10:29:32,909:INFO:            lightgbm: 4.3.0
2024-05-29 10:29:32,909:INFO:               numba: 0.59.1
2024-05-29 10:29:32,909:INFO:            requests: 2.32.2
2024-05-29 10:29:32,909:INFO:          matplotlib: 3.7.5
2024-05-29 10:29:32,909:INFO:          scikitplot: 0.3.7
2024-05-29 10:29:32,909:INFO:         yellowbrick: 1.5
2024-05-29 10:29:32,909:INFO:              plotly: 5.22.0
2024-05-29 10:29:32,909:INFO:    plotly-resampler: Not installed
2024-05-29 10:29:32,910:INFO:             kaleido: 0.2.1
2024-05-29 10:29:32,910:INFO:           schemdraw: 0.15
2024-05-29 10:29:32,910:INFO:         statsmodels: 0.14.2
2024-05-29 10:29:32,910:INFO:              sktime: 0.26.0
2024-05-29 10:29:32,910:INFO:               tbats: 1.1.3
2024-05-29 10:29:32,910:INFO:            pmdarima: 2.0.4
2024-05-29 10:29:32,910:INFO:              psutil: 5.9.0
2024-05-29 10:29:32,910:INFO:          markupsafe: 2.1.5
2024-05-29 10:29:32,910:INFO:             pickle5: Not installed
2024-05-29 10:29:32,910:INFO:         cloudpickle: 3.0.0
2024-05-29 10:29:32,910:INFO:         deprecation: 2.1.0
2024-05-29 10:29:32,910:INFO:              xxhash: 3.4.1
2024-05-29 10:29:32,911:INFO:           wurlitzer: Not installed
2024-05-29 10:29:32,911:INFO:PyCaret optional dependencies:
2024-05-29 10:29:32,911:INFO:                shap: Not installed
2024-05-29 10:29:32,911:INFO:           interpret: Not installed
2024-05-29 10:29:32,911:INFO:                umap: Not installed
2024-05-29 10:29:32,911:INFO:     ydata_profiling: Not installed
2024-05-29 10:29:32,911:INFO:  explainerdashboard: Not installed
2024-05-29 10:29:32,911:INFO:             autoviz: Not installed
2024-05-29 10:29:32,911:INFO:           fairlearn: Not installed
2024-05-29 10:29:32,911:INFO:          deepchecks: Not installed
2024-05-29 10:29:32,911:INFO:             xgboost: 2.0.3
2024-05-29 10:29:32,911:INFO:            catboost: Not installed
2024-05-29 10:29:32,912:INFO:              kmodes: Not installed
2024-05-29 10:29:32,912:INFO:             mlxtend: Not installed
2024-05-29 10:29:32,912:INFO:       statsforecast: Not installed
2024-05-29 10:29:32,912:INFO:        tune_sklearn: Not installed
2024-05-29 10:29:32,912:INFO:                 ray: Not installed
2024-05-29 10:29:32,912:INFO:            hyperopt: Not installed
2024-05-29 10:29:32,912:INFO:              optuna: Not installed
2024-05-29 10:29:32,912:INFO:               skopt: Not installed
2024-05-29 10:29:32,912:INFO:              mlflow: 2.13.0
2024-05-29 10:29:32,912:INFO:              gradio: Not installed
2024-05-29 10:29:32,912:INFO:             fastapi: Not installed
2024-05-29 10:29:32,912:INFO:             uvicorn: Not installed
2024-05-29 10:29:32,913:INFO:              m2cgen: Not installed
2024-05-29 10:29:32,913:INFO:           evidently: Not installed
2024-05-29 10:29:32,913:INFO:               fugue: Not installed
2024-05-29 10:29:32,913:INFO:           streamlit: Not installed
2024-05-29 10:29:32,913:INFO:             prophet: Not installed
2024-05-29 10:29:32,913:INFO:None
2024-05-29 10:29:32,913:INFO:Set up data.
2024-05-29 10:29:32,942:INFO:Set up folding strategy.
2024-05-29 10:29:32,943:INFO:Set up train/test split.
2024-05-29 10:29:32,999:INFO:Set up index.
2024-05-29 10:29:33,001:INFO:Assigning column types.
2024-05-29 10:29:33,034:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:29:33,105:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:29:33,107:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:29:33,151:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:29:33,156:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:29:33,227:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:29:33,229:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:29:33,273:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:29:33,278:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:29:33,278:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:29:33,351:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:29:33,395:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:29:33,400:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:29:33,472:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:29:33,516:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:29:33,520:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:29:33,521:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:29:33,637:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:29:33,641:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:29:33,758:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:29:33,762:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:29:33,764:INFO:Preparing preprocessing pipeline...
2024-05-29 10:29:33,770:INFO:Set up simple imputation.
2024-05-29 10:29:51,774:INFO:PyCaret ClassificationExperiment
2024-05-29 10:29:51,774:INFO:Logging name: codex
2024-05-29 10:29:51,774:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:29:51,774:INFO:version 3.3.2
2024-05-29 10:29:51,774:INFO:Initializing setup()
2024-05-29 10:29:51,774:INFO:self.USI: 52e2
2024-05-29 10:29:51,774:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:29:51,774:INFO:Checking environment
2024-05-29 10:29:51,775:INFO:python_version: 3.10.13
2024-05-29 10:29:51,775:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:29:51,775:INFO:machine: AMD64
2024-05-29 10:29:51,775:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:29:51,775:INFO:Memory: svmem(total=34267656192, available=18688503808, percent=45.5, used=15579152384, free=18688503808)
2024-05-29 10:29:51,775:INFO:Physical Core: 8
2024-05-29 10:29:51,775:INFO:Logical Core: 16
2024-05-29 10:29:51,775:INFO:Checking libraries
2024-05-29 10:29:51,776:INFO:System:
2024-05-29 10:29:51,776:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:29:51,776:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:29:51,776:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:29:51,776:INFO:PyCaret required dependencies:
2024-05-29 10:29:51,776:INFO:                 pip: 23.3
2024-05-29 10:29:51,776:INFO:          setuptools: 68.0.0
2024-05-29 10:29:51,776:INFO:             pycaret: 3.3.2
2024-05-29 10:29:51,776:INFO:             IPython: 8.24.0
2024-05-29 10:29:51,776:INFO:          ipywidgets: 8.1.2
2024-05-29 10:29:51,777:INFO:                tqdm: 4.66.4
2024-05-29 10:29:51,777:INFO:               numpy: 1.26.4
2024-05-29 10:29:51,777:INFO:              pandas: 2.1.4
2024-05-29 10:29:51,777:INFO:              jinja2: 3.1.4
2024-05-29 10:29:51,777:INFO:               scipy: 1.11.4
2024-05-29 10:29:51,777:INFO:              joblib: 1.3.2
2024-05-29 10:29:51,777:INFO:             sklearn: 1.4.2
2024-05-29 10:29:51,777:INFO:                pyod: 1.1.3
2024-05-29 10:29:51,777:INFO:            imblearn: 0.12.2
2024-05-29 10:29:51,777:INFO:   category_encoders: 2.6.3
2024-05-29 10:29:51,777:INFO:            lightgbm: 4.3.0
2024-05-29 10:29:51,778:INFO:               numba: 0.59.1
2024-05-29 10:29:51,778:INFO:            requests: 2.32.2
2024-05-29 10:29:51,778:INFO:          matplotlib: 3.7.5
2024-05-29 10:29:51,778:INFO:          scikitplot: 0.3.7
2024-05-29 10:29:51,778:INFO:         yellowbrick: 1.5
2024-05-29 10:29:51,778:INFO:              plotly: 5.22.0
2024-05-29 10:29:51,778:INFO:    plotly-resampler: Not installed
2024-05-29 10:29:51,778:INFO:             kaleido: 0.2.1
2024-05-29 10:29:51,778:INFO:           schemdraw: 0.15
2024-05-29 10:29:51,778:INFO:         statsmodels: 0.14.2
2024-05-29 10:29:51,778:INFO:              sktime: 0.26.0
2024-05-29 10:29:51,779:INFO:               tbats: 1.1.3
2024-05-29 10:29:51,779:INFO:            pmdarima: 2.0.4
2024-05-29 10:29:51,779:INFO:              psutil: 5.9.0
2024-05-29 10:29:51,779:INFO:          markupsafe: 2.1.5
2024-05-29 10:29:51,779:INFO:             pickle5: Not installed
2024-05-29 10:29:51,779:INFO:         cloudpickle: 3.0.0
2024-05-29 10:29:51,779:INFO:         deprecation: 2.1.0
2024-05-29 10:29:51,779:INFO:              xxhash: 3.4.1
2024-05-29 10:29:51,779:INFO:           wurlitzer: Not installed
2024-05-29 10:29:51,779:INFO:PyCaret optional dependencies:
2024-05-29 10:29:51,780:INFO:                shap: Not installed
2024-05-29 10:29:51,780:INFO:           interpret: Not installed
2024-05-29 10:29:51,780:INFO:                umap: Not installed
2024-05-29 10:29:51,780:INFO:     ydata_profiling: Not installed
2024-05-29 10:29:51,780:INFO:  explainerdashboard: Not installed
2024-05-29 10:29:51,780:INFO:             autoviz: Not installed
2024-05-29 10:29:51,780:INFO:           fairlearn: Not installed
2024-05-29 10:29:51,780:INFO:          deepchecks: Not installed
2024-05-29 10:29:51,780:INFO:             xgboost: 2.0.3
2024-05-29 10:29:51,780:INFO:            catboost: Not installed
2024-05-29 10:29:51,780:INFO:              kmodes: Not installed
2024-05-29 10:29:51,781:INFO:             mlxtend: Not installed
2024-05-29 10:29:51,781:INFO:       statsforecast: Not installed
2024-05-29 10:29:51,781:INFO:        tune_sklearn: Not installed
2024-05-29 10:29:51,781:INFO:                 ray: Not installed
2024-05-29 10:29:51,781:INFO:            hyperopt: Not installed
2024-05-29 10:29:51,781:INFO:              optuna: Not installed
2024-05-29 10:29:51,781:INFO:               skopt: Not installed
2024-05-29 10:29:51,781:INFO:              mlflow: 2.13.0
2024-05-29 10:29:51,781:INFO:              gradio: Not installed
2024-05-29 10:29:51,782:INFO:             fastapi: Not installed
2024-05-29 10:29:51,782:INFO:             uvicorn: Not installed
2024-05-29 10:29:51,782:INFO:              m2cgen: Not installed
2024-05-29 10:29:51,782:INFO:           evidently: Not installed
2024-05-29 10:29:51,782:INFO:               fugue: Not installed
2024-05-29 10:29:51,782:INFO:           streamlit: Not installed
2024-05-29 10:29:51,782:INFO:             prophet: Not installed
2024-05-29 10:29:51,782:INFO:None
2024-05-29 10:29:51,783:INFO:Set up data.
2024-05-29 10:29:51,812:INFO:Set up folding strategy.
2024-05-29 10:29:51,812:INFO:Set up train/test split.
2024-05-29 10:29:51,870:INFO:Set up index.
2024-05-29 10:29:51,872:INFO:Assigning column types.
2024-05-29 10:29:51,906:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:29:51,977:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:29:51,978:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:29:52,023:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:29:52,027:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:29:52,098:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:29:52,099:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:29:52,145:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:29:52,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:29:52,150:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:29:52,222:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:29:52,266:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:29:52,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:29:52,344:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:29:52,388:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:29:52,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:29:52,392:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:29:52,508:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:29:52,513:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:29:52,628:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:29:52,632:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:29:52,634:INFO:Preparing preprocessing pipeline...
2024-05-29 10:29:52,640:INFO:Set up simple imputation.
2024-05-29 10:31:34,125:INFO:PyCaret ClassificationExperiment
2024-05-29 10:31:34,125:INFO:Logging name: codex
2024-05-29 10:31:34,125:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:31:34,125:INFO:version 3.3.2
2024-05-29 10:31:34,125:INFO:Initializing setup()
2024-05-29 10:31:34,125:INFO:self.USI: a6eb
2024-05-29 10:31:34,126:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:31:34,126:INFO:Checking environment
2024-05-29 10:31:34,126:INFO:python_version: 3.10.13
2024-05-29 10:31:34,126:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:31:34,126:INFO:machine: AMD64
2024-05-29 10:31:34,126:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:31:34,126:INFO:Memory: svmem(total=34267656192, available=18605563904, percent=45.7, used=15662092288, free=18605563904)
2024-05-29 10:31:34,126:INFO:Physical Core: 8
2024-05-29 10:31:34,126:INFO:Logical Core: 16
2024-05-29 10:31:34,127:INFO:Checking libraries
2024-05-29 10:31:34,127:INFO:System:
2024-05-29 10:31:34,127:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:31:34,127:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:31:34,127:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:31:34,127:INFO:PyCaret required dependencies:
2024-05-29 10:31:34,127:INFO:                 pip: 23.3
2024-05-29 10:31:34,127:INFO:          setuptools: 68.0.0
2024-05-29 10:31:34,127:INFO:             pycaret: 3.3.2
2024-05-29 10:31:34,128:INFO:             IPython: 8.24.0
2024-05-29 10:31:34,128:INFO:          ipywidgets: 8.1.2
2024-05-29 10:31:34,128:INFO:                tqdm: 4.66.4
2024-05-29 10:31:34,128:INFO:               numpy: 1.26.4
2024-05-29 10:31:34,128:INFO:              pandas: 2.1.4
2024-05-29 10:31:34,128:INFO:              jinja2: 3.1.4
2024-05-29 10:31:34,128:INFO:               scipy: 1.11.4
2024-05-29 10:31:34,128:INFO:              joblib: 1.3.2
2024-05-29 10:31:34,128:INFO:             sklearn: 1.4.2
2024-05-29 10:31:34,128:INFO:                pyod: 1.1.3
2024-05-29 10:31:34,129:INFO:            imblearn: 0.12.2
2024-05-29 10:31:34,129:INFO:   category_encoders: 2.6.3
2024-05-29 10:31:34,129:INFO:            lightgbm: 4.3.0
2024-05-29 10:31:34,129:INFO:               numba: 0.59.1
2024-05-29 10:31:34,129:INFO:            requests: 2.32.2
2024-05-29 10:31:34,129:INFO:          matplotlib: 3.7.5
2024-05-29 10:31:34,129:INFO:          scikitplot: 0.3.7
2024-05-29 10:31:34,129:INFO:         yellowbrick: 1.5
2024-05-29 10:31:34,129:INFO:              plotly: 5.22.0
2024-05-29 10:31:34,129:INFO:    plotly-resampler: Not installed
2024-05-29 10:31:34,129:INFO:             kaleido: 0.2.1
2024-05-29 10:31:34,130:INFO:           schemdraw: 0.15
2024-05-29 10:31:34,130:INFO:         statsmodels: 0.14.2
2024-05-29 10:31:34,130:INFO:              sktime: 0.26.0
2024-05-29 10:31:34,130:INFO:               tbats: 1.1.3
2024-05-29 10:31:34,130:INFO:            pmdarima: 2.0.4
2024-05-29 10:31:34,130:INFO:              psutil: 5.9.0
2024-05-29 10:31:34,130:INFO:          markupsafe: 2.1.5
2024-05-29 10:31:34,130:INFO:             pickle5: Not installed
2024-05-29 10:31:34,130:INFO:         cloudpickle: 3.0.0
2024-05-29 10:31:34,130:INFO:         deprecation: 2.1.0
2024-05-29 10:31:34,130:INFO:              xxhash: 3.4.1
2024-05-29 10:31:34,131:INFO:           wurlitzer: Not installed
2024-05-29 10:31:34,131:INFO:PyCaret optional dependencies:
2024-05-29 10:31:34,131:INFO:                shap: Not installed
2024-05-29 10:31:34,131:INFO:           interpret: Not installed
2024-05-29 10:31:34,131:INFO:                umap: Not installed
2024-05-29 10:31:34,131:INFO:     ydata_profiling: Not installed
2024-05-29 10:31:34,131:INFO:  explainerdashboard: Not installed
2024-05-29 10:31:34,131:INFO:             autoviz: Not installed
2024-05-29 10:31:34,131:INFO:           fairlearn: Not installed
2024-05-29 10:31:34,131:INFO:          deepchecks: Not installed
2024-05-29 10:31:34,132:INFO:             xgboost: 2.0.3
2024-05-29 10:31:34,132:INFO:            catboost: Not installed
2024-05-29 10:31:34,132:INFO:              kmodes: Not installed
2024-05-29 10:31:34,132:INFO:             mlxtend: Not installed
2024-05-29 10:31:34,132:INFO:       statsforecast: Not installed
2024-05-29 10:31:34,132:INFO:        tune_sklearn: Not installed
2024-05-29 10:31:34,132:INFO:                 ray: Not installed
2024-05-29 10:31:34,132:INFO:            hyperopt: Not installed
2024-05-29 10:31:34,132:INFO:              optuna: Not installed
2024-05-29 10:31:34,132:INFO:               skopt: Not installed
2024-05-29 10:31:34,132:INFO:              mlflow: 2.13.0
2024-05-29 10:31:34,133:INFO:              gradio: Not installed
2024-05-29 10:31:34,133:INFO:             fastapi: Not installed
2024-05-29 10:31:34,133:INFO:             uvicorn: Not installed
2024-05-29 10:31:34,133:INFO:              m2cgen: Not installed
2024-05-29 10:31:34,133:INFO:           evidently: Not installed
2024-05-29 10:31:34,133:INFO:               fugue: Not installed
2024-05-29 10:31:34,133:INFO:           streamlit: Not installed
2024-05-29 10:31:34,133:INFO:             prophet: Not installed
2024-05-29 10:31:34,133:INFO:None
2024-05-29 10:31:34,133:INFO:Set up data.
2024-05-29 10:31:34,162:INFO:Set up folding strategy.
2024-05-29 10:31:34,162:INFO:Set up train/test split.
2024-05-29 10:31:34,220:INFO:Set up index.
2024-05-29 10:31:34,222:INFO:Assigning column types.
2024-05-29 10:31:34,255:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:31:34,326:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:31:34,327:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:31:34,372:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:31:34,376:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:31:34,448:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:31:34,449:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:31:34,494:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:31:34,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:31:34,499:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:31:34,571:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:31:34,615:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:31:34,619:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:31:34,692:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:31:34,736:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:31:34,741:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:31:34,741:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:31:34,857:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:31:34,861:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:31:34,978:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:31:34,982:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:31:34,984:INFO:Preparing preprocessing pipeline...
2024-05-29 10:31:34,989:INFO:Set up simple imputation.
2024-05-29 10:33:28,202:INFO:PyCaret ClassificationExperiment
2024-05-29 10:33:28,202:INFO:Logging name: codex
2024-05-29 10:33:28,203:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:33:28,203:INFO:version 3.3.2
2024-05-29 10:33:28,203:INFO:Initializing setup()
2024-05-29 10:33:28,203:INFO:self.USI: da22
2024-05-29 10:33:28,203:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:33:28,203:INFO:Checking environment
2024-05-29 10:33:28,203:INFO:python_version: 3.10.13
2024-05-29 10:33:28,203:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:33:28,203:INFO:machine: AMD64
2024-05-29 10:33:28,203:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:33:28,204:INFO:Memory: svmem(total=34267656192, available=18787856384, percent=45.2, used=15479799808, free=18787856384)
2024-05-29 10:33:28,204:INFO:Physical Core: 8
2024-05-29 10:33:28,204:INFO:Logical Core: 16
2024-05-29 10:33:28,204:INFO:Checking libraries
2024-05-29 10:33:28,204:INFO:System:
2024-05-29 10:33:28,204:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:33:28,204:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:33:28,204:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:33:28,204:INFO:PyCaret required dependencies:
2024-05-29 10:33:28,205:INFO:                 pip: 23.3
2024-05-29 10:33:28,205:INFO:          setuptools: 68.0.0
2024-05-29 10:33:28,205:INFO:             pycaret: 3.3.2
2024-05-29 10:33:28,205:INFO:             IPython: 8.24.0
2024-05-29 10:33:28,205:INFO:          ipywidgets: 8.1.2
2024-05-29 10:33:28,205:INFO:                tqdm: 4.66.4
2024-05-29 10:33:28,205:INFO:               numpy: 1.26.4
2024-05-29 10:33:28,205:INFO:              pandas: 2.1.4
2024-05-29 10:33:28,205:INFO:              jinja2: 3.1.4
2024-05-29 10:33:28,205:INFO:               scipy: 1.11.4
2024-05-29 10:33:28,206:INFO:              joblib: 1.3.2
2024-05-29 10:33:28,206:INFO:             sklearn: 1.4.2
2024-05-29 10:33:28,206:INFO:                pyod: 1.1.3
2024-05-29 10:33:28,206:INFO:            imblearn: 0.12.2
2024-05-29 10:33:28,206:INFO:   category_encoders: 2.6.3
2024-05-29 10:33:28,206:INFO:            lightgbm: 4.3.0
2024-05-29 10:33:28,206:INFO:               numba: 0.59.1
2024-05-29 10:33:28,206:INFO:            requests: 2.32.2
2024-05-29 10:33:28,206:INFO:          matplotlib: 3.7.5
2024-05-29 10:33:28,206:INFO:          scikitplot: 0.3.7
2024-05-29 10:33:28,206:INFO:         yellowbrick: 1.5
2024-05-29 10:33:28,206:INFO:              plotly: 5.22.0
2024-05-29 10:33:28,207:INFO:    plotly-resampler: Not installed
2024-05-29 10:33:28,207:INFO:             kaleido: 0.2.1
2024-05-29 10:33:28,207:INFO:           schemdraw: 0.15
2024-05-29 10:33:28,207:INFO:         statsmodels: 0.14.2
2024-05-29 10:33:28,207:INFO:              sktime: 0.26.0
2024-05-29 10:33:28,207:INFO:               tbats: 1.1.3
2024-05-29 10:33:28,207:INFO:            pmdarima: 2.0.4
2024-05-29 10:33:28,207:INFO:              psutil: 5.9.0
2024-05-29 10:33:28,207:INFO:          markupsafe: 2.1.5
2024-05-29 10:33:28,207:INFO:             pickle5: Not installed
2024-05-29 10:33:28,207:INFO:         cloudpickle: 3.0.0
2024-05-29 10:33:28,207:INFO:         deprecation: 2.1.0
2024-05-29 10:33:28,208:INFO:              xxhash: 3.4.1
2024-05-29 10:33:28,208:INFO:           wurlitzer: Not installed
2024-05-29 10:33:28,208:INFO:PyCaret optional dependencies:
2024-05-29 10:33:28,208:INFO:                shap: Not installed
2024-05-29 10:33:28,208:INFO:           interpret: Not installed
2024-05-29 10:33:28,208:INFO:                umap: Not installed
2024-05-29 10:33:28,208:INFO:     ydata_profiling: Not installed
2024-05-29 10:33:28,208:INFO:  explainerdashboard: Not installed
2024-05-29 10:33:28,208:INFO:             autoviz: Not installed
2024-05-29 10:33:28,209:INFO:           fairlearn: Not installed
2024-05-29 10:33:28,209:INFO:          deepchecks: Not installed
2024-05-29 10:33:28,209:INFO:             xgboost: 2.0.3
2024-05-29 10:33:28,209:INFO:            catboost: Not installed
2024-05-29 10:33:28,209:INFO:              kmodes: Not installed
2024-05-29 10:33:28,209:INFO:             mlxtend: Not installed
2024-05-29 10:33:28,209:INFO:       statsforecast: Not installed
2024-05-29 10:33:28,209:INFO:        tune_sklearn: Not installed
2024-05-29 10:33:28,209:INFO:                 ray: Not installed
2024-05-29 10:33:28,209:INFO:            hyperopt: Not installed
2024-05-29 10:33:28,209:INFO:              optuna: Not installed
2024-05-29 10:33:28,209:INFO:               skopt: Not installed
2024-05-29 10:33:28,210:INFO:              mlflow: 2.13.0
2024-05-29 10:33:28,210:INFO:              gradio: Not installed
2024-05-29 10:33:28,210:INFO:             fastapi: Not installed
2024-05-29 10:33:28,210:INFO:             uvicorn: Not installed
2024-05-29 10:33:28,210:INFO:              m2cgen: Not installed
2024-05-29 10:33:28,210:INFO:           evidently: Not installed
2024-05-29 10:33:28,210:INFO:               fugue: Not installed
2024-05-29 10:33:28,210:INFO:           streamlit: Not installed
2024-05-29 10:33:28,210:INFO:             prophet: Not installed
2024-05-29 10:33:28,210:INFO:None
2024-05-29 10:33:28,210:INFO:Set up data.
2024-05-29 10:33:28,239:INFO:Set up folding strategy.
2024-05-29 10:33:28,239:INFO:Set up train/test split.
2024-05-29 10:33:28,296:INFO:Set up index.
2024-05-29 10:33:28,298:INFO:Assigning column types.
2024-05-29 10:33:28,332:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:33:28,404:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:33:28,405:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:33:28,449:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:33:28,454:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:33:28,525:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:33:28,526:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:33:28,570:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:33:28,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:33:28,575:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:33:28,646:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:33:28,690:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:33:28,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:33:28,767:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:33:28,811:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:33:28,816:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:33:28,816:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:33:28,932:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:33:28,936:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:33:29,053:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:33:29,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:33:29,059:INFO:Preparing preprocessing pipeline...
2024-05-29 10:33:29,065:INFO:Set up simple imputation.
2024-05-29 10:34:09,191:INFO:PyCaret ClassificationExperiment
2024-05-29 10:34:09,191:INFO:Logging name: codex
2024-05-29 10:34:09,191:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:34:09,191:INFO:version 3.3.2
2024-05-29 10:34:09,191:INFO:Initializing setup()
2024-05-29 10:34:09,191:INFO:self.USI: a668
2024-05-29 10:34:09,191:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:34:09,192:INFO:Checking environment
2024-05-29 10:34:09,192:INFO:python_version: 3.10.13
2024-05-29 10:34:09,192:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:34:09,192:INFO:machine: AMD64
2024-05-29 10:34:09,192:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:34:09,192:INFO:Memory: svmem(total=34267656192, available=18702630912, percent=45.4, used=15565025280, free=18702630912)
2024-05-29 10:34:09,192:INFO:Physical Core: 8
2024-05-29 10:34:09,192:INFO:Logical Core: 16
2024-05-29 10:34:09,192:INFO:Checking libraries
2024-05-29 10:34:09,192:INFO:System:
2024-05-29 10:34:09,193:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:34:09,193:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:34:09,193:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:34:09,193:INFO:PyCaret required dependencies:
2024-05-29 10:34:09,193:INFO:                 pip: 23.3
2024-05-29 10:34:09,193:INFO:          setuptools: 68.0.0
2024-05-29 10:34:09,193:INFO:             pycaret: 3.3.2
2024-05-29 10:34:09,193:INFO:             IPython: 8.24.0
2024-05-29 10:34:09,193:INFO:          ipywidgets: 8.1.2
2024-05-29 10:34:09,193:INFO:                tqdm: 4.66.4
2024-05-29 10:34:09,193:INFO:               numpy: 1.26.4
2024-05-29 10:34:09,194:INFO:              pandas: 2.1.4
2024-05-29 10:34:09,194:INFO:              jinja2: 3.1.4
2024-05-29 10:34:09,194:INFO:               scipy: 1.11.4
2024-05-29 10:34:09,194:INFO:              joblib: 1.3.2
2024-05-29 10:34:09,194:INFO:             sklearn: 1.4.2
2024-05-29 10:34:09,194:INFO:                pyod: 1.1.3
2024-05-29 10:34:09,194:INFO:            imblearn: 0.12.2
2024-05-29 10:34:09,194:INFO:   category_encoders: 2.6.3
2024-05-29 10:34:09,194:INFO:            lightgbm: 4.3.0
2024-05-29 10:34:09,194:INFO:               numba: 0.59.1
2024-05-29 10:34:09,194:INFO:            requests: 2.32.2
2024-05-29 10:34:09,194:INFO:          matplotlib: 3.7.5
2024-05-29 10:34:09,195:INFO:          scikitplot: 0.3.7
2024-05-29 10:34:09,195:INFO:         yellowbrick: 1.5
2024-05-29 10:34:09,195:INFO:              plotly: 5.22.0
2024-05-29 10:34:09,195:INFO:    plotly-resampler: Not installed
2024-05-29 10:34:09,195:INFO:             kaleido: 0.2.1
2024-05-29 10:34:09,195:INFO:           schemdraw: 0.15
2024-05-29 10:34:09,195:INFO:         statsmodels: 0.14.2
2024-05-29 10:34:09,195:INFO:              sktime: 0.26.0
2024-05-29 10:34:09,195:INFO:               tbats: 1.1.3
2024-05-29 10:34:09,195:INFO:            pmdarima: 2.0.4
2024-05-29 10:34:09,195:INFO:              psutil: 5.9.0
2024-05-29 10:34:09,196:INFO:          markupsafe: 2.1.5
2024-05-29 10:34:09,196:INFO:             pickle5: Not installed
2024-05-29 10:34:09,196:INFO:         cloudpickle: 3.0.0
2024-05-29 10:34:09,196:INFO:         deprecation: 2.1.0
2024-05-29 10:34:09,196:INFO:              xxhash: 3.4.1
2024-05-29 10:34:09,196:INFO:           wurlitzer: Not installed
2024-05-29 10:34:09,196:INFO:PyCaret optional dependencies:
2024-05-29 10:34:09,196:INFO:                shap: Not installed
2024-05-29 10:34:09,196:INFO:           interpret: Not installed
2024-05-29 10:34:09,196:INFO:                umap: Not installed
2024-05-29 10:34:09,197:INFO:     ydata_profiling: Not installed
2024-05-29 10:34:09,197:INFO:  explainerdashboard: Not installed
2024-05-29 10:34:09,197:INFO:             autoviz: Not installed
2024-05-29 10:34:09,197:INFO:           fairlearn: Not installed
2024-05-29 10:34:09,197:INFO:          deepchecks: Not installed
2024-05-29 10:34:09,197:INFO:             xgboost: 2.0.3
2024-05-29 10:34:09,197:INFO:            catboost: Not installed
2024-05-29 10:34:09,197:INFO:              kmodes: Not installed
2024-05-29 10:34:09,197:INFO:             mlxtend: Not installed
2024-05-29 10:34:09,197:INFO:       statsforecast: Not installed
2024-05-29 10:34:09,197:INFO:        tune_sklearn: Not installed
2024-05-29 10:34:09,197:INFO:                 ray: Not installed
2024-05-29 10:34:09,198:INFO:            hyperopt: Not installed
2024-05-29 10:34:09,198:INFO:              optuna: Not installed
2024-05-29 10:34:09,198:INFO:               skopt: Not installed
2024-05-29 10:34:09,198:INFO:              mlflow: 2.13.0
2024-05-29 10:34:09,198:INFO:              gradio: Not installed
2024-05-29 10:34:09,198:INFO:             fastapi: Not installed
2024-05-29 10:34:09,198:INFO:             uvicorn: Not installed
2024-05-29 10:34:09,198:INFO:              m2cgen: Not installed
2024-05-29 10:34:09,198:INFO:           evidently: Not installed
2024-05-29 10:34:09,198:INFO:               fugue: Not installed
2024-05-29 10:34:09,198:INFO:           streamlit: Not installed
2024-05-29 10:34:09,199:INFO:             prophet: Not installed
2024-05-29 10:34:09,199:INFO:None
2024-05-29 10:34:09,199:INFO:Set up data.
2024-05-29 10:34:09,228:INFO:Set up folding strategy.
2024-05-29 10:34:09,228:INFO:Set up train/test split.
2024-05-29 10:34:09,286:INFO:Set up index.
2024-05-29 10:34:09,288:INFO:Assigning column types.
2024-05-29 10:34:09,322:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:34:09,394:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:34:09,395:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:34:09,439:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:34:09,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:34:09,516:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:34:09,517:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:34:09,561:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:34:09,566:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:34:09,566:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:34:09,638:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:34:09,683:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:34:09,687:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:34:09,760:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:34:09,804:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:34:09,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:34:09,808:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:34:09,923:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:34:09,928:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:34:10,043:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:34:10,047:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:34:10,049:INFO:Preparing preprocessing pipeline...
2024-05-29 10:34:10,055:INFO:Set up simple imputation.
2024-05-29 10:37:30,256:INFO:PyCaret ClassificationExperiment
2024-05-29 10:37:30,256:INFO:Logging name: codex
2024-05-29 10:37:30,256:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:37:30,256:INFO:version 3.3.2
2024-05-29 10:37:30,256:INFO:Initializing setup()
2024-05-29 10:37:30,256:INFO:self.USI: 379c
2024-05-29 10:37:30,256:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:37:30,257:INFO:Checking environment
2024-05-29 10:37:30,257:INFO:python_version: 3.10.13
2024-05-29 10:37:30,257:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:37:30,257:INFO:machine: AMD64
2024-05-29 10:37:30,257:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:37:30,257:INFO:Memory: svmem(total=34267656192, available=18392686592, percent=46.3, used=15874969600, free=18392686592)
2024-05-29 10:37:30,257:INFO:Physical Core: 8
2024-05-29 10:37:30,257:INFO:Logical Core: 16
2024-05-29 10:37:30,258:INFO:Checking libraries
2024-05-29 10:37:30,258:INFO:System:
2024-05-29 10:37:30,258:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:37:30,258:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:37:30,258:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:37:30,258:INFO:PyCaret required dependencies:
2024-05-29 10:37:30,258:INFO:                 pip: 23.3
2024-05-29 10:37:30,258:INFO:          setuptools: 68.0.0
2024-05-29 10:37:30,258:INFO:             pycaret: 3.3.2
2024-05-29 10:37:30,258:INFO:             IPython: 8.24.0
2024-05-29 10:37:30,259:INFO:          ipywidgets: 8.1.2
2024-05-29 10:37:30,259:INFO:                tqdm: 4.66.4
2024-05-29 10:37:30,259:INFO:               numpy: 1.26.4
2024-05-29 10:37:30,259:INFO:              pandas: 2.1.4
2024-05-29 10:37:30,259:INFO:              jinja2: 3.1.4
2024-05-29 10:37:30,259:INFO:               scipy: 1.11.4
2024-05-29 10:37:30,259:INFO:              joblib: 1.3.2
2024-05-29 10:37:30,259:INFO:             sklearn: 1.4.2
2024-05-29 10:37:30,259:INFO:                pyod: 1.1.3
2024-05-29 10:37:30,259:INFO:            imblearn: 0.12.2
2024-05-29 10:37:30,259:INFO:   category_encoders: 2.6.3
2024-05-29 10:37:30,260:INFO:            lightgbm: 4.3.0
2024-05-29 10:37:30,260:INFO:               numba: 0.59.1
2024-05-29 10:37:30,260:INFO:            requests: 2.32.2
2024-05-29 10:37:30,260:INFO:          matplotlib: 3.7.5
2024-05-29 10:37:30,260:INFO:          scikitplot: 0.3.7
2024-05-29 10:37:30,260:INFO:         yellowbrick: 1.5
2024-05-29 10:37:30,260:INFO:              plotly: 5.22.0
2024-05-29 10:37:30,260:INFO:    plotly-resampler: Not installed
2024-05-29 10:37:30,260:INFO:             kaleido: 0.2.1
2024-05-29 10:37:30,260:INFO:           schemdraw: 0.15
2024-05-29 10:37:30,261:INFO:         statsmodels: 0.14.2
2024-05-29 10:37:30,261:INFO:              sktime: 0.26.0
2024-05-29 10:37:30,261:INFO:               tbats: 1.1.3
2024-05-29 10:37:30,261:INFO:            pmdarima: 2.0.4
2024-05-29 10:37:30,261:INFO:              psutil: 5.9.0
2024-05-29 10:37:30,261:INFO:          markupsafe: 2.1.5
2024-05-29 10:37:30,261:INFO:             pickle5: Not installed
2024-05-29 10:37:30,261:INFO:         cloudpickle: 3.0.0
2024-05-29 10:37:30,261:INFO:         deprecation: 2.1.0
2024-05-29 10:37:30,261:INFO:              xxhash: 3.4.1
2024-05-29 10:37:30,261:INFO:           wurlitzer: Not installed
2024-05-29 10:37:30,262:INFO:PyCaret optional dependencies:
2024-05-29 10:37:30,262:INFO:                shap: Not installed
2024-05-29 10:37:30,262:INFO:           interpret: Not installed
2024-05-29 10:37:30,262:INFO:                umap: Not installed
2024-05-29 10:37:30,262:INFO:     ydata_profiling: Not installed
2024-05-29 10:37:30,262:INFO:  explainerdashboard: Not installed
2024-05-29 10:37:30,262:INFO:             autoviz: Not installed
2024-05-29 10:37:30,262:INFO:           fairlearn: Not installed
2024-05-29 10:37:30,262:INFO:          deepchecks: Not installed
2024-05-29 10:37:30,262:INFO:             xgboost: 2.0.3
2024-05-29 10:37:30,263:INFO:            catboost: Not installed
2024-05-29 10:37:30,263:INFO:              kmodes: Not installed
2024-05-29 10:37:30,263:INFO:             mlxtend: Not installed
2024-05-29 10:37:30,263:INFO:       statsforecast: Not installed
2024-05-29 10:37:30,263:INFO:        tune_sklearn: Not installed
2024-05-29 10:37:30,263:INFO:                 ray: Not installed
2024-05-29 10:37:30,263:INFO:            hyperopt: Not installed
2024-05-29 10:37:30,263:INFO:              optuna: Not installed
2024-05-29 10:37:30,263:INFO:               skopt: Not installed
2024-05-29 10:37:30,263:INFO:              mlflow: 2.13.0
2024-05-29 10:37:30,263:INFO:              gradio: Not installed
2024-05-29 10:37:30,264:INFO:             fastapi: Not installed
2024-05-29 10:37:30,264:INFO:             uvicorn: Not installed
2024-05-29 10:37:30,264:INFO:              m2cgen: Not installed
2024-05-29 10:37:30,264:INFO:           evidently: Not installed
2024-05-29 10:37:30,264:INFO:               fugue: Not installed
2024-05-29 10:37:30,264:INFO:           streamlit: Not installed
2024-05-29 10:37:30,264:INFO:             prophet: Not installed
2024-05-29 10:37:30,264:INFO:None
2024-05-29 10:37:30,264:INFO:Set up data.
2024-05-29 10:37:30,294:INFO:Set up folding strategy.
2024-05-29 10:37:30,294:INFO:Set up train/test split.
2024-05-29 10:37:30,351:INFO:Set up index.
2024-05-29 10:37:30,353:INFO:Assigning column types.
2024-05-29 10:37:30,386:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:37:30,457:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:37:30,458:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:37:30,502:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:37:30,507:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:37:30,578:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:37:30,579:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:37:30,624:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:37:30,628:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:37:30,629:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:37:30,701:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:37:30,745:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:37:30,749:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:37:30,822:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:37:30,867:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:37:30,871:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:37:30,871:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:37:30,987:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:37:30,991:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:37:31,108:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:37:31,113:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:37:31,114:INFO:Preparing preprocessing pipeline...
2024-05-29 10:37:31,120:INFO:Set up simple imputation.
2024-05-29 10:39:11,127:INFO:PyCaret ClassificationExperiment
2024-05-29 10:39:11,128:INFO:Logging name: codex
2024-05-29 10:39:11,128:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:39:11,128:INFO:version 3.3.2
2024-05-29 10:39:11,128:INFO:Initializing setup()
2024-05-29 10:39:11,128:INFO:self.USI: d0fa
2024-05-29 10:39:11,128:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:39:11,128:INFO:Checking environment
2024-05-29 10:39:11,128:INFO:python_version: 3.10.13
2024-05-29 10:39:11,128:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:39:11,129:INFO:machine: AMD64
2024-05-29 10:39:11,129:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:39:11,129:INFO:Memory: svmem(total=34267656192, available=18343010304, percent=46.5, used=15924645888, free=18343010304)
2024-05-29 10:39:11,129:INFO:Physical Core: 8
2024-05-29 10:39:11,129:INFO:Logical Core: 16
2024-05-29 10:39:11,129:INFO:Checking libraries
2024-05-29 10:39:11,129:INFO:System:
2024-05-29 10:39:11,129:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:39:11,129:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:39:11,130:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:39:11,130:INFO:PyCaret required dependencies:
2024-05-29 10:39:11,130:INFO:                 pip: 23.3
2024-05-29 10:39:11,130:INFO:          setuptools: 68.0.0
2024-05-29 10:39:11,130:INFO:             pycaret: 3.3.2
2024-05-29 10:39:11,130:INFO:             IPython: 8.24.0
2024-05-29 10:39:11,130:INFO:          ipywidgets: 8.1.2
2024-05-29 10:39:11,130:INFO:                tqdm: 4.66.4
2024-05-29 10:39:11,130:INFO:               numpy: 1.26.4
2024-05-29 10:39:11,130:INFO:              pandas: 2.1.4
2024-05-29 10:39:11,131:INFO:              jinja2: 3.1.4
2024-05-29 10:39:11,131:INFO:               scipy: 1.11.4
2024-05-29 10:39:11,131:INFO:              joblib: 1.3.2
2024-05-29 10:39:11,131:INFO:             sklearn: 1.4.2
2024-05-29 10:39:11,131:INFO:                pyod: 1.1.3
2024-05-29 10:39:11,131:INFO:            imblearn: 0.12.2
2024-05-29 10:39:11,131:INFO:   category_encoders: 2.6.3
2024-05-29 10:39:11,131:INFO:            lightgbm: 4.3.0
2024-05-29 10:39:11,131:INFO:               numba: 0.59.1
2024-05-29 10:39:11,131:INFO:            requests: 2.32.2
2024-05-29 10:39:11,132:INFO:          matplotlib: 3.7.5
2024-05-29 10:39:11,132:INFO:          scikitplot: 0.3.7
2024-05-29 10:39:11,132:INFO:         yellowbrick: 1.5
2024-05-29 10:39:11,132:INFO:              plotly: 5.22.0
2024-05-29 10:39:11,132:INFO:    plotly-resampler: Not installed
2024-05-29 10:39:11,132:INFO:             kaleido: 0.2.1
2024-05-29 10:39:11,132:INFO:           schemdraw: 0.15
2024-05-29 10:39:11,132:INFO:         statsmodels: 0.14.2
2024-05-29 10:39:11,132:INFO:              sktime: 0.26.0
2024-05-29 10:39:11,133:INFO:               tbats: 1.1.3
2024-05-29 10:39:11,133:INFO:            pmdarima: 2.0.4
2024-05-29 10:39:11,133:INFO:              psutil: 5.9.0
2024-05-29 10:39:11,133:INFO:          markupsafe: 2.1.5
2024-05-29 10:39:11,133:INFO:             pickle5: Not installed
2024-05-29 10:39:11,133:INFO:         cloudpickle: 3.0.0
2024-05-29 10:39:11,133:INFO:         deprecation: 2.1.0
2024-05-29 10:39:11,133:INFO:              xxhash: 3.4.1
2024-05-29 10:39:11,133:INFO:           wurlitzer: Not installed
2024-05-29 10:39:11,133:INFO:PyCaret optional dependencies:
2024-05-29 10:39:11,134:INFO:                shap: Not installed
2024-05-29 10:39:11,134:INFO:           interpret: Not installed
2024-05-29 10:39:11,134:INFO:                umap: Not installed
2024-05-29 10:39:11,134:INFO:     ydata_profiling: Not installed
2024-05-29 10:39:11,134:INFO:  explainerdashboard: Not installed
2024-05-29 10:39:11,134:INFO:             autoviz: Not installed
2024-05-29 10:39:11,134:INFO:           fairlearn: Not installed
2024-05-29 10:39:11,134:INFO:          deepchecks: Not installed
2024-05-29 10:39:11,134:INFO:             xgboost: 2.0.3
2024-05-29 10:39:11,134:INFO:            catboost: Not installed
2024-05-29 10:39:11,134:INFO:              kmodes: Not installed
2024-05-29 10:39:11,135:INFO:             mlxtend: Not installed
2024-05-29 10:39:11,135:INFO:       statsforecast: Not installed
2024-05-29 10:39:11,135:INFO:        tune_sklearn: Not installed
2024-05-29 10:39:11,135:INFO:                 ray: Not installed
2024-05-29 10:39:11,135:INFO:            hyperopt: Not installed
2024-05-29 10:39:11,135:INFO:              optuna: Not installed
2024-05-29 10:39:11,135:INFO:               skopt: Not installed
2024-05-29 10:39:11,135:INFO:              mlflow: 2.13.0
2024-05-29 10:39:11,135:INFO:              gradio: Not installed
2024-05-29 10:39:11,135:INFO:             fastapi: Not installed
2024-05-29 10:39:11,135:INFO:             uvicorn: Not installed
2024-05-29 10:39:11,135:INFO:              m2cgen: Not installed
2024-05-29 10:39:11,136:INFO:           evidently: Not installed
2024-05-29 10:39:11,136:INFO:               fugue: Not installed
2024-05-29 10:39:11,136:INFO:           streamlit: Not installed
2024-05-29 10:39:11,136:INFO:             prophet: Not installed
2024-05-29 10:39:11,136:INFO:None
2024-05-29 10:39:11,136:INFO:Set up data.
2024-05-29 10:39:11,166:INFO:Set up folding strategy.
2024-05-29 10:39:11,166:INFO:Set up train/test split.
2024-05-29 10:39:11,222:INFO:Set up index.
2024-05-29 10:39:11,224:INFO:Assigning column types.
2024-05-29 10:39:11,257:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:39:11,329:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:39:11,330:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:39:11,375:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:39:11,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:39:11,451:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:39:11,452:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:39:11,497:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:39:11,502:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:39:11,502:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:39:11,574:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:39:11,619:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:39:11,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:39:11,696:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:39:11,740:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:39:11,745:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:39:11,745:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:39:11,861:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:39:11,865:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:39:11,982:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:39:11,986:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:39:11,988:INFO:Preparing preprocessing pipeline...
2024-05-29 10:39:11,994:INFO:Set up simple imputation.
2024-05-29 10:39:32,973:INFO:PyCaret ClassificationExperiment
2024-05-29 10:39:32,973:INFO:Logging name: codex
2024-05-29 10:39:32,973:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:39:32,973:INFO:version 3.3.2
2024-05-29 10:39:32,973:INFO:Initializing setup()
2024-05-29 10:39:32,973:INFO:self.USI: cc27
2024-05-29 10:39:32,974:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:39:32,974:INFO:Checking environment
2024-05-29 10:39:32,974:INFO:python_version: 3.10.13
2024-05-29 10:39:32,974:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:39:32,974:INFO:machine: AMD64
2024-05-29 10:39:32,974:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:39:32,974:INFO:Memory: svmem(total=34267656192, available=18345422848, percent=46.5, used=15922233344, free=18345422848)
2024-05-29 10:39:32,975:INFO:Physical Core: 8
2024-05-29 10:39:32,975:INFO:Logical Core: 16
2024-05-29 10:39:32,975:INFO:Checking libraries
2024-05-29 10:39:32,975:INFO:System:
2024-05-29 10:39:32,975:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:39:32,975:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:39:32,975:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:39:32,976:INFO:PyCaret required dependencies:
2024-05-29 10:39:32,976:INFO:                 pip: 23.3
2024-05-29 10:39:32,976:INFO:          setuptools: 68.0.0
2024-05-29 10:39:32,976:INFO:             pycaret: 3.3.2
2024-05-29 10:39:32,976:INFO:             IPython: 8.24.0
2024-05-29 10:39:32,976:INFO:          ipywidgets: 8.1.2
2024-05-29 10:39:32,977:INFO:                tqdm: 4.66.4
2024-05-29 10:39:32,977:INFO:               numpy: 1.26.4
2024-05-29 10:39:32,977:INFO:              pandas: 2.1.4
2024-05-29 10:39:32,977:INFO:              jinja2: 3.1.4
2024-05-29 10:39:32,977:INFO:               scipy: 1.11.4
2024-05-29 10:39:32,977:INFO:              joblib: 1.3.2
2024-05-29 10:39:32,977:INFO:             sklearn: 1.4.2
2024-05-29 10:39:32,977:INFO:                pyod: 1.1.3
2024-05-29 10:39:32,978:INFO:            imblearn: 0.12.2
2024-05-29 10:39:32,978:INFO:   category_encoders: 2.6.3
2024-05-29 10:39:32,978:INFO:            lightgbm: 4.3.0
2024-05-29 10:39:32,978:INFO:               numba: 0.59.1
2024-05-29 10:39:32,978:INFO:            requests: 2.32.2
2024-05-29 10:39:32,978:INFO:          matplotlib: 3.7.5
2024-05-29 10:39:32,978:INFO:          scikitplot: 0.3.7
2024-05-29 10:39:32,978:INFO:         yellowbrick: 1.5
2024-05-29 10:39:32,979:INFO:              plotly: 5.22.0
2024-05-29 10:39:32,979:INFO:    plotly-resampler: Not installed
2024-05-29 10:39:32,979:INFO:             kaleido: 0.2.1
2024-05-29 10:39:32,979:INFO:           schemdraw: 0.15
2024-05-29 10:39:32,979:INFO:         statsmodels: 0.14.2
2024-05-29 10:39:32,979:INFO:              sktime: 0.26.0
2024-05-29 10:39:32,979:INFO:               tbats: 1.1.3
2024-05-29 10:39:32,980:INFO:            pmdarima: 2.0.4
2024-05-29 10:39:32,980:INFO:              psutil: 5.9.0
2024-05-29 10:39:32,980:INFO:          markupsafe: 2.1.5
2024-05-29 10:39:32,980:INFO:             pickle5: Not installed
2024-05-29 10:39:32,980:INFO:         cloudpickle: 3.0.0
2024-05-29 10:39:32,981:INFO:         deprecation: 2.1.0
2024-05-29 10:39:32,981:INFO:              xxhash: 3.4.1
2024-05-29 10:39:32,981:INFO:           wurlitzer: Not installed
2024-05-29 10:39:32,981:INFO:PyCaret optional dependencies:
2024-05-29 10:39:32,981:INFO:                shap: Not installed
2024-05-29 10:39:32,981:INFO:           interpret: Not installed
2024-05-29 10:39:32,981:INFO:                umap: Not installed
2024-05-29 10:39:32,982:INFO:     ydata_profiling: Not installed
2024-05-29 10:39:32,982:INFO:  explainerdashboard: Not installed
2024-05-29 10:39:32,982:INFO:             autoviz: Not installed
2024-05-29 10:39:32,982:INFO:           fairlearn: Not installed
2024-05-29 10:39:32,982:INFO:          deepchecks: Not installed
2024-05-29 10:39:32,982:INFO:             xgboost: 2.0.3
2024-05-29 10:39:32,983:INFO:            catboost: Not installed
2024-05-29 10:39:32,983:INFO:              kmodes: Not installed
2024-05-29 10:39:32,983:INFO:             mlxtend: Not installed
2024-05-29 10:39:32,983:INFO:       statsforecast: Not installed
2024-05-29 10:39:32,983:INFO:        tune_sklearn: Not installed
2024-05-29 10:39:32,983:INFO:                 ray: Not installed
2024-05-29 10:39:32,983:INFO:            hyperopt: Not installed
2024-05-29 10:39:32,983:INFO:              optuna: Not installed
2024-05-29 10:39:32,983:INFO:               skopt: Not installed
2024-05-29 10:39:32,983:INFO:              mlflow: 2.13.0
2024-05-29 10:39:32,984:INFO:              gradio: Not installed
2024-05-29 10:39:32,984:INFO:             fastapi: Not installed
2024-05-29 10:39:32,984:INFO:             uvicorn: Not installed
2024-05-29 10:39:32,984:INFO:              m2cgen: Not installed
2024-05-29 10:39:32,984:INFO:           evidently: Not installed
2024-05-29 10:39:32,984:INFO:               fugue: Not installed
2024-05-29 10:39:32,984:INFO:           streamlit: Not installed
2024-05-29 10:39:32,984:INFO:             prophet: Not installed
2024-05-29 10:39:32,985:INFO:None
2024-05-29 10:39:32,985:INFO:Set up data.
2024-05-29 10:39:33,025:INFO:Set up folding strategy.
2024-05-29 10:39:33,025:INFO:Set up train/test split.
2024-05-29 10:39:33,089:INFO:Set up index.
2024-05-29 10:39:33,091:INFO:Assigning column types.
2024-05-29 10:39:33,126:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:39:33,201:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:39:33,202:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:39:33,248:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:39:33,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:39:33,324:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:39:33,325:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:39:33,371:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:39:33,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:39:33,375:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:39:33,447:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:39:33,492:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:39:33,496:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:39:33,569:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:39:33,613:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:39:33,617:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:39:33,618:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:39:33,734:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:39:33,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:39:33,857:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:39:33,862:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:39:33,864:INFO:Preparing preprocessing pipeline...
2024-05-29 10:39:33,873:INFO:Set up simple imputation.
2024-05-29 10:41:30,165:INFO:PyCaret ClassificationExperiment
2024-05-29 10:41:30,165:INFO:Logging name: codex
2024-05-29 10:41:30,165:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:41:30,165:INFO:version 3.3.2
2024-05-29 10:41:30,165:INFO:Initializing setup()
2024-05-29 10:41:30,165:INFO:self.USI: a8ea
2024-05-29 10:41:30,165:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:41:30,165:INFO:Checking environment
2024-05-29 10:41:30,165:INFO:python_version: 3.10.13
2024-05-29 10:41:30,165:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:41:30,166:INFO:machine: AMD64
2024-05-29 10:41:30,166:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:41:30,166:INFO:Memory: svmem(total=34267656192, available=18319798272, percent=46.5, used=15947857920, free=18319798272)
2024-05-29 10:41:30,166:INFO:Physical Core: 8
2024-05-29 10:41:30,166:INFO:Logical Core: 16
2024-05-29 10:41:30,166:INFO:Checking libraries
2024-05-29 10:41:30,166:INFO:System:
2024-05-29 10:41:30,166:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:41:30,167:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:41:30,167:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:41:30,167:INFO:PyCaret required dependencies:
2024-05-29 10:41:30,167:INFO:                 pip: 23.3
2024-05-29 10:41:30,167:INFO:          setuptools: 68.0.0
2024-05-29 10:41:30,167:INFO:             pycaret: 3.3.2
2024-05-29 10:41:30,167:INFO:             IPython: 8.24.0
2024-05-29 10:41:30,167:INFO:          ipywidgets: 8.1.2
2024-05-29 10:41:30,167:INFO:                tqdm: 4.66.4
2024-05-29 10:41:30,167:INFO:               numpy: 1.26.4
2024-05-29 10:41:30,168:INFO:              pandas: 2.1.4
2024-05-29 10:41:30,168:INFO:              jinja2: 3.1.4
2024-05-29 10:41:30,168:INFO:               scipy: 1.11.4
2024-05-29 10:41:30,168:INFO:              joblib: 1.3.2
2024-05-29 10:41:30,168:INFO:             sklearn: 1.4.2
2024-05-29 10:41:30,168:INFO:                pyod: 1.1.3
2024-05-29 10:41:30,168:INFO:            imblearn: 0.12.2
2024-05-29 10:41:30,168:INFO:   category_encoders: 2.6.3
2024-05-29 10:41:30,168:INFO:            lightgbm: 4.3.0
2024-05-29 10:41:30,168:INFO:               numba: 0.59.1
2024-05-29 10:41:30,169:INFO:            requests: 2.32.2
2024-05-29 10:41:30,169:INFO:          matplotlib: 3.7.5
2024-05-29 10:41:30,169:INFO:          scikitplot: 0.3.7
2024-05-29 10:41:30,169:INFO:         yellowbrick: 1.5
2024-05-29 10:41:30,169:INFO:              plotly: 5.22.0
2024-05-29 10:41:30,169:INFO:    plotly-resampler: Not installed
2024-05-29 10:41:30,169:INFO:             kaleido: 0.2.1
2024-05-29 10:41:30,169:INFO:           schemdraw: 0.15
2024-05-29 10:41:30,169:INFO:         statsmodels: 0.14.2
2024-05-29 10:41:30,169:INFO:              sktime: 0.26.0
2024-05-29 10:41:30,170:INFO:               tbats: 1.1.3
2024-05-29 10:41:30,170:INFO:            pmdarima: 2.0.4
2024-05-29 10:41:30,170:INFO:              psutil: 5.9.0
2024-05-29 10:41:30,170:INFO:          markupsafe: 2.1.5
2024-05-29 10:41:30,170:INFO:             pickle5: Not installed
2024-05-29 10:41:30,170:INFO:         cloudpickle: 3.0.0
2024-05-29 10:41:30,170:INFO:         deprecation: 2.1.0
2024-05-29 10:41:30,170:INFO:              xxhash: 3.4.1
2024-05-29 10:41:30,170:INFO:           wurlitzer: Not installed
2024-05-29 10:41:30,170:INFO:PyCaret optional dependencies:
2024-05-29 10:41:30,171:INFO:                shap: Not installed
2024-05-29 10:41:30,171:INFO:           interpret: Not installed
2024-05-29 10:41:30,171:INFO:                umap: Not installed
2024-05-29 10:41:30,171:INFO:     ydata_profiling: Not installed
2024-05-29 10:41:30,171:INFO:  explainerdashboard: Not installed
2024-05-29 10:41:30,171:INFO:             autoviz: Not installed
2024-05-29 10:41:30,171:INFO:           fairlearn: Not installed
2024-05-29 10:41:30,171:INFO:          deepchecks: Not installed
2024-05-29 10:41:30,171:INFO:             xgboost: 2.0.3
2024-05-29 10:41:30,172:INFO:            catboost: Not installed
2024-05-29 10:41:30,172:INFO:              kmodes: Not installed
2024-05-29 10:41:30,172:INFO:             mlxtend: Not installed
2024-05-29 10:41:30,172:INFO:       statsforecast: Not installed
2024-05-29 10:41:30,172:INFO:        tune_sklearn: Not installed
2024-05-29 10:41:30,172:INFO:                 ray: Not installed
2024-05-29 10:41:30,172:INFO:            hyperopt: Not installed
2024-05-29 10:41:30,172:INFO:              optuna: Not installed
2024-05-29 10:41:30,172:INFO:               skopt: Not installed
2024-05-29 10:41:30,172:INFO:              mlflow: 2.13.0
2024-05-29 10:41:30,172:INFO:              gradio: Not installed
2024-05-29 10:41:30,173:INFO:             fastapi: Not installed
2024-05-29 10:41:30,173:INFO:             uvicorn: Not installed
2024-05-29 10:41:30,173:INFO:              m2cgen: Not installed
2024-05-29 10:41:30,173:INFO:           evidently: Not installed
2024-05-29 10:41:30,173:INFO:               fugue: Not installed
2024-05-29 10:41:30,173:INFO:           streamlit: Not installed
2024-05-29 10:41:30,173:INFO:             prophet: Not installed
2024-05-29 10:41:30,173:INFO:None
2024-05-29 10:41:30,173:INFO:Set up data.
2024-05-29 10:41:30,201:INFO:Set up folding strategy.
2024-05-29 10:41:30,201:INFO:Set up train/test split.
2024-05-29 10:41:30,259:INFO:Set up index.
2024-05-29 10:41:30,260:INFO:Assigning column types.
2024-05-29 10:41:30,294:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:41:30,365:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:41:30,366:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:41:30,411:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:41:30,415:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:41:30,489:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:41:30,490:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:41:30,544:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:41:30,548:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:41:30,548:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:41:30,621:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:41:30,666:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:41:30,670:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:41:30,743:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:41:30,787:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:41:30,791:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:41:30,792:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:41:30,908:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:41:30,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:41:31,029:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:41:31,034:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:41:31,035:INFO:Preparing preprocessing pipeline...
2024-05-29 10:41:31,041:INFO:Set up simple imputation.
2024-05-29 10:43:27,086:INFO:PyCaret ClassificationExperiment
2024-05-29 10:43:27,086:INFO:Logging name: codex
2024-05-29 10:43:27,087:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:43:27,087:INFO:version 3.3.2
2024-05-29 10:43:27,087:INFO:Initializing setup()
2024-05-29 10:43:27,087:INFO:self.USI: 3549
2024-05-29 10:43:27,087:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:43:27,087:INFO:Checking environment
2024-05-29 10:43:27,087:INFO:python_version: 3.10.13
2024-05-29 10:43:27,087:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:43:27,088:INFO:machine: AMD64
2024-05-29 10:43:27,088:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:43:27,088:INFO:Memory: svmem(total=34267656192, available=18864308224, percent=45.0, used=15403347968, free=18864308224)
2024-05-29 10:43:27,088:INFO:Physical Core: 8
2024-05-29 10:43:27,088:INFO:Logical Core: 16
2024-05-29 10:43:27,088:INFO:Checking libraries
2024-05-29 10:43:27,088:INFO:System:
2024-05-29 10:43:27,088:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:43:27,088:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:43:27,088:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:43:27,089:INFO:PyCaret required dependencies:
2024-05-29 10:43:27,089:INFO:                 pip: 23.3
2024-05-29 10:43:27,089:INFO:          setuptools: 68.0.0
2024-05-29 10:43:27,089:INFO:             pycaret: 3.3.2
2024-05-29 10:43:27,089:INFO:             IPython: 8.24.0
2024-05-29 10:43:27,089:INFO:          ipywidgets: 8.1.2
2024-05-29 10:43:27,089:INFO:                tqdm: 4.66.4
2024-05-29 10:43:27,089:INFO:               numpy: 1.26.4
2024-05-29 10:43:27,090:INFO:              pandas: 2.1.4
2024-05-29 10:43:27,090:INFO:              jinja2: 3.1.4
2024-05-29 10:43:27,090:INFO:               scipy: 1.11.4
2024-05-29 10:43:27,090:INFO:              joblib: 1.3.2
2024-05-29 10:43:27,090:INFO:             sklearn: 1.4.2
2024-05-29 10:43:27,090:INFO:                pyod: 1.1.3
2024-05-29 10:43:27,090:INFO:            imblearn: 0.12.2
2024-05-29 10:43:27,090:INFO:   category_encoders: 2.6.3
2024-05-29 10:43:27,090:INFO:            lightgbm: 4.3.0
2024-05-29 10:43:27,090:INFO:               numba: 0.59.1
2024-05-29 10:43:27,090:INFO:            requests: 2.32.2
2024-05-29 10:43:27,091:INFO:          matplotlib: 3.7.5
2024-05-29 10:43:27,091:INFO:          scikitplot: 0.3.7
2024-05-29 10:43:27,091:INFO:         yellowbrick: 1.5
2024-05-29 10:43:27,091:INFO:              plotly: 5.22.0
2024-05-29 10:43:27,091:INFO:    plotly-resampler: Not installed
2024-05-29 10:43:27,091:INFO:             kaleido: 0.2.1
2024-05-29 10:43:27,091:INFO:           schemdraw: 0.15
2024-05-29 10:43:27,091:INFO:         statsmodels: 0.14.2
2024-05-29 10:43:27,091:INFO:              sktime: 0.26.0
2024-05-29 10:43:27,091:INFO:               tbats: 1.1.3
2024-05-29 10:43:27,091:INFO:            pmdarima: 2.0.4
2024-05-29 10:43:27,092:INFO:              psutil: 5.9.0
2024-05-29 10:43:27,092:INFO:          markupsafe: 2.1.5
2024-05-29 10:43:27,092:INFO:             pickle5: Not installed
2024-05-29 10:43:27,092:INFO:         cloudpickle: 3.0.0
2024-05-29 10:43:27,092:INFO:         deprecation: 2.1.0
2024-05-29 10:43:27,092:INFO:              xxhash: 3.4.1
2024-05-29 10:43:27,092:INFO:           wurlitzer: Not installed
2024-05-29 10:43:27,092:INFO:PyCaret optional dependencies:
2024-05-29 10:43:27,092:INFO:                shap: Not installed
2024-05-29 10:43:27,093:INFO:           interpret: Not installed
2024-05-29 10:43:27,093:INFO:                umap: Not installed
2024-05-29 10:43:27,093:INFO:     ydata_profiling: Not installed
2024-05-29 10:43:27,093:INFO:  explainerdashboard: Not installed
2024-05-29 10:43:27,093:INFO:             autoviz: Not installed
2024-05-29 10:43:27,093:INFO:           fairlearn: Not installed
2024-05-29 10:43:27,093:INFO:          deepchecks: Not installed
2024-05-29 10:43:27,093:INFO:             xgboost: 2.0.3
2024-05-29 10:43:27,119:INFO:            catboost: Not installed
2024-05-29 10:43:27,119:INFO:              kmodes: Not installed
2024-05-29 10:43:27,119:INFO:             mlxtend: Not installed
2024-05-29 10:43:27,119:INFO:       statsforecast: Not installed
2024-05-29 10:43:27,119:INFO:        tune_sklearn: Not installed
2024-05-29 10:43:27,119:INFO:                 ray: Not installed
2024-05-29 10:43:27,120:INFO:            hyperopt: Not installed
2024-05-29 10:43:27,120:INFO:              optuna: Not installed
2024-05-29 10:43:27,120:INFO:               skopt: Not installed
2024-05-29 10:43:27,120:INFO:              mlflow: 2.13.0
2024-05-29 10:43:27,120:INFO:              gradio: Not installed
2024-05-29 10:43:27,120:INFO:             fastapi: Not installed
2024-05-29 10:43:27,120:INFO:             uvicorn: Not installed
2024-05-29 10:43:27,120:INFO:              m2cgen: Not installed
2024-05-29 10:43:27,120:INFO:           evidently: Not installed
2024-05-29 10:43:27,120:INFO:               fugue: Not installed
2024-05-29 10:43:27,120:INFO:           streamlit: Not installed
2024-05-29 10:43:27,121:INFO:             prophet: Not installed
2024-05-29 10:43:27,121:INFO:None
2024-05-29 10:43:27,121:INFO:Set up data.
2024-05-29 10:43:27,150:INFO:Set up folding strategy.
2024-05-29 10:43:27,150:INFO:Set up train/test split.
2024-05-29 10:43:27,207:INFO:Set up index.
2024-05-29 10:43:27,209:INFO:Assigning column types.
2024-05-29 10:43:27,243:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:43:27,314:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:43:27,315:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:43:27,359:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:43:27,363:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:43:27,434:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:43:27,436:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:43:27,480:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:43:27,484:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:43:27,485:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:43:27,557:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:43:27,602:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:43:27,606:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:43:27,678:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:43:27,723:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:43:27,727:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:43:27,727:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:43:27,843:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:43:27,848:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:43:27,964:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:43:27,970:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:43:27,972:INFO:Preparing preprocessing pipeline...
2024-05-29 10:43:27,978:INFO:Set up simple imputation.
2024-05-29 10:44:24,370:INFO:PyCaret ClassificationExperiment
2024-05-29 10:44:24,371:INFO:Logging name: codex
2024-05-29 10:44:24,371:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:44:24,371:INFO:version 3.3.2
2024-05-29 10:44:24,371:INFO:Initializing setup()
2024-05-29 10:44:24,371:INFO:self.USI: aa35
2024-05-29 10:44:24,371:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:44:24,371:INFO:Checking environment
2024-05-29 10:44:24,371:INFO:python_version: 3.10.13
2024-05-29 10:44:24,372:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:44:24,372:INFO:machine: AMD64
2024-05-29 10:44:24,372:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:44:24,372:INFO:Memory: svmem(total=34267656192, available=18834812928, percent=45.0, used=15432843264, free=18834812928)
2024-05-29 10:44:24,372:INFO:Physical Core: 8
2024-05-29 10:44:24,372:INFO:Logical Core: 16
2024-05-29 10:44:24,372:INFO:Checking libraries
2024-05-29 10:44:24,372:INFO:System:
2024-05-29 10:44:24,372:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:44:24,373:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:44:24,373:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:44:24,373:INFO:PyCaret required dependencies:
2024-05-29 10:44:24,373:INFO:                 pip: 23.3
2024-05-29 10:44:24,373:INFO:          setuptools: 68.0.0
2024-05-29 10:44:24,373:INFO:             pycaret: 3.3.2
2024-05-29 10:44:24,373:INFO:             IPython: 8.24.0
2024-05-29 10:44:24,373:INFO:          ipywidgets: 8.1.2
2024-05-29 10:44:24,373:INFO:                tqdm: 4.66.4
2024-05-29 10:44:24,374:INFO:               numpy: 1.26.4
2024-05-29 10:44:24,374:INFO:              pandas: 2.1.4
2024-05-29 10:44:24,374:INFO:              jinja2: 3.1.4
2024-05-29 10:44:24,374:INFO:               scipy: 1.11.4
2024-05-29 10:44:24,374:INFO:              joblib: 1.3.2
2024-05-29 10:44:24,374:INFO:             sklearn: 1.4.2
2024-05-29 10:44:24,374:INFO:                pyod: 1.1.3
2024-05-29 10:44:24,374:INFO:            imblearn: 0.12.2
2024-05-29 10:44:24,374:INFO:   category_encoders: 2.6.3
2024-05-29 10:44:24,375:INFO:            lightgbm: 4.3.0
2024-05-29 10:44:24,375:INFO:               numba: 0.59.1
2024-05-29 10:44:24,375:INFO:            requests: 2.32.2
2024-05-29 10:44:24,375:INFO:          matplotlib: 3.7.5
2024-05-29 10:44:24,375:INFO:          scikitplot: 0.3.7
2024-05-29 10:44:24,375:INFO:         yellowbrick: 1.5
2024-05-29 10:44:24,375:INFO:              plotly: 5.22.0
2024-05-29 10:44:24,375:INFO:    plotly-resampler: Not installed
2024-05-29 10:44:24,376:INFO:             kaleido: 0.2.1
2024-05-29 10:44:24,376:INFO:           schemdraw: 0.15
2024-05-29 10:44:24,376:INFO:         statsmodels: 0.14.2
2024-05-29 10:44:24,376:INFO:              sktime: 0.26.0
2024-05-29 10:44:24,376:INFO:               tbats: 1.1.3
2024-05-29 10:44:24,376:INFO:            pmdarima: 2.0.4
2024-05-29 10:44:24,376:INFO:              psutil: 5.9.0
2024-05-29 10:44:24,376:INFO:          markupsafe: 2.1.5
2024-05-29 10:44:24,376:INFO:             pickle5: Not installed
2024-05-29 10:44:24,376:INFO:         cloudpickle: 3.0.0
2024-05-29 10:44:24,377:INFO:         deprecation: 2.1.0
2024-05-29 10:44:24,377:INFO:              xxhash: 3.4.1
2024-05-29 10:44:24,377:INFO:           wurlitzer: Not installed
2024-05-29 10:44:24,377:INFO:PyCaret optional dependencies:
2024-05-29 10:44:24,377:INFO:                shap: Not installed
2024-05-29 10:44:24,377:INFO:           interpret: Not installed
2024-05-29 10:44:24,377:INFO:                umap: Not installed
2024-05-29 10:44:24,377:INFO:     ydata_profiling: Not installed
2024-05-29 10:44:24,377:INFO:  explainerdashboard: Not installed
2024-05-29 10:44:24,378:INFO:             autoviz: Not installed
2024-05-29 10:44:24,378:INFO:           fairlearn: Not installed
2024-05-29 10:44:24,378:INFO:          deepchecks: Not installed
2024-05-29 10:44:24,378:INFO:             xgboost: 2.0.3
2024-05-29 10:44:24,378:INFO:            catboost: Not installed
2024-05-29 10:44:24,378:INFO:              kmodes: Not installed
2024-05-29 10:44:24,378:INFO:             mlxtend: Not installed
2024-05-29 10:44:24,378:INFO:       statsforecast: Not installed
2024-05-29 10:44:24,378:INFO:        tune_sklearn: Not installed
2024-05-29 10:44:24,378:INFO:                 ray: Not installed
2024-05-29 10:44:24,378:INFO:            hyperopt: Not installed
2024-05-29 10:44:24,379:INFO:              optuna: Not installed
2024-05-29 10:44:24,379:INFO:               skopt: Not installed
2024-05-29 10:44:24,379:INFO:              mlflow: 2.13.0
2024-05-29 10:44:24,379:INFO:              gradio: Not installed
2024-05-29 10:44:24,379:INFO:             fastapi: Not installed
2024-05-29 10:44:24,379:INFO:             uvicorn: Not installed
2024-05-29 10:44:24,379:INFO:              m2cgen: Not installed
2024-05-29 10:44:24,379:INFO:           evidently: Not installed
2024-05-29 10:44:24,379:INFO:               fugue: Not installed
2024-05-29 10:44:24,380:INFO:           streamlit: Not installed
2024-05-29 10:44:24,380:INFO:             prophet: Not installed
2024-05-29 10:44:24,380:INFO:None
2024-05-29 10:44:24,380:INFO:Set up data.
2024-05-29 10:44:24,415:INFO:Set up folding strategy.
2024-05-29 10:44:24,415:INFO:Set up train/test split.
2024-05-29 10:44:24,474:INFO:Set up index.
2024-05-29 10:44:24,476:INFO:Assigning column types.
2024-05-29 10:44:24,509:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:44:24,580:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:44:24,581:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:44:24,625:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:44:24,629:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:44:24,701:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:44:24,702:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:44:24,747:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:44:24,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:44:24,751:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:44:24,824:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:44:24,868:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:44:24,872:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:44:24,945:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:44:24,990:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:44:24,994:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:44:24,995:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:44:25,113:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:44:25,117:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:44:25,234:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:44:25,238:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:44:25,240:INFO:Preparing preprocessing pipeline...
2024-05-29 10:44:25,246:INFO:Set up simple imputation.
2024-05-29 10:46:40,232:INFO:PyCaret ClassificationExperiment
2024-05-29 10:46:40,232:INFO:Logging name: codex
2024-05-29 10:46:40,232:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:46:40,232:INFO:version 3.3.2
2024-05-29 10:46:40,232:INFO:Initializing setup()
2024-05-29 10:46:40,232:INFO:self.USI: 66cc
2024-05-29 10:46:40,233:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:46:40,233:INFO:Checking environment
2024-05-29 10:46:40,233:INFO:python_version: 3.10.13
2024-05-29 10:46:40,233:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:46:40,233:INFO:machine: AMD64
2024-05-29 10:46:40,233:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:46:40,233:INFO:Memory: svmem(total=34267656192, available=18344546304, percent=46.5, used=15923109888, free=18344546304)
2024-05-29 10:46:40,234:INFO:Physical Core: 8
2024-05-29 10:46:40,234:INFO:Logical Core: 16
2024-05-29 10:46:40,234:INFO:Checking libraries
2024-05-29 10:46:40,234:INFO:System:
2024-05-29 10:46:40,234:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:46:40,234:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:46:40,234:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:46:40,234:INFO:PyCaret required dependencies:
2024-05-29 10:46:40,234:INFO:                 pip: 23.3
2024-05-29 10:46:40,235:INFO:          setuptools: 68.0.0
2024-05-29 10:46:40,235:INFO:             pycaret: 3.3.2
2024-05-29 10:46:40,235:INFO:             IPython: 8.24.0
2024-05-29 10:46:40,235:INFO:          ipywidgets: 8.1.2
2024-05-29 10:46:40,235:INFO:                tqdm: 4.66.4
2024-05-29 10:46:40,235:INFO:               numpy: 1.26.4
2024-05-29 10:46:40,235:INFO:              pandas: 2.1.4
2024-05-29 10:46:40,235:INFO:              jinja2: 3.1.4
2024-05-29 10:46:40,235:INFO:               scipy: 1.11.4
2024-05-29 10:46:40,235:INFO:              joblib: 1.3.2
2024-05-29 10:46:40,235:INFO:             sklearn: 1.4.2
2024-05-29 10:46:40,235:INFO:                pyod: 1.1.3
2024-05-29 10:46:40,236:INFO:            imblearn: 0.12.2
2024-05-29 10:46:40,236:INFO:   category_encoders: 2.6.3
2024-05-29 10:46:40,236:INFO:            lightgbm: 4.3.0
2024-05-29 10:46:40,236:INFO:               numba: 0.59.1
2024-05-29 10:46:40,236:INFO:            requests: 2.32.2
2024-05-29 10:46:40,236:INFO:          matplotlib: 3.7.5
2024-05-29 10:46:40,236:INFO:          scikitplot: 0.3.7
2024-05-29 10:46:40,236:INFO:         yellowbrick: 1.5
2024-05-29 10:46:40,236:INFO:              plotly: 5.22.0
2024-05-29 10:46:40,236:INFO:    plotly-resampler: Not installed
2024-05-29 10:46:40,236:INFO:             kaleido: 0.2.1
2024-05-29 10:46:40,237:INFO:           schemdraw: 0.15
2024-05-29 10:46:40,237:INFO:         statsmodels: 0.14.2
2024-05-29 10:46:40,237:INFO:              sktime: 0.26.0
2024-05-29 10:46:40,237:INFO:               tbats: 1.1.3
2024-05-29 10:46:40,237:INFO:            pmdarima: 2.0.4
2024-05-29 10:46:40,237:INFO:              psutil: 5.9.0
2024-05-29 10:46:40,237:INFO:          markupsafe: 2.1.5
2024-05-29 10:46:40,237:INFO:             pickle5: Not installed
2024-05-29 10:46:40,237:INFO:         cloudpickle: 3.0.0
2024-05-29 10:46:40,237:INFO:         deprecation: 2.1.0
2024-05-29 10:46:40,238:INFO:              xxhash: 3.4.1
2024-05-29 10:46:40,238:INFO:           wurlitzer: Not installed
2024-05-29 10:46:40,238:INFO:PyCaret optional dependencies:
2024-05-29 10:46:40,238:INFO:                shap: Not installed
2024-05-29 10:46:40,238:INFO:           interpret: Not installed
2024-05-29 10:46:40,238:INFO:                umap: Not installed
2024-05-29 10:46:40,238:INFO:     ydata_profiling: Not installed
2024-05-29 10:46:40,238:INFO:  explainerdashboard: Not installed
2024-05-29 10:46:40,238:INFO:             autoviz: Not installed
2024-05-29 10:46:40,238:INFO:           fairlearn: Not installed
2024-05-29 10:46:40,239:INFO:          deepchecks: Not installed
2024-05-29 10:46:40,239:INFO:             xgboost: 2.0.3
2024-05-29 10:46:40,239:INFO:            catboost: Not installed
2024-05-29 10:46:40,239:INFO:              kmodes: Not installed
2024-05-29 10:46:40,239:INFO:             mlxtend: Not installed
2024-05-29 10:46:40,239:INFO:       statsforecast: Not installed
2024-05-29 10:46:40,239:INFO:        tune_sklearn: Not installed
2024-05-29 10:46:40,239:INFO:                 ray: Not installed
2024-05-29 10:46:40,239:INFO:            hyperopt: Not installed
2024-05-29 10:46:40,239:INFO:              optuna: Not installed
2024-05-29 10:46:40,239:INFO:               skopt: Not installed
2024-05-29 10:46:40,239:INFO:              mlflow: 2.13.0
2024-05-29 10:46:40,240:INFO:              gradio: Not installed
2024-05-29 10:46:40,240:INFO:             fastapi: Not installed
2024-05-29 10:46:40,240:INFO:             uvicorn: Not installed
2024-05-29 10:46:40,240:INFO:              m2cgen: Not installed
2024-05-29 10:46:40,240:INFO:           evidently: Not installed
2024-05-29 10:46:40,240:INFO:               fugue: Not installed
2024-05-29 10:46:40,240:INFO:           streamlit: Not installed
2024-05-29 10:46:40,240:INFO:             prophet: Not installed
2024-05-29 10:46:40,240:INFO:None
2024-05-29 10:46:40,240:INFO:Set up data.
2024-05-29 10:46:40,270:INFO:Set up folding strategy.
2024-05-29 10:46:40,270:INFO:Set up train/test split.
2024-05-29 10:46:40,329:INFO:Set up index.
2024-05-29 10:46:40,331:INFO:Assigning column types.
2024-05-29 10:46:40,366:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:46:40,437:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:46:40,438:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:46:40,482:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:46:40,486:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:46:40,565:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:46:40,567:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:46:40,621:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:46:40,626:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:46:40,626:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:46:40,701:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:46:40,746:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:46:40,750:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:46:40,823:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:46:40,867:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:46:40,871:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:46:40,872:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:46:40,989:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:46:40,994:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:46:41,110:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:46:41,115:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:46:41,116:INFO:Preparing preprocessing pipeline...
2024-05-29 10:46:41,122:INFO:Set up simple imputation.
2024-05-29 10:47:03,438:INFO:PyCaret ClassificationExperiment
2024-05-29 10:47:03,438:INFO:Logging name: codex
2024-05-29 10:47:03,438:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:47:03,438:INFO:version 3.3.2
2024-05-29 10:47:03,438:INFO:Initializing setup()
2024-05-29 10:47:03,438:INFO:self.USI: 6d83
2024-05-29 10:47:03,439:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:47:03,439:INFO:Checking environment
2024-05-29 10:47:03,439:INFO:python_version: 3.10.13
2024-05-29 10:47:03,439:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:47:03,439:INFO:machine: AMD64
2024-05-29 10:47:03,439:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:47:03,439:INFO:Memory: svmem(total=34267656192, available=18304606208, percent=46.6, used=15963049984, free=18304606208)
2024-05-29 10:47:03,439:INFO:Physical Core: 8
2024-05-29 10:47:03,439:INFO:Logical Core: 16
2024-05-29 10:47:03,439:INFO:Checking libraries
2024-05-29 10:47:03,440:INFO:System:
2024-05-29 10:47:03,440:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:47:03,440:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:47:03,440:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:47:03,440:INFO:PyCaret required dependencies:
2024-05-29 10:47:03,440:INFO:                 pip: 23.3
2024-05-29 10:47:03,440:INFO:          setuptools: 68.0.0
2024-05-29 10:47:03,440:INFO:             pycaret: 3.3.2
2024-05-29 10:47:03,440:INFO:             IPython: 8.24.0
2024-05-29 10:47:03,440:INFO:          ipywidgets: 8.1.2
2024-05-29 10:47:03,441:INFO:                tqdm: 4.66.4
2024-05-29 10:47:03,441:INFO:               numpy: 1.26.4
2024-05-29 10:47:03,441:INFO:              pandas: 2.1.4
2024-05-29 10:47:03,441:INFO:              jinja2: 3.1.4
2024-05-29 10:47:03,441:INFO:               scipy: 1.11.4
2024-05-29 10:47:03,441:INFO:              joblib: 1.3.2
2024-05-29 10:47:03,441:INFO:             sklearn: 1.4.2
2024-05-29 10:47:03,441:INFO:                pyod: 1.1.3
2024-05-29 10:47:03,441:INFO:            imblearn: 0.12.2
2024-05-29 10:47:03,441:INFO:   category_encoders: 2.6.3
2024-05-29 10:47:03,442:INFO:            lightgbm: 4.3.0
2024-05-29 10:47:03,442:INFO:               numba: 0.59.1
2024-05-29 10:47:03,442:INFO:            requests: 2.32.2
2024-05-29 10:47:03,442:INFO:          matplotlib: 3.7.5
2024-05-29 10:47:03,442:INFO:          scikitplot: 0.3.7
2024-05-29 10:47:03,442:INFO:         yellowbrick: 1.5
2024-05-29 10:47:03,442:INFO:              plotly: 5.22.0
2024-05-29 10:47:03,442:INFO:    plotly-resampler: Not installed
2024-05-29 10:47:03,442:INFO:             kaleido: 0.2.1
2024-05-29 10:47:03,442:INFO:           schemdraw: 0.15
2024-05-29 10:47:03,442:INFO:         statsmodels: 0.14.2
2024-05-29 10:47:03,443:INFO:              sktime: 0.26.0
2024-05-29 10:47:03,443:INFO:               tbats: 1.1.3
2024-05-29 10:47:03,443:INFO:            pmdarima: 2.0.4
2024-05-29 10:47:03,443:INFO:              psutil: 5.9.0
2024-05-29 10:47:03,443:INFO:          markupsafe: 2.1.5
2024-05-29 10:47:03,443:INFO:             pickle5: Not installed
2024-05-29 10:47:03,443:INFO:         cloudpickle: 3.0.0
2024-05-29 10:47:03,443:INFO:         deprecation: 2.1.0
2024-05-29 10:47:03,443:INFO:              xxhash: 3.4.1
2024-05-29 10:47:03,443:INFO:           wurlitzer: Not installed
2024-05-29 10:47:03,444:INFO:PyCaret optional dependencies:
2024-05-29 10:47:03,444:INFO:                shap: Not installed
2024-05-29 10:47:03,444:INFO:           interpret: Not installed
2024-05-29 10:47:03,444:INFO:                umap: Not installed
2024-05-29 10:47:03,444:INFO:     ydata_profiling: Not installed
2024-05-29 10:47:03,444:INFO:  explainerdashboard: Not installed
2024-05-29 10:47:03,444:INFO:             autoviz: Not installed
2024-05-29 10:47:03,444:INFO:           fairlearn: Not installed
2024-05-29 10:47:03,444:INFO:          deepchecks: Not installed
2024-05-29 10:47:03,444:INFO:             xgboost: 2.0.3
2024-05-29 10:47:03,445:INFO:            catboost: Not installed
2024-05-29 10:47:03,445:INFO:              kmodes: Not installed
2024-05-29 10:47:03,445:INFO:             mlxtend: Not installed
2024-05-29 10:47:03,445:INFO:       statsforecast: Not installed
2024-05-29 10:47:03,445:INFO:        tune_sklearn: Not installed
2024-05-29 10:47:03,445:INFO:                 ray: Not installed
2024-05-29 10:47:03,445:INFO:            hyperopt: Not installed
2024-05-29 10:47:03,445:INFO:              optuna: Not installed
2024-05-29 10:47:03,445:INFO:               skopt: Not installed
2024-05-29 10:47:03,445:INFO:              mlflow: 2.13.0
2024-05-29 10:47:03,445:INFO:              gradio: Not installed
2024-05-29 10:47:03,446:INFO:             fastapi: Not installed
2024-05-29 10:47:03,446:INFO:             uvicorn: Not installed
2024-05-29 10:47:03,446:INFO:              m2cgen: Not installed
2024-05-29 10:47:03,446:INFO:           evidently: Not installed
2024-05-29 10:47:03,446:INFO:               fugue: Not installed
2024-05-29 10:47:03,446:INFO:           streamlit: Not installed
2024-05-29 10:47:03,446:INFO:             prophet: Not installed
2024-05-29 10:47:03,446:INFO:None
2024-05-29 10:47:03,446:INFO:Set up data.
2024-05-29 10:47:03,477:INFO:Set up folding strategy.
2024-05-29 10:47:03,477:INFO:Set up train/test split.
2024-05-29 10:47:03,538:INFO:Set up index.
2024-05-29 10:47:03,540:INFO:Assigning column types.
2024-05-29 10:47:03,575:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:47:03,647:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:47:03,649:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:47:03,694:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:47:03,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:47:03,773:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:47:03,774:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:47:03,820:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:47:03,825:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:47:03,825:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:47:03,898:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:47:03,943:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:47:03,947:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:47:04,024:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:47:04,085:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:47:04,090:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:47:04,091:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:47:04,211:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:47:04,216:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:47:04,334:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:47:04,339:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:47:04,340:INFO:Preparing preprocessing pipeline...
2024-05-29 10:47:04,346:INFO:Set up simple imputation.
2024-05-29 10:49:45,715:INFO:PyCaret ClassificationExperiment
2024-05-29 10:49:45,715:INFO:Logging name: codex
2024-05-29 10:49:45,715:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:49:45,716:INFO:version 3.3.2
2024-05-29 10:49:45,716:INFO:Initializing setup()
2024-05-29 10:49:45,716:INFO:self.USI: 5a1e
2024-05-29 10:49:45,716:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:49:45,716:INFO:Checking environment
2024-05-29 10:49:45,716:INFO:python_version: 3.10.13
2024-05-29 10:49:45,716:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:49:45,716:INFO:machine: AMD64
2024-05-29 10:49:45,716:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:49:45,716:INFO:Memory: svmem(total=34267656192, available=17896214528, percent=47.8, used=16371441664, free=17896214528)
2024-05-29 10:49:45,716:INFO:Physical Core: 8
2024-05-29 10:49:45,717:INFO:Logical Core: 16
2024-05-29 10:49:45,717:INFO:Checking libraries
2024-05-29 10:49:45,717:INFO:System:
2024-05-29 10:49:45,717:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:49:45,717:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:49:45,717:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:49:45,717:INFO:PyCaret required dependencies:
2024-05-29 10:49:45,718:INFO:                 pip: 23.3
2024-05-29 10:49:45,718:INFO:          setuptools: 68.0.0
2024-05-29 10:49:45,718:INFO:             pycaret: 3.3.2
2024-05-29 10:49:45,718:INFO:             IPython: 8.24.0
2024-05-29 10:49:45,718:INFO:          ipywidgets: 8.1.2
2024-05-29 10:49:45,718:INFO:                tqdm: 4.66.4
2024-05-29 10:49:45,718:INFO:               numpy: 1.26.4
2024-05-29 10:49:45,718:INFO:              pandas: 2.1.4
2024-05-29 10:49:45,718:INFO:              jinja2: 3.1.4
2024-05-29 10:49:45,718:INFO:               scipy: 1.11.4
2024-05-29 10:49:45,718:INFO:              joblib: 1.3.2
2024-05-29 10:49:45,719:INFO:             sklearn: 1.4.2
2024-05-29 10:49:45,719:INFO:                pyod: 1.1.3
2024-05-29 10:49:45,719:INFO:            imblearn: 0.12.2
2024-05-29 10:49:45,719:INFO:   category_encoders: 2.6.3
2024-05-29 10:49:45,719:INFO:            lightgbm: 4.3.0
2024-05-29 10:49:45,719:INFO:               numba: 0.59.1
2024-05-29 10:49:45,719:INFO:            requests: 2.32.2
2024-05-29 10:49:45,719:INFO:          matplotlib: 3.7.5
2024-05-29 10:49:45,720:INFO:          scikitplot: 0.3.7
2024-05-29 10:49:45,720:INFO:         yellowbrick: 1.5
2024-05-29 10:49:45,720:INFO:              plotly: 5.22.0
2024-05-29 10:49:45,720:INFO:    plotly-resampler: Not installed
2024-05-29 10:49:45,720:INFO:             kaleido: 0.2.1
2024-05-29 10:49:45,720:INFO:           schemdraw: 0.15
2024-05-29 10:49:45,720:INFO:         statsmodels: 0.14.2
2024-05-29 10:49:45,720:INFO:              sktime: 0.26.0
2024-05-29 10:49:45,720:INFO:               tbats: 1.1.3
2024-05-29 10:49:45,720:INFO:            pmdarima: 2.0.4
2024-05-29 10:49:45,720:INFO:              psutil: 5.9.0
2024-05-29 10:49:45,721:INFO:          markupsafe: 2.1.5
2024-05-29 10:49:45,721:INFO:             pickle5: Not installed
2024-05-29 10:49:45,721:INFO:         cloudpickle: 3.0.0
2024-05-29 10:49:45,721:INFO:         deprecation: 2.1.0
2024-05-29 10:49:45,721:INFO:              xxhash: 3.4.1
2024-05-29 10:49:45,721:INFO:           wurlitzer: Not installed
2024-05-29 10:49:45,721:INFO:PyCaret optional dependencies:
2024-05-29 10:49:45,721:INFO:                shap: Not installed
2024-05-29 10:49:45,721:INFO:           interpret: Not installed
2024-05-29 10:49:45,721:INFO:                umap: Not installed
2024-05-29 10:49:45,722:INFO:     ydata_profiling: Not installed
2024-05-29 10:49:45,722:INFO:  explainerdashboard: Not installed
2024-05-29 10:49:45,722:INFO:             autoviz: Not installed
2024-05-29 10:49:45,722:INFO:           fairlearn: Not installed
2024-05-29 10:49:45,722:INFO:          deepchecks: Not installed
2024-05-29 10:49:45,722:INFO:             xgboost: 2.0.3
2024-05-29 10:49:45,722:INFO:            catboost: Not installed
2024-05-29 10:49:45,722:INFO:              kmodes: Not installed
2024-05-29 10:49:45,722:INFO:             mlxtend: Not installed
2024-05-29 10:49:45,722:INFO:       statsforecast: Not installed
2024-05-29 10:49:45,722:INFO:        tune_sklearn: Not installed
2024-05-29 10:49:45,722:INFO:                 ray: Not installed
2024-05-29 10:49:45,723:INFO:            hyperopt: Not installed
2024-05-29 10:49:45,723:INFO:              optuna: Not installed
2024-05-29 10:49:45,723:INFO:               skopt: Not installed
2024-05-29 10:49:45,723:INFO:              mlflow: 2.13.0
2024-05-29 10:49:45,723:INFO:              gradio: Not installed
2024-05-29 10:49:45,723:INFO:             fastapi: Not installed
2024-05-29 10:49:45,723:INFO:             uvicorn: Not installed
2024-05-29 10:49:45,723:INFO:              m2cgen: Not installed
2024-05-29 10:49:45,723:INFO:           evidently: Not installed
2024-05-29 10:49:45,723:INFO:               fugue: Not installed
2024-05-29 10:49:45,723:INFO:           streamlit: Not installed
2024-05-29 10:49:45,723:INFO:             prophet: Not installed
2024-05-29 10:49:45,724:INFO:None
2024-05-29 10:49:45,724:INFO:Set up data.
2024-05-29 10:49:45,757:INFO:Set up folding strategy.
2024-05-29 10:49:45,757:INFO:Set up train/test split.
2024-05-29 10:49:45,816:INFO:Set up index.
2024-05-29 10:49:45,819:INFO:Assigning column types.
2024-05-29 10:49:45,852:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:49:45,923:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:49:45,924:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:49:45,969:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:49:45,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:49:46,045:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:49:46,046:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:49:46,097:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:49:46,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:49:46,104:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:49:46,179:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:49:46,224:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:49:46,228:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:49:46,301:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:49:46,345:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:49:46,349:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:49:46,350:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:49:46,466:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:49:46,470:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:49:46,588:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:49:46,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:49:46,594:INFO:Preparing preprocessing pipeline...
2024-05-29 10:49:46,603:INFO:Set up simple imputation.
2024-05-29 10:49:54,560:INFO:PyCaret ClassificationExperiment
2024-05-29 10:49:54,560:INFO:Logging name: codex
2024-05-29 10:49:54,560:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:49:54,560:INFO:version 3.3.2
2024-05-29 10:49:54,560:INFO:Initializing setup()
2024-05-29 10:49:54,560:INFO:self.USI: 1204
2024-05-29 10:49:54,560:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:49:54,560:INFO:Checking environment
2024-05-29 10:49:54,561:INFO:python_version: 3.10.13
2024-05-29 10:49:54,561:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:49:54,561:INFO:machine: AMD64
2024-05-29 10:49:54,561:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:49:54,561:INFO:Memory: svmem(total=34267656192, available=17870012416, percent=47.9, used=16397643776, free=17870012416)
2024-05-29 10:49:54,561:INFO:Physical Core: 8
2024-05-29 10:49:54,561:INFO:Logical Core: 16
2024-05-29 10:49:54,561:INFO:Checking libraries
2024-05-29 10:49:54,561:INFO:System:
2024-05-29 10:49:54,562:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:49:54,562:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:49:54,562:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:49:54,562:INFO:PyCaret required dependencies:
2024-05-29 10:49:54,562:INFO:                 pip: 23.3
2024-05-29 10:49:54,562:INFO:          setuptools: 68.0.0
2024-05-29 10:49:54,562:INFO:             pycaret: 3.3.2
2024-05-29 10:49:54,563:INFO:             IPython: 8.24.0
2024-05-29 10:49:54,563:INFO:          ipywidgets: 8.1.2
2024-05-29 10:49:54,563:INFO:                tqdm: 4.66.4
2024-05-29 10:49:54,563:INFO:               numpy: 1.26.4
2024-05-29 10:49:54,563:INFO:              pandas: 2.1.4
2024-05-29 10:49:54,563:INFO:              jinja2: 3.1.4
2024-05-29 10:49:54,563:INFO:               scipy: 1.11.4
2024-05-29 10:49:54,563:INFO:              joblib: 1.3.2
2024-05-29 10:49:54,563:INFO:             sklearn: 1.4.2
2024-05-29 10:49:54,563:INFO:                pyod: 1.1.3
2024-05-29 10:49:54,564:INFO:            imblearn: 0.12.2
2024-05-29 10:49:54,564:INFO:   category_encoders: 2.6.3
2024-05-29 10:49:54,564:INFO:            lightgbm: 4.3.0
2024-05-29 10:49:54,564:INFO:               numba: 0.59.1
2024-05-29 10:49:54,564:INFO:            requests: 2.32.2
2024-05-29 10:49:54,564:INFO:          matplotlib: 3.7.5
2024-05-29 10:49:54,564:INFO:          scikitplot: 0.3.7
2024-05-29 10:49:54,564:INFO:         yellowbrick: 1.5
2024-05-29 10:49:54,564:INFO:              plotly: 5.22.0
2024-05-29 10:49:54,564:INFO:    plotly-resampler: Not installed
2024-05-29 10:49:54,564:INFO:             kaleido: 0.2.1
2024-05-29 10:49:54,565:INFO:           schemdraw: 0.15
2024-05-29 10:49:54,565:INFO:         statsmodels: 0.14.2
2024-05-29 10:49:54,565:INFO:              sktime: 0.26.0
2024-05-29 10:49:54,565:INFO:               tbats: 1.1.3
2024-05-29 10:49:54,565:INFO:            pmdarima: 2.0.4
2024-05-29 10:49:54,565:INFO:              psutil: 5.9.0
2024-05-29 10:49:54,565:INFO:          markupsafe: 2.1.5
2024-05-29 10:49:54,565:INFO:             pickle5: Not installed
2024-05-29 10:49:54,565:INFO:         cloudpickle: 3.0.0
2024-05-29 10:49:54,566:INFO:         deprecation: 2.1.0
2024-05-29 10:49:54,566:INFO:              xxhash: 3.4.1
2024-05-29 10:49:54,566:INFO:           wurlitzer: Not installed
2024-05-29 10:49:54,566:INFO:PyCaret optional dependencies:
2024-05-29 10:49:54,566:INFO:                shap: Not installed
2024-05-29 10:49:54,566:INFO:           interpret: Not installed
2024-05-29 10:49:54,566:INFO:                umap: Not installed
2024-05-29 10:49:54,566:INFO:     ydata_profiling: Not installed
2024-05-29 10:49:54,566:INFO:  explainerdashboard: Not installed
2024-05-29 10:49:54,566:INFO:             autoviz: Not installed
2024-05-29 10:49:54,567:INFO:           fairlearn: Not installed
2024-05-29 10:49:54,567:INFO:          deepchecks: Not installed
2024-05-29 10:49:54,567:INFO:             xgboost: 2.0.3
2024-05-29 10:49:54,567:INFO:            catboost: Not installed
2024-05-29 10:49:54,567:INFO:              kmodes: Not installed
2024-05-29 10:49:54,567:INFO:             mlxtend: Not installed
2024-05-29 10:49:54,567:INFO:       statsforecast: Not installed
2024-05-29 10:49:54,567:INFO:        tune_sklearn: Not installed
2024-05-29 10:49:54,567:INFO:                 ray: Not installed
2024-05-29 10:49:54,567:INFO:            hyperopt: Not installed
2024-05-29 10:49:54,567:INFO:              optuna: Not installed
2024-05-29 10:49:54,567:INFO:               skopt: Not installed
2024-05-29 10:49:54,568:INFO:              mlflow: 2.13.0
2024-05-29 10:49:54,568:INFO:              gradio: Not installed
2024-05-29 10:49:54,568:INFO:             fastapi: Not installed
2024-05-29 10:49:54,568:INFO:             uvicorn: Not installed
2024-05-29 10:49:54,568:INFO:              m2cgen: Not installed
2024-05-29 10:49:54,568:INFO:           evidently: Not installed
2024-05-29 10:49:54,568:INFO:               fugue: Not installed
2024-05-29 10:49:54,568:INFO:           streamlit: Not installed
2024-05-29 10:49:54,568:INFO:             prophet: Not installed
2024-05-29 10:49:54,568:INFO:None
2024-05-29 10:49:54,569:INFO:Set up data.
2024-05-29 10:49:54,598:INFO:Set up folding strategy.
2024-05-29 10:49:54,598:INFO:Set up train/test split.
2024-05-29 10:49:54,658:INFO:Set up index.
2024-05-29 10:49:54,660:INFO:Assigning column types.
2024-05-29 10:49:54,694:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:49:54,766:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:49:54,767:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:49:54,811:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:49:54,816:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:49:54,887:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:49:54,889:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:49:54,933:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:49:54,938:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:49:54,938:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:49:55,010:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:49:55,054:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:49:55,059:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:49:55,131:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:49:55,176:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:49:55,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:49:55,180:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:49:55,298:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:49:55,302:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:49:55,419:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:49:55,424:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:49:55,425:INFO:Preparing preprocessing pipeline...
2024-05-29 10:49:55,434:INFO:Set up simple imputation.
2024-05-29 10:52:01,561:INFO:PyCaret ClassificationExperiment
2024-05-29 10:52:01,562:INFO:Logging name: codex
2024-05-29 10:52:01,562:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:52:01,562:INFO:version 3.3.2
2024-05-29 10:52:01,562:INFO:Initializing setup()
2024-05-29 10:52:01,562:INFO:self.USI: 6bb4
2024-05-29 10:52:01,562:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:52:01,562:INFO:Checking environment
2024-05-29 10:52:01,562:INFO:python_version: 3.10.13
2024-05-29 10:52:01,562:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:52:01,563:INFO:machine: AMD64
2024-05-29 10:52:01,563:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:52:01,563:INFO:Memory: svmem(total=34267656192, available=18027290624, percent=47.4, used=16240365568, free=18027290624)
2024-05-29 10:52:01,563:INFO:Physical Core: 8
2024-05-29 10:52:01,563:INFO:Logical Core: 16
2024-05-29 10:52:01,563:INFO:Checking libraries
2024-05-29 10:52:01,563:INFO:System:
2024-05-29 10:52:01,563:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:52:01,563:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:52:01,563:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:52:01,563:INFO:PyCaret required dependencies:
2024-05-29 10:52:01,564:INFO:                 pip: 23.3
2024-05-29 10:52:01,564:INFO:          setuptools: 68.0.0
2024-05-29 10:52:01,564:INFO:             pycaret: 3.3.2
2024-05-29 10:52:01,564:INFO:             IPython: 8.24.0
2024-05-29 10:52:01,564:INFO:          ipywidgets: 8.1.2
2024-05-29 10:52:01,564:INFO:                tqdm: 4.66.4
2024-05-29 10:52:01,564:INFO:               numpy: 1.26.4
2024-05-29 10:52:01,564:INFO:              pandas: 2.1.4
2024-05-29 10:52:01,564:INFO:              jinja2: 3.1.4
2024-05-29 10:52:01,564:INFO:               scipy: 1.11.4
2024-05-29 10:52:01,565:INFO:              joblib: 1.3.2
2024-05-29 10:52:01,565:INFO:             sklearn: 1.4.2
2024-05-29 10:52:01,565:INFO:                pyod: 1.1.3
2024-05-29 10:52:01,565:INFO:            imblearn: 0.12.2
2024-05-29 10:52:01,565:INFO:   category_encoders: 2.6.3
2024-05-29 10:52:01,565:INFO:            lightgbm: 4.3.0
2024-05-29 10:52:01,565:INFO:               numba: 0.59.1
2024-05-29 10:52:01,565:INFO:            requests: 2.32.2
2024-05-29 10:52:01,565:INFO:          matplotlib: 3.7.5
2024-05-29 10:52:01,565:INFO:          scikitplot: 0.3.7
2024-05-29 10:52:01,565:INFO:         yellowbrick: 1.5
2024-05-29 10:52:01,565:INFO:              plotly: 5.22.0
2024-05-29 10:52:01,566:INFO:    plotly-resampler: Not installed
2024-05-29 10:52:01,566:INFO:             kaleido: 0.2.1
2024-05-29 10:52:01,566:INFO:           schemdraw: 0.15
2024-05-29 10:52:01,566:INFO:         statsmodels: 0.14.2
2024-05-29 10:52:01,566:INFO:              sktime: 0.26.0
2024-05-29 10:52:01,566:INFO:               tbats: 1.1.3
2024-05-29 10:52:01,566:INFO:            pmdarima: 2.0.4
2024-05-29 10:52:01,566:INFO:              psutil: 5.9.0
2024-05-29 10:52:01,566:INFO:          markupsafe: 2.1.5
2024-05-29 10:52:01,566:INFO:             pickle5: Not installed
2024-05-29 10:52:01,566:INFO:         cloudpickle: 3.0.0
2024-05-29 10:52:01,567:INFO:         deprecation: 2.1.0
2024-05-29 10:52:01,567:INFO:              xxhash: 3.4.1
2024-05-29 10:52:01,567:INFO:           wurlitzer: Not installed
2024-05-29 10:52:01,567:INFO:PyCaret optional dependencies:
2024-05-29 10:52:01,567:INFO:                shap: Not installed
2024-05-29 10:52:01,567:INFO:           interpret: Not installed
2024-05-29 10:52:01,567:INFO:                umap: Not installed
2024-05-29 10:52:01,567:INFO:     ydata_profiling: Not installed
2024-05-29 10:52:01,567:INFO:  explainerdashboard: Not installed
2024-05-29 10:52:01,567:INFO:             autoviz: Not installed
2024-05-29 10:52:01,567:INFO:           fairlearn: Not installed
2024-05-29 10:52:01,568:INFO:          deepchecks: Not installed
2024-05-29 10:52:01,568:INFO:             xgboost: 2.0.3
2024-05-29 10:52:01,568:INFO:            catboost: Not installed
2024-05-29 10:52:01,568:INFO:              kmodes: Not installed
2024-05-29 10:52:01,568:INFO:             mlxtend: Not installed
2024-05-29 10:52:01,568:INFO:       statsforecast: Not installed
2024-05-29 10:52:01,568:INFO:        tune_sklearn: Not installed
2024-05-29 10:52:01,568:INFO:                 ray: Not installed
2024-05-29 10:52:01,568:INFO:            hyperopt: Not installed
2024-05-29 10:52:01,568:INFO:              optuna: Not installed
2024-05-29 10:52:01,568:INFO:               skopt: Not installed
2024-05-29 10:52:01,569:INFO:              mlflow: 2.13.0
2024-05-29 10:52:01,569:INFO:              gradio: Not installed
2024-05-29 10:52:01,569:INFO:             fastapi: Not installed
2024-05-29 10:52:01,569:INFO:             uvicorn: Not installed
2024-05-29 10:52:01,569:INFO:              m2cgen: Not installed
2024-05-29 10:52:01,569:INFO:           evidently: Not installed
2024-05-29 10:52:01,569:INFO:               fugue: Not installed
2024-05-29 10:52:01,569:INFO:           streamlit: Not installed
2024-05-29 10:52:01,569:INFO:             prophet: Not installed
2024-05-29 10:52:01,569:INFO:None
2024-05-29 10:52:01,570:INFO:Set up data.
2024-05-29 10:52:03,096:INFO:Set up folding strategy.
2024-05-29 10:52:03,097:INFO:Set up train/test split.
2024-05-29 10:52:03,156:INFO:Set up index.
2024-05-29 10:52:03,157:INFO:Assigning column types.
2024-05-29 10:52:03,165:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:52:03,239:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:52:03,241:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:52:03,286:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:52:03,291:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:52:03,365:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:52:03,367:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:52:03,411:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:52:03,415:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:52:03,416:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:52:03,487:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:52:03,531:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:52:03,536:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:52:03,608:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:52:03,652:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:52:03,657:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:52:03,657:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:52:03,772:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:52:03,777:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:52:03,893:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:52:03,898:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:52:03,899:INFO:Preparing preprocessing pipeline...
2024-05-29 10:52:03,902:INFO:Set up simple imputation.
2024-05-29 10:52:03,930:INFO:Set up encoding of ordinal features.
2024-05-29 10:52:03,946:INFO:Set up encoding of categorical features.
2024-05-29 10:55:04,914:INFO:PyCaret ClassificationExperiment
2024-05-29 10:55:04,914:INFO:Logging name: codex
2024-05-29 10:55:04,915:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:55:04,915:INFO:version 3.3.2
2024-05-29 10:55:04,915:INFO:Initializing setup()
2024-05-29 10:55:04,915:INFO:self.USI: 9d65
2024-05-29 10:55:04,915:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:55:04,915:INFO:Checking environment
2024-05-29 10:55:04,915:INFO:python_version: 3.10.13
2024-05-29 10:55:04,916:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:55:04,916:INFO:machine: AMD64
2024-05-29 10:55:04,916:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:55:04,916:INFO:Memory: svmem(total=34267656192, available=17704931328, percent=48.3, used=16562724864, free=17704931328)
2024-05-29 10:55:04,916:INFO:Physical Core: 8
2024-05-29 10:55:04,916:INFO:Logical Core: 16
2024-05-29 10:55:04,916:INFO:Checking libraries
2024-05-29 10:55:04,916:INFO:System:
2024-05-29 10:55:04,916:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:55:04,917:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:55:04,917:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:55:04,917:INFO:PyCaret required dependencies:
2024-05-29 10:55:04,917:INFO:                 pip: 23.3
2024-05-29 10:55:04,917:INFO:          setuptools: 68.0.0
2024-05-29 10:55:04,917:INFO:             pycaret: 3.3.2
2024-05-29 10:55:04,917:INFO:             IPython: 8.24.0
2024-05-29 10:55:04,917:INFO:          ipywidgets: 8.1.2
2024-05-29 10:55:04,917:INFO:                tqdm: 4.66.4
2024-05-29 10:55:04,917:INFO:               numpy: 1.26.4
2024-05-29 10:55:04,917:INFO:              pandas: 2.1.4
2024-05-29 10:55:04,918:INFO:              jinja2: 3.1.4
2024-05-29 10:55:04,918:INFO:               scipy: 1.11.4
2024-05-29 10:55:04,918:INFO:              joblib: 1.3.2
2024-05-29 10:55:04,918:INFO:             sklearn: 1.4.2
2024-05-29 10:55:04,918:INFO:                pyod: 1.1.3
2024-05-29 10:55:04,918:INFO:            imblearn: 0.12.2
2024-05-29 10:55:04,918:INFO:   category_encoders: 2.6.3
2024-05-29 10:55:04,918:INFO:            lightgbm: 4.3.0
2024-05-29 10:55:04,918:INFO:               numba: 0.59.1
2024-05-29 10:55:04,918:INFO:            requests: 2.32.2
2024-05-29 10:55:04,918:INFO:          matplotlib: 3.7.5
2024-05-29 10:55:04,919:INFO:          scikitplot: 0.3.7
2024-05-29 10:55:04,919:INFO:         yellowbrick: 1.5
2024-05-29 10:55:04,919:INFO:              plotly: 5.22.0
2024-05-29 10:55:04,919:INFO:    plotly-resampler: Not installed
2024-05-29 10:55:04,919:INFO:             kaleido: 0.2.1
2024-05-29 10:55:04,919:INFO:           schemdraw: 0.15
2024-05-29 10:55:04,919:INFO:         statsmodels: 0.14.2
2024-05-29 10:55:04,919:INFO:              sktime: 0.26.0
2024-05-29 10:55:04,919:INFO:               tbats: 1.1.3
2024-05-29 10:55:04,919:INFO:            pmdarima: 2.0.4
2024-05-29 10:55:04,919:INFO:              psutil: 5.9.0
2024-05-29 10:55:04,919:INFO:          markupsafe: 2.1.5
2024-05-29 10:55:04,920:INFO:             pickle5: Not installed
2024-05-29 10:55:04,920:INFO:         cloudpickle: 3.0.0
2024-05-29 10:55:04,920:INFO:         deprecation: 2.1.0
2024-05-29 10:55:04,920:INFO:              xxhash: 3.4.1
2024-05-29 10:55:04,920:INFO:           wurlitzer: Not installed
2024-05-29 10:55:04,920:INFO:PyCaret optional dependencies:
2024-05-29 10:55:04,920:INFO:                shap: Not installed
2024-05-29 10:55:04,920:INFO:           interpret: Not installed
2024-05-29 10:55:04,920:INFO:                umap: Not installed
2024-05-29 10:55:04,920:INFO:     ydata_profiling: Not installed
2024-05-29 10:55:04,921:INFO:  explainerdashboard: Not installed
2024-05-29 10:55:04,921:INFO:             autoviz: Not installed
2024-05-29 10:55:04,921:INFO:           fairlearn: Not installed
2024-05-29 10:55:04,921:INFO:          deepchecks: Not installed
2024-05-29 10:55:04,921:INFO:             xgboost: 2.0.3
2024-05-29 10:55:04,921:INFO:            catboost: Not installed
2024-05-29 10:55:04,921:INFO:              kmodes: Not installed
2024-05-29 10:55:04,921:INFO:             mlxtend: Not installed
2024-05-29 10:55:04,921:INFO:       statsforecast: Not installed
2024-05-29 10:55:04,921:INFO:        tune_sklearn: Not installed
2024-05-29 10:55:04,922:INFO:                 ray: Not installed
2024-05-29 10:55:04,922:INFO:            hyperopt: Not installed
2024-05-29 10:55:04,922:INFO:              optuna: Not installed
2024-05-29 10:55:04,922:INFO:               skopt: Not installed
2024-05-29 10:55:04,922:INFO:              mlflow: 2.13.0
2024-05-29 10:55:04,922:INFO:              gradio: Not installed
2024-05-29 10:55:04,922:INFO:             fastapi: Not installed
2024-05-29 10:55:04,922:INFO:             uvicorn: Not installed
2024-05-29 10:55:04,922:INFO:              m2cgen: Not installed
2024-05-29 10:55:04,922:INFO:           evidently: Not installed
2024-05-29 10:55:04,922:INFO:               fugue: Not installed
2024-05-29 10:55:04,923:INFO:           streamlit: Not installed
2024-05-29 10:55:04,923:INFO:             prophet: Not installed
2024-05-29 10:55:04,923:INFO:None
2024-05-29 10:55:04,923:INFO:Set up data.
2024-05-29 10:55:04,952:INFO:Set up folding strategy.
2024-05-29 10:55:04,952:INFO:Set up train/test split.
2024-05-29 10:55:05,011:INFO:Set up index.
2024-05-29 10:55:05,013:INFO:Assigning column types.
2024-05-29 10:55:05,047:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:55:05,120:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:55:05,122:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:55:05,168:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:55:05,172:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:55:05,245:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:55:05,246:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:55:05,292:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:55:05,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:55:05,297:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:55:05,370:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:55:05,416:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:55:05,420:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:55:05,493:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:55:05,539:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:55:05,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:55:05,544:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:55:05,663:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:55:05,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:55:05,788:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:55:05,794:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:55:05,797:INFO:Preparing preprocessing pipeline...
2024-05-29 10:55:05,807:INFO:Set up simple imputation.
2024-05-29 10:57:28,857:INFO:PyCaret ClassificationExperiment
2024-05-29 10:57:28,857:INFO:Logging name: codex
2024-05-29 10:57:28,857:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 10:57:28,857:INFO:version 3.3.2
2024-05-29 10:57:28,857:INFO:Initializing setup()
2024-05-29 10:57:28,857:INFO:self.USI: 8418
2024-05-29 10:57:28,857:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 10:57:28,857:INFO:Checking environment
2024-05-29 10:57:28,857:INFO:python_version: 3.10.13
2024-05-29 10:57:28,857:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 10:57:28,858:INFO:machine: AMD64
2024-05-29 10:57:28,858:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 10:57:28,858:INFO:Memory: svmem(total=34267656192, available=17494319104, percent=48.9, used=16773337088, free=17494319104)
2024-05-29 10:57:28,858:INFO:Physical Core: 8
2024-05-29 10:57:28,858:INFO:Logical Core: 16
2024-05-29 10:57:28,858:INFO:Checking libraries
2024-05-29 10:57:28,858:INFO:System:
2024-05-29 10:57:28,858:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 10:57:28,858:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 10:57:28,858:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 10:57:28,858:INFO:PyCaret required dependencies:
2024-05-29 10:57:28,859:INFO:                 pip: 23.3
2024-05-29 10:57:28,859:INFO:          setuptools: 68.0.0
2024-05-29 10:57:28,859:INFO:             pycaret: 3.3.2
2024-05-29 10:57:28,859:INFO:             IPython: 8.24.0
2024-05-29 10:57:28,859:INFO:          ipywidgets: 8.1.2
2024-05-29 10:57:28,859:INFO:                tqdm: 4.66.4
2024-05-29 10:57:28,859:INFO:               numpy: 1.26.4
2024-05-29 10:57:28,859:INFO:              pandas: 2.1.4
2024-05-29 10:57:28,859:INFO:              jinja2: 3.1.4
2024-05-29 10:57:28,859:INFO:               scipy: 1.11.4
2024-05-29 10:57:28,860:INFO:              joblib: 1.3.2
2024-05-29 10:57:28,860:INFO:             sklearn: 1.4.2
2024-05-29 10:57:28,860:INFO:                pyod: 1.1.3
2024-05-29 10:57:28,860:INFO:            imblearn: 0.12.2
2024-05-29 10:57:28,860:INFO:   category_encoders: 2.6.3
2024-05-29 10:57:28,860:INFO:            lightgbm: 4.3.0
2024-05-29 10:57:28,860:INFO:               numba: 0.59.1
2024-05-29 10:57:28,860:INFO:            requests: 2.32.2
2024-05-29 10:57:28,860:INFO:          matplotlib: 3.7.5
2024-05-29 10:57:28,860:INFO:          scikitplot: 0.3.7
2024-05-29 10:57:28,860:INFO:         yellowbrick: 1.5
2024-05-29 10:57:28,860:INFO:              plotly: 5.22.0
2024-05-29 10:57:28,861:INFO:    plotly-resampler: Not installed
2024-05-29 10:57:28,861:INFO:             kaleido: 0.2.1
2024-05-29 10:57:28,861:INFO:           schemdraw: 0.15
2024-05-29 10:57:28,861:INFO:         statsmodels: 0.14.2
2024-05-29 10:57:28,861:INFO:              sktime: 0.26.0
2024-05-29 10:57:28,861:INFO:               tbats: 1.1.3
2024-05-29 10:57:28,861:INFO:            pmdarima: 2.0.4
2024-05-29 10:57:28,861:INFO:              psutil: 5.9.0
2024-05-29 10:57:28,861:INFO:          markupsafe: 2.1.5
2024-05-29 10:57:28,861:INFO:             pickle5: Not installed
2024-05-29 10:57:28,861:INFO:         cloudpickle: 3.0.0
2024-05-29 10:57:28,862:INFO:         deprecation: 2.1.0
2024-05-29 10:57:28,862:INFO:              xxhash: 3.4.1
2024-05-29 10:57:28,862:INFO:           wurlitzer: Not installed
2024-05-29 10:57:28,862:INFO:PyCaret optional dependencies:
2024-05-29 10:57:28,862:INFO:                shap: Not installed
2024-05-29 10:57:28,862:INFO:           interpret: Not installed
2024-05-29 10:57:28,862:INFO:                umap: Not installed
2024-05-29 10:57:28,862:INFO:     ydata_profiling: Not installed
2024-05-29 10:57:28,862:INFO:  explainerdashboard: Not installed
2024-05-29 10:57:28,862:INFO:             autoviz: Not installed
2024-05-29 10:57:28,862:INFO:           fairlearn: Not installed
2024-05-29 10:57:28,862:INFO:          deepchecks: Not installed
2024-05-29 10:57:28,863:INFO:             xgboost: 2.0.3
2024-05-29 10:57:28,863:INFO:            catboost: Not installed
2024-05-29 10:57:28,863:INFO:              kmodes: Not installed
2024-05-29 10:57:28,863:INFO:             mlxtend: Not installed
2024-05-29 10:57:28,863:INFO:       statsforecast: Not installed
2024-05-29 10:57:28,863:INFO:        tune_sklearn: Not installed
2024-05-29 10:57:28,863:INFO:                 ray: Not installed
2024-05-29 10:57:28,863:INFO:            hyperopt: Not installed
2024-05-29 10:57:28,863:INFO:              optuna: Not installed
2024-05-29 10:57:28,863:INFO:               skopt: Not installed
2024-05-29 10:57:28,863:INFO:              mlflow: 2.13.0
2024-05-29 10:57:28,864:INFO:              gradio: Not installed
2024-05-29 10:57:28,864:INFO:             fastapi: Not installed
2024-05-29 10:57:28,864:INFO:             uvicorn: Not installed
2024-05-29 10:57:28,864:INFO:              m2cgen: Not installed
2024-05-29 10:57:28,864:INFO:           evidently: Not installed
2024-05-29 10:57:28,864:INFO:               fugue: Not installed
2024-05-29 10:57:28,864:INFO:           streamlit: Not installed
2024-05-29 10:57:28,864:INFO:             prophet: Not installed
2024-05-29 10:57:28,864:INFO:None
2024-05-29 10:57:28,864:INFO:Set up data.
2024-05-29 10:57:28,893:INFO:Set up folding strategy.
2024-05-29 10:57:28,894:INFO:Set up train/test split.
2024-05-29 10:57:28,949:INFO:Set up index.
2024-05-29 10:57:28,951:INFO:Assigning column types.
2024-05-29 10:57:28,985:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 10:57:29,056:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:57:29,057:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:57:29,102:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:57:29,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:57:29,178:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 10:57:29,179:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:57:29,224:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:57:29,229:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:57:29,229:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 10:57:29,302:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:57:29,347:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:57:29,351:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:57:29,424:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 10:57:29,468:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:57:29,473:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:57:29,473:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 10:57:29,589:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:57:29,594:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:57:29,710:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 10:57:29,715:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 10:57:29,716:INFO:Preparing preprocessing pipeline...
2024-05-29 10:57:29,723:INFO:Set up simple imputation.
2024-05-29 11:00:23,899:INFO:PyCaret ClassificationExperiment
2024-05-29 11:00:23,899:INFO:Logging name: codex
2024-05-29 11:00:23,899:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 11:00:23,899:INFO:version 3.3.2
2024-05-29 11:00:23,899:INFO:Initializing setup()
2024-05-29 11:00:23,899:INFO:self.USI: 6c83
2024-05-29 11:00:23,899:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 11:00:23,899:INFO:Checking environment
2024-05-29 11:00:23,899:INFO:python_version: 3.10.13
2024-05-29 11:00:23,900:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 11:00:23,900:INFO:machine: AMD64
2024-05-29 11:00:23,900:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 11:00:23,900:INFO:Memory: svmem(total=34267656192, available=17447624704, percent=49.1, used=16820031488, free=17447624704)
2024-05-29 11:00:23,900:INFO:Physical Core: 8
2024-05-29 11:00:23,900:INFO:Logical Core: 16
2024-05-29 11:00:23,900:INFO:Checking libraries
2024-05-29 11:00:23,900:INFO:System:
2024-05-29 11:00:23,900:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 11:00:23,900:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 11:00:23,900:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 11:00:23,901:INFO:PyCaret required dependencies:
2024-05-29 11:00:23,901:INFO:                 pip: 23.3
2024-05-29 11:00:23,901:INFO:          setuptools: 68.0.0
2024-05-29 11:00:23,901:INFO:             pycaret: 3.3.2
2024-05-29 11:00:23,901:INFO:             IPython: 8.24.0
2024-05-29 11:00:23,901:INFO:          ipywidgets: 8.1.2
2024-05-29 11:00:23,901:INFO:                tqdm: 4.66.4
2024-05-29 11:00:23,901:INFO:               numpy: 1.26.4
2024-05-29 11:00:23,901:INFO:              pandas: 2.1.4
2024-05-29 11:00:23,901:INFO:              jinja2: 3.1.4
2024-05-29 11:00:23,902:INFO:               scipy: 1.11.4
2024-05-29 11:00:23,902:INFO:              joblib: 1.3.2
2024-05-29 11:00:23,902:INFO:             sklearn: 1.4.2
2024-05-29 11:00:23,902:INFO:                pyod: 1.1.3
2024-05-29 11:00:23,902:INFO:            imblearn: 0.12.2
2024-05-29 11:00:23,902:INFO:   category_encoders: 2.6.3
2024-05-29 11:00:23,902:INFO:            lightgbm: 4.3.0
2024-05-29 11:00:23,902:INFO:               numba: 0.59.1
2024-05-29 11:00:23,902:INFO:            requests: 2.32.2
2024-05-29 11:00:23,902:INFO:          matplotlib: 3.7.5
2024-05-29 11:00:23,903:INFO:          scikitplot: 0.3.7
2024-05-29 11:00:23,903:INFO:         yellowbrick: 1.5
2024-05-29 11:00:23,903:INFO:              plotly: 5.22.0
2024-05-29 11:00:23,903:INFO:    plotly-resampler: Not installed
2024-05-29 11:00:23,903:INFO:             kaleido: 0.2.1
2024-05-29 11:00:23,903:INFO:           schemdraw: 0.15
2024-05-29 11:00:23,903:INFO:         statsmodels: 0.14.2
2024-05-29 11:00:23,903:INFO:              sktime: 0.26.0
2024-05-29 11:00:23,903:INFO:               tbats: 1.1.3
2024-05-29 11:00:23,903:INFO:            pmdarima: 2.0.4
2024-05-29 11:00:23,903:INFO:              psutil: 5.9.0
2024-05-29 11:00:23,904:INFO:          markupsafe: 2.1.5
2024-05-29 11:00:23,904:INFO:             pickle5: Not installed
2024-05-29 11:00:23,904:INFO:         cloudpickle: 3.0.0
2024-05-29 11:00:23,904:INFO:         deprecation: 2.1.0
2024-05-29 11:00:23,904:INFO:              xxhash: 3.4.1
2024-05-29 11:00:23,904:INFO:           wurlitzer: Not installed
2024-05-29 11:00:23,904:INFO:PyCaret optional dependencies:
2024-05-29 11:00:23,904:INFO:                shap: Not installed
2024-05-29 11:00:23,904:INFO:           interpret: Not installed
2024-05-29 11:00:23,905:INFO:                umap: Not installed
2024-05-29 11:00:23,905:INFO:     ydata_profiling: Not installed
2024-05-29 11:00:23,905:INFO:  explainerdashboard: Not installed
2024-05-29 11:00:23,905:INFO:             autoviz: Not installed
2024-05-29 11:00:23,905:INFO:           fairlearn: Not installed
2024-05-29 11:00:23,905:INFO:          deepchecks: Not installed
2024-05-29 11:00:23,905:INFO:             xgboost: 2.0.3
2024-05-29 11:00:23,905:INFO:            catboost: Not installed
2024-05-29 11:00:23,905:INFO:              kmodes: Not installed
2024-05-29 11:00:23,905:INFO:             mlxtend: Not installed
2024-05-29 11:00:23,905:INFO:       statsforecast: Not installed
2024-05-29 11:00:23,906:INFO:        tune_sklearn: Not installed
2024-05-29 11:00:23,906:INFO:                 ray: Not installed
2024-05-29 11:00:23,906:INFO:            hyperopt: Not installed
2024-05-29 11:00:23,906:INFO:              optuna: Not installed
2024-05-29 11:00:23,906:INFO:               skopt: Not installed
2024-05-29 11:00:23,906:INFO:              mlflow: 2.13.0
2024-05-29 11:00:23,906:INFO:              gradio: Not installed
2024-05-29 11:00:23,906:INFO:             fastapi: Not installed
2024-05-29 11:00:23,906:INFO:             uvicorn: Not installed
2024-05-29 11:00:23,906:INFO:              m2cgen: Not installed
2024-05-29 11:00:23,907:INFO:           evidently: Not installed
2024-05-29 11:00:23,907:INFO:               fugue: Not installed
2024-05-29 11:00:23,907:INFO:           streamlit: Not installed
2024-05-29 11:00:23,907:INFO:             prophet: Not installed
2024-05-29 11:00:23,907:INFO:None
2024-05-29 11:00:23,907:INFO:Set up data.
2024-05-29 11:00:25,402:INFO:Set up folding strategy.
2024-05-29 11:00:25,402:INFO:Set up train/test split.
2024-05-29 11:00:25,443:INFO:Set up index.
2024-05-29 11:00:25,445:INFO:Assigning column types.
2024-05-29 11:00:25,452:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 11:00:25,523:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:00:25,525:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:00:25,569:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:00:25,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:00:25,645:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:00:25,646:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:00:25,691:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:00:25,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:00:25,696:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 11:00:25,768:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:00:25,812:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:00:25,816:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:00:25,889:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:00:25,933:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:00:25,937:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:00:25,938:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 11:00:26,055:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:00:26,059:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:00:26,176:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:00:26,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:00:26,181:INFO:Preparing preprocessing pipeline...
2024-05-29 11:00:26,184:INFO:Set up simple imputation.
2024-05-29 11:00:26,212:INFO:Set up encoding of ordinal features.
2024-05-29 11:00:26,232:INFO:Set up encoding of categorical features.
2024-05-29 11:00:29,526:INFO:Finished creating preprocessing pipeline.
2024-05-29 11:00:29,631:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['fe...
                                    include=['feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12'],
                                    transformer=TargetEncoder(cols=['feature_7',
                                                                    'feature_8',
                                                                    'feature_9',
                                                                    'feature_10',
                                                                    'feature_11',
                                                                    'feature_12'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-29 11:00:29,632:INFO:Creating final display dataframe.
2024-05-29 11:00:32,228:INFO:Setup _display_container:                     Description            Value
0                    Session id             4878
1                        Target           target
2                   Target type           Binary
3           Original data shape      (90000, 18)
4        Transformed data shape      (90000, 55)
5   Transformed train set shape      (72000, 55)
6    Transformed test set shape      (18000, 55)
7          Categorical features               17
8                    Preprocess             True
9               Imputation type           simple
10           Numeric imputation             mean
11       Categorical imputation             mode
12     Maximum one-hot encoding               25
13              Encoding method             None
14               Fold Generator  StratifiedKFold
15                  Fold Number               10
16                     CPU Jobs               -1
17                      Use GPU            False
18               Log Experiment     MlflowLogger
19              Experiment Name            codex
20                          USI             6c83
2024-05-29 11:00:32,355:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:00:32,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:00:32,480:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:00:32,484:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:00:32,486:INFO:Logging experiment in loggers
2024-05-29 11:00:32,918:INFO:SubProcess save_model() called ==================================
2024-05-29 11:00:33,128:INFO:Initializing save_model()
2024-05-29 11:00:33,128:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['fe...
                                    include=['feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12'],
                                    transformer=TargetEncoder(cols=['feature_7',
                                                                    'feature_8',
                                                                    'feature_9',
                                                                    'feature_10',
                                                                    'feature_11',
                                                                    'feature_12'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), model_name=C:\Users\Adm\AppData\Local\Temp\tmpurzg6bxl\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['fe...
                                    include=['feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12'],
                                    transformer=TargetEncoder(cols=['feature_7',
                                                                    'feature_8',
                                                                    'feature_9',
                                                                    'feature_10',
                                                                    'feature_11',
                                                                    'feature_12'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-29 11:00:33,128:INFO:Adding model into prep_pipe
2024-05-29 11:00:33,128:WARNING:Only Model saved as it was a pipeline.
2024-05-29 11:00:33,167:INFO:C:\Users\Adm\AppData\Local\Temp\tmpurzg6bxl\Transformation Pipeline.pkl saved in current working directory
2024-05-29 11:00:33,272:INFO:Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['fe...
                                    include=['feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12'],
                                    transformer=TargetEncoder(cols=['feature_7',
                                                                    'feature_8',
                                                                    'feature_9',
                                                                    'feature_10',
                                                                    'feature_11',
                                                                    'feature_12'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-29 11:00:33,272:INFO:save_model() successfully completed......................................
2024-05-29 11:00:35,133:INFO:SubProcess save_model() end ==================================
2024-05-29 11:00:35,163:INFO:setup() successfully completed in 8.62s...............
2024-05-29 11:09:06,156:INFO:PyCaret ClassificationExperiment
2024-05-29 11:09:06,156:INFO:Logging name: codex
2024-05-29 11:09:06,156:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 11:09:06,156:INFO:version 3.3.2
2024-05-29 11:09:06,156:INFO:Initializing setup()
2024-05-29 11:09:06,157:INFO:self.USI: de5a
2024-05-29 11:09:06,157:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 11:09:06,157:INFO:Checking environment
2024-05-29 11:09:06,157:INFO:python_version: 3.10.13
2024-05-29 11:09:06,157:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 11:09:06,157:INFO:machine: AMD64
2024-05-29 11:09:06,157:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 11:09:06,157:INFO:Memory: svmem(total=34267656192, available=17199874048, percent=49.8, used=17067782144, free=17199874048)
2024-05-29 11:09:06,157:INFO:Physical Core: 8
2024-05-29 11:09:06,157:INFO:Logical Core: 16
2024-05-29 11:09:06,158:INFO:Checking libraries
2024-05-29 11:09:06,158:INFO:System:
2024-05-29 11:09:06,158:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 11:09:06,158:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 11:09:06,158:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 11:09:06,158:INFO:PyCaret required dependencies:
2024-05-29 11:09:06,158:INFO:                 pip: 23.3
2024-05-29 11:09:06,158:INFO:          setuptools: 68.0.0
2024-05-29 11:09:06,158:INFO:             pycaret: 3.3.2
2024-05-29 11:09:06,158:INFO:             IPython: 8.24.0
2024-05-29 11:09:06,158:INFO:          ipywidgets: 8.1.2
2024-05-29 11:09:06,159:INFO:                tqdm: 4.66.4
2024-05-29 11:09:06,159:INFO:               numpy: 1.26.4
2024-05-29 11:09:06,159:INFO:              pandas: 2.1.4
2024-05-29 11:09:06,159:INFO:              jinja2: 3.1.4
2024-05-29 11:09:06,159:INFO:               scipy: 1.11.4
2024-05-29 11:09:06,159:INFO:              joblib: 1.3.2
2024-05-29 11:09:06,159:INFO:             sklearn: 1.4.2
2024-05-29 11:09:06,159:INFO:                pyod: 1.1.3
2024-05-29 11:09:06,159:INFO:            imblearn: 0.12.2
2024-05-29 11:09:06,160:INFO:   category_encoders: 2.6.3
2024-05-29 11:09:06,160:INFO:            lightgbm: 4.3.0
2024-05-29 11:09:06,160:INFO:               numba: 0.59.1
2024-05-29 11:09:06,160:INFO:            requests: 2.32.2
2024-05-29 11:09:06,160:INFO:          matplotlib: 3.7.5
2024-05-29 11:09:06,160:INFO:          scikitplot: 0.3.7
2024-05-29 11:09:06,160:INFO:         yellowbrick: 1.5
2024-05-29 11:09:06,160:INFO:              plotly: 5.22.0
2024-05-29 11:09:06,160:INFO:    plotly-resampler: Not installed
2024-05-29 11:09:06,160:INFO:             kaleido: 0.2.1
2024-05-29 11:09:06,160:INFO:           schemdraw: 0.15
2024-05-29 11:09:06,161:INFO:         statsmodels: 0.14.2
2024-05-29 11:09:06,161:INFO:              sktime: 0.26.0
2024-05-29 11:09:06,161:INFO:               tbats: 1.1.3
2024-05-29 11:09:06,161:INFO:            pmdarima: 2.0.4
2024-05-29 11:09:06,161:INFO:              psutil: 5.9.0
2024-05-29 11:09:06,161:INFO:          markupsafe: 2.1.5
2024-05-29 11:09:06,161:INFO:             pickle5: Not installed
2024-05-29 11:09:06,161:INFO:         cloudpickle: 3.0.0
2024-05-29 11:09:06,161:INFO:         deprecation: 2.1.0
2024-05-29 11:09:06,161:INFO:              xxhash: 3.4.1
2024-05-29 11:09:06,162:INFO:           wurlitzer: Not installed
2024-05-29 11:09:06,162:INFO:PyCaret optional dependencies:
2024-05-29 11:09:06,162:INFO:                shap: Not installed
2024-05-29 11:09:06,162:INFO:           interpret: Not installed
2024-05-29 11:09:06,162:INFO:                umap: Not installed
2024-05-29 11:09:06,162:INFO:     ydata_profiling: Not installed
2024-05-29 11:09:06,162:INFO:  explainerdashboard: Not installed
2024-05-29 11:09:06,162:INFO:             autoviz: Not installed
2024-05-29 11:09:06,162:INFO:           fairlearn: Not installed
2024-05-29 11:09:06,162:INFO:          deepchecks: Not installed
2024-05-29 11:09:06,163:INFO:             xgboost: 2.0.3
2024-05-29 11:09:06,163:INFO:            catboost: Not installed
2024-05-29 11:09:06,163:INFO:              kmodes: Not installed
2024-05-29 11:09:06,163:INFO:             mlxtend: Not installed
2024-05-29 11:09:06,163:INFO:       statsforecast: Not installed
2024-05-29 11:09:06,163:INFO:        tune_sklearn: Not installed
2024-05-29 11:09:06,163:INFO:                 ray: Not installed
2024-05-29 11:09:06,163:INFO:            hyperopt: Not installed
2024-05-29 11:09:06,163:INFO:              optuna: Not installed
2024-05-29 11:09:06,163:INFO:               skopt: Not installed
2024-05-29 11:09:06,164:INFO:              mlflow: 2.13.0
2024-05-29 11:09:06,164:INFO:              gradio: Not installed
2024-05-29 11:09:06,164:INFO:             fastapi: Not installed
2024-05-29 11:09:06,164:INFO:             uvicorn: Not installed
2024-05-29 11:09:06,164:INFO:              m2cgen: Not installed
2024-05-29 11:09:06,164:INFO:           evidently: Not installed
2024-05-29 11:09:06,164:INFO:               fugue: Not installed
2024-05-29 11:09:06,164:INFO:           streamlit: Not installed
2024-05-29 11:09:06,165:INFO:             prophet: Not installed
2024-05-29 11:09:06,165:INFO:None
2024-05-29 11:09:06,165:INFO:Set up data.
2024-05-29 11:09:06,201:INFO:Set up folding strategy.
2024-05-29 11:09:06,201:INFO:Set up train/test split.
2024-05-29 11:09:06,266:INFO:Set up index.
2024-05-29 11:09:06,268:INFO:Assigning column types.
2024-05-29 11:09:06,303:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 11:09:06,374:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:09:06,375:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:09:06,419:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:09:06,423:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:09:06,495:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:09:06,496:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:09:06,541:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:09:06,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:09:06,546:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 11:09:06,619:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:09:06,663:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:09:06,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:09:06,741:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:09:06,786:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:09:06,790:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:09:06,790:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 11:09:06,909:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:09:06,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:09:07,030:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:09:07,034:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:09:07,036:INFO:Preparing preprocessing pipeline...
2024-05-29 11:09:07,042:INFO:Set up simple imputation.
2024-05-29 11:16:40,399:INFO:PyCaret ClassificationExperiment
2024-05-29 11:16:40,399:INFO:Logging name: codex
2024-05-29 11:16:40,399:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 11:16:40,399:INFO:version 3.3.2
2024-05-29 11:16:40,400:INFO:Initializing setup()
2024-05-29 11:16:40,400:INFO:self.USI: fbaa
2024-05-29 11:16:40,400:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 11:16:40,400:INFO:Checking environment
2024-05-29 11:16:40,400:INFO:python_version: 3.10.13
2024-05-29 11:16:40,400:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 11:16:40,400:INFO:machine: AMD64
2024-05-29 11:16:40,400:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 11:16:40,400:INFO:Memory: svmem(total=34267656192, available=18938941440, percent=44.7, used=15328714752, free=18938941440)
2024-05-29 11:16:40,401:INFO:Physical Core: 8
2024-05-29 11:16:40,401:INFO:Logical Core: 16
2024-05-29 11:16:40,401:INFO:Checking libraries
2024-05-29 11:16:40,401:INFO:System:
2024-05-29 11:16:40,401:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 11:16:40,401:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 11:16:40,401:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 11:16:40,401:INFO:PyCaret required dependencies:
2024-05-29 11:16:40,401:INFO:                 pip: 23.3
2024-05-29 11:16:40,401:INFO:          setuptools: 68.0.0
2024-05-29 11:16:40,402:INFO:             pycaret: 3.3.2
2024-05-29 11:16:40,402:INFO:             IPython: 8.24.0
2024-05-29 11:16:40,402:INFO:          ipywidgets: 8.1.2
2024-05-29 11:16:40,402:INFO:                tqdm: 4.66.4
2024-05-29 11:16:40,402:INFO:               numpy: 1.26.4
2024-05-29 11:16:40,402:INFO:              pandas: 2.1.4
2024-05-29 11:16:40,402:INFO:              jinja2: 3.1.4
2024-05-29 11:16:40,402:INFO:               scipy: 1.11.4
2024-05-29 11:16:40,402:INFO:              joblib: 1.3.2
2024-05-29 11:16:40,403:INFO:             sklearn: 1.4.2
2024-05-29 11:16:40,403:INFO:                pyod: 1.1.3
2024-05-29 11:16:40,403:INFO:            imblearn: 0.12.2
2024-05-29 11:16:40,403:INFO:   category_encoders: 2.6.3
2024-05-29 11:16:40,403:INFO:            lightgbm: 4.3.0
2024-05-29 11:16:40,403:INFO:               numba: 0.59.1
2024-05-29 11:16:40,403:INFO:            requests: 2.32.2
2024-05-29 11:16:40,403:INFO:          matplotlib: 3.7.5
2024-05-29 11:16:40,403:INFO:          scikitplot: 0.3.7
2024-05-29 11:16:40,403:INFO:         yellowbrick: 1.5
2024-05-29 11:16:40,404:INFO:              plotly: 5.22.0
2024-05-29 11:16:40,404:INFO:    plotly-resampler: Not installed
2024-05-29 11:16:40,404:INFO:             kaleido: 0.2.1
2024-05-29 11:16:40,404:INFO:           schemdraw: 0.15
2024-05-29 11:16:40,404:INFO:         statsmodels: 0.14.2
2024-05-29 11:16:40,404:INFO:              sktime: 0.26.0
2024-05-29 11:16:40,404:INFO:               tbats: 1.1.3
2024-05-29 11:16:40,404:INFO:            pmdarima: 2.0.4
2024-05-29 11:16:40,404:INFO:              psutil: 5.9.0
2024-05-29 11:16:40,405:INFO:          markupsafe: 2.1.5
2024-05-29 11:16:40,405:INFO:             pickle5: Not installed
2024-05-29 11:16:40,405:INFO:         cloudpickle: 3.0.0
2024-05-29 11:16:40,405:INFO:         deprecation: 2.1.0
2024-05-29 11:16:40,405:INFO:              xxhash: 3.4.1
2024-05-29 11:16:40,405:INFO:           wurlitzer: Not installed
2024-05-29 11:16:40,405:INFO:PyCaret optional dependencies:
2024-05-29 11:16:40,405:INFO:                shap: Not installed
2024-05-29 11:16:40,405:INFO:           interpret: Not installed
2024-05-29 11:16:40,406:INFO:                umap: Not installed
2024-05-29 11:16:40,406:INFO:     ydata_profiling: Not installed
2024-05-29 11:16:40,406:INFO:  explainerdashboard: Not installed
2024-05-29 11:16:40,406:INFO:             autoviz: Not installed
2024-05-29 11:16:40,407:INFO:           fairlearn: Not installed
2024-05-29 11:16:40,407:INFO:          deepchecks: Not installed
2024-05-29 11:16:40,407:INFO:             xgboost: 2.0.3
2024-05-29 11:16:40,407:INFO:            catboost: Not installed
2024-05-29 11:16:40,407:INFO:              kmodes: Not installed
2024-05-29 11:16:40,407:INFO:             mlxtend: Not installed
2024-05-29 11:16:40,407:INFO:       statsforecast: Not installed
2024-05-29 11:16:40,407:INFO:        tune_sklearn: Not installed
2024-05-29 11:16:40,407:INFO:                 ray: Not installed
2024-05-29 11:16:40,407:INFO:            hyperopt: Not installed
2024-05-29 11:16:40,407:INFO:              optuna: Not installed
2024-05-29 11:16:40,408:INFO:               skopt: Not installed
2024-05-29 11:16:40,408:INFO:              mlflow: 2.13.0
2024-05-29 11:16:40,408:INFO:              gradio: Not installed
2024-05-29 11:16:40,408:INFO:             fastapi: Not installed
2024-05-29 11:16:40,408:INFO:             uvicorn: Not installed
2024-05-29 11:16:40,408:INFO:              m2cgen: Not installed
2024-05-29 11:16:40,408:INFO:           evidently: Not installed
2024-05-29 11:16:40,408:INFO:               fugue: Not installed
2024-05-29 11:16:40,408:INFO:           streamlit: Not installed
2024-05-29 11:16:40,408:INFO:             prophet: Not installed
2024-05-29 11:16:40,408:INFO:None
2024-05-29 11:16:40,408:INFO:Set up data.
2024-05-29 11:16:40,438:INFO:Set up folding strategy.
2024-05-29 11:16:40,438:INFO:Set up train/test split.
2024-05-29 11:16:40,497:INFO:Set up index.
2024-05-29 11:16:40,499:INFO:Assigning column types.
2024-05-29 11:16:40,533:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 11:16:40,604:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:16:40,606:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:16:40,650:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:16:40,654:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:16:40,726:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:16:40,727:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:16:40,772:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:16:40,777:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:16:40,777:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 11:16:40,850:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:16:40,895:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:16:40,899:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:16:40,972:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:16:41,016:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:16:41,021:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:16:41,021:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 11:16:41,137:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:16:41,142:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:16:41,258:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:16:41,263:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:16:41,264:INFO:Preparing preprocessing pipeline...
2024-05-29 11:16:41,271:INFO:Set up simple imputation.
2024-05-29 11:17:56,615:INFO:PyCaret ClassificationExperiment
2024-05-29 11:17:56,615:INFO:Logging name: codex
2024-05-29 11:17:56,615:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 11:17:56,615:INFO:version 3.3.2
2024-05-29 11:17:56,615:INFO:Initializing setup()
2024-05-29 11:17:56,615:INFO:self.USI: 3313
2024-05-29 11:17:56,615:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 11:17:56,615:INFO:Checking environment
2024-05-29 11:17:56,616:INFO:python_version: 3.10.13
2024-05-29 11:17:56,616:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 11:17:56,616:INFO:machine: AMD64
2024-05-29 11:17:56,616:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 11:17:56,616:INFO:Memory: svmem(total=34267656192, available=18768977920, percent=45.2, used=15498678272, free=18768977920)
2024-05-29 11:17:56,616:INFO:Physical Core: 8
2024-05-29 11:17:56,616:INFO:Logical Core: 16
2024-05-29 11:17:56,616:INFO:Checking libraries
2024-05-29 11:17:56,616:INFO:System:
2024-05-29 11:17:56,616:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 11:17:56,617:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 11:17:56,617:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 11:17:56,617:INFO:PyCaret required dependencies:
2024-05-29 11:17:56,617:INFO:                 pip: 23.3
2024-05-29 11:17:56,617:INFO:          setuptools: 68.0.0
2024-05-29 11:17:56,617:INFO:             pycaret: 3.3.2
2024-05-29 11:17:56,617:INFO:             IPython: 8.24.0
2024-05-29 11:17:56,617:INFO:          ipywidgets: 8.1.2
2024-05-29 11:17:56,618:INFO:                tqdm: 4.66.4
2024-05-29 11:17:56,618:INFO:               numpy: 1.26.4
2024-05-29 11:17:56,618:INFO:              pandas: 2.1.4
2024-05-29 11:17:56,618:INFO:              jinja2: 3.1.4
2024-05-29 11:17:56,618:INFO:               scipy: 1.11.4
2024-05-29 11:17:56,618:INFO:              joblib: 1.3.2
2024-05-29 11:17:56,618:INFO:             sklearn: 1.4.2
2024-05-29 11:17:56,618:INFO:                pyod: 1.1.3
2024-05-29 11:17:56,618:INFO:            imblearn: 0.12.2
2024-05-29 11:17:56,619:INFO:   category_encoders: 2.6.3
2024-05-29 11:17:56,619:INFO:            lightgbm: 4.3.0
2024-05-29 11:17:56,619:INFO:               numba: 0.59.1
2024-05-29 11:17:56,619:INFO:            requests: 2.32.2
2024-05-29 11:17:56,619:INFO:          matplotlib: 3.7.5
2024-05-29 11:17:56,619:INFO:          scikitplot: 0.3.7
2024-05-29 11:17:56,619:INFO:         yellowbrick: 1.5
2024-05-29 11:17:56,619:INFO:              plotly: 5.22.0
2024-05-29 11:17:56,619:INFO:    plotly-resampler: Not installed
2024-05-29 11:17:56,619:INFO:             kaleido: 0.2.1
2024-05-29 11:17:56,619:INFO:           schemdraw: 0.15
2024-05-29 11:17:56,619:INFO:         statsmodels: 0.14.2
2024-05-29 11:17:56,620:INFO:              sktime: 0.26.0
2024-05-29 11:17:56,620:INFO:               tbats: 1.1.3
2024-05-29 11:17:56,620:INFO:            pmdarima: 2.0.4
2024-05-29 11:17:56,620:INFO:              psutil: 5.9.0
2024-05-29 11:17:56,620:INFO:          markupsafe: 2.1.5
2024-05-29 11:17:56,620:INFO:             pickle5: Not installed
2024-05-29 11:17:56,620:INFO:         cloudpickle: 3.0.0
2024-05-29 11:17:56,620:INFO:         deprecation: 2.1.0
2024-05-29 11:17:56,620:INFO:              xxhash: 3.4.1
2024-05-29 11:17:56,620:INFO:           wurlitzer: Not installed
2024-05-29 11:17:56,620:INFO:PyCaret optional dependencies:
2024-05-29 11:17:56,621:INFO:                shap: Not installed
2024-05-29 11:17:56,621:INFO:           interpret: Not installed
2024-05-29 11:17:56,621:INFO:                umap: Not installed
2024-05-29 11:17:56,621:INFO:     ydata_profiling: Not installed
2024-05-29 11:17:56,621:INFO:  explainerdashboard: Not installed
2024-05-29 11:17:56,621:INFO:             autoviz: Not installed
2024-05-29 11:17:56,621:INFO:           fairlearn: Not installed
2024-05-29 11:17:56,621:INFO:          deepchecks: Not installed
2024-05-29 11:17:56,621:INFO:             xgboost: 2.0.3
2024-05-29 11:17:56,621:INFO:            catboost: Not installed
2024-05-29 11:17:56,621:INFO:              kmodes: Not installed
2024-05-29 11:17:56,622:INFO:             mlxtend: Not installed
2024-05-29 11:17:56,622:INFO:       statsforecast: Not installed
2024-05-29 11:17:56,622:INFO:        tune_sklearn: Not installed
2024-05-29 11:17:56,622:INFO:                 ray: Not installed
2024-05-29 11:17:56,622:INFO:            hyperopt: Not installed
2024-05-29 11:17:56,622:INFO:              optuna: Not installed
2024-05-29 11:17:56,622:INFO:               skopt: Not installed
2024-05-29 11:17:56,622:INFO:              mlflow: 2.13.0
2024-05-29 11:17:56,622:INFO:              gradio: Not installed
2024-05-29 11:17:56,622:INFO:             fastapi: Not installed
2024-05-29 11:17:56,622:INFO:             uvicorn: Not installed
2024-05-29 11:17:56,622:INFO:              m2cgen: Not installed
2024-05-29 11:17:56,623:INFO:           evidently: Not installed
2024-05-29 11:17:56,623:INFO:               fugue: Not installed
2024-05-29 11:17:56,623:INFO:           streamlit: Not installed
2024-05-29 11:17:56,623:INFO:             prophet: Not installed
2024-05-29 11:17:56,623:INFO:None
2024-05-29 11:17:56,623:INFO:Set up data.
2024-05-29 11:17:56,654:INFO:Set up folding strategy.
2024-05-29 11:17:56,654:INFO:Set up train/test split.
2024-05-29 11:17:56,722:INFO:Set up index.
2024-05-29 11:17:56,724:INFO:Assigning column types.
2024-05-29 11:17:56,762:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 11:17:56,834:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:17:56,837:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:17:56,882:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:17:56,887:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:17:56,959:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:17:56,960:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:17:57,006:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:17:57,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:17:57,011:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 11:17:57,084:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:17:57,129:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:17:57,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:17:57,207:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:17:57,252:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:17:57,256:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:17:57,257:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 11:17:57,373:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:17:57,378:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:17:57,496:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:17:57,501:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:17:57,503:INFO:Preparing preprocessing pipeline...
2024-05-29 11:17:57,509:INFO:Set up simple imputation.
2024-05-29 11:34:06,160:INFO:PyCaret ClassificationExperiment
2024-05-29 11:34:06,161:INFO:Logging name: codex
2024-05-29 11:34:06,161:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 11:34:06,161:INFO:version 3.3.2
2024-05-29 11:34:06,161:INFO:Initializing setup()
2024-05-29 11:34:06,161:INFO:self.USI: 1899
2024-05-29 11:34:06,161:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 11:34:06,161:INFO:Checking environment
2024-05-29 11:34:06,161:INFO:python_version: 3.10.13
2024-05-29 11:34:06,161:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 11:34:06,162:INFO:machine: AMD64
2024-05-29 11:34:06,162:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 11:34:06,162:INFO:Memory: svmem(total=34267656192, available=18399637504, percent=46.3, used=15868018688, free=18399637504)
2024-05-29 11:34:06,162:INFO:Physical Core: 8
2024-05-29 11:34:06,162:INFO:Logical Core: 16
2024-05-29 11:34:06,162:INFO:Checking libraries
2024-05-29 11:34:06,162:INFO:System:
2024-05-29 11:34:06,162:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 11:34:06,162:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 11:34:06,162:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 11:34:06,162:INFO:PyCaret required dependencies:
2024-05-29 11:34:06,163:INFO:                 pip: 23.3
2024-05-29 11:34:06,163:INFO:          setuptools: 68.0.0
2024-05-29 11:34:06,163:INFO:             pycaret: 3.3.2
2024-05-29 11:34:06,163:INFO:             IPython: 8.24.0
2024-05-29 11:34:06,163:INFO:          ipywidgets: 8.1.2
2024-05-29 11:34:06,163:INFO:                tqdm: 4.66.4
2024-05-29 11:34:06,163:INFO:               numpy: 1.26.4
2024-05-29 11:34:06,163:INFO:              pandas: 2.1.4
2024-05-29 11:34:06,163:INFO:              jinja2: 3.1.4
2024-05-29 11:34:06,163:INFO:               scipy: 1.11.4
2024-05-29 11:34:06,163:INFO:              joblib: 1.3.2
2024-05-29 11:34:06,164:INFO:             sklearn: 1.4.2
2024-05-29 11:34:06,164:INFO:                pyod: 1.1.3
2024-05-29 11:34:06,164:INFO:            imblearn: 0.12.2
2024-05-29 11:34:06,164:INFO:   category_encoders: 2.6.3
2024-05-29 11:34:06,164:INFO:            lightgbm: 4.3.0
2024-05-29 11:34:06,164:INFO:               numba: 0.59.1
2024-05-29 11:34:06,164:INFO:            requests: 2.32.2
2024-05-29 11:34:06,164:INFO:          matplotlib: 3.7.5
2024-05-29 11:34:06,164:INFO:          scikitplot: 0.3.7
2024-05-29 11:34:06,164:INFO:         yellowbrick: 1.5
2024-05-29 11:34:06,164:INFO:              plotly: 5.22.0
2024-05-29 11:34:06,164:INFO:    plotly-resampler: Not installed
2024-05-29 11:34:06,165:INFO:             kaleido: 0.2.1
2024-05-29 11:34:06,165:INFO:           schemdraw: 0.15
2024-05-29 11:34:06,165:INFO:         statsmodels: 0.14.2
2024-05-29 11:34:06,165:INFO:              sktime: 0.26.0
2024-05-29 11:34:06,165:INFO:               tbats: 1.1.3
2024-05-29 11:34:06,165:INFO:            pmdarima: 2.0.4
2024-05-29 11:34:06,165:INFO:              psutil: 5.9.0
2024-05-29 11:34:06,165:INFO:          markupsafe: 2.1.5
2024-05-29 11:34:06,165:INFO:             pickle5: Not installed
2024-05-29 11:34:06,165:INFO:         cloudpickle: 3.0.0
2024-05-29 11:34:06,165:INFO:         deprecation: 2.1.0
2024-05-29 11:34:06,165:INFO:              xxhash: 3.4.1
2024-05-29 11:34:06,166:INFO:           wurlitzer: Not installed
2024-05-29 11:34:06,166:INFO:PyCaret optional dependencies:
2024-05-29 11:34:06,166:INFO:                shap: Not installed
2024-05-29 11:34:06,166:INFO:           interpret: Not installed
2024-05-29 11:34:06,166:INFO:                umap: Not installed
2024-05-29 11:34:06,166:INFO:     ydata_profiling: Not installed
2024-05-29 11:34:06,166:INFO:  explainerdashboard: Not installed
2024-05-29 11:34:06,166:INFO:             autoviz: Not installed
2024-05-29 11:34:06,166:INFO:           fairlearn: Not installed
2024-05-29 11:34:06,166:INFO:          deepchecks: Not installed
2024-05-29 11:34:06,166:INFO:             xgboost: 2.0.3
2024-05-29 11:34:06,167:INFO:            catboost: Not installed
2024-05-29 11:34:06,167:INFO:              kmodes: Not installed
2024-05-29 11:34:06,167:INFO:             mlxtend: Not installed
2024-05-29 11:34:06,167:INFO:       statsforecast: Not installed
2024-05-29 11:34:06,167:INFO:        tune_sklearn: Not installed
2024-05-29 11:34:06,167:INFO:                 ray: Not installed
2024-05-29 11:34:06,167:INFO:            hyperopt: Not installed
2024-05-29 11:34:06,167:INFO:              optuna: Not installed
2024-05-29 11:34:06,167:INFO:               skopt: Not installed
2024-05-29 11:34:06,167:INFO:              mlflow: 2.13.0
2024-05-29 11:34:06,167:INFO:              gradio: Not installed
2024-05-29 11:34:06,168:INFO:             fastapi: Not installed
2024-05-29 11:34:06,168:INFO:             uvicorn: Not installed
2024-05-29 11:34:06,168:INFO:              m2cgen: Not installed
2024-05-29 11:34:06,168:INFO:           evidently: Not installed
2024-05-29 11:34:06,168:INFO:               fugue: Not installed
2024-05-29 11:34:06,168:INFO:           streamlit: Not installed
2024-05-29 11:34:06,168:INFO:             prophet: Not installed
2024-05-29 11:34:06,168:INFO:None
2024-05-29 11:34:06,168:INFO:Set up data.
2024-05-29 11:34:06,197:INFO:Set up folding strategy.
2024-05-29 11:34:06,198:INFO:Set up train/test split.
2024-05-29 11:34:06,254:INFO:Set up index.
2024-05-29 11:34:06,256:INFO:Assigning column types.
2024-05-29 11:34:06,289:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 11:34:06,360:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:34:06,361:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:34:06,406:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:34:06,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:34:06,482:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:34:06,483:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:34:06,528:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:34:06,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:34:06,533:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 11:34:06,605:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:34:06,649:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:34:06,654:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:34:06,727:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:34:06,771:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:34:06,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:34:06,776:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 11:34:06,892:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:34:06,896:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:34:07,012:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:34:07,016:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:34:07,018:INFO:Preparing preprocessing pipeline...
2024-05-29 11:34:07,024:INFO:Set up simple imputation.
2024-05-29 11:35:02,158:INFO:PyCaret ClassificationExperiment
2024-05-29 11:35:02,159:INFO:Logging name: codex
2024-05-29 11:35:02,159:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 11:35:02,159:INFO:version 3.3.2
2024-05-29 11:35:02,159:INFO:Initializing setup()
2024-05-29 11:35:02,159:INFO:self.USI: 1817
2024-05-29 11:35:02,159:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 11:35:02,159:INFO:Checking environment
2024-05-29 11:35:02,159:INFO:python_version: 3.10.13
2024-05-29 11:35:02,159:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 11:35:02,160:INFO:machine: AMD64
2024-05-29 11:35:02,160:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 11:35:02,160:INFO:Memory: svmem(total=34267656192, available=18474737664, percent=46.1, used=15792918528, free=18474737664)
2024-05-29 11:35:02,160:INFO:Physical Core: 8
2024-05-29 11:35:02,160:INFO:Logical Core: 16
2024-05-29 11:35:02,160:INFO:Checking libraries
2024-05-29 11:35:02,160:INFO:System:
2024-05-29 11:35:02,160:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 11:35:02,160:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 11:35:02,160:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 11:35:02,160:INFO:PyCaret required dependencies:
2024-05-29 11:35:02,161:INFO:                 pip: 23.3
2024-05-29 11:35:02,161:INFO:          setuptools: 68.0.0
2024-05-29 11:35:02,161:INFO:             pycaret: 3.3.2
2024-05-29 11:35:02,161:INFO:             IPython: 8.24.0
2024-05-29 11:35:02,161:INFO:          ipywidgets: 8.1.2
2024-05-29 11:35:02,161:INFO:                tqdm: 4.66.4
2024-05-29 11:35:02,161:INFO:               numpy: 1.26.4
2024-05-29 11:35:02,161:INFO:              pandas: 2.1.4
2024-05-29 11:35:02,161:INFO:              jinja2: 3.1.4
2024-05-29 11:35:02,161:INFO:               scipy: 1.11.4
2024-05-29 11:35:02,162:INFO:              joblib: 1.3.2
2024-05-29 11:35:02,162:INFO:             sklearn: 1.4.2
2024-05-29 11:35:02,162:INFO:                pyod: 1.1.3
2024-05-29 11:35:02,162:INFO:            imblearn: 0.12.2
2024-05-29 11:35:02,162:INFO:   category_encoders: 2.6.3
2024-05-29 11:35:02,162:INFO:            lightgbm: 4.3.0
2024-05-29 11:35:02,162:INFO:               numba: 0.59.1
2024-05-29 11:35:02,162:INFO:            requests: 2.32.2
2024-05-29 11:35:02,162:INFO:          matplotlib: 3.7.5
2024-05-29 11:35:02,162:INFO:          scikitplot: 0.3.7
2024-05-29 11:35:02,162:INFO:         yellowbrick: 1.5
2024-05-29 11:35:02,163:INFO:              plotly: 5.22.0
2024-05-29 11:35:02,163:INFO:    plotly-resampler: Not installed
2024-05-29 11:35:02,163:INFO:             kaleido: 0.2.1
2024-05-29 11:35:02,163:INFO:           schemdraw: 0.15
2024-05-29 11:35:02,163:INFO:         statsmodels: 0.14.2
2024-05-29 11:35:02,163:INFO:              sktime: 0.26.0
2024-05-29 11:35:02,163:INFO:               tbats: 1.1.3
2024-05-29 11:35:02,163:INFO:            pmdarima: 2.0.4
2024-05-29 11:35:02,163:INFO:              psutil: 5.9.0
2024-05-29 11:35:02,163:INFO:          markupsafe: 2.1.5
2024-05-29 11:35:02,163:INFO:             pickle5: Not installed
2024-05-29 11:35:02,163:INFO:         cloudpickle: 3.0.0
2024-05-29 11:35:02,164:INFO:         deprecation: 2.1.0
2024-05-29 11:35:02,164:INFO:              xxhash: 3.4.1
2024-05-29 11:35:02,164:INFO:           wurlitzer: Not installed
2024-05-29 11:35:02,164:INFO:PyCaret optional dependencies:
2024-05-29 11:35:02,164:INFO:                shap: Not installed
2024-05-29 11:35:02,164:INFO:           interpret: Not installed
2024-05-29 11:35:02,164:INFO:                umap: Not installed
2024-05-29 11:35:02,164:INFO:     ydata_profiling: Not installed
2024-05-29 11:35:02,164:INFO:  explainerdashboard: Not installed
2024-05-29 11:35:02,164:INFO:             autoviz: Not installed
2024-05-29 11:35:02,165:INFO:           fairlearn: Not installed
2024-05-29 11:35:02,165:INFO:          deepchecks: Not installed
2024-05-29 11:35:02,165:INFO:             xgboost: 2.0.3
2024-05-29 11:35:02,165:INFO:            catboost: Not installed
2024-05-29 11:35:02,165:INFO:              kmodes: Not installed
2024-05-29 11:35:02,165:INFO:             mlxtend: Not installed
2024-05-29 11:35:02,165:INFO:       statsforecast: Not installed
2024-05-29 11:35:02,165:INFO:        tune_sklearn: Not installed
2024-05-29 11:35:02,165:INFO:                 ray: Not installed
2024-05-29 11:35:02,165:INFO:            hyperopt: Not installed
2024-05-29 11:35:02,165:INFO:              optuna: Not installed
2024-05-29 11:35:02,166:INFO:               skopt: Not installed
2024-05-29 11:35:02,166:INFO:              mlflow: 2.13.0
2024-05-29 11:35:02,166:INFO:              gradio: Not installed
2024-05-29 11:35:02,166:INFO:             fastapi: Not installed
2024-05-29 11:35:02,166:INFO:             uvicorn: Not installed
2024-05-29 11:35:02,166:INFO:              m2cgen: Not installed
2024-05-29 11:35:02,166:INFO:           evidently: Not installed
2024-05-29 11:35:02,166:INFO:               fugue: Not installed
2024-05-29 11:35:02,166:INFO:           streamlit: Not installed
2024-05-29 11:35:02,166:INFO:             prophet: Not installed
2024-05-29 11:35:02,166:INFO:None
2024-05-29 11:35:02,166:INFO:Set up data.
2024-05-29 11:35:02,195:INFO:Set up folding strategy.
2024-05-29 11:35:02,195:INFO:Set up train/test split.
2024-05-29 11:35:02,258:INFO:Set up index.
2024-05-29 11:35:02,260:INFO:Assigning column types.
2024-05-29 11:35:02,295:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 11:35:02,376:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:35:02,378:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:35:02,428:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:35:02,433:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:35:02,514:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:35:02,515:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:35:02,567:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:35:02,572:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:35:02,572:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 11:35:02,654:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:35:02,705:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:35:02,710:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:35:02,793:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:35:02,844:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:35:02,848:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:35:02,849:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 11:35:02,982:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:35:02,987:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:35:03,123:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:35:03,127:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:35:03,129:INFO:Preparing preprocessing pipeline...
2024-05-29 11:35:03,135:INFO:Set up simple imputation.
2024-05-29 11:35:56,155:INFO:PyCaret ClassificationExperiment
2024-05-29 11:35:56,155:INFO:Logging name: codex
2024-05-29 11:35:56,155:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 11:35:56,155:INFO:version 3.3.2
2024-05-29 11:35:56,155:INFO:Initializing setup()
2024-05-29 11:35:56,155:INFO:self.USI: 85c2
2024-05-29 11:35:56,155:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 11:35:56,155:INFO:Checking environment
2024-05-29 11:35:56,156:INFO:python_version: 3.10.13
2024-05-29 11:35:56,156:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 11:35:56,156:INFO:machine: AMD64
2024-05-29 11:35:56,156:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 11:35:56,156:INFO:Memory: svmem(total=34267656192, available=18339831808, percent=46.5, used=15927824384, free=18339831808)
2024-05-29 11:35:56,156:INFO:Physical Core: 8
2024-05-29 11:35:56,156:INFO:Logical Core: 16
2024-05-29 11:35:56,156:INFO:Checking libraries
2024-05-29 11:35:56,156:INFO:System:
2024-05-29 11:35:56,157:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 11:35:56,157:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 11:35:56,157:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 11:35:56,157:INFO:PyCaret required dependencies:
2024-05-29 11:35:56,157:INFO:                 pip: 23.3
2024-05-29 11:35:56,157:INFO:          setuptools: 68.0.0
2024-05-29 11:35:56,157:INFO:             pycaret: 3.3.2
2024-05-29 11:35:56,157:INFO:             IPython: 8.24.0
2024-05-29 11:35:56,157:INFO:          ipywidgets: 8.1.2
2024-05-29 11:35:56,157:INFO:                tqdm: 4.66.4
2024-05-29 11:35:56,158:INFO:               numpy: 1.26.4
2024-05-29 11:35:56,158:INFO:              pandas: 2.1.4
2024-05-29 11:35:56,158:INFO:              jinja2: 3.1.4
2024-05-29 11:35:56,158:INFO:               scipy: 1.11.4
2024-05-29 11:35:56,158:INFO:              joblib: 1.3.2
2024-05-29 11:35:56,158:INFO:             sklearn: 1.4.2
2024-05-29 11:35:56,158:INFO:                pyod: 1.1.3
2024-05-29 11:35:56,158:INFO:            imblearn: 0.12.2
2024-05-29 11:35:56,158:INFO:   category_encoders: 2.6.3
2024-05-29 11:35:56,158:INFO:            lightgbm: 4.3.0
2024-05-29 11:35:56,159:INFO:               numba: 0.59.1
2024-05-29 11:35:56,159:INFO:            requests: 2.32.2
2024-05-29 11:35:56,159:INFO:          matplotlib: 3.7.5
2024-05-29 11:35:56,159:INFO:          scikitplot: 0.3.7
2024-05-29 11:35:56,159:INFO:         yellowbrick: 1.5
2024-05-29 11:35:56,159:INFO:              plotly: 5.22.0
2024-05-29 11:35:56,159:INFO:    plotly-resampler: Not installed
2024-05-29 11:35:56,159:INFO:             kaleido: 0.2.1
2024-05-29 11:35:56,159:INFO:           schemdraw: 0.15
2024-05-29 11:35:56,159:INFO:         statsmodels: 0.14.2
2024-05-29 11:35:56,159:INFO:              sktime: 0.26.0
2024-05-29 11:35:56,160:INFO:               tbats: 1.1.3
2024-05-29 11:35:56,160:INFO:            pmdarima: 2.0.4
2024-05-29 11:35:56,160:INFO:              psutil: 5.9.0
2024-05-29 11:35:56,160:INFO:          markupsafe: 2.1.5
2024-05-29 11:35:56,160:INFO:             pickle5: Not installed
2024-05-29 11:35:56,160:INFO:         cloudpickle: 3.0.0
2024-05-29 11:35:56,160:INFO:         deprecation: 2.1.0
2024-05-29 11:35:56,160:INFO:              xxhash: 3.4.1
2024-05-29 11:35:56,160:INFO:           wurlitzer: Not installed
2024-05-29 11:35:56,161:INFO:PyCaret optional dependencies:
2024-05-29 11:35:56,161:INFO:                shap: Not installed
2024-05-29 11:35:56,161:INFO:           interpret: Not installed
2024-05-29 11:35:56,161:INFO:                umap: Not installed
2024-05-29 11:35:56,161:INFO:     ydata_profiling: Not installed
2024-05-29 11:35:56,161:INFO:  explainerdashboard: Not installed
2024-05-29 11:35:56,161:INFO:             autoviz: Not installed
2024-05-29 11:35:56,162:INFO:           fairlearn: Not installed
2024-05-29 11:35:56,162:INFO:          deepchecks: Not installed
2024-05-29 11:35:56,162:INFO:             xgboost: 2.0.3
2024-05-29 11:35:56,162:INFO:            catboost: Not installed
2024-05-29 11:35:56,162:INFO:              kmodes: Not installed
2024-05-29 11:35:56,162:INFO:             mlxtend: Not installed
2024-05-29 11:35:56,162:INFO:       statsforecast: Not installed
2024-05-29 11:35:56,162:INFO:        tune_sklearn: Not installed
2024-05-29 11:35:56,162:INFO:                 ray: Not installed
2024-05-29 11:35:56,163:INFO:            hyperopt: Not installed
2024-05-29 11:35:56,163:INFO:              optuna: Not installed
2024-05-29 11:35:56,163:INFO:               skopt: Not installed
2024-05-29 11:35:56,163:INFO:              mlflow: 2.13.0
2024-05-29 11:35:56,163:INFO:              gradio: Not installed
2024-05-29 11:35:56,163:INFO:             fastapi: Not installed
2024-05-29 11:35:56,163:INFO:             uvicorn: Not installed
2024-05-29 11:35:56,163:INFO:              m2cgen: Not installed
2024-05-29 11:35:56,163:INFO:           evidently: Not installed
2024-05-29 11:35:56,163:INFO:               fugue: Not installed
2024-05-29 11:35:56,163:INFO:           streamlit: Not installed
2024-05-29 11:35:56,163:INFO:             prophet: Not installed
2024-05-29 11:35:56,164:INFO:None
2024-05-29 11:35:56,164:INFO:Set up data.
2024-05-29 11:35:56,196:INFO:Set up folding strategy.
2024-05-29 11:35:56,197:INFO:Set up train/test split.
2024-05-29 11:35:56,257:INFO:Set up index.
2024-05-29 11:35:56,260:INFO:Assigning column types.
2024-05-29 11:35:56,303:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 11:35:56,374:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:35:56,376:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:35:56,420:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:35:56,424:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:35:56,496:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:35:56,497:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:35:56,542:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:35:56,547:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:35:56,547:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 11:35:56,620:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:35:56,665:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:35:56,669:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:35:56,743:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:35:56,788:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:35:56,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:35:56,793:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 11:35:56,910:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:35:56,915:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:35:57,031:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:35:57,036:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:35:57,037:INFO:Preparing preprocessing pipeline...
2024-05-29 11:35:57,044:INFO:Set up simple imputation.
2024-05-29 11:35:57,044:INFO:Set up column transformation.
2024-05-29 11:35:57,044:INFO:Set up feature normalization.
2024-05-29 11:36:27,132:INFO:PyCaret ClassificationExperiment
2024-05-29 11:36:27,132:INFO:Logging name: codex
2024-05-29 11:36:27,132:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 11:36:27,132:INFO:version 3.3.2
2024-05-29 11:36:27,133:INFO:Initializing setup()
2024-05-29 11:36:27,133:INFO:self.USI: b33b
2024-05-29 11:36:27,133:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 11:36:27,133:INFO:Checking environment
2024-05-29 11:36:27,133:INFO:python_version: 3.10.13
2024-05-29 11:36:27,133:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 11:36:27,133:INFO:machine: AMD64
2024-05-29 11:36:27,133:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 11:36:27,133:INFO:Memory: svmem(total=34267656192, available=18162831360, percent=47.0, used=16104824832, free=18162831360)
2024-05-29 11:36:27,133:INFO:Physical Core: 8
2024-05-29 11:36:27,134:INFO:Logical Core: 16
2024-05-29 11:36:27,134:INFO:Checking libraries
2024-05-29 11:36:27,134:INFO:System:
2024-05-29 11:36:27,134:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 11:36:27,134:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 11:36:27,134:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 11:36:27,134:INFO:PyCaret required dependencies:
2024-05-29 11:36:27,134:INFO:                 pip: 23.3
2024-05-29 11:36:27,134:INFO:          setuptools: 68.0.0
2024-05-29 11:36:27,134:INFO:             pycaret: 3.3.2
2024-05-29 11:36:27,135:INFO:             IPython: 8.24.0
2024-05-29 11:36:27,135:INFO:          ipywidgets: 8.1.2
2024-05-29 11:36:27,135:INFO:                tqdm: 4.66.4
2024-05-29 11:36:27,135:INFO:               numpy: 1.26.4
2024-05-29 11:36:27,135:INFO:              pandas: 2.1.4
2024-05-29 11:36:27,135:INFO:              jinja2: 3.1.4
2024-05-29 11:36:27,135:INFO:               scipy: 1.11.4
2024-05-29 11:36:27,135:INFO:              joblib: 1.3.2
2024-05-29 11:36:27,135:INFO:             sklearn: 1.4.2
2024-05-29 11:36:27,135:INFO:                pyod: 1.1.3
2024-05-29 11:36:27,135:INFO:            imblearn: 0.12.2
2024-05-29 11:36:27,136:INFO:   category_encoders: 2.6.3
2024-05-29 11:36:27,136:INFO:            lightgbm: 4.3.0
2024-05-29 11:36:27,136:INFO:               numba: 0.59.1
2024-05-29 11:36:27,136:INFO:            requests: 2.32.2
2024-05-29 11:36:27,136:INFO:          matplotlib: 3.7.5
2024-05-29 11:36:27,136:INFO:          scikitplot: 0.3.7
2024-05-29 11:36:27,136:INFO:         yellowbrick: 1.5
2024-05-29 11:36:27,136:INFO:              plotly: 5.22.0
2024-05-29 11:36:27,136:INFO:    plotly-resampler: Not installed
2024-05-29 11:36:27,136:INFO:             kaleido: 0.2.1
2024-05-29 11:36:27,136:INFO:           schemdraw: 0.15
2024-05-29 11:36:27,137:INFO:         statsmodels: 0.14.2
2024-05-29 11:36:27,137:INFO:              sktime: 0.26.0
2024-05-29 11:36:27,137:INFO:               tbats: 1.1.3
2024-05-29 11:36:27,137:INFO:            pmdarima: 2.0.4
2024-05-29 11:36:27,137:INFO:              psutil: 5.9.0
2024-05-29 11:36:27,137:INFO:          markupsafe: 2.1.5
2024-05-29 11:36:27,137:INFO:             pickle5: Not installed
2024-05-29 11:36:27,137:INFO:         cloudpickle: 3.0.0
2024-05-29 11:36:27,137:INFO:         deprecation: 2.1.0
2024-05-29 11:36:27,137:INFO:              xxhash: 3.4.1
2024-05-29 11:36:27,137:INFO:           wurlitzer: Not installed
2024-05-29 11:36:27,138:INFO:PyCaret optional dependencies:
2024-05-29 11:36:27,138:INFO:                shap: Not installed
2024-05-29 11:36:27,138:INFO:           interpret: Not installed
2024-05-29 11:36:27,138:INFO:                umap: Not installed
2024-05-29 11:36:27,138:INFO:     ydata_profiling: Not installed
2024-05-29 11:36:27,138:INFO:  explainerdashboard: Not installed
2024-05-29 11:36:27,138:INFO:             autoviz: Not installed
2024-05-29 11:36:27,138:INFO:           fairlearn: Not installed
2024-05-29 11:36:27,138:INFO:          deepchecks: Not installed
2024-05-29 11:36:27,138:INFO:             xgboost: 2.0.3
2024-05-29 11:36:27,138:INFO:            catboost: Not installed
2024-05-29 11:36:27,139:INFO:              kmodes: Not installed
2024-05-29 11:36:27,139:INFO:             mlxtend: Not installed
2024-05-29 11:36:27,139:INFO:       statsforecast: Not installed
2024-05-29 11:36:27,139:INFO:        tune_sklearn: Not installed
2024-05-29 11:36:27,139:INFO:                 ray: Not installed
2024-05-29 11:36:27,139:INFO:            hyperopt: Not installed
2024-05-29 11:36:27,139:INFO:              optuna: Not installed
2024-05-29 11:36:27,139:INFO:               skopt: Not installed
2024-05-29 11:36:27,139:INFO:              mlflow: 2.13.0
2024-05-29 11:36:27,139:INFO:              gradio: Not installed
2024-05-29 11:36:27,140:INFO:             fastapi: Not installed
2024-05-29 11:36:27,140:INFO:             uvicorn: Not installed
2024-05-29 11:36:27,140:INFO:              m2cgen: Not installed
2024-05-29 11:36:27,140:INFO:           evidently: Not installed
2024-05-29 11:36:27,140:INFO:               fugue: Not installed
2024-05-29 11:36:27,140:INFO:           streamlit: Not installed
2024-05-29 11:36:27,140:INFO:             prophet: Not installed
2024-05-29 11:36:27,140:INFO:None
2024-05-29 11:36:27,140:INFO:Set up data.
2024-05-29 11:36:27,171:INFO:Set up folding strategy.
2024-05-29 11:36:27,171:INFO:Set up train/test split.
2024-05-29 11:36:27,235:INFO:Set up index.
2024-05-29 11:36:27,237:INFO:Assigning column types.
2024-05-29 11:36:27,278:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 11:36:27,350:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:36:27,351:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:36:27,396:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:36:27,400:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:36:27,471:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:36:27,472:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:36:27,517:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:36:27,521:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:36:27,522:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 11:36:27,595:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:36:27,639:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:36:27,644:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:36:27,717:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:36:27,761:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:36:27,766:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:36:27,766:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 11:36:27,887:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:36:27,891:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:36:28,007:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:36:28,012:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:36:28,013:INFO:Preparing preprocessing pipeline...
2024-05-29 11:36:28,020:INFO:Set up simple imputation.
2024-05-29 11:36:28,020:INFO:Set up column transformation.
2024-05-29 11:36:28,020:INFO:Set up feature normalization.
2024-05-29 11:37:13,169:INFO:PyCaret ClassificationExperiment
2024-05-29 11:37:13,169:INFO:Logging name: codex
2024-05-29 11:37:13,170:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 11:37:13,170:INFO:version 3.3.2
2024-05-29 11:37:13,170:INFO:Initializing setup()
2024-05-29 11:37:13,170:INFO:self.USI: 7d31
2024-05-29 11:37:13,170:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 11:37:13,170:INFO:Checking environment
2024-05-29 11:37:13,170:INFO:python_version: 3.10.13
2024-05-29 11:37:13,171:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 11:37:13,171:INFO:machine: AMD64
2024-05-29 11:37:13,171:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 11:37:13,171:INFO:Memory: svmem(total=34267656192, available=18125062144, percent=47.1, used=16142594048, free=18125062144)
2024-05-29 11:37:13,171:INFO:Physical Core: 8
2024-05-29 11:37:13,171:INFO:Logical Core: 16
2024-05-29 11:37:13,172:INFO:Checking libraries
2024-05-29 11:37:13,172:INFO:System:
2024-05-29 11:37:13,172:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 11:37:13,172:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 11:37:13,172:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 11:37:13,172:INFO:PyCaret required dependencies:
2024-05-29 11:37:13,173:INFO:                 pip: 23.3
2024-05-29 11:37:13,173:INFO:          setuptools: 68.0.0
2024-05-29 11:37:13,173:INFO:             pycaret: 3.3.2
2024-05-29 11:37:13,173:INFO:             IPython: 8.24.0
2024-05-29 11:37:13,173:INFO:          ipywidgets: 8.1.2
2024-05-29 11:37:13,174:INFO:                tqdm: 4.66.4
2024-05-29 11:37:13,174:INFO:               numpy: 1.26.4
2024-05-29 11:37:13,174:INFO:              pandas: 2.1.4
2024-05-29 11:37:13,174:INFO:              jinja2: 3.1.4
2024-05-29 11:37:13,174:INFO:               scipy: 1.11.4
2024-05-29 11:37:13,174:INFO:              joblib: 1.3.2
2024-05-29 11:37:13,174:INFO:             sklearn: 1.4.2
2024-05-29 11:37:13,175:INFO:                pyod: 1.1.3
2024-05-29 11:37:13,175:INFO:            imblearn: 0.12.2
2024-05-29 11:37:13,175:INFO:   category_encoders: 2.6.3
2024-05-29 11:37:13,175:INFO:            lightgbm: 4.3.0
2024-05-29 11:37:13,175:INFO:               numba: 0.59.1
2024-05-29 11:37:13,175:INFO:            requests: 2.32.2
2024-05-29 11:37:13,175:INFO:          matplotlib: 3.7.5
2024-05-29 11:37:13,176:INFO:          scikitplot: 0.3.7
2024-05-29 11:37:13,176:INFO:         yellowbrick: 1.5
2024-05-29 11:37:13,176:INFO:              plotly: 5.22.0
2024-05-29 11:37:13,176:INFO:    plotly-resampler: Not installed
2024-05-29 11:37:13,176:INFO:             kaleido: 0.2.1
2024-05-29 11:37:13,176:INFO:           schemdraw: 0.15
2024-05-29 11:37:13,176:INFO:         statsmodels: 0.14.2
2024-05-29 11:37:13,176:INFO:              sktime: 0.26.0
2024-05-29 11:37:13,177:INFO:               tbats: 1.1.3
2024-05-29 11:37:13,177:INFO:            pmdarima: 2.0.4
2024-05-29 11:37:13,177:INFO:              psutil: 5.9.0
2024-05-29 11:37:13,177:INFO:          markupsafe: 2.1.5
2024-05-29 11:37:13,177:INFO:             pickle5: Not installed
2024-05-29 11:37:13,177:INFO:         cloudpickle: 3.0.0
2024-05-29 11:37:13,177:INFO:         deprecation: 2.1.0
2024-05-29 11:37:13,178:INFO:              xxhash: 3.4.1
2024-05-29 11:37:13,178:INFO:           wurlitzer: Not installed
2024-05-29 11:37:13,178:INFO:PyCaret optional dependencies:
2024-05-29 11:37:13,178:INFO:                shap: Not installed
2024-05-29 11:37:13,178:INFO:           interpret: Not installed
2024-05-29 11:37:13,179:INFO:                umap: Not installed
2024-05-29 11:37:13,179:INFO:     ydata_profiling: Not installed
2024-05-29 11:37:13,179:INFO:  explainerdashboard: Not installed
2024-05-29 11:37:13,179:INFO:             autoviz: Not installed
2024-05-29 11:37:13,179:INFO:           fairlearn: Not installed
2024-05-29 11:37:13,179:INFO:          deepchecks: Not installed
2024-05-29 11:37:13,180:INFO:             xgboost: 2.0.3
2024-05-29 11:37:13,180:INFO:            catboost: Not installed
2024-05-29 11:37:13,180:INFO:              kmodes: Not installed
2024-05-29 11:37:13,180:INFO:             mlxtend: Not installed
2024-05-29 11:37:13,180:INFO:       statsforecast: Not installed
2024-05-29 11:37:13,180:INFO:        tune_sklearn: Not installed
2024-05-29 11:37:13,181:INFO:                 ray: Not installed
2024-05-29 11:37:13,181:INFO:            hyperopt: Not installed
2024-05-29 11:37:13,181:INFO:              optuna: Not installed
2024-05-29 11:37:13,181:INFO:               skopt: Not installed
2024-05-29 11:37:13,181:INFO:              mlflow: 2.13.0
2024-05-29 11:37:13,181:INFO:              gradio: Not installed
2024-05-29 11:37:13,181:INFO:             fastapi: Not installed
2024-05-29 11:37:13,181:INFO:             uvicorn: Not installed
2024-05-29 11:37:13,182:INFO:              m2cgen: Not installed
2024-05-29 11:37:13,182:INFO:           evidently: Not installed
2024-05-29 11:37:13,182:INFO:               fugue: Not installed
2024-05-29 11:37:13,182:INFO:           streamlit: Not installed
2024-05-29 11:37:13,182:INFO:             prophet: Not installed
2024-05-29 11:37:13,182:INFO:None
2024-05-29 11:37:13,182:INFO:Set up data.
2024-05-29 11:37:13,241:INFO:Set up folding strategy.
2024-05-29 11:37:13,241:INFO:Set up train/test split.
2024-05-29 11:37:13,324:INFO:Set up index.
2024-05-29 11:37:13,327:INFO:Assigning column types.
2024-05-29 11:37:13,369:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 11:37:13,452:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:37:13,453:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:37:13,504:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:37:13,509:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:37:13,592:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:37:13,593:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:37:13,644:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:37:13,649:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:37:13,650:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 11:37:13,735:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:37:13,786:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:37:13,791:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:37:13,875:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:37:13,926:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:37:13,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:37:13,931:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 11:37:14,065:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:37:14,070:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:37:14,205:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:37:14,210:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:37:14,212:INFO:Preparing preprocessing pipeline...
2024-05-29 11:37:14,219:INFO:Set up simple imputation.
2024-05-29 11:37:14,219:INFO:Set up column transformation.
2024-05-29 11:37:25,165:INFO:PyCaret ClassificationExperiment
2024-05-29 11:37:25,166:INFO:Logging name: codex
2024-05-29 11:37:25,166:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 11:37:25,166:INFO:version 3.3.2
2024-05-29 11:37:25,166:INFO:Initializing setup()
2024-05-29 11:37:25,166:INFO:self.USI: 4d67
2024-05-29 11:37:25,166:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 11:37:25,167:INFO:Checking environment
2024-05-29 11:37:25,167:INFO:python_version: 3.10.13
2024-05-29 11:37:25,167:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 11:37:25,167:INFO:machine: AMD64
2024-05-29 11:37:25,167:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 11:37:25,167:INFO:Memory: svmem(total=34267656192, available=18144411648, percent=47.1, used=16123244544, free=18144411648)
2024-05-29 11:37:25,167:INFO:Physical Core: 8
2024-05-29 11:37:25,167:INFO:Logical Core: 16
2024-05-29 11:37:25,168:INFO:Checking libraries
2024-05-29 11:37:25,168:INFO:System:
2024-05-29 11:37:25,168:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 11:37:25,168:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 11:37:25,168:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 11:37:25,168:INFO:PyCaret required dependencies:
2024-05-29 11:37:25,169:INFO:                 pip: 23.3
2024-05-29 11:37:25,169:INFO:          setuptools: 68.0.0
2024-05-29 11:37:25,169:INFO:             pycaret: 3.3.2
2024-05-29 11:37:25,169:INFO:             IPython: 8.24.0
2024-05-29 11:37:25,169:INFO:          ipywidgets: 8.1.2
2024-05-29 11:37:25,169:INFO:                tqdm: 4.66.4
2024-05-29 11:37:25,169:INFO:               numpy: 1.26.4
2024-05-29 11:37:25,169:INFO:              pandas: 2.1.4
2024-05-29 11:37:25,170:INFO:              jinja2: 3.1.4
2024-05-29 11:37:25,170:INFO:               scipy: 1.11.4
2024-05-29 11:37:25,170:INFO:              joblib: 1.3.2
2024-05-29 11:37:25,170:INFO:             sklearn: 1.4.2
2024-05-29 11:37:25,170:INFO:                pyod: 1.1.3
2024-05-29 11:37:25,170:INFO:            imblearn: 0.12.2
2024-05-29 11:37:25,170:INFO:   category_encoders: 2.6.3
2024-05-29 11:37:25,170:INFO:            lightgbm: 4.3.0
2024-05-29 11:37:25,171:INFO:               numba: 0.59.1
2024-05-29 11:37:25,171:INFO:            requests: 2.32.2
2024-05-29 11:37:25,171:INFO:          matplotlib: 3.7.5
2024-05-29 11:37:25,171:INFO:          scikitplot: 0.3.7
2024-05-29 11:37:25,171:INFO:         yellowbrick: 1.5
2024-05-29 11:37:25,171:INFO:              plotly: 5.22.0
2024-05-29 11:37:25,171:INFO:    plotly-resampler: Not installed
2024-05-29 11:37:25,171:INFO:             kaleido: 0.2.1
2024-05-29 11:37:25,171:INFO:           schemdraw: 0.15
2024-05-29 11:37:25,172:INFO:         statsmodels: 0.14.2
2024-05-29 11:37:25,172:INFO:              sktime: 0.26.0
2024-05-29 11:37:25,172:INFO:               tbats: 1.1.3
2024-05-29 11:37:25,172:INFO:            pmdarima: 2.0.4
2024-05-29 11:37:25,172:INFO:              psutil: 5.9.0
2024-05-29 11:37:25,172:INFO:          markupsafe: 2.1.5
2024-05-29 11:37:25,172:INFO:             pickle5: Not installed
2024-05-29 11:37:25,172:INFO:         cloudpickle: 3.0.0
2024-05-29 11:37:25,173:INFO:         deprecation: 2.1.0
2024-05-29 11:37:25,173:INFO:              xxhash: 3.4.1
2024-05-29 11:37:25,173:INFO:           wurlitzer: Not installed
2024-05-29 11:37:25,173:INFO:PyCaret optional dependencies:
2024-05-29 11:37:25,173:INFO:                shap: Not installed
2024-05-29 11:37:25,173:INFO:           interpret: Not installed
2024-05-29 11:37:25,173:INFO:                umap: Not installed
2024-05-29 11:37:25,174:INFO:     ydata_profiling: Not installed
2024-05-29 11:37:25,174:INFO:  explainerdashboard: Not installed
2024-05-29 11:37:25,174:INFO:             autoviz: Not installed
2024-05-29 11:37:25,174:INFO:           fairlearn: Not installed
2024-05-29 11:37:25,174:INFO:          deepchecks: Not installed
2024-05-29 11:37:25,174:INFO:             xgboost: 2.0.3
2024-05-29 11:37:25,174:INFO:            catboost: Not installed
2024-05-29 11:37:25,174:INFO:              kmodes: Not installed
2024-05-29 11:37:25,174:INFO:             mlxtend: Not installed
2024-05-29 11:37:25,175:INFO:       statsforecast: Not installed
2024-05-29 11:37:25,175:INFO:        tune_sklearn: Not installed
2024-05-29 11:37:25,175:INFO:                 ray: Not installed
2024-05-29 11:37:25,175:INFO:            hyperopt: Not installed
2024-05-29 11:37:25,175:INFO:              optuna: Not installed
2024-05-29 11:37:25,175:INFO:               skopt: Not installed
2024-05-29 11:37:25,175:INFO:              mlflow: 2.13.0
2024-05-29 11:37:25,175:INFO:              gradio: Not installed
2024-05-29 11:37:25,176:INFO:             fastapi: Not installed
2024-05-29 11:37:25,176:INFO:             uvicorn: Not installed
2024-05-29 11:37:25,176:INFO:              m2cgen: Not installed
2024-05-29 11:37:25,176:INFO:           evidently: Not installed
2024-05-29 11:37:25,176:INFO:               fugue: Not installed
2024-05-29 11:37:25,176:INFO:           streamlit: Not installed
2024-05-29 11:37:25,176:INFO:             prophet: Not installed
2024-05-29 11:37:25,176:INFO:None
2024-05-29 11:37:25,177:INFO:Set up data.
2024-05-29 11:37:25,219:INFO:Set up folding strategy.
2024-05-29 11:37:25,220:INFO:Set up train/test split.
2024-05-29 11:37:25,284:INFO:Set up index.
2024-05-29 11:37:25,286:INFO:Assigning column types.
2024-05-29 11:37:25,327:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 11:37:25,399:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:37:25,401:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:37:25,445:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:37:25,449:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:37:25,521:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:37:25,522:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:37:25,568:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:37:25,572:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:37:25,572:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 11:37:25,645:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:37:25,689:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:37:25,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:37:25,768:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:37:25,818:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:37:25,823:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:37:25,823:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 11:37:25,944:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:37:25,948:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:37:26,066:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:37:26,070:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:37:26,072:INFO:Preparing preprocessing pipeline...
2024-05-29 11:37:26,078:INFO:Set up simple imputation.
2024-05-29 11:37:45,121:INFO:PyCaret ClassificationExperiment
2024-05-29 11:37:45,121:INFO:Logging name: codex
2024-05-29 11:37:45,121:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 11:37:45,121:INFO:version 3.3.2
2024-05-29 11:37:45,121:INFO:Initializing setup()
2024-05-29 11:37:45,121:INFO:self.USI: c08b
2024-05-29 11:37:45,121:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y_test', 'exp_id', 'X_test', 'X_train', '_available_plots', 'gpu_n_jobs_param', 'data', 'html_param', 'exp_name_log', 'y', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'gpu_param', 'target_param', 'fold_generator', 'USI', 'pipeline', 'idx', 'X', 'fold_groups_param', 'n_jobs_param', 'y_train', 'seed', 'logging_param', 'fold_shuffle_param'}
2024-05-29 11:37:45,122:INFO:Checking environment
2024-05-29 11:37:45,122:INFO:python_version: 3.10.13
2024-05-29 11:37:45,122:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 11:37:45,122:INFO:machine: AMD64
2024-05-29 11:37:45,122:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 11:37:45,122:INFO:Memory: svmem(total=34267656192, available=18129580032, percent=47.1, used=16138076160, free=18129580032)
2024-05-29 11:37:45,122:INFO:Physical Core: 8
2024-05-29 11:37:45,122:INFO:Logical Core: 16
2024-05-29 11:37:45,123:INFO:Checking libraries
2024-05-29 11:37:45,123:INFO:System:
2024-05-29 11:37:45,123:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 11:37:45,123:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 11:37:45,123:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 11:37:45,123:INFO:PyCaret required dependencies:
2024-05-29 11:37:45,123:INFO:                 pip: 23.3
2024-05-29 11:37:45,123:INFO:          setuptools: 68.0.0
2024-05-29 11:37:45,123:INFO:             pycaret: 3.3.2
2024-05-29 11:37:45,123:INFO:             IPython: 8.24.0
2024-05-29 11:37:45,124:INFO:          ipywidgets: 8.1.2
2024-05-29 11:37:45,124:INFO:                tqdm: 4.66.4
2024-05-29 11:37:45,124:INFO:               numpy: 1.26.4
2024-05-29 11:37:45,124:INFO:              pandas: 2.1.4
2024-05-29 11:37:45,124:INFO:              jinja2: 3.1.4
2024-05-29 11:37:45,124:INFO:               scipy: 1.11.4
2024-05-29 11:37:45,124:INFO:              joblib: 1.3.2
2024-05-29 11:37:45,124:INFO:             sklearn: 1.4.2
2024-05-29 11:37:45,124:INFO:                pyod: 1.1.3
2024-05-29 11:37:45,124:INFO:            imblearn: 0.12.2
2024-05-29 11:37:45,124:INFO:   category_encoders: 2.6.3
2024-05-29 11:37:45,125:INFO:            lightgbm: 4.3.0
2024-05-29 11:37:45,125:INFO:               numba: 0.59.1
2024-05-29 11:37:45,125:INFO:            requests: 2.32.2
2024-05-29 11:37:45,125:INFO:          matplotlib: 3.7.5
2024-05-29 11:37:45,125:INFO:          scikitplot: 0.3.7
2024-05-29 11:37:45,125:INFO:         yellowbrick: 1.5
2024-05-29 11:37:45,125:INFO:              plotly: 5.22.0
2024-05-29 11:37:45,125:INFO:    plotly-resampler: Not installed
2024-05-29 11:37:45,125:INFO:             kaleido: 0.2.1
2024-05-29 11:37:45,125:INFO:           schemdraw: 0.15
2024-05-29 11:37:45,125:INFO:         statsmodels: 0.14.2
2024-05-29 11:37:45,125:INFO:              sktime: 0.26.0
2024-05-29 11:37:45,126:INFO:               tbats: 1.1.3
2024-05-29 11:37:45,126:INFO:            pmdarima: 2.0.4
2024-05-29 11:37:45,126:INFO:              psutil: 5.9.0
2024-05-29 11:37:45,126:INFO:          markupsafe: 2.1.5
2024-05-29 11:37:45,126:INFO:             pickle5: Not installed
2024-05-29 11:37:45,126:INFO:         cloudpickle: 3.0.0
2024-05-29 11:37:45,126:INFO:         deprecation: 2.1.0
2024-05-29 11:37:45,126:INFO:              xxhash: 3.4.1
2024-05-29 11:37:45,126:INFO:           wurlitzer: Not installed
2024-05-29 11:37:45,126:INFO:PyCaret optional dependencies:
2024-05-29 11:37:45,127:INFO:                shap: Not installed
2024-05-29 11:37:45,127:INFO:           interpret: Not installed
2024-05-29 11:37:45,127:INFO:                umap: Not installed
2024-05-29 11:37:45,127:INFO:     ydata_profiling: Not installed
2024-05-29 11:37:45,127:INFO:  explainerdashboard: Not installed
2024-05-29 11:37:45,127:INFO:             autoviz: Not installed
2024-05-29 11:37:45,127:INFO:           fairlearn: Not installed
2024-05-29 11:37:45,127:INFO:          deepchecks: Not installed
2024-05-29 11:37:45,127:INFO:             xgboost: 2.0.3
2024-05-29 11:37:45,127:INFO:            catboost: Not installed
2024-05-29 11:37:45,127:INFO:              kmodes: Not installed
2024-05-29 11:37:45,128:INFO:             mlxtend: Not installed
2024-05-29 11:37:45,128:INFO:       statsforecast: Not installed
2024-05-29 11:37:45,128:INFO:        tune_sklearn: Not installed
2024-05-29 11:37:45,128:INFO:                 ray: Not installed
2024-05-29 11:37:45,128:INFO:            hyperopt: Not installed
2024-05-29 11:37:45,128:INFO:              optuna: Not installed
2024-05-29 11:37:45,128:INFO:               skopt: Not installed
2024-05-29 11:37:45,128:INFO:              mlflow: 2.13.0
2024-05-29 11:37:45,128:INFO:              gradio: Not installed
2024-05-29 11:37:45,129:INFO:             fastapi: Not installed
2024-05-29 11:37:45,129:INFO:             uvicorn: Not installed
2024-05-29 11:37:45,129:INFO:              m2cgen: Not installed
2024-05-29 11:37:45,129:INFO:           evidently: Not installed
2024-05-29 11:37:45,129:INFO:               fugue: Not installed
2024-05-29 11:37:45,129:INFO:           streamlit: Not installed
2024-05-29 11:37:45,129:INFO:             prophet: Not installed
2024-05-29 11:37:45,129:INFO:None
2024-05-29 11:37:45,129:INFO:Set up data.
2024-05-29 11:37:45,161:INFO:Set up folding strategy.
2024-05-29 11:37:45,161:INFO:Set up train/test split.
2024-05-29 11:37:45,230:INFO:Set up index.
2024-05-29 11:37:45,232:INFO:Assigning column types.
2024-05-29 11:37:45,273:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 11:37:45,345:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:37:45,346:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:37:45,391:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:37:45,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:37:45,467:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:37:45,468:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:37:45,513:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:37:45,518:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:37:45,518:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 11:37:45,591:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:37:45,636:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:37:45,640:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:37:45,713:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:37:45,758:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:37:45,762:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:37:45,763:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 11:37:45,879:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:37:45,884:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:37:46,002:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:37:46,006:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:37:46,008:INFO:Preparing preprocessing pipeline...
2024-05-29 11:37:46,019:INFO:Set up simple imputation.
2024-05-29 11:37:46,019:INFO:Set up feature normalization.
2024-05-29 11:41:37,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-29 11:41:37,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-29 11:41:37,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-29 11:41:37,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-29 11:47:16,535:INFO:PyCaret ClassificationExperiment
2024-05-29 11:47:16,535:INFO:Logging name: codex
2024-05-29 11:47:16,535:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 11:47:16,536:INFO:version 3.3.2
2024-05-29 11:47:16,536:INFO:Initializing setup()
2024-05-29 11:47:16,536:INFO:self.USI: f870
2024-05-29 11:47:16,536:INFO:self._variable_keys: {'logging_param', 'fold_shuffle_param', 'fix_imbalance', 'USI', 'log_plots_param', 'idx', 'X', 'is_multiclass', 'exp_name_log', 'fold_groups_param', 'y_train', 'gpu_n_jobs_param', 'n_jobs_param', 'memory', 'target_param', 'y', '_available_plots', '_ml_usecase', 'X_test', 'y_test', 'X_train', 'html_param', 'gpu_param', 'fold_generator', 'data', 'seed', 'exp_id', 'pipeline'}
2024-05-29 11:47:16,536:INFO:Checking environment
2024-05-29 11:47:16,536:INFO:python_version: 3.10.13
2024-05-29 11:47:16,536:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 11:47:16,536:INFO:machine: AMD64
2024-05-29 11:47:16,536:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 11:47:16,536:INFO:Memory: svmem(total=34267656192, available=18980200448, percent=44.6, used=15287455744, free=18980200448)
2024-05-29 11:47:16,536:INFO:Physical Core: 8
2024-05-29 11:47:16,537:INFO:Logical Core: 16
2024-05-29 11:47:16,537:INFO:Checking libraries
2024-05-29 11:47:16,537:INFO:System:
2024-05-29 11:47:16,537:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 11:47:16,537:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 11:47:16,537:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 11:47:16,537:INFO:PyCaret required dependencies:
2024-05-29 11:47:16,573:INFO:                 pip: 23.3
2024-05-29 11:47:16,573:INFO:          setuptools: 68.0.0
2024-05-29 11:47:16,573:INFO:             pycaret: 3.3.2
2024-05-29 11:47:16,573:INFO:             IPython: 8.24.0
2024-05-29 11:47:16,573:INFO:          ipywidgets: 8.1.2
2024-05-29 11:47:16,573:INFO:                tqdm: 4.66.4
2024-05-29 11:47:16,573:INFO:               numpy: 1.26.4
2024-05-29 11:47:16,574:INFO:              pandas: 2.1.4
2024-05-29 11:47:16,574:INFO:              jinja2: 3.1.4
2024-05-29 11:47:16,574:INFO:               scipy: 1.11.4
2024-05-29 11:47:16,574:INFO:              joblib: 1.3.2
2024-05-29 11:47:16,574:INFO:             sklearn: 1.4.2
2024-05-29 11:47:16,574:INFO:                pyod: 1.1.3
2024-05-29 11:47:16,574:INFO:            imblearn: 0.12.2
2024-05-29 11:47:16,574:INFO:   category_encoders: 2.6.3
2024-05-29 11:47:16,574:INFO:            lightgbm: 4.3.0
2024-05-29 11:47:16,574:INFO:               numba: 0.59.1
2024-05-29 11:47:16,574:INFO:            requests: 2.32.2
2024-05-29 11:47:16,574:INFO:          matplotlib: 3.7.5
2024-05-29 11:47:16,574:INFO:          scikitplot: 0.3.7
2024-05-29 11:47:16,575:INFO:         yellowbrick: 1.5
2024-05-29 11:47:16,575:INFO:              plotly: 5.22.0
2024-05-29 11:47:16,575:INFO:    plotly-resampler: Not installed
2024-05-29 11:47:16,575:INFO:             kaleido: 0.2.1
2024-05-29 11:47:16,575:INFO:           schemdraw: 0.15
2024-05-29 11:47:16,575:INFO:         statsmodels: 0.14.2
2024-05-29 11:47:16,575:INFO:              sktime: 0.26.0
2024-05-29 11:47:16,575:INFO:               tbats: 1.1.3
2024-05-29 11:47:16,575:INFO:            pmdarima: 2.0.4
2024-05-29 11:47:16,575:INFO:              psutil: 5.9.0
2024-05-29 11:47:16,575:INFO:          markupsafe: 2.1.5
2024-05-29 11:47:16,575:INFO:             pickle5: Not installed
2024-05-29 11:47:16,576:INFO:         cloudpickle: 3.0.0
2024-05-29 11:47:16,576:INFO:         deprecation: 2.1.0
2024-05-29 11:47:16,576:INFO:              xxhash: 3.4.1
2024-05-29 11:47:16,576:INFO:           wurlitzer: Not installed
2024-05-29 11:47:16,576:INFO:PyCaret optional dependencies:
2024-05-29 11:47:16,601:INFO:                shap: Not installed
2024-05-29 11:47:16,601:INFO:           interpret: Not installed
2024-05-29 11:47:16,601:INFO:                umap: Not installed
2024-05-29 11:47:16,601:INFO:     ydata_profiling: Not installed
2024-05-29 11:47:16,602:INFO:  explainerdashboard: Not installed
2024-05-29 11:47:16,602:INFO:             autoviz: Not installed
2024-05-29 11:47:16,602:INFO:           fairlearn: Not installed
2024-05-29 11:47:16,602:INFO:          deepchecks: Not installed
2024-05-29 11:47:16,602:INFO:             xgboost: 2.0.3
2024-05-29 11:47:16,602:INFO:            catboost: Not installed
2024-05-29 11:47:16,602:INFO:              kmodes: Not installed
2024-05-29 11:47:16,602:INFO:             mlxtend: Not installed
2024-05-29 11:47:16,602:INFO:       statsforecast: Not installed
2024-05-29 11:47:16,602:INFO:        tune_sklearn: Not installed
2024-05-29 11:47:16,602:INFO:                 ray: Not installed
2024-05-29 11:47:16,602:INFO:            hyperopt: Not installed
2024-05-29 11:47:16,603:INFO:              optuna: Not installed
2024-05-29 11:47:16,603:INFO:               skopt: Not installed
2024-05-29 11:47:16,603:INFO:              mlflow: 2.13.0
2024-05-29 11:47:16,603:INFO:              gradio: Not installed
2024-05-29 11:47:16,603:INFO:             fastapi: Not installed
2024-05-29 11:47:16,603:INFO:             uvicorn: Not installed
2024-05-29 11:47:16,603:INFO:              m2cgen: Not installed
2024-05-29 11:47:16,603:INFO:           evidently: Not installed
2024-05-29 11:47:16,603:INFO:               fugue: Not installed
2024-05-29 11:47:16,603:INFO:           streamlit: Not installed
2024-05-29 11:47:16,603:INFO:             prophet: Not installed
2024-05-29 11:47:16,603:INFO:None
2024-05-29 11:47:16,603:INFO:Set up data.
2024-05-29 11:47:16,632:INFO:Set up folding strategy.
2024-05-29 11:47:16,632:INFO:Set up train/test split.
2024-05-29 11:47:16,689:INFO:Set up index.
2024-05-29 11:47:16,691:INFO:Assigning column types.
2024-05-29 11:47:16,724:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 11:47:16,796:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:47:16,801:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:47:16,855:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:16,859:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:16,932:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:47:16,933:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:47:16,979:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:16,983:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:16,984:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 11:47:17,057:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:47:17,102:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:17,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:17,179:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:47:17,225:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:17,229:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:17,230:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 11:47:17,349:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:17,353:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:17,471:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:17,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:17,515:INFO:Finished creating preprocessing pipeline.
2024-05-29 11:47:17,515:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2024-05-29 11:47:17,515:INFO:Creating final display dataframe.
2024-05-29 11:47:17,737:INFO:Setup _display_container:                    Description        Value
0                   Session id         2977
1                       Target       target
2                  Target type       Binary
3          Original data shape  (90000, 18)
4       Transformed data shape  (90000, 18)
5  Transformed train set shape  (72000, 18)
6   Transformed test set shape  (18000, 18)
7             Numeric features           17
2024-05-29 11:47:17,866:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:17,871:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:17,991:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:17,995:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:17,997:INFO:Logging experiment in loggers
2024-05-29 11:47:18,368:INFO:SubProcess save_model() called ==================================
2024-05-29 11:47:18,369:INFO:Initializing save_model()
2024-05-29 11:47:18,369:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), model_name=C:\Users\Adm\AppData\Local\Temp\tmp93av66h0\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-29 11:47:18,369:INFO:Adding model into prep_pipe
2024-05-29 11:47:18,369:WARNING:Only Model saved as it was a pipeline.
2024-05-29 11:47:18,374:INFO:C:\Users\Adm\AppData\Local\Temp\tmp93av66h0\Transformation Pipeline.pkl saved in current working directory
2024-05-29 11:47:18,375:INFO:Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2024-05-29 11:47:18,375:INFO:save_model() successfully completed......................................
2024-05-29 11:47:20,059:INFO:SubProcess save_model() end ==================================
2024-05-29 11:47:20,082:INFO:setup() successfully completed in 1.5s...............
2024-05-29 11:47:40,124:INFO:PyCaret ClassificationExperiment
2024-05-29 11:47:40,124:INFO:Logging name: codex
2024-05-29 11:47:40,124:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 11:47:40,124:INFO:version 3.3.2
2024-05-29 11:47:40,124:INFO:Initializing setup()
2024-05-29 11:47:40,124:INFO:self.USI: 6e47
2024-05-29 11:47:40,125:INFO:self._variable_keys: {'logging_param', 'fold_shuffle_param', 'fix_imbalance', 'USI', 'log_plots_param', 'idx', 'X', 'is_multiclass', 'exp_name_log', 'fold_groups_param', 'y_train', 'gpu_n_jobs_param', 'n_jobs_param', 'memory', 'target_param', 'y', '_available_plots', '_ml_usecase', 'X_test', 'y_test', 'X_train', 'html_param', 'gpu_param', 'fold_generator', 'data', 'seed', 'exp_id', 'pipeline'}
2024-05-29 11:47:40,125:INFO:Checking environment
2024-05-29 11:47:40,125:INFO:python_version: 3.10.13
2024-05-29 11:47:40,125:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 11:47:40,125:INFO:machine: AMD64
2024-05-29 11:47:40,125:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 11:47:40,125:INFO:Memory: svmem(total=34267656192, available=18858631168, percent=45.0, used=15409025024, free=18858631168)
2024-05-29 11:47:40,125:INFO:Physical Core: 8
2024-05-29 11:47:40,125:INFO:Logical Core: 16
2024-05-29 11:47:40,126:INFO:Checking libraries
2024-05-29 11:47:40,126:INFO:System:
2024-05-29 11:47:40,126:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 11:47:40,126:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 11:47:40,127:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 11:47:40,127:INFO:PyCaret required dependencies:
2024-05-29 11:47:40,127:INFO:                 pip: 23.3
2024-05-29 11:47:40,127:INFO:          setuptools: 68.0.0
2024-05-29 11:47:40,127:INFO:             pycaret: 3.3.2
2024-05-29 11:47:40,127:INFO:             IPython: 8.24.0
2024-05-29 11:47:40,127:INFO:          ipywidgets: 8.1.2
2024-05-29 11:47:40,127:INFO:                tqdm: 4.66.4
2024-05-29 11:47:40,127:INFO:               numpy: 1.26.4
2024-05-29 11:47:40,127:INFO:              pandas: 2.1.4
2024-05-29 11:47:40,128:INFO:              jinja2: 3.1.4
2024-05-29 11:47:40,128:INFO:               scipy: 1.11.4
2024-05-29 11:47:40,128:INFO:              joblib: 1.3.2
2024-05-29 11:47:40,128:INFO:             sklearn: 1.4.2
2024-05-29 11:47:40,128:INFO:                pyod: 1.1.3
2024-05-29 11:47:40,128:INFO:            imblearn: 0.12.2
2024-05-29 11:47:40,128:INFO:   category_encoders: 2.6.3
2024-05-29 11:47:40,128:INFO:            lightgbm: 4.3.0
2024-05-29 11:47:40,128:INFO:               numba: 0.59.1
2024-05-29 11:47:40,128:INFO:            requests: 2.32.2
2024-05-29 11:47:40,128:INFO:          matplotlib: 3.7.5
2024-05-29 11:47:40,128:INFO:          scikitplot: 0.3.7
2024-05-29 11:47:40,129:INFO:         yellowbrick: 1.5
2024-05-29 11:47:40,129:INFO:              plotly: 5.22.0
2024-05-29 11:47:40,129:INFO:    plotly-resampler: Not installed
2024-05-29 11:47:40,129:INFO:             kaleido: 0.2.1
2024-05-29 11:47:40,129:INFO:           schemdraw: 0.15
2024-05-29 11:47:40,129:INFO:         statsmodels: 0.14.2
2024-05-29 11:47:40,129:INFO:              sktime: 0.26.0
2024-05-29 11:47:40,129:INFO:               tbats: 1.1.3
2024-05-29 11:47:40,129:INFO:            pmdarima: 2.0.4
2024-05-29 11:47:40,129:INFO:              psutil: 5.9.0
2024-05-29 11:47:40,129:INFO:          markupsafe: 2.1.5
2024-05-29 11:47:40,129:INFO:             pickle5: Not installed
2024-05-29 11:47:40,129:INFO:         cloudpickle: 3.0.0
2024-05-29 11:47:40,130:INFO:         deprecation: 2.1.0
2024-05-29 11:47:40,130:INFO:              xxhash: 3.4.1
2024-05-29 11:47:40,130:INFO:           wurlitzer: Not installed
2024-05-29 11:47:40,130:INFO:PyCaret optional dependencies:
2024-05-29 11:47:40,130:INFO:                shap: Not installed
2024-05-29 11:47:40,130:INFO:           interpret: Not installed
2024-05-29 11:47:40,130:INFO:                umap: Not installed
2024-05-29 11:47:40,130:INFO:     ydata_profiling: Not installed
2024-05-29 11:47:40,130:INFO:  explainerdashboard: Not installed
2024-05-29 11:47:40,130:INFO:             autoviz: Not installed
2024-05-29 11:47:40,130:INFO:           fairlearn: Not installed
2024-05-29 11:47:40,130:INFO:          deepchecks: Not installed
2024-05-29 11:47:40,130:INFO:             xgboost: 2.0.3
2024-05-29 11:47:40,130:INFO:            catboost: Not installed
2024-05-29 11:47:40,130:INFO:              kmodes: Not installed
2024-05-29 11:47:40,132:INFO:             mlxtend: Not installed
2024-05-29 11:47:40,132:INFO:       statsforecast: Not installed
2024-05-29 11:47:40,132:INFO:        tune_sklearn: Not installed
2024-05-29 11:47:40,132:INFO:                 ray: Not installed
2024-05-29 11:47:40,132:INFO:            hyperopt: Not installed
2024-05-29 11:47:40,132:INFO:              optuna: Not installed
2024-05-29 11:47:40,132:INFO:               skopt: Not installed
2024-05-29 11:47:40,132:INFO:              mlflow: 2.13.0
2024-05-29 11:47:40,132:INFO:              gradio: Not installed
2024-05-29 11:47:40,132:INFO:             fastapi: Not installed
2024-05-29 11:47:40,132:INFO:             uvicorn: Not installed
2024-05-29 11:47:40,132:INFO:              m2cgen: Not installed
2024-05-29 11:47:40,133:INFO:           evidently: Not installed
2024-05-29 11:47:40,133:INFO:               fugue: Not installed
2024-05-29 11:47:40,133:INFO:           streamlit: Not installed
2024-05-29 11:47:40,133:INFO:             prophet: Not installed
2024-05-29 11:47:40,133:INFO:None
2024-05-29 11:47:40,133:INFO:Set up data.
2024-05-29 11:47:40,162:INFO:Set up folding strategy.
2024-05-29 11:47:40,162:INFO:Set up train/test split.
2024-05-29 11:47:40,222:INFO:Set up index.
2024-05-29 11:47:40,223:INFO:Assigning column types.
2024-05-29 11:47:40,258:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 11:47:40,330:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:47:40,332:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:47:40,377:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:40,381:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:40,454:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:47:40,455:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:47:40,501:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:40,505:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:40,505:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 11:47:40,579:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:47:40,624:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:40,628:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:40,703:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:47:40,748:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:40,753:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:40,753:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 11:47:40,876:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:40,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:40,999:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:41,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:41,005:INFO:Preparing preprocessing pipeline...
2024-05-29 11:47:41,011:INFO:Set up simple imputation.
2024-05-29 11:47:48,313:INFO:PyCaret ClassificationExperiment
2024-05-29 11:47:48,313:INFO:Logging name: codex
2024-05-29 11:47:48,313:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 11:47:48,313:INFO:version 3.3.2
2024-05-29 11:47:48,313:INFO:Initializing setup()
2024-05-29 11:47:48,313:INFO:self.USI: b86b
2024-05-29 11:47:48,313:INFO:self._variable_keys: {'logging_param', 'fold_shuffle_param', 'fix_imbalance', 'USI', 'log_plots_param', 'idx', 'X', 'is_multiclass', 'exp_name_log', 'fold_groups_param', 'y_train', 'gpu_n_jobs_param', 'n_jobs_param', 'memory', 'target_param', 'y', '_available_plots', '_ml_usecase', 'X_test', 'y_test', 'X_train', 'html_param', 'gpu_param', 'fold_generator', 'data', 'seed', 'exp_id', 'pipeline'}
2024-05-29 11:47:48,313:INFO:Checking environment
2024-05-29 11:47:48,314:INFO:python_version: 3.10.13
2024-05-29 11:47:48,314:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 11:47:48,314:INFO:machine: AMD64
2024-05-29 11:47:48,314:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 11:47:48,314:INFO:Memory: svmem(total=34267656192, available=18737594368, percent=45.3, used=15530061824, free=18737594368)
2024-05-29 11:47:48,314:INFO:Physical Core: 8
2024-05-29 11:47:48,314:INFO:Logical Core: 16
2024-05-29 11:47:48,314:INFO:Checking libraries
2024-05-29 11:47:48,315:INFO:System:
2024-05-29 11:47:48,315:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 11:47:48,315:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 11:47:48,315:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 11:47:48,315:INFO:PyCaret required dependencies:
2024-05-29 11:47:48,315:INFO:                 pip: 23.3
2024-05-29 11:47:48,315:INFO:          setuptools: 68.0.0
2024-05-29 11:47:48,315:INFO:             pycaret: 3.3.2
2024-05-29 11:47:48,315:INFO:             IPython: 8.24.0
2024-05-29 11:47:48,315:INFO:          ipywidgets: 8.1.2
2024-05-29 11:47:48,316:INFO:                tqdm: 4.66.4
2024-05-29 11:47:48,316:INFO:               numpy: 1.26.4
2024-05-29 11:47:48,316:INFO:              pandas: 2.1.4
2024-05-29 11:47:48,316:INFO:              jinja2: 3.1.4
2024-05-29 11:47:48,316:INFO:               scipy: 1.11.4
2024-05-29 11:47:48,316:INFO:              joblib: 1.3.2
2024-05-29 11:47:48,316:INFO:             sklearn: 1.4.2
2024-05-29 11:47:48,316:INFO:                pyod: 1.1.3
2024-05-29 11:47:48,316:INFO:            imblearn: 0.12.2
2024-05-29 11:47:48,316:INFO:   category_encoders: 2.6.3
2024-05-29 11:47:48,317:INFO:            lightgbm: 4.3.0
2024-05-29 11:47:48,317:INFO:               numba: 0.59.1
2024-05-29 11:47:48,317:INFO:            requests: 2.32.2
2024-05-29 11:47:48,317:INFO:          matplotlib: 3.7.5
2024-05-29 11:47:48,317:INFO:          scikitplot: 0.3.7
2024-05-29 11:47:48,317:INFO:         yellowbrick: 1.5
2024-05-29 11:47:48,317:INFO:              plotly: 5.22.0
2024-05-29 11:47:48,317:INFO:    plotly-resampler: Not installed
2024-05-29 11:47:48,317:INFO:             kaleido: 0.2.1
2024-05-29 11:47:48,317:INFO:           schemdraw: 0.15
2024-05-29 11:47:48,317:INFO:         statsmodels: 0.14.2
2024-05-29 11:47:48,318:INFO:              sktime: 0.26.0
2024-05-29 11:47:48,318:INFO:               tbats: 1.1.3
2024-05-29 11:47:48,318:INFO:            pmdarima: 2.0.4
2024-05-29 11:47:48,318:INFO:              psutil: 5.9.0
2024-05-29 11:47:48,318:INFO:          markupsafe: 2.1.5
2024-05-29 11:47:48,318:INFO:             pickle5: Not installed
2024-05-29 11:47:48,318:INFO:         cloudpickle: 3.0.0
2024-05-29 11:47:48,318:INFO:         deprecation: 2.1.0
2024-05-29 11:47:48,318:INFO:              xxhash: 3.4.1
2024-05-29 11:47:48,319:INFO:           wurlitzer: Not installed
2024-05-29 11:47:48,319:INFO:PyCaret optional dependencies:
2024-05-29 11:47:48,319:INFO:                shap: Not installed
2024-05-29 11:47:48,319:INFO:           interpret: Not installed
2024-05-29 11:47:48,319:INFO:                umap: Not installed
2024-05-29 11:47:48,319:INFO:     ydata_profiling: Not installed
2024-05-29 11:47:48,319:INFO:  explainerdashboard: Not installed
2024-05-29 11:47:48,319:INFO:             autoviz: Not installed
2024-05-29 11:47:48,319:INFO:           fairlearn: Not installed
2024-05-29 11:47:48,319:INFO:          deepchecks: Not installed
2024-05-29 11:47:48,320:INFO:             xgboost: 2.0.3
2024-05-29 11:47:48,320:INFO:            catboost: Not installed
2024-05-29 11:47:48,320:INFO:              kmodes: Not installed
2024-05-29 11:47:48,320:INFO:             mlxtend: Not installed
2024-05-29 11:47:48,320:INFO:       statsforecast: Not installed
2024-05-29 11:47:48,320:INFO:        tune_sklearn: Not installed
2024-05-29 11:47:48,320:INFO:                 ray: Not installed
2024-05-29 11:47:48,320:INFO:            hyperopt: Not installed
2024-05-29 11:47:48,320:INFO:              optuna: Not installed
2024-05-29 11:47:48,320:INFO:               skopt: Not installed
2024-05-29 11:47:48,321:INFO:              mlflow: 2.13.0
2024-05-29 11:47:48,321:INFO:              gradio: Not installed
2024-05-29 11:47:48,321:INFO:             fastapi: Not installed
2024-05-29 11:47:48,321:INFO:             uvicorn: Not installed
2024-05-29 11:47:48,321:INFO:              m2cgen: Not installed
2024-05-29 11:47:48,321:INFO:           evidently: Not installed
2024-05-29 11:47:48,321:INFO:               fugue: Not installed
2024-05-29 11:47:48,321:INFO:           streamlit: Not installed
2024-05-29 11:47:48,321:INFO:             prophet: Not installed
2024-05-29 11:47:48,321:INFO:None
2024-05-29 11:47:48,322:INFO:Set up data.
2024-05-29 11:47:48,358:INFO:Set up folding strategy.
2024-05-29 11:47:48,358:INFO:Set up train/test split.
2024-05-29 11:47:48,424:INFO:Set up index.
2024-05-29 11:47:48,426:INFO:Assigning column types.
2024-05-29 11:47:48,467:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 11:47:48,542:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:47:48,543:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:47:48,590:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:48,595:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:48,669:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:47:48,671:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:47:48,717:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:48,721:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:48,722:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 11:47:48,810:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:47:48,857:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:48,863:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:48,943:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:47:48,990:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:48,995:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:48,996:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 11:47:49,117:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:49,121:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:49,242:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:49,246:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:49,286:INFO:Finished creating preprocessing pipeline.
2024-05-29 11:47:49,287:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2024-05-29 11:47:49,287:INFO:Creating final display dataframe.
2024-05-29 11:47:49,460:INFO:Setup _display_container:                    Description        Value
0                   Session id         5946
1                       Target       target
2                  Target type       Binary
3          Original data shape  (90000, 18)
4       Transformed data shape  (90000, 18)
5  Transformed train set shape  (72000, 18)
6   Transformed test set shape  (18000, 18)
7             Numeric features           17
2024-05-29 11:47:49,619:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:49,624:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:49,746:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:49,750:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:49,752:INFO:Logging experiment in loggers
2024-05-29 11:47:49,941:INFO:SubProcess save_model() called ==================================
2024-05-29 11:47:49,942:INFO:Initializing save_model()
2024-05-29 11:47:49,942:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), model_name=C:\Users\Adm\AppData\Local\Temp\tmp20u_0f8m\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-29 11:47:49,942:INFO:Adding model into prep_pipe
2024-05-29 11:47:49,942:WARNING:Only Model saved as it was a pipeline.
2024-05-29 11:47:49,947:INFO:C:\Users\Adm\AppData\Local\Temp\tmp20u_0f8m\Transformation Pipeline.pkl saved in current working directory
2024-05-29 11:47:49,948:INFO:Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2024-05-29 11:47:49,948:INFO:save_model() successfully completed......................................
2024-05-29 11:47:51,634:INFO:SubProcess save_model() end ==================================
2024-05-29 11:47:51,655:INFO:setup() successfully completed in 1.49s...............
2024-05-29 11:47:56,111:INFO:PyCaret ClassificationExperiment
2024-05-29 11:47:56,112:INFO:Logging name: codex
2024-05-29 11:47:56,112:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 11:47:56,112:INFO:version 3.3.2
2024-05-29 11:47:56,112:INFO:Initializing setup()
2024-05-29 11:47:56,112:INFO:self.USI: 3904
2024-05-29 11:47:56,112:INFO:self._variable_keys: {'logging_param', 'fold_shuffle_param', 'fix_imbalance', 'USI', 'log_plots_param', 'idx', 'X', 'is_multiclass', 'exp_name_log', 'fold_groups_param', 'y_train', 'gpu_n_jobs_param', 'n_jobs_param', 'memory', 'target_param', 'y', '_available_plots', '_ml_usecase', 'X_test', 'y_test', 'X_train', 'html_param', 'gpu_param', 'fold_generator', 'data', 'seed', 'exp_id', 'pipeline'}
2024-05-29 11:47:56,112:INFO:Checking environment
2024-05-29 11:47:56,112:INFO:python_version: 3.10.13
2024-05-29 11:47:56,113:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 11:47:56,113:INFO:machine: AMD64
2024-05-29 11:47:56,113:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 11:47:56,113:INFO:Memory: svmem(total=34267656192, available=18735017984, percent=45.3, used=15532638208, free=18735017984)
2024-05-29 11:47:56,113:INFO:Physical Core: 8
2024-05-29 11:47:56,113:INFO:Logical Core: 16
2024-05-29 11:47:56,113:INFO:Checking libraries
2024-05-29 11:47:56,113:INFO:System:
2024-05-29 11:47:56,114:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 11:47:56,114:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 11:47:56,114:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 11:47:56,114:INFO:PyCaret required dependencies:
2024-05-29 11:47:56,114:INFO:                 pip: 23.3
2024-05-29 11:47:56,114:INFO:          setuptools: 68.0.0
2024-05-29 11:47:56,114:INFO:             pycaret: 3.3.2
2024-05-29 11:47:56,114:INFO:             IPython: 8.24.0
2024-05-29 11:47:56,114:INFO:          ipywidgets: 8.1.2
2024-05-29 11:47:56,115:INFO:                tqdm: 4.66.4
2024-05-29 11:47:56,115:INFO:               numpy: 1.26.4
2024-05-29 11:47:56,115:INFO:              pandas: 2.1.4
2024-05-29 11:47:56,115:INFO:              jinja2: 3.1.4
2024-05-29 11:47:56,115:INFO:               scipy: 1.11.4
2024-05-29 11:47:56,115:INFO:              joblib: 1.3.2
2024-05-29 11:47:56,115:INFO:             sklearn: 1.4.2
2024-05-29 11:47:56,115:INFO:                pyod: 1.1.3
2024-05-29 11:47:56,115:INFO:            imblearn: 0.12.2
2024-05-29 11:47:56,115:INFO:   category_encoders: 2.6.3
2024-05-29 11:47:56,115:INFO:            lightgbm: 4.3.0
2024-05-29 11:47:56,116:INFO:               numba: 0.59.1
2024-05-29 11:47:56,116:INFO:            requests: 2.32.2
2024-05-29 11:47:56,116:INFO:          matplotlib: 3.7.5
2024-05-29 11:47:56,116:INFO:          scikitplot: 0.3.7
2024-05-29 11:47:56,116:INFO:         yellowbrick: 1.5
2024-05-29 11:47:56,116:INFO:              plotly: 5.22.0
2024-05-29 11:47:56,116:INFO:    plotly-resampler: Not installed
2024-05-29 11:47:56,116:INFO:             kaleido: 0.2.1
2024-05-29 11:47:56,116:INFO:           schemdraw: 0.15
2024-05-29 11:47:56,116:INFO:         statsmodels: 0.14.2
2024-05-29 11:47:56,116:INFO:              sktime: 0.26.0
2024-05-29 11:47:56,117:INFO:               tbats: 1.1.3
2024-05-29 11:47:56,117:INFO:            pmdarima: 2.0.4
2024-05-29 11:47:56,117:INFO:              psutil: 5.9.0
2024-05-29 11:47:56,117:INFO:          markupsafe: 2.1.5
2024-05-29 11:47:56,117:INFO:             pickle5: Not installed
2024-05-29 11:47:56,117:INFO:         cloudpickle: 3.0.0
2024-05-29 11:47:56,117:INFO:         deprecation: 2.1.0
2024-05-29 11:47:56,117:INFO:              xxhash: 3.4.1
2024-05-29 11:47:56,117:INFO:           wurlitzer: Not installed
2024-05-29 11:47:56,117:INFO:PyCaret optional dependencies:
2024-05-29 11:47:56,118:INFO:                shap: Not installed
2024-05-29 11:47:56,118:INFO:           interpret: Not installed
2024-05-29 11:47:56,118:INFO:                umap: Not installed
2024-05-29 11:47:56,118:INFO:     ydata_profiling: Not installed
2024-05-29 11:47:56,118:INFO:  explainerdashboard: Not installed
2024-05-29 11:47:56,118:INFO:             autoviz: Not installed
2024-05-29 11:47:56,118:INFO:           fairlearn: Not installed
2024-05-29 11:47:56,118:INFO:          deepchecks: Not installed
2024-05-29 11:47:56,119:INFO:             xgboost: 2.0.3
2024-05-29 11:47:56,119:INFO:            catboost: Not installed
2024-05-29 11:47:56,119:INFO:              kmodes: Not installed
2024-05-29 11:47:56,119:INFO:             mlxtend: Not installed
2024-05-29 11:47:56,119:INFO:       statsforecast: Not installed
2024-05-29 11:47:56,119:INFO:        tune_sklearn: Not installed
2024-05-29 11:47:56,119:INFO:                 ray: Not installed
2024-05-29 11:47:56,119:INFO:            hyperopt: Not installed
2024-05-29 11:47:56,119:INFO:              optuna: Not installed
2024-05-29 11:47:56,119:INFO:               skopt: Not installed
2024-05-29 11:47:56,120:INFO:              mlflow: 2.13.0
2024-05-29 11:47:56,120:INFO:              gradio: Not installed
2024-05-29 11:47:56,120:INFO:             fastapi: Not installed
2024-05-29 11:47:56,120:INFO:             uvicorn: Not installed
2024-05-29 11:47:56,120:INFO:              m2cgen: Not installed
2024-05-29 11:47:56,120:INFO:           evidently: Not installed
2024-05-29 11:47:56,120:INFO:               fugue: Not installed
2024-05-29 11:47:56,120:INFO:           streamlit: Not installed
2024-05-29 11:47:56,120:INFO:             prophet: Not installed
2024-05-29 11:47:56,120:INFO:None
2024-05-29 11:47:56,120:INFO:Set up data.
2024-05-29 11:47:56,151:INFO:Set up folding strategy.
2024-05-29 11:47:56,151:INFO:Set up train/test split.
2024-05-29 11:47:56,214:INFO:Set up index.
2024-05-29 11:47:56,216:INFO:Assigning column types.
2024-05-29 11:47:56,252:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 11:47:56,325:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:47:56,326:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:47:56,372:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:56,376:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:56,450:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 11:47:56,451:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:47:56,496:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:56,501:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:56,502:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 11:47:56,575:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:47:56,620:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:56,625:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:56,700:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 11:47:56,745:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:56,749:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:56,750:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 11:47:56,869:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:56,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:56,994:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:56,997:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:57,037:INFO:Finished creating preprocessing pipeline.
2024-05-29 11:47:57,037:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2024-05-29 11:47:57,037:INFO:Creating final display dataframe.
2024-05-29 11:47:57,219:INFO:Setup _display_container:                    Description        Value
0                   Session id         1013
1                       Target       target
2                  Target type       Binary
3          Original data shape  (90000, 18)
4       Transformed data shape  (90000, 18)
5  Transformed train set shape  (72000, 18)
6   Transformed test set shape  (18000, 18)
7             Numeric features           17
2024-05-29 11:47:57,397:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:57,403:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:57,548:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 11:47:57,553:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 11:47:57,555:INFO:Logging experiment in loggers
2024-05-29 11:47:57,695:INFO:SubProcess save_model() called ==================================
2024-05-29 11:47:57,696:INFO:Initializing save_model()
2024-05-29 11:47:57,696:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), model_name=C:\Users\Adm\AppData\Local\Temp\tmpz63lvwwh\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-29 11:47:57,696:INFO:Adding model into prep_pipe
2024-05-29 11:47:57,696:WARNING:Only Model saved as it was a pipeline.
2024-05-29 11:47:57,701:INFO:C:\Users\Adm\AppData\Local\Temp\tmpz63lvwwh\Transformation Pipeline.pkl saved in current working directory
2024-05-29 11:47:57,702:INFO:Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2024-05-29 11:47:57,702:INFO:save_model() successfully completed......................................
2024-05-29 11:47:59,321:INFO:SubProcess save_model() end ==================================
2024-05-29 11:47:59,342:INFO:setup() successfully completed in 1.48s...............
2024-05-29 11:47:59,386:INFO:Initializing compare_models()
2024-05-29 11:47:59,386:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199B5F7EE90>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000199B5F7EE90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-29 11:47:59,386:INFO:Checking exceptions
2024-05-29 11:47:59,413:INFO:Preparing display monitor
2024-05-29 11:47:59,441:INFO:Initializing Logistic Regression
2024-05-29 11:47:59,441:INFO:Total runtime is 0.0 minutes
2024-05-29 11:47:59,446:INFO:SubProcess create_model() called ==================================
2024-05-29 11:47:59,447:INFO:Initializing create_model()
2024-05-29 11:47:59,447:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199B5F7EE90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A04E597E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 11:47:59,447:INFO:Checking exceptions
2024-05-29 11:47:59,447:INFO:Importing libraries
2024-05-29 11:47:59,448:INFO:Copying training dataset
2024-05-29 11:47:59,498:INFO:Defining folds
2024-05-29 11:47:59,498:INFO:Declaring metric variables
2024-05-29 11:47:59,503:INFO:Importing untrained model
2024-05-29 11:47:59,508:INFO:Logistic Regression Imported successfully
2024-05-29 11:47:59,518:INFO:Starting cross validation
2024-05-29 11:47:59,519:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 11:48:06,053:INFO:Calculating mean and std
2024-05-29 11:48:06,055:INFO:Creating metrics dataframe
2024-05-29 11:48:06,058:INFO:Uploading results into container
2024-05-29 11:48:06,059:INFO:Uploading model into container now
2024-05-29 11:48:06,059:INFO:_master_model_container: 1
2024-05-29 11:48:06,060:INFO:_display_container: 2
2024-05-29 11:48:06,060:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1013, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-29 11:48:06,060:INFO:create_model() successfully completed......................................
2024-05-29 11:48:07,707:INFO:SubProcess create_model() end ==================================
2024-05-29 11:48:07,707:INFO:Creating metrics dataframe
2024-05-29 11:48:07,716:INFO:Initializing K Neighbors Classifier
2024-05-29 11:48:07,717:INFO:Total runtime is 0.1379378835360209 minutes
2024-05-29 11:48:07,721:INFO:SubProcess create_model() called ==================================
2024-05-29 11:48:07,721:INFO:Initializing create_model()
2024-05-29 11:48:07,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199B5F7EE90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A04E597E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 11:48:07,721:INFO:Checking exceptions
2024-05-29 11:48:07,722:INFO:Importing libraries
2024-05-29 11:48:07,722:INFO:Copying training dataset
2024-05-29 11:48:07,772:INFO:Defining folds
2024-05-29 11:48:07,772:INFO:Declaring metric variables
2024-05-29 11:48:07,776:INFO:Importing untrained model
2024-05-29 11:48:07,781:INFO:K Neighbors Classifier Imported successfully
2024-05-29 11:48:07,789:INFO:Starting cross validation
2024-05-29 11:48:07,790:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 11:48:20,438:INFO:Calculating mean and std
2024-05-29 11:48:20,441:INFO:Creating metrics dataframe
2024-05-29 11:48:20,444:INFO:Uploading results into container
2024-05-29 11:48:20,445:INFO:Uploading model into container now
2024-05-29 11:48:20,445:INFO:_master_model_container: 2
2024-05-29 11:48:20,446:INFO:_display_container: 2
2024-05-29 11:48:20,446:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-29 11:48:20,447:INFO:create_model() successfully completed......................................
2024-05-29 11:48:22,027:INFO:SubProcess create_model() end ==================================
2024-05-29 11:48:22,027:INFO:Creating metrics dataframe
2024-05-29 11:48:22,037:INFO:Initializing Naive Bayes
2024-05-29 11:48:22,038:INFO:Total runtime is 0.37661652962366743 minutes
2024-05-29 11:48:22,042:INFO:SubProcess create_model() called ==================================
2024-05-29 11:48:22,042:INFO:Initializing create_model()
2024-05-29 11:48:22,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199B5F7EE90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A04E597E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 11:48:22,043:INFO:Checking exceptions
2024-05-29 11:48:22,043:INFO:Importing libraries
2024-05-29 11:48:22,043:INFO:Copying training dataset
2024-05-29 11:48:22,092:INFO:Defining folds
2024-05-29 11:48:22,093:INFO:Declaring metric variables
2024-05-29 11:48:22,097:INFO:Importing untrained model
2024-05-29 11:48:22,102:INFO:Naive Bayes Imported successfully
2024-05-29 11:48:22,112:INFO:Starting cross validation
2024-05-29 11:48:22,113:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 11:48:22,370:INFO:Calculating mean and std
2024-05-29 11:48:22,372:INFO:Creating metrics dataframe
2024-05-29 11:48:22,374:INFO:Uploading results into container
2024-05-29 11:48:22,375:INFO:Uploading model into container now
2024-05-29 11:48:22,376:INFO:_master_model_container: 3
2024-05-29 11:48:22,376:INFO:_display_container: 2
2024-05-29 11:48:22,376:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-29 11:48:22,376:INFO:create_model() successfully completed......................................
2024-05-29 11:48:24,035:INFO:SubProcess create_model() end ==================================
2024-05-29 11:48:24,035:INFO:Creating metrics dataframe
2024-05-29 11:48:24,045:INFO:Initializing Decision Tree Classifier
2024-05-29 11:48:24,046:INFO:Total runtime is 0.4100830634435018 minutes
2024-05-29 11:48:24,050:INFO:SubProcess create_model() called ==================================
2024-05-29 11:48:24,051:INFO:Initializing create_model()
2024-05-29 11:48:24,051:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199B5F7EE90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A04E597E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 11:48:24,051:INFO:Checking exceptions
2024-05-29 11:48:24,051:INFO:Importing libraries
2024-05-29 11:48:24,051:INFO:Copying training dataset
2024-05-29 11:48:24,101:INFO:Defining folds
2024-05-29 11:48:24,101:INFO:Declaring metric variables
2024-05-29 11:48:24,107:INFO:Importing untrained model
2024-05-29 11:48:24,112:INFO:Decision Tree Classifier Imported successfully
2024-05-29 11:48:24,120:INFO:Starting cross validation
2024-05-29 11:48:24,121:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 11:48:24,730:INFO:Calculating mean and std
2024-05-29 11:48:24,732:INFO:Creating metrics dataframe
2024-05-29 11:48:24,734:INFO:Uploading results into container
2024-05-29 11:48:24,735:INFO:Uploading model into container now
2024-05-29 11:48:24,735:INFO:_master_model_container: 4
2024-05-29 11:48:24,736:INFO:_display_container: 2
2024-05-29 11:48:24,736:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1013, splitter='best')
2024-05-29 11:48:24,736:INFO:create_model() successfully completed......................................
2024-05-29 11:48:26,503:INFO:SubProcess create_model() end ==================================
2024-05-29 11:48:26,503:INFO:Creating metrics dataframe
2024-05-29 11:48:26,514:INFO:Initializing SVM - Linear Kernel
2024-05-29 11:48:26,514:INFO:Total runtime is 0.4512131651242574 minutes
2024-05-29 11:48:26,519:INFO:SubProcess create_model() called ==================================
2024-05-29 11:48:26,519:INFO:Initializing create_model()
2024-05-29 11:48:26,519:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199B5F7EE90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A04E597E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 11:48:26,519:INFO:Checking exceptions
2024-05-29 11:48:26,520:INFO:Importing libraries
2024-05-29 11:48:26,520:INFO:Copying training dataset
2024-05-29 11:48:26,570:INFO:Defining folds
2024-05-29 11:48:26,570:INFO:Declaring metric variables
2024-05-29 11:48:26,575:INFO:Importing untrained model
2024-05-29 11:48:26,580:INFO:SVM - Linear Kernel Imported successfully
2024-05-29 11:48:26,589:INFO:Starting cross validation
2024-05-29 11:48:26,590:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 11:48:27,043:INFO:Calculating mean and std
2024-05-29 11:48:27,045:INFO:Creating metrics dataframe
2024-05-29 11:48:27,047:INFO:Uploading results into container
2024-05-29 11:48:27,048:INFO:Uploading model into container now
2024-05-29 11:48:27,049:INFO:_master_model_container: 5
2024-05-29 11:48:27,049:INFO:_display_container: 2
2024-05-29 11:48:27,050:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1013, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-29 11:48:27,050:INFO:create_model() successfully completed......................................
2024-05-29 11:48:28,727:INFO:SubProcess create_model() end ==================================
2024-05-29 11:48:28,728:INFO:Creating metrics dataframe
2024-05-29 11:48:28,739:INFO:Initializing Ridge Classifier
2024-05-29 11:48:28,739:INFO:Total runtime is 0.4883060018221537 minutes
2024-05-29 11:48:28,744:INFO:SubProcess create_model() called ==================================
2024-05-29 11:48:28,744:INFO:Initializing create_model()
2024-05-29 11:48:28,744:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199B5F7EE90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A04E597E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 11:48:28,744:INFO:Checking exceptions
2024-05-29 11:48:28,745:INFO:Importing libraries
2024-05-29 11:48:28,745:INFO:Copying training dataset
2024-05-29 11:48:28,795:INFO:Defining folds
2024-05-29 11:48:28,795:INFO:Declaring metric variables
2024-05-29 11:48:28,800:INFO:Importing untrained model
2024-05-29 11:48:28,806:INFO:Ridge Classifier Imported successfully
2024-05-29 11:48:28,815:INFO:Starting cross validation
2024-05-29 11:48:28,816:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 11:48:29,067:INFO:Calculating mean and std
2024-05-29 11:48:29,069:INFO:Creating metrics dataframe
2024-05-29 11:48:29,071:INFO:Uploading results into container
2024-05-29 11:48:29,072:INFO:Uploading model into container now
2024-05-29 11:48:29,073:INFO:_master_model_container: 6
2024-05-29 11:48:29,073:INFO:_display_container: 2
2024-05-29 11:48:29,073:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1013, solver='auto',
                tol=0.0001)
2024-05-29 11:48:29,074:INFO:create_model() successfully completed......................................
2024-05-29 11:48:30,699:INFO:SubProcess create_model() end ==================================
2024-05-29 11:48:30,699:INFO:Creating metrics dataframe
2024-05-29 11:48:30,710:INFO:Initializing Random Forest Classifier
2024-05-29 11:48:30,711:INFO:Total runtime is 0.5211726903915406 minutes
2024-05-29 11:48:30,715:INFO:SubProcess create_model() called ==================================
2024-05-29 11:48:30,716:INFO:Initializing create_model()
2024-05-29 11:48:30,716:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199B5F7EE90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A04E597E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 11:48:30,716:INFO:Checking exceptions
2024-05-29 11:48:30,716:INFO:Importing libraries
2024-05-29 11:48:30,716:INFO:Copying training dataset
2024-05-29 11:48:30,765:INFO:Defining folds
2024-05-29 11:48:30,766:INFO:Declaring metric variables
2024-05-29 11:48:30,770:INFO:Importing untrained model
2024-05-29 11:48:30,775:INFO:Random Forest Classifier Imported successfully
2024-05-29 11:48:30,784:INFO:Starting cross validation
2024-05-29 11:48:30,785:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 11:48:38,907:INFO:Calculating mean and std
2024-05-29 11:48:38,909:INFO:Creating metrics dataframe
2024-05-29 11:48:38,913:INFO:Uploading results into container
2024-05-29 11:48:38,913:INFO:Uploading model into container now
2024-05-29 11:48:38,914:INFO:_master_model_container: 7
2024-05-29 11:48:38,914:INFO:_display_container: 2
2024-05-29 11:48:38,915:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1013, verbose=0,
                       warm_start=False)
2024-05-29 11:48:38,916:INFO:create_model() successfully completed......................................
2024-05-29 11:48:40,620:INFO:SubProcess create_model() end ==================================
2024-05-29 11:48:40,620:INFO:Creating metrics dataframe
2024-05-29 11:48:40,633:INFO:Initializing Quadratic Discriminant Analysis
2024-05-29 11:48:40,633:INFO:Total runtime is 0.6865424633026124 minutes
2024-05-29 11:48:40,639:INFO:SubProcess create_model() called ==================================
2024-05-29 11:48:40,639:INFO:Initializing create_model()
2024-05-29 11:48:40,640:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199B5F7EE90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A04E597E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 11:48:40,640:INFO:Checking exceptions
2024-05-29 11:48:40,640:INFO:Importing libraries
2024-05-29 11:48:40,640:INFO:Copying training dataset
2024-05-29 11:48:40,692:INFO:Defining folds
2024-05-29 11:48:40,692:INFO:Declaring metric variables
2024-05-29 11:48:40,698:INFO:Importing untrained model
2024-05-29 11:48:40,703:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-29 11:48:40,713:INFO:Starting cross validation
2024-05-29 11:48:40,714:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 11:48:41,109:INFO:Calculating mean and std
2024-05-29 11:48:41,111:INFO:Creating metrics dataframe
2024-05-29 11:48:41,113:INFO:Uploading results into container
2024-05-29 11:48:41,114:INFO:Uploading model into container now
2024-05-29 11:48:41,115:INFO:_master_model_container: 8
2024-05-29 11:48:41,115:INFO:_display_container: 2
2024-05-29 11:48:41,115:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-29 11:48:41,115:INFO:create_model() successfully completed......................................
2024-05-29 11:48:42,794:INFO:SubProcess create_model() end ==================================
2024-05-29 11:48:42,795:INFO:Creating metrics dataframe
2024-05-29 11:48:42,807:INFO:Initializing Ada Boost Classifier
2024-05-29 11:48:42,808:INFO:Total runtime is 0.7227865378061931 minutes
2024-05-29 11:48:42,812:INFO:SubProcess create_model() called ==================================
2024-05-29 11:48:42,812:INFO:Initializing create_model()
2024-05-29 11:48:42,813:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199B5F7EE90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A04E597E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 11:48:42,813:INFO:Checking exceptions
2024-05-29 11:48:42,813:INFO:Importing libraries
2024-05-29 11:48:42,813:INFO:Copying training dataset
2024-05-29 11:48:42,864:INFO:Defining folds
2024-05-29 11:48:42,864:INFO:Declaring metric variables
2024-05-29 11:48:42,869:INFO:Importing untrained model
2024-05-29 11:48:42,874:INFO:Ada Boost Classifier Imported successfully
2024-05-29 11:48:42,884:INFO:Starting cross validation
2024-05-29 11:48:42,885:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 11:48:42,940:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 11:48:42,953:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 11:48:42,969:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 11:48:42,984:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 11:48:43,001:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 11:48:43,017:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 11:48:43,042:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 11:48:43,058:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 11:48:43,069:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 11:48:43,092:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 11:48:45,854:INFO:Calculating mean and std
2024-05-29 11:48:45,856:INFO:Creating metrics dataframe
2024-05-29 11:48:45,859:INFO:Uploading results into container
2024-05-29 11:48:45,860:INFO:Uploading model into container now
2024-05-29 11:48:45,860:INFO:_master_model_container: 9
2024-05-29 11:48:45,861:INFO:_display_container: 2
2024-05-29 11:48:45,861:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1013)
2024-05-29 11:48:45,862:INFO:create_model() successfully completed......................................
2024-05-29 11:48:47,489:INFO:SubProcess create_model() end ==================================
2024-05-29 11:48:47,489:INFO:Creating metrics dataframe
2024-05-29 11:48:47,503:INFO:Initializing Gradient Boosting Classifier
2024-05-29 11:48:47,503:INFO:Total runtime is 0.8010418653488159 minutes
2024-05-29 11:48:47,509:INFO:SubProcess create_model() called ==================================
2024-05-29 11:48:47,509:INFO:Initializing create_model()
2024-05-29 11:48:47,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199B5F7EE90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A04E597E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 11:48:47,509:INFO:Checking exceptions
2024-05-29 11:48:47,510:INFO:Importing libraries
2024-05-29 11:48:47,510:INFO:Copying training dataset
2024-05-29 11:48:47,561:INFO:Defining folds
2024-05-29 11:48:47,561:INFO:Declaring metric variables
2024-05-29 11:48:47,566:INFO:Importing untrained model
2024-05-29 11:48:47,572:INFO:Gradient Boosting Classifier Imported successfully
2024-05-29 11:48:47,582:INFO:Starting cross validation
2024-05-29 11:48:47,584:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 11:48:56,819:INFO:Calculating mean and std
2024-05-29 11:48:56,821:INFO:Creating metrics dataframe
2024-05-29 11:48:56,823:INFO:Uploading results into container
2024-05-29 11:48:56,824:INFO:Uploading model into container now
2024-05-29 11:48:56,824:INFO:_master_model_container: 10
2024-05-29 11:48:56,825:INFO:_display_container: 2
2024-05-29 11:48:56,825:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1013, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-29 11:48:56,825:INFO:create_model() successfully completed......................................
2024-05-29 11:48:58,393:INFO:SubProcess create_model() end ==================================
2024-05-29 11:48:58,394:INFO:Creating metrics dataframe
2024-05-29 11:48:58,408:INFO:Initializing Linear Discriminant Analysis
2024-05-29 11:48:58,408:INFO:Total runtime is 0.9827842911084493 minutes
2024-05-29 11:48:58,412:INFO:SubProcess create_model() called ==================================
2024-05-29 11:48:58,413:INFO:Initializing create_model()
2024-05-29 11:48:58,413:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199B5F7EE90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A04E597E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 11:48:58,414:INFO:Checking exceptions
2024-05-29 11:48:58,414:INFO:Importing libraries
2024-05-29 11:48:58,414:INFO:Copying training dataset
2024-05-29 11:48:58,464:INFO:Defining folds
2024-05-29 11:48:58,464:INFO:Declaring metric variables
2024-05-29 11:48:58,469:INFO:Importing untrained model
2024-05-29 11:48:58,474:INFO:Linear Discriminant Analysis Imported successfully
2024-05-29 11:48:58,483:INFO:Starting cross validation
2024-05-29 11:48:58,484:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 11:48:58,815:INFO:Calculating mean and std
2024-05-29 11:48:58,817:INFO:Creating metrics dataframe
2024-05-29 11:48:58,819:INFO:Uploading results into container
2024-05-29 11:48:58,820:INFO:Uploading model into container now
2024-05-29 11:48:58,821:INFO:_master_model_container: 11
2024-05-29 11:48:58,821:INFO:_display_container: 2
2024-05-29 11:48:58,821:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-29 11:48:58,821:INFO:create_model() successfully completed......................................
2024-05-29 11:49:00,583:INFO:SubProcess create_model() end ==================================
2024-05-29 11:49:00,583:INFO:Creating metrics dataframe
2024-05-29 11:49:00,598:INFO:Initializing Extra Trees Classifier
2024-05-29 11:49:00,598:INFO:Total runtime is 1.0192815343538921 minutes
2024-05-29 11:49:00,602:INFO:SubProcess create_model() called ==================================
2024-05-29 11:49:00,603:INFO:Initializing create_model()
2024-05-29 11:49:00,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199B5F7EE90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A04E597E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 11:49:00,603:INFO:Checking exceptions
2024-05-29 11:49:00,603:INFO:Importing libraries
2024-05-29 11:49:00,603:INFO:Copying training dataset
2024-05-29 11:49:00,652:INFO:Defining folds
2024-05-29 11:49:00,653:INFO:Declaring metric variables
2024-05-29 11:49:00,657:INFO:Importing untrained model
2024-05-29 11:49:00,662:INFO:Extra Trees Classifier Imported successfully
2024-05-29 11:49:00,672:INFO:Starting cross validation
2024-05-29 11:49:00,673:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 11:49:09,050:INFO:Calculating mean and std
2024-05-29 11:49:09,053:INFO:Creating metrics dataframe
2024-05-29 11:49:09,056:INFO:Uploading results into container
2024-05-29 11:49:09,057:INFO:Uploading model into container now
2024-05-29 11:49:09,058:INFO:_master_model_container: 12
2024-05-29 11:49:09,058:INFO:_display_container: 2
2024-05-29 11:49:09,059:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1013, verbose=0,
                     warm_start=False)
2024-05-29 11:49:09,059:INFO:create_model() successfully completed......................................
2024-05-29 11:49:10,846:INFO:SubProcess create_model() end ==================================
2024-05-29 11:49:10,846:INFO:Creating metrics dataframe
2024-05-29 11:49:10,862:INFO:Initializing Extreme Gradient Boosting
2024-05-29 11:49:10,862:INFO:Total runtime is 1.190360160668691 minutes
2024-05-29 11:49:10,867:INFO:SubProcess create_model() called ==================================
2024-05-29 11:49:10,867:INFO:Initializing create_model()
2024-05-29 11:49:10,867:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199B5F7EE90>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A04E597E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 11:49:10,868:INFO:Checking exceptions
2024-05-29 11:49:10,868:INFO:Importing libraries
2024-05-29 11:49:10,868:INFO:Copying training dataset
2024-05-29 11:49:10,921:INFO:Defining folds
2024-05-29 11:49:10,922:INFO:Declaring metric variables
2024-05-29 11:49:10,927:INFO:Importing untrained model
2024-05-29 11:49:10,934:INFO:Extreme Gradient Boosting Imported successfully
2024-05-29 11:49:10,943:INFO:Starting cross validation
2024-05-29 11:49:10,945:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 11:49:12,556:INFO:Calculating mean and std
2024-05-29 11:49:12,558:INFO:Creating metrics dataframe
2024-05-29 11:49:12,560:INFO:Uploading results into container
2024-05-29 11:49:12,561:INFO:Uploading model into container now
2024-05-29 11:49:12,561:INFO:_master_model_container: 13
2024-05-29 11:49:12,562:INFO:_display_container: 2
2024-05-29 11:49:12,563:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-29 11:49:12,563:INFO:create_model() successfully completed......................................
2024-05-29 11:49:14,138:INFO:SubProcess create_model() end ==================================
2024-05-29 11:49:14,139:INFO:Creating metrics dataframe
2024-05-29 11:49:14,154:INFO:Initializing Light Gradient Boosting Machine
2024-05-29 11:49:14,154:INFO:Total runtime is 1.2452109734217327 minutes
2024-05-29 11:49:14,158:INFO:SubProcess create_model() called ==================================
2024-05-29 11:49:14,159:INFO:Initializing create_model()
2024-05-29 11:49:14,159:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199B5F7EE90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A04E597E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 11:49:14,159:INFO:Checking exceptions
2024-05-29 11:49:14,159:INFO:Importing libraries
2024-05-29 11:49:14,160:INFO:Copying training dataset
2024-05-29 11:49:14,209:INFO:Defining folds
2024-05-29 11:49:14,209:INFO:Declaring metric variables
2024-05-29 11:49:14,215:INFO:Importing untrained model
2024-05-29 11:49:14,219:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-29 11:49:14,228:INFO:Starting cross validation
2024-05-29 11:49:14,230:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 11:49:16,948:INFO:Calculating mean and std
2024-05-29 11:49:16,951:INFO:Creating metrics dataframe
2024-05-29 11:49:16,955:INFO:Uploading results into container
2024-05-29 11:49:16,956:INFO:Uploading model into container now
2024-05-29 11:49:16,957:INFO:_master_model_container: 14
2024-05-29 11:49:16,957:INFO:_display_container: 2
2024-05-29 11:49:16,958:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1013, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-29 11:49:16,958:INFO:create_model() successfully completed......................................
2024-05-29 11:49:18,681:INFO:SubProcess create_model() end ==================================
2024-05-29 11:49:18,681:INFO:Creating metrics dataframe
2024-05-29 11:49:18,697:INFO:Initializing Dummy Classifier
2024-05-29 11:49:18,697:INFO:Total runtime is 1.3209398945172628 minutes
2024-05-29 11:49:18,702:INFO:SubProcess create_model() called ==================================
2024-05-29 11:49:18,702:INFO:Initializing create_model()
2024-05-29 11:49:18,702:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199B5F7EE90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A04E597E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 11:49:18,702:INFO:Checking exceptions
2024-05-29 11:49:18,703:INFO:Importing libraries
2024-05-29 11:49:18,703:INFO:Copying training dataset
2024-05-29 11:49:18,753:INFO:Defining folds
2024-05-29 11:49:18,753:INFO:Declaring metric variables
2024-05-29 11:49:18,758:INFO:Importing untrained model
2024-05-29 11:49:18,763:INFO:Dummy Classifier Imported successfully
2024-05-29 11:49:18,773:INFO:Starting cross validation
2024-05-29 11:49:18,774:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 11:49:18,845:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 11:49:18,861:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 11:49:18,881:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 11:49:18,890:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 11:49:18,916:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 11:49:18,933:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 11:49:18,939:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 11:49:18,950:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 11:49:18,966:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 11:49:18,979:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 11:49:18,993:INFO:Calculating mean and std
2024-05-29 11:49:18,995:INFO:Creating metrics dataframe
2024-05-29 11:49:18,997:INFO:Uploading results into container
2024-05-29 11:49:18,998:INFO:Uploading model into container now
2024-05-29 11:49:18,999:INFO:_master_model_container: 15
2024-05-29 11:49:18,999:INFO:_display_container: 2
2024-05-29 11:49:18,999:INFO:DummyClassifier(constant=None, random_state=1013, strategy='prior')
2024-05-29 11:49:18,999:INFO:create_model() successfully completed......................................
2024-05-29 11:49:20,761:INFO:SubProcess create_model() end ==================================
2024-05-29 11:49:20,761:INFO:Creating metrics dataframe
2024-05-29 11:49:20,781:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-29 11:49:20,793:INFO:Initializing create_model()
2024-05-29 11:49:20,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199B5F7EE90>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 11:49:20,794:INFO:Checking exceptions
2024-05-29 11:49:20,796:INFO:Importing libraries
2024-05-29 11:49:20,796:INFO:Copying training dataset
2024-05-29 11:49:20,850:INFO:Defining folds
2024-05-29 11:49:20,850:INFO:Declaring metric variables
2024-05-29 11:49:20,850:INFO:Importing untrained model
2024-05-29 11:49:20,850:INFO:Declaring custom model
2024-05-29 11:49:20,852:INFO:Extreme Gradient Boosting Imported successfully
2024-05-29 11:49:20,853:INFO:Cross validation set to False
2024-05-29 11:49:20,853:INFO:Fitting Model
2024-05-29 11:49:21,171:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-29 11:49:21,171:INFO:create_model() successfully completed......................................
2024-05-29 11:49:22,847:INFO:Creating Dashboard logs
2024-05-29 11:49:22,852:INFO:Model: Extreme Gradient Boosting
2024-05-29 11:49:22,949:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 1013, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2024-05-29 11:49:23,226:INFO:Initializing predict_model()
2024-05-29 11:49:23,226:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000199B5F7EE90>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000019A047A32E0>)
2024-05-29 11:49:23,226:INFO:Checking exceptions
2024-05-29 11:49:23,226:INFO:Preloading libraries
2024-05-29 11:49:25,096:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2024-05-29 11:49:28,657:INFO:Creating Dashboard logs
2024-05-29 11:49:28,662:INFO:Model: Light Gradient Boosting Machine
2024-05-29 11:49:28,746:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 1013, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-05-29 11:49:30,663:INFO:Creating Dashboard logs
2024-05-29 11:49:30,667:INFO:Model: Gradient Boosting Classifier
2024-05-29 11:49:30,751:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 1013, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-29 11:49:32,696:INFO:Creating Dashboard logs
2024-05-29 11:49:32,701:INFO:Model: Random Forest Classifier
2024-05-29 11:49:32,799:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1013, 'verbose': 0, 'warm_start': False}
2024-05-29 11:49:34,772:INFO:Creating Dashboard logs
2024-05-29 11:49:34,776:INFO:Model: Ada Boost Classifier
2024-05-29 11:49:34,863:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 1013}
2024-05-29 11:49:36,739:INFO:Creating Dashboard logs
2024-05-29 11:49:36,743:INFO:Model: Extra Trees Classifier
2024-05-29 11:49:36,830:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1013, 'verbose': 0, 'warm_start': False}
2024-05-29 11:49:38,771:INFO:Creating Dashboard logs
2024-05-29 11:49:38,775:INFO:Model: Logistic Regression
2024-05-29 11:49:38,862:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 1013, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-05-29 11:49:40,882:INFO:Creating Dashboard logs
2024-05-29 11:49:40,887:INFO:Model: Ridge Classifier
2024-05-29 11:49:40,979:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 1013, 'solver': 'auto', 'tol': 0.0001}
2024-05-29 11:49:43,047:INFO:Creating Dashboard logs
2024-05-29 11:49:43,052:INFO:Model: Linear Discriminant Analysis
2024-05-29 11:49:43,137:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-05-29 11:49:45,039:INFO:Creating Dashboard logs
2024-05-29 11:49:45,044:INFO:Model: SVM - Linear Kernel
2024-05-29 11:49:45,129:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 1013, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-29 11:49:47,056:INFO:Creating Dashboard logs
2024-05-29 11:49:47,061:INFO:Model: K Neighbors Classifier
2024-05-29 11:49:47,146:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2024-05-29 11:49:49,143:INFO:Creating Dashboard logs
2024-05-29 11:49:49,148:INFO:Model: Decision Tree Classifier
2024-05-29 11:49:49,240:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 1013, 'splitter': 'best'}
2024-05-29 11:49:51,283:INFO:Creating Dashboard logs
2024-05-29 11:49:51,288:INFO:Model: Quadratic Discriminant Analysis
2024-05-29 11:49:51,374:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2024-05-29 11:49:53,231:INFO:Creating Dashboard logs
2024-05-29 11:49:53,235:INFO:Model: Naive Bayes
2024-05-29 11:49:53,320:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-05-29 11:49:55,173:INFO:Creating Dashboard logs
2024-05-29 11:49:55,178:INFO:Model: Dummy Classifier
2024-05-29 11:49:55,301:INFO:Logged params: {'constant': None, 'random_state': 1013, 'strategy': 'prior'}
2024-05-29 11:49:57,297:INFO:_master_model_container: 15
2024-05-29 11:49:57,298:INFO:_display_container: 2
2024-05-29 11:49:57,299:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-29 11:49:57,299:INFO:compare_models() successfully completed......................................
2024-05-29 14:36:56,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-29 14:36:56,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-29 14:36:56,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-29 14:36:56,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-29 15:33:23,675:INFO:PyCaret ClassificationExperiment
2024-05-29 15:33:23,675:INFO:Logging name: codex
2024-05-29 15:33:23,675:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 15:33:23,675:INFO:version 3.3.2
2024-05-29 15:33:23,676:INFO:Initializing setup()
2024-05-29 15:33:23,676:INFO:self.USI: 9da5
2024-05-29 15:33:23,676:INFO:self._variable_keys: {'n_jobs_param', 'fix_imbalance', 'gpu_param', 'memory', 'html_param', 'pipeline', 'exp_name_log', 'target_param', '_ml_usecase', 'fold_groups_param', 'y_train', 'USI', 'is_multiclass', '_available_plots', 'seed', 'log_plots_param', 'exp_id', 'fold_shuffle_param', 'y_test', 'X', 'X_train', 'gpu_n_jobs_param', 'data', 'X_test', 'fold_generator', 'idx', 'logging_param', 'y'}
2024-05-29 15:33:23,676:INFO:Checking environment
2024-05-29 15:33:23,676:INFO:python_version: 3.10.13
2024-05-29 15:33:23,676:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 15:33:23,677:INFO:machine: AMD64
2024-05-29 15:33:23,677:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 15:33:23,677:INFO:Memory: svmem(total=34267656192, available=16309391360, percent=52.4, used=17958264832, free=16309391360)
2024-05-29 15:33:23,677:INFO:Physical Core: 8
2024-05-29 15:33:23,677:INFO:Logical Core: 16
2024-05-29 15:33:23,677:INFO:Checking libraries
2024-05-29 15:33:23,678:INFO:System:
2024-05-29 15:33:23,678:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 15:33:23,678:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 15:33:23,678:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 15:33:23,678:INFO:PyCaret required dependencies:
2024-05-29 15:33:23,756:INFO:                 pip: 23.3
2024-05-29 15:33:23,756:INFO:          setuptools: 68.0.0
2024-05-29 15:33:23,756:INFO:             pycaret: 3.3.2
2024-05-29 15:33:23,756:INFO:             IPython: 8.24.0
2024-05-29 15:33:23,756:INFO:          ipywidgets: 8.1.2
2024-05-29 15:33:23,757:INFO:                tqdm: 4.66.4
2024-05-29 15:33:23,757:INFO:               numpy: 1.26.4
2024-05-29 15:33:23,757:INFO:              pandas: 2.1.4
2024-05-29 15:33:23,757:INFO:              jinja2: 3.1.4
2024-05-29 15:33:23,757:INFO:               scipy: 1.11.4
2024-05-29 15:33:23,757:INFO:              joblib: 1.3.2
2024-05-29 15:33:23,757:INFO:             sklearn: 1.4.2
2024-05-29 15:33:23,757:INFO:                pyod: 1.1.3
2024-05-29 15:33:23,757:INFO:            imblearn: 0.12.2
2024-05-29 15:33:23,757:INFO:   category_encoders: 2.6.3
2024-05-29 15:33:23,757:INFO:            lightgbm: 4.3.0
2024-05-29 15:33:23,758:INFO:               numba: 0.59.1
2024-05-29 15:33:23,758:INFO:            requests: 2.32.2
2024-05-29 15:33:23,758:INFO:          matplotlib: 3.7.5
2024-05-29 15:33:23,758:INFO:          scikitplot: 0.3.7
2024-05-29 15:33:23,758:INFO:         yellowbrick: 1.5
2024-05-29 15:33:23,759:INFO:              plotly: 5.22.0
2024-05-29 15:33:23,759:INFO:    plotly-resampler: Not installed
2024-05-29 15:33:23,759:INFO:             kaleido: 0.2.1
2024-05-29 15:33:23,759:INFO:           schemdraw: 0.15
2024-05-29 15:33:23,759:INFO:         statsmodels: 0.14.2
2024-05-29 15:33:23,760:INFO:              sktime: 0.26.0
2024-05-29 15:33:23,760:INFO:               tbats: 1.1.3
2024-05-29 15:33:23,760:INFO:            pmdarima: 2.0.4
2024-05-29 15:33:23,760:INFO:              psutil: 5.9.0
2024-05-29 15:33:23,760:INFO:          markupsafe: 2.1.5
2024-05-29 15:33:23,761:INFO:             pickle5: Not installed
2024-05-29 15:33:23,761:INFO:         cloudpickle: 3.0.0
2024-05-29 15:33:23,761:INFO:         deprecation: 2.1.0
2024-05-29 15:33:23,761:INFO:              xxhash: 3.4.1
2024-05-29 15:33:23,761:INFO:           wurlitzer: Not installed
2024-05-29 15:33:23,761:INFO:PyCaret optional dependencies:
2024-05-29 15:33:23,789:INFO:                shap: Not installed
2024-05-29 15:33:23,790:INFO:           interpret: Not installed
2024-05-29 15:33:23,790:INFO:                umap: Not installed
2024-05-29 15:33:23,790:INFO:     ydata_profiling: Not installed
2024-05-29 15:33:23,790:INFO:  explainerdashboard: Not installed
2024-05-29 15:33:23,790:INFO:             autoviz: Not installed
2024-05-29 15:33:23,790:INFO:           fairlearn: Not installed
2024-05-29 15:33:23,790:INFO:          deepchecks: Not installed
2024-05-29 15:33:23,790:INFO:             xgboost: 2.0.3
2024-05-29 15:33:23,790:INFO:            catboost: Not installed
2024-05-29 15:33:23,790:INFO:              kmodes: Not installed
2024-05-29 15:33:23,790:INFO:             mlxtend: Not installed
2024-05-29 15:33:23,791:INFO:       statsforecast: Not installed
2024-05-29 15:33:23,791:INFO:        tune_sklearn: Not installed
2024-05-29 15:33:23,791:INFO:                 ray: Not installed
2024-05-29 15:33:23,791:INFO:            hyperopt: 0.2.7
2024-05-29 15:33:23,791:INFO:              optuna: Not installed
2024-05-29 15:33:23,791:INFO:               skopt: Not installed
2024-05-29 15:33:23,791:INFO:              mlflow: 2.13.0
2024-05-29 15:33:23,791:INFO:              gradio: Not installed
2024-05-29 15:33:23,791:INFO:             fastapi: Not installed
2024-05-29 15:33:23,791:INFO:             uvicorn: Not installed
2024-05-29 15:33:23,791:INFO:              m2cgen: Not installed
2024-05-29 15:33:23,792:INFO:           evidently: Not installed
2024-05-29 15:33:23,792:INFO:               fugue: Not installed
2024-05-29 15:33:23,792:INFO:           streamlit: Not installed
2024-05-29 15:33:23,792:INFO:             prophet: Not installed
2024-05-29 15:33:23,792:INFO:None
2024-05-29 15:33:23,792:INFO:Set up data.
2024-05-29 15:33:23,825:INFO:Set up folding strategy.
2024-05-29 15:33:23,825:INFO:Set up train/test split.
2024-05-29 15:33:23,888:INFO:Set up index.
2024-05-29 15:33:23,891:INFO:Assigning column types.
2024-05-29 15:33:23,926:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 15:33:23,999:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 15:33:24,004:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 15:33:24,058:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 15:33:24,063:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 15:33:24,137:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 15:33:24,138:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 15:33:24,184:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 15:33:24,188:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 15:33:24,189:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 15:33:24,263:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 15:33:24,308:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 15:33:24,313:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 15:33:24,387:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 15:33:24,432:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 15:33:24,436:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 15:33:24,437:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 15:33:24,557:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 15:33:24,561:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 15:33:24,680:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 15:33:24,684:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 15:33:24,725:INFO:Finished creating preprocessing pipeline.
2024-05-29 15:33:24,726:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2024-05-29 15:33:24,726:INFO:Creating final display dataframe.
2024-05-29 15:33:24,907:INFO:Setup _display_container:                    Description        Value
0                   Session id         6792
1                       Target       target
2                  Target type       Binary
3          Original data shape  (90000, 18)
4       Transformed data shape  (90000, 18)
5  Transformed train set shape  (72000, 18)
6   Transformed test set shape  (18000, 18)
7             Numeric features           17
2024-05-29 15:33:25,034:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 15:33:25,038:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 15:33:25,162:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 15:33:25,166:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 15:33:25,168:INFO:Logging experiment in loggers
2024-05-29 15:33:25,545:INFO:SubProcess save_model() called ==================================
2024-05-29 15:33:25,545:INFO:Initializing save_model()
2024-05-29 15:33:25,545:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), model_name=C:\Users\Adm\AppData\Local\Temp\tmp7_8zbpd4\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-29 15:33:25,545:INFO:Adding model into prep_pipe
2024-05-29 15:33:25,546:WARNING:Only Model saved as it was a pipeline.
2024-05-29 15:33:25,551:INFO:C:\Users\Adm\AppData\Local\Temp\tmp7_8zbpd4\Transformation Pipeline.pkl saved in current working directory
2024-05-29 15:33:25,551:INFO:Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2024-05-29 15:33:25,551:INFO:save_model() successfully completed......................................
2024-05-29 15:33:27,215:INFO:SubProcess save_model() end ==================================
2024-05-29 15:33:27,240:INFO:setup() successfully completed in 1.55s...............
2024-05-29 15:33:27,240:INFO:Initializing compare_models()
2024-05-29 15:33:27,240:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC4E8BBE0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC4E8BBE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-29 15:33:27,240:INFO:Checking exceptions
2024-05-29 15:33:27,269:INFO:Preparing display monitor
2024-05-29 15:33:27,301:INFO:Initializing Logistic Regression
2024-05-29 15:33:27,302:INFO:Total runtime is 1.717408498128255e-05 minutes
2024-05-29 15:33:27,308:INFO:SubProcess create_model() called ==================================
2024-05-29 15:33:27,308:INFO:Initializing create_model()
2024-05-29 15:33:27,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC4E8BBE0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC41DE440>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 15:33:27,309:INFO:Checking exceptions
2024-05-29 15:33:27,309:INFO:Importing libraries
2024-05-29 15:33:27,309:INFO:Copying training dataset
2024-05-29 15:33:27,366:INFO:Defining folds
2024-05-29 15:33:27,366:INFO:Declaring metric variables
2024-05-29 15:33:27,371:INFO:Importing untrained model
2024-05-29 15:33:27,376:INFO:Logistic Regression Imported successfully
2024-05-29 15:33:27,387:INFO:Starting cross validation
2024-05-29 15:33:27,388:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 15:33:34,251:INFO:Calculating mean and std
2024-05-29 15:33:34,255:INFO:Creating metrics dataframe
2024-05-29 15:33:34,258:INFO:Uploading results into container
2024-05-29 15:33:34,260:INFO:Uploading model into container now
2024-05-29 15:33:34,261:INFO:_master_model_container: 1
2024-05-29 15:33:34,261:INFO:_display_container: 2
2024-05-29 15:33:34,262:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6792, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-29 15:33:34,263:INFO:create_model() successfully completed......................................
2024-05-29 15:33:35,845:INFO:SubProcess create_model() end ==================================
2024-05-29 15:33:35,846:INFO:Creating metrics dataframe
2024-05-29 15:33:35,855:INFO:Initializing K Neighbors Classifier
2024-05-29 15:33:35,855:INFO:Total runtime is 0.14256662925084432 minutes
2024-05-29 15:33:35,859:INFO:SubProcess create_model() called ==================================
2024-05-29 15:33:35,860:INFO:Initializing create_model()
2024-05-29 15:33:35,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC4E8BBE0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC41DE440>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 15:33:35,860:INFO:Checking exceptions
2024-05-29 15:33:35,860:INFO:Importing libraries
2024-05-29 15:33:35,861:INFO:Copying training dataset
2024-05-29 15:33:35,911:INFO:Defining folds
2024-05-29 15:33:35,911:INFO:Declaring metric variables
2024-05-29 15:33:35,916:INFO:Importing untrained model
2024-05-29 15:33:35,921:INFO:K Neighbors Classifier Imported successfully
2024-05-29 15:33:35,930:INFO:Starting cross validation
2024-05-29 15:33:35,931:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 15:33:49,128:INFO:Calculating mean and std
2024-05-29 15:33:49,130:INFO:Creating metrics dataframe
2024-05-29 15:33:49,133:INFO:Uploading results into container
2024-05-29 15:33:49,135:INFO:Uploading model into container now
2024-05-29 15:33:49,135:INFO:_master_model_container: 2
2024-05-29 15:33:49,136:INFO:_display_container: 2
2024-05-29 15:33:49,137:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-29 15:33:49,137:INFO:create_model() successfully completed......................................
2024-05-29 15:33:50,715:INFO:SubProcess create_model() end ==================================
2024-05-29 15:33:50,715:INFO:Creating metrics dataframe
2024-05-29 15:33:50,725:INFO:Initializing Naive Bayes
2024-05-29 15:33:50,725:INFO:Total runtime is 0.3904001235961914 minutes
2024-05-29 15:33:50,729:INFO:SubProcess create_model() called ==================================
2024-05-29 15:33:50,730:INFO:Initializing create_model()
2024-05-29 15:33:50,730:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC4E8BBE0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC41DE440>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 15:33:50,730:INFO:Checking exceptions
2024-05-29 15:33:50,731:INFO:Importing libraries
2024-05-29 15:33:50,731:INFO:Copying training dataset
2024-05-29 15:33:50,781:INFO:Defining folds
2024-05-29 15:33:50,781:INFO:Declaring metric variables
2024-05-29 15:33:50,786:INFO:Importing untrained model
2024-05-29 15:33:50,791:INFO:Naive Bayes Imported successfully
2024-05-29 15:33:50,800:INFO:Starting cross validation
2024-05-29 15:33:50,801:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 15:33:51,088:INFO:Calculating mean and std
2024-05-29 15:33:51,090:INFO:Creating metrics dataframe
2024-05-29 15:33:51,092:INFO:Uploading results into container
2024-05-29 15:33:51,093:INFO:Uploading model into container now
2024-05-29 15:33:51,094:INFO:_master_model_container: 3
2024-05-29 15:33:51,094:INFO:_display_container: 2
2024-05-29 15:33:51,094:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-29 15:33:51,094:INFO:create_model() successfully completed......................................
2024-05-29 15:33:52,768:INFO:SubProcess create_model() end ==================================
2024-05-29 15:33:52,768:INFO:Creating metrics dataframe
2024-05-29 15:33:52,779:INFO:Initializing Decision Tree Classifier
2024-05-29 15:33:52,779:INFO:Total runtime is 0.4246406475702922 minutes
2024-05-29 15:33:52,784:INFO:SubProcess create_model() called ==================================
2024-05-29 15:33:52,785:INFO:Initializing create_model()
2024-05-29 15:33:52,785:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC4E8BBE0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC41DE440>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 15:33:52,786:INFO:Checking exceptions
2024-05-29 15:33:52,786:INFO:Importing libraries
2024-05-29 15:33:52,786:INFO:Copying training dataset
2024-05-29 15:33:52,836:INFO:Defining folds
2024-05-29 15:33:52,836:INFO:Declaring metric variables
2024-05-29 15:33:52,840:INFO:Importing untrained model
2024-05-29 15:33:52,845:INFO:Decision Tree Classifier Imported successfully
2024-05-29 15:33:52,855:INFO:Starting cross validation
2024-05-29 15:33:52,856:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 15:33:53,514:INFO:Calculating mean and std
2024-05-29 15:33:53,516:INFO:Creating metrics dataframe
2024-05-29 15:33:53,519:INFO:Uploading results into container
2024-05-29 15:33:53,520:INFO:Uploading model into container now
2024-05-29 15:33:53,521:INFO:_master_model_container: 4
2024-05-29 15:33:53,521:INFO:_display_container: 2
2024-05-29 15:33:53,522:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=6792, splitter='best')
2024-05-29 15:33:53,522:INFO:create_model() successfully completed......................................
2024-05-29 15:33:55,324:INFO:SubProcess create_model() end ==================================
2024-05-29 15:33:55,325:INFO:Creating metrics dataframe
2024-05-29 15:33:55,335:INFO:Initializing SVM - Linear Kernel
2024-05-29 15:33:55,335:INFO:Total runtime is 0.4672451893488566 minutes
2024-05-29 15:33:55,341:INFO:SubProcess create_model() called ==================================
2024-05-29 15:33:55,342:INFO:Initializing create_model()
2024-05-29 15:33:55,342:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC4E8BBE0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC41DE440>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 15:33:55,342:INFO:Checking exceptions
2024-05-29 15:33:55,342:INFO:Importing libraries
2024-05-29 15:33:55,342:INFO:Copying training dataset
2024-05-29 15:33:55,395:INFO:Defining folds
2024-05-29 15:33:55,396:INFO:Declaring metric variables
2024-05-29 15:33:55,401:INFO:Importing untrained model
2024-05-29 15:33:55,407:INFO:SVM - Linear Kernel Imported successfully
2024-05-29 15:33:55,417:INFO:Starting cross validation
2024-05-29 15:33:55,418:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 15:33:55,908:INFO:Calculating mean and std
2024-05-29 15:33:55,910:INFO:Creating metrics dataframe
2024-05-29 15:33:55,913:INFO:Uploading results into container
2024-05-29 15:33:55,914:INFO:Uploading model into container now
2024-05-29 15:33:55,915:INFO:_master_model_container: 5
2024-05-29 15:33:55,916:INFO:_display_container: 2
2024-05-29 15:33:55,916:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6792, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-29 15:33:55,916:INFO:create_model() successfully completed......................................
2024-05-29 15:33:57,608:INFO:SubProcess create_model() end ==================================
2024-05-29 15:33:57,608:INFO:Creating metrics dataframe
2024-05-29 15:33:57,620:INFO:Initializing Ridge Classifier
2024-05-29 15:33:57,620:INFO:Total runtime is 0.5053175687789917 minutes
2024-05-29 15:33:57,624:INFO:SubProcess create_model() called ==================================
2024-05-29 15:33:57,625:INFO:Initializing create_model()
2024-05-29 15:33:57,625:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC4E8BBE0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC41DE440>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 15:33:57,625:INFO:Checking exceptions
2024-05-29 15:33:57,625:INFO:Importing libraries
2024-05-29 15:33:57,626:INFO:Copying training dataset
2024-05-29 15:33:57,675:INFO:Defining folds
2024-05-29 15:33:57,675:INFO:Declaring metric variables
2024-05-29 15:33:57,680:INFO:Importing untrained model
2024-05-29 15:33:57,686:INFO:Ridge Classifier Imported successfully
2024-05-29 15:33:57,695:INFO:Starting cross validation
2024-05-29 15:33:57,696:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 15:33:57,979:INFO:Calculating mean and std
2024-05-29 15:33:57,981:INFO:Creating metrics dataframe
2024-05-29 15:33:57,984:INFO:Uploading results into container
2024-05-29 15:33:57,985:INFO:Uploading model into container now
2024-05-29 15:33:57,985:INFO:_master_model_container: 6
2024-05-29 15:33:57,985:INFO:_display_container: 2
2024-05-29 15:33:57,986:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6792, solver='auto',
                tol=0.0001)
2024-05-29 15:33:57,987:INFO:create_model() successfully completed......................................
2024-05-29 15:33:59,611:INFO:SubProcess create_model() end ==================================
2024-05-29 15:33:59,611:INFO:Creating metrics dataframe
2024-05-29 15:33:59,624:INFO:Initializing Random Forest Classifier
2024-05-29 15:33:59,625:INFO:Total runtime is 0.5387338002522787 minutes
2024-05-29 15:33:59,629:INFO:SubProcess create_model() called ==================================
2024-05-29 15:33:59,630:INFO:Initializing create_model()
2024-05-29 15:33:59,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC4E8BBE0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC41DE440>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 15:33:59,630:INFO:Checking exceptions
2024-05-29 15:33:59,630:INFO:Importing libraries
2024-05-29 15:33:59,630:INFO:Copying training dataset
2024-05-29 15:33:59,679:INFO:Defining folds
2024-05-29 15:33:59,680:INFO:Declaring metric variables
2024-05-29 15:33:59,685:INFO:Importing untrained model
2024-05-29 15:33:59,690:INFO:Random Forest Classifier Imported successfully
2024-05-29 15:33:59,699:INFO:Starting cross validation
2024-05-29 15:33:59,700:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 15:34:08,147:INFO:Calculating mean and std
2024-05-29 15:34:08,149:INFO:Creating metrics dataframe
2024-05-29 15:34:08,153:INFO:Uploading results into container
2024-05-29 15:34:08,154:INFO:Uploading model into container now
2024-05-29 15:34:08,155:INFO:_master_model_container: 7
2024-05-29 15:34:08,155:INFO:_display_container: 2
2024-05-29 15:34:08,156:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6792, verbose=0,
                       warm_start=False)
2024-05-29 15:34:08,156:INFO:create_model() successfully completed......................................
2024-05-29 15:34:09,926:INFO:SubProcess create_model() end ==================================
2024-05-29 15:34:09,926:INFO:Creating metrics dataframe
2024-05-29 15:34:09,941:INFO:Initializing Quadratic Discriminant Analysis
2024-05-29 15:34:09,941:INFO:Total runtime is 0.7106697281201682 minutes
2024-05-29 15:34:09,946:INFO:SubProcess create_model() called ==================================
2024-05-29 15:34:09,946:INFO:Initializing create_model()
2024-05-29 15:34:09,946:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC4E8BBE0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC41DE440>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 15:34:09,947:INFO:Checking exceptions
2024-05-29 15:34:09,947:INFO:Importing libraries
2024-05-29 15:34:09,947:INFO:Copying training dataset
2024-05-29 15:34:10,000:INFO:Defining folds
2024-05-29 15:34:10,000:INFO:Declaring metric variables
2024-05-29 15:34:10,005:INFO:Importing untrained model
2024-05-29 15:34:10,011:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-29 15:34:10,021:INFO:Starting cross validation
2024-05-29 15:34:10,023:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 15:34:10,414:INFO:Calculating mean and std
2024-05-29 15:34:10,416:INFO:Creating metrics dataframe
2024-05-29 15:34:10,419:INFO:Uploading results into container
2024-05-29 15:34:10,419:INFO:Uploading model into container now
2024-05-29 15:34:10,420:INFO:_master_model_container: 8
2024-05-29 15:34:10,420:INFO:_display_container: 2
2024-05-29 15:34:10,420:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-29 15:34:10,421:INFO:create_model() successfully completed......................................
2024-05-29 15:34:12,112:INFO:SubProcess create_model() end ==================================
2024-05-29 15:34:12,112:INFO:Creating metrics dataframe
2024-05-29 15:34:12,126:INFO:Initializing Ada Boost Classifier
2024-05-29 15:34:12,126:INFO:Total runtime is 0.7470833023389182 minutes
2024-05-29 15:34:12,130:INFO:SubProcess create_model() called ==================================
2024-05-29 15:34:12,131:INFO:Initializing create_model()
2024-05-29 15:34:12,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC4E8BBE0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC41DE440>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 15:34:12,131:INFO:Checking exceptions
2024-05-29 15:34:12,131:INFO:Importing libraries
2024-05-29 15:34:12,132:INFO:Copying training dataset
2024-05-29 15:34:12,181:INFO:Defining folds
2024-05-29 15:34:12,181:INFO:Declaring metric variables
2024-05-29 15:34:12,187:INFO:Importing untrained model
2024-05-29 15:34:12,191:INFO:Ada Boost Classifier Imported successfully
2024-05-29 15:34:12,201:INFO:Starting cross validation
2024-05-29 15:34:12,202:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 15:34:12,260:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 15:34:12,277:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 15:34:12,295:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 15:34:12,310:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 15:34:12,328:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 15:34:12,352:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 15:34:12,367:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 15:34:12,392:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 15:34:12,405:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 15:34:12,425:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 15:34:15,375:INFO:Calculating mean and std
2024-05-29 15:34:15,377:INFO:Creating metrics dataframe
2024-05-29 15:34:15,379:INFO:Uploading results into container
2024-05-29 15:34:15,380:INFO:Uploading model into container now
2024-05-29 15:34:15,380:INFO:_master_model_container: 9
2024-05-29 15:34:15,380:INFO:_display_container: 2
2024-05-29 15:34:15,381:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=6792)
2024-05-29 15:34:15,381:INFO:create_model() successfully completed......................................
2024-05-29 15:34:17,051:INFO:SubProcess create_model() end ==================================
2024-05-29 15:34:17,052:INFO:Creating metrics dataframe
2024-05-29 15:34:17,066:INFO:Initializing Gradient Boosting Classifier
2024-05-29 15:34:17,067:INFO:Total runtime is 0.8294432163238527 minutes
2024-05-29 15:34:17,072:INFO:SubProcess create_model() called ==================================
2024-05-29 15:34:17,072:INFO:Initializing create_model()
2024-05-29 15:34:17,072:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC4E8BBE0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC41DE440>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 15:34:17,072:INFO:Checking exceptions
2024-05-29 15:34:17,073:INFO:Importing libraries
2024-05-29 15:34:17,073:INFO:Copying training dataset
2024-05-29 15:34:17,123:INFO:Defining folds
2024-05-29 15:34:17,124:INFO:Declaring metric variables
2024-05-29 15:34:17,129:INFO:Importing untrained model
2024-05-29 15:34:17,134:INFO:Gradient Boosting Classifier Imported successfully
2024-05-29 15:34:17,145:INFO:Starting cross validation
2024-05-29 15:34:17,146:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 15:34:26,775:INFO:Calculating mean and std
2024-05-29 15:34:26,777:INFO:Creating metrics dataframe
2024-05-29 15:34:26,780:INFO:Uploading results into container
2024-05-29 15:34:26,780:INFO:Uploading model into container now
2024-05-29 15:34:26,781:INFO:_master_model_container: 10
2024-05-29 15:34:26,781:INFO:_display_container: 2
2024-05-29 15:34:26,782:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6792, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-29 15:34:26,782:INFO:create_model() successfully completed......................................
2024-05-29 15:34:28,351:INFO:SubProcess create_model() end ==================================
2024-05-29 15:34:28,351:INFO:Creating metrics dataframe
2024-05-29 15:34:28,365:INFO:Initializing Linear Discriminant Analysis
2024-05-29 15:34:28,365:INFO:Total runtime is 1.0177473187446595 minutes
2024-05-29 15:34:28,370:INFO:SubProcess create_model() called ==================================
2024-05-29 15:34:28,370:INFO:Initializing create_model()
2024-05-29 15:34:28,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC4E8BBE0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC41DE440>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 15:34:28,371:INFO:Checking exceptions
2024-05-29 15:34:28,371:INFO:Importing libraries
2024-05-29 15:34:28,371:INFO:Copying training dataset
2024-05-29 15:34:28,424:INFO:Defining folds
2024-05-29 15:34:28,424:INFO:Declaring metric variables
2024-05-29 15:34:28,429:INFO:Importing untrained model
2024-05-29 15:34:28,435:INFO:Linear Discriminant Analysis Imported successfully
2024-05-29 15:34:28,446:INFO:Starting cross validation
2024-05-29 15:34:28,447:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 15:34:28,774:INFO:Calculating mean and std
2024-05-29 15:34:28,776:INFO:Creating metrics dataframe
2024-05-29 15:34:28,778:INFO:Uploading results into container
2024-05-29 15:34:28,779:INFO:Uploading model into container now
2024-05-29 15:34:28,780:INFO:_master_model_container: 11
2024-05-29 15:34:28,780:INFO:_display_container: 2
2024-05-29 15:34:28,780:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-29 15:34:28,781:INFO:create_model() successfully completed......................................
2024-05-29 15:34:30,430:INFO:SubProcess create_model() end ==================================
2024-05-29 15:34:30,430:INFO:Creating metrics dataframe
2024-05-29 15:34:30,445:INFO:Initializing Extra Trees Classifier
2024-05-29 15:34:30,445:INFO:Total runtime is 1.0524016459782919 minutes
2024-05-29 15:34:30,450:INFO:SubProcess create_model() called ==================================
2024-05-29 15:34:30,450:INFO:Initializing create_model()
2024-05-29 15:34:30,450:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC4E8BBE0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC41DE440>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 15:34:30,451:INFO:Checking exceptions
2024-05-29 15:34:30,451:INFO:Importing libraries
2024-05-29 15:34:30,451:INFO:Copying training dataset
2024-05-29 15:34:30,501:INFO:Defining folds
2024-05-29 15:34:30,501:INFO:Declaring metric variables
2024-05-29 15:34:30,506:INFO:Importing untrained model
2024-05-29 15:34:30,511:INFO:Extra Trees Classifier Imported successfully
2024-05-29 15:34:30,522:INFO:Starting cross validation
2024-05-29 15:34:30,524:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 15:34:39,065:INFO:Calculating mean and std
2024-05-29 15:34:39,067:INFO:Creating metrics dataframe
2024-05-29 15:34:39,072:INFO:Uploading results into container
2024-05-29 15:34:39,073:INFO:Uploading model into container now
2024-05-29 15:34:39,073:INFO:_master_model_container: 12
2024-05-29 15:34:39,074:INFO:_display_container: 2
2024-05-29 15:34:39,074:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=6792, verbose=0,
                     warm_start=False)
2024-05-29 15:34:39,075:INFO:create_model() successfully completed......................................
2024-05-29 15:34:40,808:INFO:SubProcess create_model() end ==================================
2024-05-29 15:34:40,808:INFO:Creating metrics dataframe
2024-05-29 15:34:40,823:INFO:Initializing Extreme Gradient Boosting
2024-05-29 15:34:40,824:INFO:Total runtime is 1.2253863970438639 minutes
2024-05-29 15:34:40,828:INFO:SubProcess create_model() called ==================================
2024-05-29 15:34:40,829:INFO:Initializing create_model()
2024-05-29 15:34:40,829:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC4E8BBE0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC41DE440>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 15:34:40,829:INFO:Checking exceptions
2024-05-29 15:34:40,829:INFO:Importing libraries
2024-05-29 15:34:40,829:INFO:Copying training dataset
2024-05-29 15:34:40,881:INFO:Defining folds
2024-05-29 15:34:40,882:INFO:Declaring metric variables
2024-05-29 15:34:40,888:INFO:Importing untrained model
2024-05-29 15:34:40,894:INFO:Extreme Gradient Boosting Imported successfully
2024-05-29 15:34:40,906:INFO:Starting cross validation
2024-05-29 15:34:40,907:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 15:34:42,436:INFO:Calculating mean and std
2024-05-29 15:34:42,438:INFO:Creating metrics dataframe
2024-05-29 15:34:42,440:INFO:Uploading results into container
2024-05-29 15:34:42,441:INFO:Uploading model into container now
2024-05-29 15:34:42,442:INFO:_master_model_container: 13
2024-05-29 15:34:42,442:INFO:_display_container: 2
2024-05-29 15:34:42,443:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-29 15:34:42,443:INFO:create_model() successfully completed......................................
2024-05-29 15:34:44,049:INFO:SubProcess create_model() end ==================================
2024-05-29 15:34:44,049:INFO:Creating metrics dataframe
2024-05-29 15:34:44,065:INFO:Initializing Light Gradient Boosting Machine
2024-05-29 15:34:44,065:INFO:Total runtime is 1.279401687781016 minutes
2024-05-29 15:34:44,070:INFO:SubProcess create_model() called ==================================
2024-05-29 15:34:44,071:INFO:Initializing create_model()
2024-05-29 15:34:44,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC4E8BBE0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC41DE440>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 15:34:44,071:INFO:Checking exceptions
2024-05-29 15:34:44,071:INFO:Importing libraries
2024-05-29 15:34:44,071:INFO:Copying training dataset
2024-05-29 15:34:44,120:INFO:Defining folds
2024-05-29 15:34:44,120:INFO:Declaring metric variables
2024-05-29 15:34:44,125:INFO:Importing untrained model
2024-05-29 15:34:44,131:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-29 15:34:44,141:INFO:Starting cross validation
2024-05-29 15:34:44,142:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 15:34:46,440:INFO:Calculating mean and std
2024-05-29 15:34:46,442:INFO:Creating metrics dataframe
2024-05-29 15:34:46,446:INFO:Uploading results into container
2024-05-29 15:34:46,447:INFO:Uploading model into container now
2024-05-29 15:34:46,448:INFO:_master_model_container: 14
2024-05-29 15:34:46,448:INFO:_display_container: 2
2024-05-29 15:34:46,449:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6792, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-29 15:34:46,449:INFO:create_model() successfully completed......................................
2024-05-29 15:34:48,150:INFO:SubProcess create_model() end ==================================
2024-05-29 15:34:48,151:INFO:Creating metrics dataframe
2024-05-29 15:34:48,167:INFO:Initializing Dummy Classifier
2024-05-29 15:34:48,167:INFO:Total runtime is 1.347778304417928 minutes
2024-05-29 15:34:48,172:INFO:SubProcess create_model() called ==================================
2024-05-29 15:34:48,173:INFO:Initializing create_model()
2024-05-29 15:34:48,173:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC4E8BBE0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC41DE440>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 15:34:48,173:INFO:Checking exceptions
2024-05-29 15:34:48,173:INFO:Importing libraries
2024-05-29 15:34:48,173:INFO:Copying training dataset
2024-05-29 15:34:48,224:INFO:Defining folds
2024-05-29 15:34:48,224:INFO:Declaring metric variables
2024-05-29 15:34:48,230:INFO:Importing untrained model
2024-05-29 15:34:48,235:INFO:Dummy Classifier Imported successfully
2024-05-29 15:34:48,245:INFO:Starting cross validation
2024-05-29 15:34:48,247:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 15:34:48,329:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 15:34:48,350:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 15:34:48,363:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 15:34:48,391:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 15:34:48,405:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 15:34:48,425:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 15:34:48,438:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 15:34:48,462:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 15:34:48,480:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 15:34:48,492:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 15:34:48,513:INFO:Calculating mean and std
2024-05-29 15:34:48,515:INFO:Creating metrics dataframe
2024-05-29 15:34:48,517:INFO:Uploading results into container
2024-05-29 15:34:48,518:INFO:Uploading model into container now
2024-05-29 15:34:48,519:INFO:_master_model_container: 15
2024-05-29 15:34:48,519:INFO:_display_container: 2
2024-05-29 15:34:48,519:INFO:DummyClassifier(constant=None, random_state=6792, strategy='prior')
2024-05-29 15:34:48,520:INFO:create_model() successfully completed......................................
2024-05-29 15:34:50,254:INFO:SubProcess create_model() end ==================================
2024-05-29 15:34:50,254:INFO:Creating metrics dataframe
2024-05-29 15:34:50,275:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-29 15:34:50,286:INFO:Initializing create_model()
2024-05-29 15:34:50,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC4E8BBE0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 15:34:50,287:INFO:Checking exceptions
2024-05-29 15:34:50,289:INFO:Importing libraries
2024-05-29 15:34:50,289:INFO:Copying training dataset
2024-05-29 15:34:50,336:INFO:Defining folds
2024-05-29 15:34:50,337:INFO:Declaring metric variables
2024-05-29 15:34:50,337:INFO:Importing untrained model
2024-05-29 15:34:50,337:INFO:Declaring custom model
2024-05-29 15:34:50,339:INFO:Extreme Gradient Boosting Imported successfully
2024-05-29 15:34:50,340:INFO:Cross validation set to False
2024-05-29 15:34:50,340:INFO:Fitting Model
2024-05-29 15:34:50,665:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-29 15:34:50,665:INFO:create_model() successfully completed......................................
2024-05-29 15:34:52,295:INFO:Creating Dashboard logs
2024-05-29 15:34:52,300:INFO:Model: Extreme Gradient Boosting
2024-05-29 15:34:52,404:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 6792, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2024-05-29 15:34:52,677:INFO:Initializing predict_model()
2024-05-29 15:34:52,678:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC4E8BBE0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AC09FFF760>)
2024-05-29 15:34:52,678:INFO:Checking exceptions
2024-05-29 15:34:52,678:INFO:Preloading libraries
2024-05-29 15:34:54,550:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2024-05-29 15:34:58,133:INFO:Creating Dashboard logs
2024-05-29 15:34:58,138:INFO:Model: Light Gradient Boosting Machine
2024-05-29 15:34:58,226:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 6792, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-05-29 15:35:00,143:INFO:Creating Dashboard logs
2024-05-29 15:35:00,148:INFO:Model: Random Forest Classifier
2024-05-29 15:35:00,234:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 6792, 'verbose': 0, 'warm_start': False}
2024-05-29 15:35:02,417:INFO:Creating Dashboard logs
2024-05-29 15:35:02,423:INFO:Model: Gradient Boosting Classifier
2024-05-29 15:35:02,521:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 6792, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-29 15:35:04,582:INFO:Creating Dashboard logs
2024-05-29 15:35:04,587:INFO:Model: Extra Trees Classifier
2024-05-29 15:35:04,677:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 6792, 'verbose': 0, 'warm_start': False}
2024-05-29 15:35:06,741:INFO:Creating Dashboard logs
2024-05-29 15:35:06,746:INFO:Model: Ada Boost Classifier
2024-05-29 15:35:06,837:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 6792}
2024-05-29 15:35:08,709:INFO:Creating Dashboard logs
2024-05-29 15:35:08,713:INFO:Model: Logistic Regression
2024-05-29 15:35:08,801:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 6792, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-05-29 15:35:10,726:INFO:Creating Dashboard logs
2024-05-29 15:35:10,731:INFO:Model: SVM - Linear Kernel
2024-05-29 15:35:10,826:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 6792, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-29 15:35:12,939:INFO:Creating Dashboard logs
2024-05-29 15:35:12,944:INFO:Model: Ridge Classifier
2024-05-29 15:35:13,033:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 6792, 'solver': 'auto', 'tol': 0.0001}
2024-05-29 15:35:14,975:INFO:Creating Dashboard logs
2024-05-29 15:35:14,980:INFO:Model: Linear Discriminant Analysis
2024-05-29 15:35:15,066:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-05-29 15:35:16,939:INFO:Creating Dashboard logs
2024-05-29 15:35:16,944:INFO:Model: K Neighbors Classifier
2024-05-29 15:35:17,030:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2024-05-29 15:35:18,917:INFO:Creating Dashboard logs
2024-05-29 15:35:18,922:INFO:Model: Decision Tree Classifier
2024-05-29 15:35:19,017:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 6792, 'splitter': 'best'}
2024-05-29 15:35:21,042:INFO:Creating Dashboard logs
2024-05-29 15:35:21,047:INFO:Model: Quadratic Discriminant Analysis
2024-05-29 15:35:21,138:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2024-05-29 15:35:23,121:INFO:Creating Dashboard logs
2024-05-29 15:35:23,125:INFO:Model: Naive Bayes
2024-05-29 15:35:23,211:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-05-29 15:35:25,068:INFO:Creating Dashboard logs
2024-05-29 15:35:25,072:INFO:Model: Dummy Classifier
2024-05-29 15:35:25,158:INFO:Logged params: {'constant': None, 'random_state': 6792, 'strategy': 'prior'}
2024-05-29 15:35:27,120:INFO:_master_model_container: 15
2024-05-29 15:35:27,121:INFO:_display_container: 2
2024-05-29 15:35:27,122:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-29 15:35:27,123:INFO:compare_models() successfully completed......................................
2024-05-29 16:38:52,980:INFO:PyCaret ClassificationExperiment
2024-05-29 16:38:52,981:INFO:Logging name: codex
2024-05-29 16:38:52,981:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 16:38:52,981:INFO:version 3.3.2
2024-05-29 16:38:52,981:INFO:Initializing setup()
2024-05-29 16:38:52,981:INFO:self.USI: 45a4
2024-05-29 16:38:52,981:INFO:self._variable_keys: {'n_jobs_param', 'fix_imbalance', 'gpu_param', 'memory', 'html_param', 'pipeline', 'exp_name_log', 'target_param', '_ml_usecase', 'fold_groups_param', 'y_train', 'USI', 'is_multiclass', '_available_plots', 'seed', 'log_plots_param', 'exp_id', 'fold_shuffle_param', 'y_test', 'X', 'X_train', 'gpu_n_jobs_param', 'data', 'X_test', 'fold_generator', 'idx', 'logging_param', 'y'}
2024-05-29 16:38:52,981:INFO:Checking environment
2024-05-29 16:38:52,982:INFO:python_version: 3.10.13
2024-05-29 16:38:52,982:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 16:38:52,982:INFO:machine: AMD64
2024-05-29 16:38:52,982:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 16:38:52,982:INFO:Memory: svmem(total=34267656192, available=16936673280, percent=50.6, used=17330982912, free=16936673280)
2024-05-29 16:38:52,982:INFO:Physical Core: 8
2024-05-29 16:38:52,982:INFO:Logical Core: 16
2024-05-29 16:38:52,982:INFO:Checking libraries
2024-05-29 16:38:52,982:INFO:System:
2024-05-29 16:38:52,982:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 16:38:52,983:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 16:38:52,983:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 16:38:52,983:INFO:PyCaret required dependencies:
2024-05-29 16:38:52,983:INFO:                 pip: 23.3
2024-05-29 16:38:52,983:INFO:          setuptools: 68.0.0
2024-05-29 16:38:52,984:INFO:             pycaret: 3.3.2
2024-05-29 16:38:52,984:INFO:             IPython: 8.24.0
2024-05-29 16:38:52,984:INFO:          ipywidgets: 8.1.2
2024-05-29 16:38:52,984:INFO:                tqdm: 4.66.4
2024-05-29 16:38:52,984:INFO:               numpy: 1.26.4
2024-05-29 16:38:52,984:INFO:              pandas: 2.1.4
2024-05-29 16:38:52,984:INFO:              jinja2: 3.1.4
2024-05-29 16:38:52,984:INFO:               scipy: 1.11.4
2024-05-29 16:38:52,984:INFO:              joblib: 1.3.2
2024-05-29 16:38:52,985:INFO:             sklearn: 1.4.2
2024-05-29 16:38:52,985:INFO:                pyod: 1.1.3
2024-05-29 16:38:52,985:INFO:            imblearn: 0.12.2
2024-05-29 16:38:52,985:INFO:   category_encoders: 2.6.3
2024-05-29 16:38:52,985:INFO:            lightgbm: 4.3.0
2024-05-29 16:38:52,985:INFO:               numba: 0.59.1
2024-05-29 16:38:52,985:INFO:            requests: 2.32.2
2024-05-29 16:38:52,985:INFO:          matplotlib: 3.7.5
2024-05-29 16:38:52,985:INFO:          scikitplot: 0.3.7
2024-05-29 16:38:52,985:INFO:         yellowbrick: 1.5
2024-05-29 16:38:52,985:INFO:              plotly: 5.22.0
2024-05-29 16:38:52,985:INFO:    plotly-resampler: Not installed
2024-05-29 16:38:52,986:INFO:             kaleido: 0.2.1
2024-05-29 16:38:52,986:INFO:           schemdraw: 0.15
2024-05-29 16:38:52,986:INFO:         statsmodels: 0.14.2
2024-05-29 16:38:52,986:INFO:              sktime: 0.26.0
2024-05-29 16:38:52,986:INFO:               tbats: 1.1.3
2024-05-29 16:38:52,986:INFO:            pmdarima: 2.0.4
2024-05-29 16:38:52,986:INFO:              psutil: 5.9.0
2024-05-29 16:38:52,986:INFO:          markupsafe: 2.1.5
2024-05-29 16:38:52,986:INFO:             pickle5: Not installed
2024-05-29 16:38:52,986:INFO:         cloudpickle: 3.0.0
2024-05-29 16:38:52,987:INFO:         deprecation: 2.1.0
2024-05-29 16:38:52,987:INFO:              xxhash: 3.4.1
2024-05-29 16:38:52,987:INFO:           wurlitzer: Not installed
2024-05-29 16:38:52,987:INFO:PyCaret optional dependencies:
2024-05-29 16:38:52,987:INFO:                shap: Not installed
2024-05-29 16:38:52,987:INFO:           interpret: Not installed
2024-05-29 16:38:52,987:INFO:                umap: Not installed
2024-05-29 16:38:52,987:INFO:     ydata_profiling: Not installed
2024-05-29 16:38:52,988:INFO:  explainerdashboard: Not installed
2024-05-29 16:38:52,988:INFO:             autoviz: Not installed
2024-05-29 16:38:52,988:INFO:           fairlearn: Not installed
2024-05-29 16:38:52,988:INFO:          deepchecks: Not installed
2024-05-29 16:38:52,988:INFO:             xgboost: 2.0.3
2024-05-29 16:38:52,988:INFO:            catboost: Not installed
2024-05-29 16:38:52,988:INFO:              kmodes: Not installed
2024-05-29 16:38:52,988:INFO:             mlxtend: Not installed
2024-05-29 16:38:52,988:INFO:       statsforecast: Not installed
2024-05-29 16:38:52,988:INFO:        tune_sklearn: Not installed
2024-05-29 16:38:52,988:INFO:                 ray: Not installed
2024-05-29 16:38:52,989:INFO:            hyperopt: 0.2.7
2024-05-29 16:38:52,989:INFO:              optuna: Not installed
2024-05-29 16:38:52,989:INFO:               skopt: Not installed
2024-05-29 16:38:52,989:INFO:              mlflow: 2.13.0
2024-05-29 16:38:52,989:INFO:              gradio: Not installed
2024-05-29 16:38:52,989:INFO:             fastapi: Not installed
2024-05-29 16:38:52,989:INFO:             uvicorn: Not installed
2024-05-29 16:38:52,989:INFO:              m2cgen: Not installed
2024-05-29 16:38:52,989:INFO:           evidently: Not installed
2024-05-29 16:38:52,990:INFO:               fugue: Not installed
2024-05-29 16:38:52,990:INFO:           streamlit: Not installed
2024-05-29 16:38:52,990:INFO:             prophet: Not installed
2024-05-29 16:38:52,990:INFO:None
2024-05-29 16:38:52,990:INFO:Set up data.
2024-05-29 16:38:53,020:INFO:Set up folding strategy.
2024-05-29 16:38:53,020:INFO:Set up train/test split.
2024-05-29 16:38:53,080:INFO:Set up index.
2024-05-29 16:38:53,082:INFO:Assigning column types.
2024-05-29 16:38:53,117:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 16:38:53,191:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 16:38:53,192:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 16:38:53,238:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 16:38:53,242:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 16:38:53,315:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 16:38:53,316:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 16:38:53,362:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 16:38:53,366:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 16:38:53,367:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 16:38:53,446:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 16:38:53,496:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 16:38:53,501:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 16:38:53,577:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 16:38:53,623:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 16:38:53,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 16:38:53,628:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 16:38:53,747:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 16:38:53,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 16:38:53,869:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 16:38:53,874:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 16:38:53,911:INFO:Finished creating preprocessing pipeline.
2024-05-29 16:38:53,912:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2024-05-29 16:38:53,912:INFO:Creating final display dataframe.
2024-05-29 16:38:54,081:INFO:Setup _display_container:                    Description        Value
0                   Session id         3492
1                       Target       target
2                  Target type       Binary
3          Original data shape  (90000, 18)
4       Transformed data shape  (90000, 18)
5  Transformed train set shape  (72000, 18)
6   Transformed test set shape  (18000, 18)
7             Numeric features           17
2024-05-29 16:38:54,227:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 16:38:54,232:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 16:38:54,352:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 16:38:54,357:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 16:38:54,359:INFO:Logging experiment in loggers
2024-05-29 16:38:54,508:INFO:SubProcess save_model() called ==================================
2024-05-29 16:38:54,509:INFO:Initializing save_model()
2024-05-29 16:38:54,509:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), model_name=C:\Users\Adm\AppData\Local\Temp\tmpuzxe1i6w\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-29 16:38:54,509:INFO:Adding model into prep_pipe
2024-05-29 16:38:54,509:WARNING:Only Model saved as it was a pipeline.
2024-05-29 16:38:54,514:INFO:C:\Users\Adm\AppData\Local\Temp\tmpuzxe1i6w\Transformation Pipeline.pkl saved in current working directory
2024-05-29 16:38:54,515:INFO:Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2024-05-29 16:38:54,515:INFO:save_model() successfully completed......................................
2024-05-29 16:38:56,313:INFO:SubProcess save_model() end ==================================
2024-05-29 16:38:56,335:INFO:setup() successfully completed in 1.42s...............
2024-05-29 16:38:56,380:INFO:Initializing compare_models()
2024-05-29 16:38:56,380:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC0FD36D0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC0FD36D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-29 16:38:56,381:INFO:Checking exceptions
2024-05-29 16:38:56,408:INFO:Preparing display monitor
2024-05-29 16:38:56,438:INFO:Initializing Logistic Regression
2024-05-29 16:38:56,438:INFO:Total runtime is 0.0 minutes
2024-05-29 16:38:56,444:INFO:SubProcess create_model() called ==================================
2024-05-29 16:38:56,444:INFO:Initializing create_model()
2024-05-29 16:38:56,445:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC0FD36D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC4131A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:38:56,445:INFO:Checking exceptions
2024-05-29 16:38:56,445:INFO:Importing libraries
2024-05-29 16:38:56,445:INFO:Copying training dataset
2024-05-29 16:38:56,493:INFO:Defining folds
2024-05-29 16:38:56,493:INFO:Declaring metric variables
2024-05-29 16:38:56,498:INFO:Importing untrained model
2024-05-29 16:38:56,503:INFO:Logistic Regression Imported successfully
2024-05-29 16:38:56,512:INFO:Starting cross validation
2024-05-29 16:38:56,513:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:39:03,030:INFO:Calculating mean and std
2024-05-29 16:39:03,033:INFO:Creating metrics dataframe
2024-05-29 16:39:03,035:INFO:Uploading results into container
2024-05-29 16:39:03,036:INFO:Uploading model into container now
2024-05-29 16:39:03,037:INFO:_master_model_container: 1
2024-05-29 16:39:03,037:INFO:_display_container: 2
2024-05-29 16:39:03,038:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3492, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-29 16:39:03,038:INFO:create_model() successfully completed......................................
2024-05-29 16:39:04,596:INFO:SubProcess create_model() end ==================================
2024-05-29 16:39:04,596:INFO:Creating metrics dataframe
2024-05-29 16:39:04,605:INFO:Initializing K Neighbors Classifier
2024-05-29 16:39:04,605:INFO:Total runtime is 0.13611645301183065 minutes
2024-05-29 16:39:04,610:INFO:SubProcess create_model() called ==================================
2024-05-29 16:39:04,610:INFO:Initializing create_model()
2024-05-29 16:39:04,610:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC0FD36D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC4131A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:39:04,610:INFO:Checking exceptions
2024-05-29 16:39:04,612:INFO:Importing libraries
2024-05-29 16:39:04,612:INFO:Copying training dataset
2024-05-29 16:39:04,658:INFO:Defining folds
2024-05-29 16:39:04,659:INFO:Declaring metric variables
2024-05-29 16:39:04,663:INFO:Importing untrained model
2024-05-29 16:39:04,668:INFO:K Neighbors Classifier Imported successfully
2024-05-29 16:39:04,679:INFO:Starting cross validation
2024-05-29 16:39:04,680:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:39:17,425:INFO:Calculating mean and std
2024-05-29 16:39:17,426:INFO:Creating metrics dataframe
2024-05-29 16:39:17,429:INFO:Uploading results into container
2024-05-29 16:39:17,430:INFO:Uploading model into container now
2024-05-29 16:39:17,431:INFO:_master_model_container: 2
2024-05-29 16:39:17,431:INFO:_display_container: 2
2024-05-29 16:39:17,431:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-29 16:39:17,433:INFO:create_model() successfully completed......................................
2024-05-29 16:39:19,009:INFO:SubProcess create_model() end ==================================
2024-05-29 16:39:19,009:INFO:Creating metrics dataframe
2024-05-29 16:39:19,019:INFO:Initializing Naive Bayes
2024-05-29 16:39:19,019:INFO:Total runtime is 0.3763510545094808 minutes
2024-05-29 16:39:19,024:INFO:SubProcess create_model() called ==================================
2024-05-29 16:39:19,024:INFO:Initializing create_model()
2024-05-29 16:39:19,024:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC0FD36D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC4131A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:39:19,025:INFO:Checking exceptions
2024-05-29 16:39:19,025:INFO:Importing libraries
2024-05-29 16:39:19,025:INFO:Copying training dataset
2024-05-29 16:39:19,072:INFO:Defining folds
2024-05-29 16:39:19,072:INFO:Declaring metric variables
2024-05-29 16:39:19,077:INFO:Importing untrained model
2024-05-29 16:39:19,081:INFO:Naive Bayes Imported successfully
2024-05-29 16:39:19,091:INFO:Starting cross validation
2024-05-29 16:39:19,092:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:39:19,373:INFO:Calculating mean and std
2024-05-29 16:39:19,375:INFO:Creating metrics dataframe
2024-05-29 16:39:19,377:INFO:Uploading results into container
2024-05-29 16:39:19,378:INFO:Uploading model into container now
2024-05-29 16:39:19,379:INFO:_master_model_container: 3
2024-05-29 16:39:19,379:INFO:_display_container: 2
2024-05-29 16:39:19,379:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-29 16:39:19,380:INFO:create_model() successfully completed......................................
2024-05-29 16:39:21,047:INFO:SubProcess create_model() end ==================================
2024-05-29 16:39:21,048:INFO:Creating metrics dataframe
2024-05-29 16:39:21,058:INFO:Initializing Decision Tree Classifier
2024-05-29 16:39:21,058:INFO:Total runtime is 0.41033284664154057 minutes
2024-05-29 16:39:21,063:INFO:SubProcess create_model() called ==================================
2024-05-29 16:39:21,063:INFO:Initializing create_model()
2024-05-29 16:39:21,063:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC0FD36D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC4131A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:39:21,063:INFO:Checking exceptions
2024-05-29 16:39:21,064:INFO:Importing libraries
2024-05-29 16:39:21,064:INFO:Copying training dataset
2024-05-29 16:39:21,114:INFO:Defining folds
2024-05-29 16:39:21,114:INFO:Declaring metric variables
2024-05-29 16:39:21,119:INFO:Importing untrained model
2024-05-29 16:39:21,125:INFO:Decision Tree Classifier Imported successfully
2024-05-29 16:39:21,134:INFO:Starting cross validation
2024-05-29 16:39:21,135:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:39:21,721:INFO:Calculating mean and std
2024-05-29 16:39:21,723:INFO:Creating metrics dataframe
2024-05-29 16:39:21,725:INFO:Uploading results into container
2024-05-29 16:39:21,726:INFO:Uploading model into container now
2024-05-29 16:39:21,727:INFO:_master_model_container: 4
2024-05-29 16:39:21,727:INFO:_display_container: 2
2024-05-29 16:39:21,728:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3492, splitter='best')
2024-05-29 16:39:21,728:INFO:create_model() successfully completed......................................
2024-05-29 16:39:23,369:INFO:SubProcess create_model() end ==================================
2024-05-29 16:39:23,369:INFO:Creating metrics dataframe
2024-05-29 16:39:23,379:INFO:Initializing SVM - Linear Kernel
2024-05-29 16:39:23,380:INFO:Total runtime is 0.44903344313303634 minutes
2024-05-29 16:39:23,384:INFO:SubProcess create_model() called ==================================
2024-05-29 16:39:23,385:INFO:Initializing create_model()
2024-05-29 16:39:23,385:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC0FD36D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC4131A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:39:23,385:INFO:Checking exceptions
2024-05-29 16:39:23,385:INFO:Importing libraries
2024-05-29 16:39:23,386:INFO:Copying training dataset
2024-05-29 16:39:23,433:INFO:Defining folds
2024-05-29 16:39:23,433:INFO:Declaring metric variables
2024-05-29 16:39:23,438:INFO:Importing untrained model
2024-05-29 16:39:23,443:INFO:SVM - Linear Kernel Imported successfully
2024-05-29 16:39:23,453:INFO:Starting cross validation
2024-05-29 16:39:23,454:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:39:23,926:INFO:Calculating mean and std
2024-05-29 16:39:23,928:INFO:Creating metrics dataframe
2024-05-29 16:39:23,930:INFO:Uploading results into container
2024-05-29 16:39:23,931:INFO:Uploading model into container now
2024-05-29 16:39:23,931:INFO:_master_model_container: 5
2024-05-29 16:39:23,932:INFO:_display_container: 2
2024-05-29 16:39:23,932:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3492, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-29 16:39:23,933:INFO:create_model() successfully completed......................................
2024-05-29 16:39:25,571:INFO:SubProcess create_model() end ==================================
2024-05-29 16:39:25,571:INFO:Creating metrics dataframe
2024-05-29 16:39:25,583:INFO:Initializing Ridge Classifier
2024-05-29 16:39:25,583:INFO:Total runtime is 0.4857510169347128 minutes
2024-05-29 16:39:25,587:INFO:SubProcess create_model() called ==================================
2024-05-29 16:39:25,588:INFO:Initializing create_model()
2024-05-29 16:39:25,588:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC0FD36D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC4131A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:39:25,588:INFO:Checking exceptions
2024-05-29 16:39:25,588:INFO:Importing libraries
2024-05-29 16:39:25,588:INFO:Copying training dataset
2024-05-29 16:39:25,638:INFO:Defining folds
2024-05-29 16:39:25,639:INFO:Declaring metric variables
2024-05-29 16:39:25,643:INFO:Importing untrained model
2024-05-29 16:39:25,648:INFO:Ridge Classifier Imported successfully
2024-05-29 16:39:25,658:INFO:Starting cross validation
2024-05-29 16:39:25,659:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:39:25,925:INFO:Calculating mean and std
2024-05-29 16:39:25,927:INFO:Creating metrics dataframe
2024-05-29 16:39:25,929:INFO:Uploading results into container
2024-05-29 16:39:25,930:INFO:Uploading model into container now
2024-05-29 16:39:25,931:INFO:_master_model_container: 6
2024-05-29 16:39:25,931:INFO:_display_container: 2
2024-05-29 16:39:25,932:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3492, solver='auto',
                tol=0.0001)
2024-05-29 16:39:25,932:INFO:create_model() successfully completed......................................
2024-05-29 16:39:27,602:INFO:SubProcess create_model() end ==================================
2024-05-29 16:39:27,604:INFO:Creating metrics dataframe
2024-05-29 16:39:27,615:INFO:Initializing Random Forest Classifier
2024-05-29 16:39:27,615:INFO:Total runtime is 0.5196140050888062 minutes
2024-05-29 16:39:27,620:INFO:SubProcess create_model() called ==================================
2024-05-29 16:39:27,620:INFO:Initializing create_model()
2024-05-29 16:39:27,620:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC0FD36D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC4131A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:39:27,620:INFO:Checking exceptions
2024-05-29 16:39:27,621:INFO:Importing libraries
2024-05-29 16:39:27,621:INFO:Copying training dataset
2024-05-29 16:39:27,670:INFO:Defining folds
2024-05-29 16:39:27,671:INFO:Declaring metric variables
2024-05-29 16:39:27,675:INFO:Importing untrained model
2024-05-29 16:39:27,681:INFO:Random Forest Classifier Imported successfully
2024-05-29 16:39:27,690:INFO:Starting cross validation
2024-05-29 16:39:27,691:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:39:36,026:INFO:Calculating mean and std
2024-05-29 16:39:36,029:INFO:Creating metrics dataframe
2024-05-29 16:39:36,033:INFO:Uploading results into container
2024-05-29 16:39:36,034:INFO:Uploading model into container now
2024-05-29 16:39:36,035:INFO:_master_model_container: 7
2024-05-29 16:39:36,035:INFO:_display_container: 2
2024-05-29 16:39:36,036:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3492, verbose=0,
                       warm_start=False)
2024-05-29 16:39:36,036:INFO:create_model() successfully completed......................................
2024-05-29 16:39:37,599:INFO:SubProcess create_model() end ==================================
2024-05-29 16:39:37,599:INFO:Creating metrics dataframe
2024-05-29 16:39:37,612:INFO:Initializing Quadratic Discriminant Analysis
2024-05-29 16:39:37,612:INFO:Total runtime is 0.6862318754196167 minutes
2024-05-29 16:39:37,617:INFO:SubProcess create_model() called ==================================
2024-05-29 16:39:37,617:INFO:Initializing create_model()
2024-05-29 16:39:37,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC0FD36D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC4131A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:39:37,618:INFO:Checking exceptions
2024-05-29 16:39:37,618:INFO:Importing libraries
2024-05-29 16:39:37,618:INFO:Copying training dataset
2024-05-29 16:39:37,666:INFO:Defining folds
2024-05-29 16:39:37,666:INFO:Declaring metric variables
2024-05-29 16:39:37,672:INFO:Importing untrained model
2024-05-29 16:39:37,677:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-29 16:39:37,686:INFO:Starting cross validation
2024-05-29 16:39:37,687:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:39:38,115:INFO:Calculating mean and std
2024-05-29 16:39:38,117:INFO:Creating metrics dataframe
2024-05-29 16:39:38,120:INFO:Uploading results into container
2024-05-29 16:39:38,121:INFO:Uploading model into container now
2024-05-29 16:39:38,121:INFO:_master_model_container: 8
2024-05-29 16:39:38,121:INFO:_display_container: 2
2024-05-29 16:39:38,122:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-29 16:39:38,122:INFO:create_model() successfully completed......................................
2024-05-29 16:39:39,926:INFO:SubProcess create_model() end ==================================
2024-05-29 16:39:39,927:INFO:Creating metrics dataframe
2024-05-29 16:39:39,939:INFO:Initializing Ada Boost Classifier
2024-05-29 16:39:39,940:INFO:Total runtime is 0.7250300606091817 minutes
2024-05-29 16:39:39,944:INFO:SubProcess create_model() called ==================================
2024-05-29 16:39:39,945:INFO:Initializing create_model()
2024-05-29 16:39:39,945:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC0FD36D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC4131A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:39:39,945:INFO:Checking exceptions
2024-05-29 16:39:39,945:INFO:Importing libraries
2024-05-29 16:39:39,946:INFO:Copying training dataset
2024-05-29 16:39:39,996:INFO:Defining folds
2024-05-29 16:39:39,996:INFO:Declaring metric variables
2024-05-29 16:39:40,001:INFO:Importing untrained model
2024-05-29 16:39:40,006:INFO:Ada Boost Classifier Imported successfully
2024-05-29 16:39:40,015:INFO:Starting cross validation
2024-05-29 16:39:40,017:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:39:40,076:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 16:39:40,096:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 16:39:40,115:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 16:39:40,130:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 16:39:40,154:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 16:39:40,171:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 16:39:40,190:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 16:39:40,222:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 16:39:40,245:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 16:39:40,264:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 16:39:43,433:INFO:Calculating mean and std
2024-05-29 16:39:43,435:INFO:Creating metrics dataframe
2024-05-29 16:39:43,437:INFO:Uploading results into container
2024-05-29 16:39:43,438:INFO:Uploading model into container now
2024-05-29 16:39:43,438:INFO:_master_model_container: 9
2024-05-29 16:39:43,438:INFO:_display_container: 2
2024-05-29 16:39:43,439:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3492)
2024-05-29 16:39:43,439:INFO:create_model() successfully completed......................................
2024-05-29 16:39:45,038:INFO:SubProcess create_model() end ==================================
2024-05-29 16:39:45,039:INFO:Creating metrics dataframe
2024-05-29 16:39:45,052:INFO:Initializing Gradient Boosting Classifier
2024-05-29 16:39:45,052:INFO:Total runtime is 0.8102322459220886 minutes
2024-05-29 16:39:45,056:INFO:SubProcess create_model() called ==================================
2024-05-29 16:39:45,057:INFO:Initializing create_model()
2024-05-29 16:39:45,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC0FD36D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC4131A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:39:45,057:INFO:Checking exceptions
2024-05-29 16:39:45,058:INFO:Importing libraries
2024-05-29 16:39:45,058:INFO:Copying training dataset
2024-05-29 16:39:45,105:INFO:Defining folds
2024-05-29 16:39:45,106:INFO:Declaring metric variables
2024-05-29 16:39:45,110:INFO:Importing untrained model
2024-05-29 16:39:45,116:INFO:Gradient Boosting Classifier Imported successfully
2024-05-29 16:39:45,125:INFO:Starting cross validation
2024-05-29 16:39:45,126:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:39:55,349:INFO:Calculating mean and std
2024-05-29 16:39:55,351:INFO:Creating metrics dataframe
2024-05-29 16:39:55,353:INFO:Uploading results into container
2024-05-29 16:39:55,354:INFO:Uploading model into container now
2024-05-29 16:39:55,354:INFO:_master_model_container: 10
2024-05-29 16:39:55,354:INFO:_display_container: 2
2024-05-29 16:39:55,355:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3492, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-29 16:39:55,355:INFO:create_model() successfully completed......................................
2024-05-29 16:39:57,046:INFO:SubProcess create_model() end ==================================
2024-05-29 16:39:57,046:INFO:Creating metrics dataframe
2024-05-29 16:39:57,060:INFO:Initializing Linear Discriminant Analysis
2024-05-29 16:39:57,060:INFO:Total runtime is 1.0103668530782064 minutes
2024-05-29 16:39:57,066:INFO:SubProcess create_model() called ==================================
2024-05-29 16:39:57,066:INFO:Initializing create_model()
2024-05-29 16:39:57,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC0FD36D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC4131A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:39:57,067:INFO:Checking exceptions
2024-05-29 16:39:57,067:INFO:Importing libraries
2024-05-29 16:39:57,067:INFO:Copying training dataset
2024-05-29 16:39:57,116:INFO:Defining folds
2024-05-29 16:39:57,116:INFO:Declaring metric variables
2024-05-29 16:39:57,121:INFO:Importing untrained model
2024-05-29 16:39:57,126:INFO:Linear Discriminant Analysis Imported successfully
2024-05-29 16:39:57,136:INFO:Starting cross validation
2024-05-29 16:39:57,137:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:39:57,522:INFO:Calculating mean and std
2024-05-29 16:39:57,524:INFO:Creating metrics dataframe
2024-05-29 16:39:57,527:INFO:Uploading results into container
2024-05-29 16:39:57,528:INFO:Uploading model into container now
2024-05-29 16:39:57,528:INFO:_master_model_container: 11
2024-05-29 16:39:57,529:INFO:_display_container: 2
2024-05-29 16:39:57,529:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-29 16:39:57,529:INFO:create_model() successfully completed......................................
2024-05-29 16:39:59,316:INFO:SubProcess create_model() end ==================================
2024-05-29 16:39:59,316:INFO:Creating metrics dataframe
2024-05-29 16:39:59,331:INFO:Initializing Extra Trees Classifier
2024-05-29 16:39:59,331:INFO:Total runtime is 1.0482183337211608 minutes
2024-05-29 16:39:59,335:INFO:SubProcess create_model() called ==================================
2024-05-29 16:39:59,336:INFO:Initializing create_model()
2024-05-29 16:39:59,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC0FD36D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC4131A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:39:59,336:INFO:Checking exceptions
2024-05-29 16:39:59,336:INFO:Importing libraries
2024-05-29 16:39:59,337:INFO:Copying training dataset
2024-05-29 16:39:59,385:INFO:Defining folds
2024-05-29 16:39:59,385:INFO:Declaring metric variables
2024-05-29 16:39:59,390:INFO:Importing untrained model
2024-05-29 16:39:59,395:INFO:Extra Trees Classifier Imported successfully
2024-05-29 16:39:59,403:INFO:Starting cross validation
2024-05-29 16:39:59,404:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:40:08,388:INFO:Calculating mean and std
2024-05-29 16:40:08,392:INFO:Creating metrics dataframe
2024-05-29 16:40:08,396:INFO:Uploading results into container
2024-05-29 16:40:08,397:INFO:Uploading model into container now
2024-05-29 16:40:08,398:INFO:_master_model_container: 12
2024-05-29 16:40:08,398:INFO:_display_container: 2
2024-05-29 16:40:08,400:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3492, verbose=0,
                     warm_start=False)
2024-05-29 16:40:08,400:INFO:create_model() successfully completed......................................
2024-05-29 16:40:10,138:INFO:SubProcess create_model() end ==================================
2024-05-29 16:40:10,138:INFO:Creating metrics dataframe
2024-05-29 16:40:10,153:INFO:Initializing Extreme Gradient Boosting
2024-05-29 16:40:10,154:INFO:Total runtime is 1.228589614232381 minutes
2024-05-29 16:40:10,158:INFO:SubProcess create_model() called ==================================
2024-05-29 16:40:10,159:INFO:Initializing create_model()
2024-05-29 16:40:10,159:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC0FD36D0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC4131A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:40:10,159:INFO:Checking exceptions
2024-05-29 16:40:10,160:INFO:Importing libraries
2024-05-29 16:40:10,160:INFO:Copying training dataset
2024-05-29 16:40:10,211:INFO:Defining folds
2024-05-29 16:40:10,211:INFO:Declaring metric variables
2024-05-29 16:40:10,216:INFO:Importing untrained model
2024-05-29 16:40:10,222:INFO:Extreme Gradient Boosting Imported successfully
2024-05-29 16:40:10,234:INFO:Starting cross validation
2024-05-29 16:40:10,235:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:40:11,815:INFO:Calculating mean and std
2024-05-29 16:40:11,817:INFO:Creating metrics dataframe
2024-05-29 16:40:11,820:INFO:Uploading results into container
2024-05-29 16:40:11,820:INFO:Uploading model into container now
2024-05-29 16:40:11,821:INFO:_master_model_container: 13
2024-05-29 16:40:11,821:INFO:_display_container: 2
2024-05-29 16:40:11,822:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-29 16:40:11,822:INFO:create_model() successfully completed......................................
2024-05-29 16:40:13,520:INFO:SubProcess create_model() end ==================================
2024-05-29 16:40:13,521:INFO:Creating metrics dataframe
2024-05-29 16:40:13,536:INFO:Initializing Light Gradient Boosting Machine
2024-05-29 16:40:13,536:INFO:Total runtime is 1.284959085782369 minutes
2024-05-29 16:40:13,541:INFO:SubProcess create_model() called ==================================
2024-05-29 16:40:13,541:INFO:Initializing create_model()
2024-05-29 16:40:13,541:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC0FD36D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC4131A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:40:13,541:INFO:Checking exceptions
2024-05-29 16:40:13,542:INFO:Importing libraries
2024-05-29 16:40:13,542:INFO:Copying training dataset
2024-05-29 16:40:13,591:INFO:Defining folds
2024-05-29 16:40:13,592:INFO:Declaring metric variables
2024-05-29 16:40:13,597:INFO:Importing untrained model
2024-05-29 16:40:13,602:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-29 16:40:13,612:INFO:Starting cross validation
2024-05-29 16:40:13,613:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:40:16,114:INFO:Calculating mean and std
2024-05-29 16:40:16,116:INFO:Creating metrics dataframe
2024-05-29 16:40:16,120:INFO:Uploading results into container
2024-05-29 16:40:16,121:INFO:Uploading model into container now
2024-05-29 16:40:16,121:INFO:_master_model_container: 14
2024-05-29 16:40:16,121:INFO:_display_container: 2
2024-05-29 16:40:16,122:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3492, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-29 16:40:16,122:INFO:create_model() successfully completed......................................
2024-05-29 16:40:17,745:INFO:SubProcess create_model() end ==================================
2024-05-29 16:40:17,746:INFO:Creating metrics dataframe
2024-05-29 16:40:17,762:INFO:Initializing Dummy Classifier
2024-05-29 16:40:17,762:INFO:Total runtime is 1.3553994099299114 minutes
2024-05-29 16:40:17,767:INFO:SubProcess create_model() called ==================================
2024-05-29 16:40:17,767:INFO:Initializing create_model()
2024-05-29 16:40:17,768:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC0FD36D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC4131A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:40:17,768:INFO:Checking exceptions
2024-05-29 16:40:17,768:INFO:Importing libraries
2024-05-29 16:40:17,768:INFO:Copying training dataset
2024-05-29 16:40:17,830:INFO:Defining folds
2024-05-29 16:40:17,830:INFO:Declaring metric variables
2024-05-29 16:40:17,836:INFO:Importing untrained model
2024-05-29 16:40:17,841:INFO:Dummy Classifier Imported successfully
2024-05-29 16:40:17,851:INFO:Starting cross validation
2024-05-29 16:40:17,852:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:40:17,927:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 16:40:17,947:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 16:40:17,972:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 16:40:17,986:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 16:40:17,999:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 16:40:18,018:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 16:40:18,033:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 16:40:18,053:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 16:40:18,069:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 16:40:18,083:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 16:40:18,102:INFO:Calculating mean and std
2024-05-29 16:40:18,104:INFO:Creating metrics dataframe
2024-05-29 16:40:18,107:INFO:Uploading results into container
2024-05-29 16:40:18,107:INFO:Uploading model into container now
2024-05-29 16:40:18,108:INFO:_master_model_container: 15
2024-05-29 16:40:18,108:INFO:_display_container: 2
2024-05-29 16:40:18,108:INFO:DummyClassifier(constant=None, random_state=3492, strategy='prior')
2024-05-29 16:40:18,108:INFO:create_model() successfully completed......................................
2024-05-29 16:40:19,780:INFO:SubProcess create_model() end ==================================
2024-05-29 16:40:19,780:INFO:Creating metrics dataframe
2024-05-29 16:40:19,797:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-29 16:40:19,810:INFO:Initializing create_model()
2024-05-29 16:40:19,810:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC0FD36D0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:40:19,811:INFO:Checking exceptions
2024-05-29 16:40:19,813:INFO:Importing libraries
2024-05-29 16:40:19,814:INFO:Copying training dataset
2024-05-29 16:40:19,859:INFO:Defining folds
2024-05-29 16:40:19,859:INFO:Declaring metric variables
2024-05-29 16:40:19,860:INFO:Importing untrained model
2024-05-29 16:40:19,860:INFO:Declaring custom model
2024-05-29 16:40:19,862:INFO:Extreme Gradient Boosting Imported successfully
2024-05-29 16:40:19,863:INFO:Cross validation set to False
2024-05-29 16:40:19,863:INFO:Fitting Model
2024-05-29 16:40:20,121:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-29 16:40:20,121:INFO:create_model() successfully completed......................................
2024-05-29 16:40:21,763:INFO:Creating Dashboard logs
2024-05-29 16:40:21,768:INFO:Model: Extreme Gradient Boosting
2024-05-29 16:40:21,857:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 3492, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2024-05-29 16:40:22,136:INFO:Initializing predict_model()
2024-05-29 16:40:22,136:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC0FD36D0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AC0B4443A0>)
2024-05-29 16:40:22,136:INFO:Checking exceptions
2024-05-29 16:40:22,136:INFO:Preloading libraries
2024-05-29 16:40:25,715:INFO:Creating Dashboard logs
2024-05-29 16:40:25,720:INFO:Model: Light Gradient Boosting Machine
2024-05-29 16:40:25,806:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 3492, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-05-29 16:40:27,761:INFO:Creating Dashboard logs
2024-05-29 16:40:27,765:INFO:Model: Random Forest Classifier
2024-05-29 16:40:27,858:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 3492, 'verbose': 0, 'warm_start': False}
2024-05-29 16:40:29,964:INFO:Creating Dashboard logs
2024-05-29 16:40:29,969:INFO:Model: Gradient Boosting Classifier
2024-05-29 16:40:30,061:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 3492, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-29 16:40:32,286:INFO:Creating Dashboard logs
2024-05-29 16:40:32,291:INFO:Model: Extra Trees Classifier
2024-05-29 16:40:32,382:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 3492, 'verbose': 0, 'warm_start': False}
2024-05-29 16:40:34,353:INFO:Creating Dashboard logs
2024-05-29 16:40:34,358:INFO:Model: Ada Boost Classifier
2024-05-29 16:40:34,446:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 3492}
2024-05-29 16:40:36,406:INFO:Creating Dashboard logs
2024-05-29 16:40:36,412:INFO:Model: Logistic Regression
2024-05-29 16:40:36,510:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 3492, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-05-29 16:40:38,634:INFO:Creating Dashboard logs
2024-05-29 16:40:38,639:INFO:Model: Ridge Classifier
2024-05-29 16:40:38,732:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 3492, 'solver': 'auto', 'tol': 0.0001}
2024-05-29 16:40:40,654:INFO:Creating Dashboard logs
2024-05-29 16:40:40,659:INFO:Model: Linear Discriminant Analysis
2024-05-29 16:40:40,757:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-05-29 16:40:42,874:INFO:Creating Dashboard logs
2024-05-29 16:40:42,879:INFO:Model: SVM - Linear Kernel
2024-05-29 16:40:42,966:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 3492, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-29 16:40:44,914:INFO:Creating Dashboard logs
2024-05-29 16:40:44,919:INFO:Model: K Neighbors Classifier
2024-05-29 16:40:45,009:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2024-05-29 16:40:46,930:INFO:Creating Dashboard logs
2024-05-29 16:40:46,935:INFO:Model: Decision Tree Classifier
2024-05-29 16:40:47,024:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 3492, 'splitter': 'best'}
2024-05-29 16:40:48,967:INFO:Creating Dashboard logs
2024-05-29 16:40:48,971:INFO:Model: Quadratic Discriminant Analysis
2024-05-29 16:40:49,062:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2024-05-29 16:40:50,969:INFO:Creating Dashboard logs
2024-05-29 16:40:50,975:INFO:Model: Naive Bayes
2024-05-29 16:40:51,065:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-05-29 16:40:52,971:INFO:Creating Dashboard logs
2024-05-29 16:40:52,976:INFO:Model: Dummy Classifier
2024-05-29 16:40:53,065:INFO:Logged params: {'constant': None, 'random_state': 3492, 'strategy': 'prior'}
2024-05-29 16:40:54,968:INFO:_master_model_container: 15
2024-05-29 16:40:54,968:INFO:_display_container: 2
2024-05-29 16:40:54,969:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-29 16:40:54,969:INFO:compare_models() successfully completed......................................
2024-05-29 16:42:42,996:INFO:PyCaret ClassificationExperiment
2024-05-29 16:42:42,997:INFO:Logging name: codex
2024-05-29 16:42:42,997:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 16:42:42,997:INFO:version 3.3.2
2024-05-29 16:42:42,997:INFO:Initializing setup()
2024-05-29 16:42:42,997:INFO:self.USI: d31f
2024-05-29 16:42:42,997:INFO:self._variable_keys: {'n_jobs_param', 'fix_imbalance', 'gpu_param', 'memory', 'html_param', 'pipeline', 'exp_name_log', 'target_param', '_ml_usecase', 'fold_groups_param', 'y_train', 'USI', 'is_multiclass', '_available_plots', 'seed', 'log_plots_param', 'exp_id', 'fold_shuffle_param', 'y_test', 'X', 'X_train', 'gpu_n_jobs_param', 'data', 'X_test', 'fold_generator', 'idx', 'logging_param', 'y'}
2024-05-29 16:42:42,997:INFO:Checking environment
2024-05-29 16:42:42,997:INFO:python_version: 3.10.13
2024-05-29 16:42:42,997:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 16:42:42,998:INFO:machine: AMD64
2024-05-29 16:42:42,998:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 16:42:42,998:INFO:Memory: svmem(total=34267656192, available=14651723776, percent=57.2, used=19615932416, free=14651723776)
2024-05-29 16:42:42,998:INFO:Physical Core: 8
2024-05-29 16:42:42,998:INFO:Logical Core: 16
2024-05-29 16:42:42,998:INFO:Checking libraries
2024-05-29 16:42:42,998:INFO:System:
2024-05-29 16:42:42,998:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 16:42:42,998:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 16:42:42,998:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 16:42:42,999:INFO:PyCaret required dependencies:
2024-05-29 16:42:42,999:INFO:                 pip: 23.3
2024-05-29 16:42:42,999:INFO:          setuptools: 68.0.0
2024-05-29 16:42:42,999:INFO:             pycaret: 3.3.2
2024-05-29 16:42:42,999:INFO:             IPython: 8.24.0
2024-05-29 16:42:42,999:INFO:          ipywidgets: 8.1.2
2024-05-29 16:42:42,999:INFO:                tqdm: 4.66.4
2024-05-29 16:42:42,999:INFO:               numpy: 1.26.4
2024-05-29 16:42:42,999:INFO:              pandas: 2.1.4
2024-05-29 16:42:43,000:INFO:              jinja2: 3.1.4
2024-05-29 16:42:43,000:INFO:               scipy: 1.11.4
2024-05-29 16:42:43,000:INFO:              joblib: 1.3.2
2024-05-29 16:42:43,000:INFO:             sklearn: 1.4.2
2024-05-29 16:42:43,000:INFO:                pyod: 1.1.3
2024-05-29 16:42:43,000:INFO:            imblearn: 0.12.2
2024-05-29 16:42:43,000:INFO:   category_encoders: 2.6.3
2024-05-29 16:42:43,001:INFO:            lightgbm: 4.3.0
2024-05-29 16:42:43,001:INFO:               numba: 0.59.1
2024-05-29 16:42:43,001:INFO:            requests: 2.32.2
2024-05-29 16:42:43,001:INFO:          matplotlib: 3.7.5
2024-05-29 16:42:43,001:INFO:          scikitplot: 0.3.7
2024-05-29 16:42:43,001:INFO:         yellowbrick: 1.5
2024-05-29 16:42:43,001:INFO:              plotly: 5.22.0
2024-05-29 16:42:43,001:INFO:    plotly-resampler: Not installed
2024-05-29 16:42:43,001:INFO:             kaleido: 0.2.1
2024-05-29 16:42:43,001:INFO:           schemdraw: 0.15
2024-05-29 16:42:43,002:INFO:         statsmodels: 0.14.2
2024-05-29 16:42:43,002:INFO:              sktime: 0.26.0
2024-05-29 16:42:43,002:INFO:               tbats: 1.1.3
2024-05-29 16:42:43,002:INFO:            pmdarima: 2.0.4
2024-05-29 16:42:43,002:INFO:              psutil: 5.9.0
2024-05-29 16:42:43,002:INFO:          markupsafe: 2.1.5
2024-05-29 16:42:43,002:INFO:             pickle5: Not installed
2024-05-29 16:42:43,002:INFO:         cloudpickle: 3.0.0
2024-05-29 16:42:43,002:INFO:         deprecation: 2.1.0
2024-05-29 16:42:43,002:INFO:              xxhash: 3.4.1
2024-05-29 16:42:43,002:INFO:           wurlitzer: Not installed
2024-05-29 16:42:43,002:INFO:PyCaret optional dependencies:
2024-05-29 16:42:43,002:INFO:                shap: Not installed
2024-05-29 16:42:43,002:INFO:           interpret: Not installed
2024-05-29 16:42:43,003:INFO:                umap: Not installed
2024-05-29 16:42:43,003:INFO:     ydata_profiling: Not installed
2024-05-29 16:42:43,003:INFO:  explainerdashboard: Not installed
2024-05-29 16:42:43,003:INFO:             autoviz: Not installed
2024-05-29 16:42:43,003:INFO:           fairlearn: Not installed
2024-05-29 16:42:43,003:INFO:          deepchecks: Not installed
2024-05-29 16:42:43,003:INFO:             xgboost: 2.0.3
2024-05-29 16:42:43,003:INFO:            catboost: Not installed
2024-05-29 16:42:43,003:INFO:              kmodes: Not installed
2024-05-29 16:42:43,003:INFO:             mlxtend: Not installed
2024-05-29 16:42:43,003:INFO:       statsforecast: Not installed
2024-05-29 16:42:43,003:INFO:        tune_sklearn: Not installed
2024-05-29 16:42:43,004:INFO:                 ray: Not installed
2024-05-29 16:42:43,004:INFO:            hyperopt: 0.2.7
2024-05-29 16:42:43,004:INFO:              optuna: Not installed
2024-05-29 16:42:43,004:INFO:               skopt: Not installed
2024-05-29 16:42:43,004:INFO:              mlflow: 2.13.0
2024-05-29 16:42:43,004:INFO:              gradio: Not installed
2024-05-29 16:42:43,004:INFO:             fastapi: Not installed
2024-05-29 16:42:43,004:INFO:             uvicorn: Not installed
2024-05-29 16:42:43,004:INFO:              m2cgen: Not installed
2024-05-29 16:42:43,005:INFO:           evidently: Not installed
2024-05-29 16:42:43,005:INFO:               fugue: Not installed
2024-05-29 16:42:43,005:INFO:           streamlit: Not installed
2024-05-29 16:42:43,005:INFO:             prophet: Not installed
2024-05-29 16:42:43,005:INFO:None
2024-05-29 16:42:43,005:INFO:Set up data.
2024-05-29 16:42:43,033:INFO:Set up folding strategy.
2024-05-29 16:42:43,033:INFO:Set up train/test split.
2024-05-29 16:42:43,091:INFO:Set up index.
2024-05-29 16:42:43,092:INFO:Assigning column types.
2024-05-29 16:42:43,126:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 16:42:43,199:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 16:42:43,200:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 16:42:43,245:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 16:42:43,249:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 16:42:43,324:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 16:42:43,326:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 16:42:43,372:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 16:42:43,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 16:42:43,376:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 16:42:43,451:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 16:42:43,496:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 16:42:43,501:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 16:42:43,576:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 16:42:43,621:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 16:42:43,626:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 16:42:43,626:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 16:42:43,746:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 16:42:43,750:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 16:42:43,872:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 16:42:43,877:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 16:42:43,913:INFO:Finished creating preprocessing pipeline.
2024-05-29 16:42:43,914:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2024-05-29 16:42:43,914:INFO:Creating final display dataframe.
2024-05-29 16:42:44,083:INFO:Setup _display_container:                    Description        Value
0                   Session id         8002
1                       Target       target
2                  Target type       Binary
3          Original data shape  (90000, 18)
4       Transformed data shape  (90000, 18)
5  Transformed train set shape  (72000, 18)
6   Transformed test set shape  (18000, 18)
7             Numeric features           17
2024-05-29 16:42:44,266:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 16:42:44,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 16:42:44,392:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 16:42:44,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 16:42:44,398:INFO:Logging experiment in loggers
2024-05-29 16:42:44,555:INFO:SubProcess save_model() called ==================================
2024-05-29 16:42:44,556:INFO:Initializing save_model()
2024-05-29 16:42:44,556:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), model_name=C:\Users\Adm\AppData\Local\Temp\tmp0_nip1gw\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-29 16:42:44,556:INFO:Adding model into prep_pipe
2024-05-29 16:42:44,556:WARNING:Only Model saved as it was a pipeline.
2024-05-29 16:42:44,561:INFO:C:\Users\Adm\AppData\Local\Temp\tmp0_nip1gw\Transformation Pipeline.pkl saved in current working directory
2024-05-29 16:42:44,562:INFO:Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2024-05-29 16:42:44,562:INFO:save_model() successfully completed......................................
2024-05-29 16:42:46,228:INFO:SubProcess save_model() end ==================================
2024-05-29 16:42:46,249:INFO:setup() successfully completed in 1.46s...............
2024-05-29 16:42:46,294:INFO:Initializing compare_models()
2024-05-29 16:42:46,294:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC10EFDF0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC10EFDF0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-29 16:42:46,294:INFO:Checking exceptions
2024-05-29 16:42:46,321:INFO:Preparing display monitor
2024-05-29 16:42:46,350:INFO:Initializing Logistic Regression
2024-05-29 16:42:46,350:INFO:Total runtime is 0.0 minutes
2024-05-29 16:42:46,355:INFO:SubProcess create_model() called ==================================
2024-05-29 16:42:46,356:INFO:Initializing create_model()
2024-05-29 16:42:46,356:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC10EFDF0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC0F54760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:42:46,356:INFO:Checking exceptions
2024-05-29 16:42:46,357:INFO:Importing libraries
2024-05-29 16:42:46,357:INFO:Copying training dataset
2024-05-29 16:42:46,405:INFO:Defining folds
2024-05-29 16:42:46,406:INFO:Declaring metric variables
2024-05-29 16:42:46,411:INFO:Importing untrained model
2024-05-29 16:42:46,416:INFO:Logistic Regression Imported successfully
2024-05-29 16:42:46,426:INFO:Starting cross validation
2024-05-29 16:42:46,427:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:42:47,964:INFO:Calculating mean and std
2024-05-29 16:42:47,966:INFO:Creating metrics dataframe
2024-05-29 16:42:47,969:INFO:Uploading results into container
2024-05-29 16:42:47,970:INFO:Uploading model into container now
2024-05-29 16:42:47,970:INFO:_master_model_container: 1
2024-05-29 16:42:47,970:INFO:_display_container: 2
2024-05-29 16:42:47,971:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8002, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-29 16:42:47,971:INFO:create_model() successfully completed......................................
2024-05-29 16:42:49,572:INFO:SubProcess create_model() end ==================================
2024-05-29 16:42:49,573:INFO:Creating metrics dataframe
2024-05-29 16:42:49,581:INFO:Initializing K Neighbors Classifier
2024-05-29 16:42:49,581:INFO:Total runtime is 0.0538375457127889 minutes
2024-05-29 16:42:49,586:INFO:SubProcess create_model() called ==================================
2024-05-29 16:42:49,587:INFO:Initializing create_model()
2024-05-29 16:42:49,587:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC10EFDF0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC0F54760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:42:49,587:INFO:Checking exceptions
2024-05-29 16:42:49,587:INFO:Importing libraries
2024-05-29 16:42:49,587:INFO:Copying training dataset
2024-05-29 16:42:49,651:INFO:Defining folds
2024-05-29 16:42:49,652:INFO:Declaring metric variables
2024-05-29 16:42:49,658:INFO:Importing untrained model
2024-05-29 16:42:49,664:INFO:K Neighbors Classifier Imported successfully
2024-05-29 16:42:49,674:INFO:Starting cross validation
2024-05-29 16:42:49,675:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:42:59,623:INFO:Calculating mean and std
2024-05-29 16:42:59,625:INFO:Creating metrics dataframe
2024-05-29 16:42:59,627:INFO:Uploading results into container
2024-05-29 16:42:59,628:INFO:Uploading model into container now
2024-05-29 16:42:59,629:INFO:_master_model_container: 2
2024-05-29 16:42:59,629:INFO:_display_container: 2
2024-05-29 16:42:59,630:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-29 16:42:59,630:INFO:create_model() successfully completed......................................
2024-05-29 16:43:01,204:INFO:SubProcess create_model() end ==================================
2024-05-29 16:43:01,204:INFO:Creating metrics dataframe
2024-05-29 16:43:01,214:INFO:Initializing Naive Bayes
2024-05-29 16:43:01,214:INFO:Total runtime is 0.24772252241770426 minutes
2024-05-29 16:43:01,219:INFO:SubProcess create_model() called ==================================
2024-05-29 16:43:01,219:INFO:Initializing create_model()
2024-05-29 16:43:01,219:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC10EFDF0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC0F54760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:43:01,220:INFO:Checking exceptions
2024-05-29 16:43:01,220:INFO:Importing libraries
2024-05-29 16:43:01,220:INFO:Copying training dataset
2024-05-29 16:43:01,266:INFO:Defining folds
2024-05-29 16:43:01,266:INFO:Declaring metric variables
2024-05-29 16:43:01,271:INFO:Importing untrained model
2024-05-29 16:43:01,276:INFO:Naive Bayes Imported successfully
2024-05-29 16:43:01,285:INFO:Starting cross validation
2024-05-29 16:43:01,287:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:43:01,564:INFO:Calculating mean and std
2024-05-29 16:43:01,566:INFO:Creating metrics dataframe
2024-05-29 16:43:01,569:INFO:Uploading results into container
2024-05-29 16:43:01,569:INFO:Uploading model into container now
2024-05-29 16:43:01,570:INFO:_master_model_container: 3
2024-05-29 16:43:01,570:INFO:_display_container: 2
2024-05-29 16:43:01,570:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-29 16:43:01,570:INFO:create_model() successfully completed......................................
2024-05-29 16:43:03,213:INFO:SubProcess create_model() end ==================================
2024-05-29 16:43:03,214:INFO:Creating metrics dataframe
2024-05-29 16:43:03,224:INFO:Initializing Decision Tree Classifier
2024-05-29 16:43:03,224:INFO:Total runtime is 0.2812224229176839 minutes
2024-05-29 16:43:03,228:INFO:SubProcess create_model() called ==================================
2024-05-29 16:43:03,229:INFO:Initializing create_model()
2024-05-29 16:43:03,229:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC10EFDF0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC0F54760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:43:03,229:INFO:Checking exceptions
2024-05-29 16:43:03,230:INFO:Importing libraries
2024-05-29 16:43:03,230:INFO:Copying training dataset
2024-05-29 16:43:03,277:INFO:Defining folds
2024-05-29 16:43:03,277:INFO:Declaring metric variables
2024-05-29 16:43:03,282:INFO:Importing untrained model
2024-05-29 16:43:03,287:INFO:Decision Tree Classifier Imported successfully
2024-05-29 16:43:03,296:INFO:Starting cross validation
2024-05-29 16:43:03,297:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:43:03,918:INFO:Calculating mean and std
2024-05-29 16:43:03,920:INFO:Creating metrics dataframe
2024-05-29 16:43:03,922:INFO:Uploading results into container
2024-05-29 16:43:03,923:INFO:Uploading model into container now
2024-05-29 16:43:03,924:INFO:_master_model_container: 4
2024-05-29 16:43:03,924:INFO:_display_container: 2
2024-05-29 16:43:03,924:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8002, splitter='best')
2024-05-29 16:43:03,925:INFO:create_model() successfully completed......................................
2024-05-29 16:43:05,577:INFO:SubProcess create_model() end ==================================
2024-05-29 16:43:05,577:INFO:Creating metrics dataframe
2024-05-29 16:43:05,588:INFO:Initializing SVM - Linear Kernel
2024-05-29 16:43:05,588:INFO:Total runtime is 0.3206225434939066 minutes
2024-05-29 16:43:05,593:INFO:SubProcess create_model() called ==================================
2024-05-29 16:43:05,593:INFO:Initializing create_model()
2024-05-29 16:43:05,593:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC10EFDF0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC0F54760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:43:05,594:INFO:Checking exceptions
2024-05-29 16:43:05,594:INFO:Importing libraries
2024-05-29 16:43:05,594:INFO:Copying training dataset
2024-05-29 16:43:05,642:INFO:Defining folds
2024-05-29 16:43:05,642:INFO:Declaring metric variables
2024-05-29 16:43:05,646:INFO:Importing untrained model
2024-05-29 16:43:05,652:INFO:SVM - Linear Kernel Imported successfully
2024-05-29 16:43:05,661:INFO:Starting cross validation
2024-05-29 16:43:05,663:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:43:06,131:INFO:Calculating mean and std
2024-05-29 16:43:06,133:INFO:Creating metrics dataframe
2024-05-29 16:43:06,135:INFO:Uploading results into container
2024-05-29 16:43:06,136:INFO:Uploading model into container now
2024-05-29 16:43:06,137:INFO:_master_model_container: 5
2024-05-29 16:43:06,137:INFO:_display_container: 2
2024-05-29 16:43:06,138:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8002, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-29 16:43:06,138:INFO:create_model() successfully completed......................................
2024-05-29 16:43:07,805:INFO:SubProcess create_model() end ==================================
2024-05-29 16:43:07,805:INFO:Creating metrics dataframe
2024-05-29 16:43:07,816:INFO:Initializing Ridge Classifier
2024-05-29 16:43:07,816:INFO:Total runtime is 0.35775575240453084 minutes
2024-05-29 16:43:07,821:INFO:SubProcess create_model() called ==================================
2024-05-29 16:43:07,822:INFO:Initializing create_model()
2024-05-29 16:43:07,822:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC10EFDF0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC0F54760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:43:07,822:INFO:Checking exceptions
2024-05-29 16:43:07,822:INFO:Importing libraries
2024-05-29 16:43:07,822:INFO:Copying training dataset
2024-05-29 16:43:07,876:INFO:Defining folds
2024-05-29 16:43:07,876:INFO:Declaring metric variables
2024-05-29 16:43:07,882:INFO:Importing untrained model
2024-05-29 16:43:07,889:INFO:Ridge Classifier Imported successfully
2024-05-29 16:43:07,899:INFO:Starting cross validation
2024-05-29 16:43:07,900:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:43:08,211:INFO:Calculating mean and std
2024-05-29 16:43:08,213:INFO:Creating metrics dataframe
2024-05-29 16:43:08,216:INFO:Uploading results into container
2024-05-29 16:43:08,217:INFO:Uploading model into container now
2024-05-29 16:43:08,217:INFO:_master_model_container: 6
2024-05-29 16:43:08,217:INFO:_display_container: 2
2024-05-29 16:43:08,218:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8002, solver='auto',
                tol=0.0001)
2024-05-29 16:43:08,219:INFO:create_model() successfully completed......................................
2024-05-29 16:43:09,865:INFO:SubProcess create_model() end ==================================
2024-05-29 16:43:09,865:INFO:Creating metrics dataframe
2024-05-29 16:43:09,878:INFO:Initializing Random Forest Classifier
2024-05-29 16:43:09,878:INFO:Total runtime is 0.3921222805976868 minutes
2024-05-29 16:43:09,883:INFO:SubProcess create_model() called ==================================
2024-05-29 16:43:09,884:INFO:Initializing create_model()
2024-05-29 16:43:09,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC10EFDF0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC0F54760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:43:09,885:INFO:Checking exceptions
2024-05-29 16:43:09,885:INFO:Importing libraries
2024-05-29 16:43:09,885:INFO:Copying training dataset
2024-05-29 16:43:09,932:INFO:Defining folds
2024-05-29 16:43:09,932:INFO:Declaring metric variables
2024-05-29 16:43:09,938:INFO:Importing untrained model
2024-05-29 16:43:09,943:INFO:Random Forest Classifier Imported successfully
2024-05-29 16:43:09,952:INFO:Starting cross validation
2024-05-29 16:43:09,954:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:43:18,263:INFO:Calculating mean and std
2024-05-29 16:43:18,265:INFO:Creating metrics dataframe
2024-05-29 16:43:18,268:INFO:Uploading results into container
2024-05-29 16:43:18,269:INFO:Uploading model into container now
2024-05-29 16:43:18,270:INFO:_master_model_container: 7
2024-05-29 16:43:18,270:INFO:_display_container: 2
2024-05-29 16:43:18,271:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8002, verbose=0,
                       warm_start=False)
2024-05-29 16:43:18,271:INFO:create_model() successfully completed......................................
2024-05-29 16:43:19,860:INFO:SubProcess create_model() end ==================================
2024-05-29 16:43:19,861:INFO:Creating metrics dataframe
2024-05-29 16:43:19,873:INFO:Initializing Quadratic Discriminant Analysis
2024-05-29 16:43:19,873:INFO:Total runtime is 0.5587101658185323 minutes
2024-05-29 16:43:19,877:INFO:SubProcess create_model() called ==================================
2024-05-29 16:43:19,878:INFO:Initializing create_model()
2024-05-29 16:43:19,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC10EFDF0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC0F54760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:43:19,878:INFO:Checking exceptions
2024-05-29 16:43:19,878:INFO:Importing libraries
2024-05-29 16:43:19,879:INFO:Copying training dataset
2024-05-29 16:43:19,926:INFO:Defining folds
2024-05-29 16:43:19,926:INFO:Declaring metric variables
2024-05-29 16:43:19,931:INFO:Importing untrained model
2024-05-29 16:43:19,936:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-29 16:43:19,945:INFO:Starting cross validation
2024-05-29 16:43:19,946:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:43:20,306:INFO:Calculating mean and std
2024-05-29 16:43:20,308:INFO:Creating metrics dataframe
2024-05-29 16:43:20,310:INFO:Uploading results into container
2024-05-29 16:43:20,311:INFO:Uploading model into container now
2024-05-29 16:43:20,312:INFO:_master_model_container: 8
2024-05-29 16:43:20,312:INFO:_display_container: 2
2024-05-29 16:43:20,312:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-29 16:43:20,312:INFO:create_model() successfully completed......................................
2024-05-29 16:43:21,961:INFO:SubProcess create_model() end ==================================
2024-05-29 16:43:21,961:INFO:Creating metrics dataframe
2024-05-29 16:43:21,974:INFO:Initializing Ada Boost Classifier
2024-05-29 16:43:21,974:INFO:Total runtime is 0.593727155526479 minutes
2024-05-29 16:43:21,979:INFO:SubProcess create_model() called ==================================
2024-05-29 16:43:21,979:INFO:Initializing create_model()
2024-05-29 16:43:21,979:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC10EFDF0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC0F54760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:43:21,979:INFO:Checking exceptions
2024-05-29 16:43:21,980:INFO:Importing libraries
2024-05-29 16:43:21,980:INFO:Copying training dataset
2024-05-29 16:43:22,035:INFO:Defining folds
2024-05-29 16:43:22,035:INFO:Declaring metric variables
2024-05-29 16:43:22,041:INFO:Importing untrained model
2024-05-29 16:43:22,046:INFO:Ada Boost Classifier Imported successfully
2024-05-29 16:43:22,056:INFO:Starting cross validation
2024-05-29 16:43:22,057:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:43:22,112:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 16:43:22,126:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 16:43:22,144:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 16:43:22,163:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 16:43:22,179:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 16:43:22,198:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 16:43:22,215:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 16:43:22,242:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 16:43:22,262:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 16:43:22,283:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 16:43:25,116:INFO:Calculating mean and std
2024-05-29 16:43:25,118:INFO:Creating metrics dataframe
2024-05-29 16:43:25,120:INFO:Uploading results into container
2024-05-29 16:43:25,121:INFO:Uploading model into container now
2024-05-29 16:43:25,121:INFO:_master_model_container: 9
2024-05-29 16:43:25,121:INFO:_display_container: 2
2024-05-29 16:43:25,122:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8002)
2024-05-29 16:43:25,122:INFO:create_model() successfully completed......................................
2024-05-29 16:43:26,691:INFO:SubProcess create_model() end ==================================
2024-05-29 16:43:26,691:INFO:Creating metrics dataframe
2024-05-29 16:43:26,704:INFO:Initializing Gradient Boosting Classifier
2024-05-29 16:43:26,704:INFO:Total runtime is 0.6725689848264058 minutes
2024-05-29 16:43:26,709:INFO:SubProcess create_model() called ==================================
2024-05-29 16:43:26,709:INFO:Initializing create_model()
2024-05-29 16:43:26,709:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC10EFDF0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC0F54760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:43:26,709:INFO:Checking exceptions
2024-05-29 16:43:26,710:INFO:Importing libraries
2024-05-29 16:43:26,710:INFO:Copying training dataset
2024-05-29 16:43:26,756:INFO:Defining folds
2024-05-29 16:43:26,757:INFO:Declaring metric variables
2024-05-29 16:43:26,761:INFO:Importing untrained model
2024-05-29 16:43:26,766:INFO:Gradient Boosting Classifier Imported successfully
2024-05-29 16:43:26,776:INFO:Starting cross validation
2024-05-29 16:43:26,777:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:43:36,124:INFO:Calculating mean and std
2024-05-29 16:43:36,126:INFO:Creating metrics dataframe
2024-05-29 16:43:36,128:INFO:Uploading results into container
2024-05-29 16:43:36,129:INFO:Uploading model into container now
2024-05-29 16:43:36,130:INFO:_master_model_container: 10
2024-05-29 16:43:36,130:INFO:_display_container: 2
2024-05-29 16:43:36,131:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8002, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-29 16:43:36,131:INFO:create_model() successfully completed......................................
2024-05-29 16:43:37,696:INFO:SubProcess create_model() end ==================================
2024-05-29 16:43:37,697:INFO:Creating metrics dataframe
2024-05-29 16:43:37,710:INFO:Initializing Linear Discriminant Analysis
2024-05-29 16:43:37,711:INFO:Total runtime is 0.8560157179832458 minutes
2024-05-29 16:43:37,715:INFO:SubProcess create_model() called ==================================
2024-05-29 16:43:37,716:INFO:Initializing create_model()
2024-05-29 16:43:37,716:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC10EFDF0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC0F54760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:43:37,716:INFO:Checking exceptions
2024-05-29 16:43:37,716:INFO:Importing libraries
2024-05-29 16:43:37,716:INFO:Copying training dataset
2024-05-29 16:43:37,763:INFO:Defining folds
2024-05-29 16:43:37,763:INFO:Declaring metric variables
2024-05-29 16:43:37,768:INFO:Importing untrained model
2024-05-29 16:43:37,774:INFO:Linear Discriminant Analysis Imported successfully
2024-05-29 16:43:37,784:INFO:Starting cross validation
2024-05-29 16:43:37,785:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:43:38,147:INFO:Calculating mean and std
2024-05-29 16:43:38,149:INFO:Creating metrics dataframe
2024-05-29 16:43:38,152:INFO:Uploading results into container
2024-05-29 16:43:38,152:INFO:Uploading model into container now
2024-05-29 16:43:38,153:INFO:_master_model_container: 11
2024-05-29 16:43:38,153:INFO:_display_container: 2
2024-05-29 16:43:38,154:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-29 16:43:38,154:INFO:create_model() successfully completed......................................
2024-05-29 16:43:39,815:INFO:SubProcess create_model() end ==================================
2024-05-29 16:43:39,816:INFO:Creating metrics dataframe
2024-05-29 16:43:39,830:INFO:Initializing Extra Trees Classifier
2024-05-29 16:43:39,830:INFO:Total runtime is 0.8913236896197001 minutes
2024-05-29 16:43:39,834:INFO:SubProcess create_model() called ==================================
2024-05-29 16:43:39,835:INFO:Initializing create_model()
2024-05-29 16:43:39,835:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC10EFDF0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC0F54760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:43:39,836:INFO:Checking exceptions
2024-05-29 16:43:39,836:INFO:Importing libraries
2024-05-29 16:43:39,836:INFO:Copying training dataset
2024-05-29 16:43:39,884:INFO:Defining folds
2024-05-29 16:43:39,884:INFO:Declaring metric variables
2024-05-29 16:43:39,889:INFO:Importing untrained model
2024-05-29 16:43:39,894:INFO:Extra Trees Classifier Imported successfully
2024-05-29 16:43:39,904:INFO:Starting cross validation
2024-05-29 16:43:39,905:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:43:48,353:INFO:Calculating mean and std
2024-05-29 16:43:48,355:INFO:Creating metrics dataframe
2024-05-29 16:43:48,358:INFO:Uploading results into container
2024-05-29 16:43:48,359:INFO:Uploading model into container now
2024-05-29 16:43:48,361:INFO:_master_model_container: 12
2024-05-29 16:43:48,361:INFO:_display_container: 2
2024-05-29 16:43:48,362:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8002, verbose=0,
                     warm_start=False)
2024-05-29 16:43:48,363:INFO:create_model() successfully completed......................................
2024-05-29 16:43:49,937:INFO:SubProcess create_model() end ==================================
2024-05-29 16:43:49,937:INFO:Creating metrics dataframe
2024-05-29 16:43:49,951:INFO:Initializing Extreme Gradient Boosting
2024-05-29 16:43:49,952:INFO:Total runtime is 1.0600240031878154 minutes
2024-05-29 16:43:49,956:INFO:SubProcess create_model() called ==================================
2024-05-29 16:43:49,957:INFO:Initializing create_model()
2024-05-29 16:43:49,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC10EFDF0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC0F54760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:43:49,957:INFO:Checking exceptions
2024-05-29 16:43:49,957:INFO:Importing libraries
2024-05-29 16:43:49,958:INFO:Copying training dataset
2024-05-29 16:43:50,004:INFO:Defining folds
2024-05-29 16:43:50,004:INFO:Declaring metric variables
2024-05-29 16:43:50,009:INFO:Importing untrained model
2024-05-29 16:43:50,014:INFO:Extreme Gradient Boosting Imported successfully
2024-05-29 16:43:50,024:INFO:Starting cross validation
2024-05-29 16:43:50,025:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:43:51,463:INFO:Calculating mean and std
2024-05-29 16:43:51,465:INFO:Creating metrics dataframe
2024-05-29 16:43:51,468:INFO:Uploading results into container
2024-05-29 16:43:51,468:INFO:Uploading model into container now
2024-05-29 16:43:51,470:INFO:_master_model_container: 13
2024-05-29 16:43:51,470:INFO:_display_container: 2
2024-05-29 16:43:51,472:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-29 16:43:51,472:INFO:create_model() successfully completed......................................
2024-05-29 16:43:53,049:INFO:SubProcess create_model() end ==================================
2024-05-29 16:43:53,049:INFO:Creating metrics dataframe
2024-05-29 16:43:53,065:INFO:Initializing Light Gradient Boosting Machine
2024-05-29 16:43:53,065:INFO:Total runtime is 1.1119073828061423 minutes
2024-05-29 16:43:53,070:INFO:SubProcess create_model() called ==================================
2024-05-29 16:43:53,070:INFO:Initializing create_model()
2024-05-29 16:43:53,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC10EFDF0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC0F54760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:43:53,071:INFO:Checking exceptions
2024-05-29 16:43:53,071:INFO:Importing libraries
2024-05-29 16:43:53,071:INFO:Copying training dataset
2024-05-29 16:43:53,116:INFO:Defining folds
2024-05-29 16:43:53,117:INFO:Declaring metric variables
2024-05-29 16:43:53,122:INFO:Importing untrained model
2024-05-29 16:43:53,128:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-29 16:43:53,138:INFO:Starting cross validation
2024-05-29 16:43:53,139:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:43:55,318:INFO:Calculating mean and std
2024-05-29 16:43:55,321:INFO:Creating metrics dataframe
2024-05-29 16:43:55,324:INFO:Uploading results into container
2024-05-29 16:43:55,326:INFO:Uploading model into container now
2024-05-29 16:43:55,327:INFO:_master_model_container: 14
2024-05-29 16:43:55,327:INFO:_display_container: 2
2024-05-29 16:43:55,328:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8002, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-29 16:43:55,328:INFO:create_model() successfully completed......................................
2024-05-29 16:43:56,921:INFO:SubProcess create_model() end ==================================
2024-05-29 16:43:56,921:INFO:Creating metrics dataframe
2024-05-29 16:43:56,937:INFO:Initializing Dummy Classifier
2024-05-29 16:43:56,937:INFO:Total runtime is 1.1764489452044171 minutes
2024-05-29 16:43:56,942:INFO:SubProcess create_model() called ==================================
2024-05-29 16:43:56,942:INFO:Initializing create_model()
2024-05-29 16:43:56,943:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC10EFDF0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABC0F54760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:43:56,943:INFO:Checking exceptions
2024-05-29 16:43:56,943:INFO:Importing libraries
2024-05-29 16:43:56,943:INFO:Copying training dataset
2024-05-29 16:43:56,990:INFO:Defining folds
2024-05-29 16:43:56,990:INFO:Declaring metric variables
2024-05-29 16:43:56,996:INFO:Importing untrained model
2024-05-29 16:43:57,001:INFO:Dummy Classifier Imported successfully
2024-05-29 16:43:57,010:INFO:Starting cross validation
2024-05-29 16:43:57,011:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 16:43:57,086:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 16:43:57,096:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 16:43:57,111:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 16:43:57,127:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 16:43:57,146:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 16:43:57,171:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 16:43:57,177:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 16:43:57,198:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 16:43:57,213:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 16:43:57,226:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 16:43:57,246:INFO:Calculating mean and std
2024-05-29 16:43:57,248:INFO:Creating metrics dataframe
2024-05-29 16:43:57,250:INFO:Uploading results into container
2024-05-29 16:43:57,251:INFO:Uploading model into container now
2024-05-29 16:43:57,251:INFO:_master_model_container: 15
2024-05-29 16:43:57,252:INFO:_display_container: 2
2024-05-29 16:43:57,252:INFO:DummyClassifier(constant=None, random_state=8002, strategy='prior')
2024-05-29 16:43:57,253:INFO:create_model() successfully completed......................................
2024-05-29 16:43:58,914:INFO:SubProcess create_model() end ==================================
2024-05-29 16:43:58,914:INFO:Creating metrics dataframe
2024-05-29 16:43:58,931:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-29 16:43:58,945:INFO:Initializing create_model()
2024-05-29 16:43:58,945:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC10EFDF0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 16:43:58,945:INFO:Checking exceptions
2024-05-29 16:43:58,947:INFO:Importing libraries
2024-05-29 16:43:58,948:INFO:Copying training dataset
2024-05-29 16:43:58,994:INFO:Defining folds
2024-05-29 16:43:58,994:INFO:Declaring metric variables
2024-05-29 16:43:58,995:INFO:Importing untrained model
2024-05-29 16:43:58,995:INFO:Declaring custom model
2024-05-29 16:43:58,997:INFO:Extreme Gradient Boosting Imported successfully
2024-05-29 16:43:58,998:INFO:Cross validation set to False
2024-05-29 16:43:58,998:INFO:Fitting Model
2024-05-29 16:43:59,250:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-29 16:43:59,250:INFO:create_model() successfully completed......................................
2024-05-29 16:44:00,917:INFO:Creating Dashboard logs
2024-05-29 16:44:00,923:INFO:Model: Extreme Gradient Boosting
2024-05-29 16:44:01,014:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 8002, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2024-05-29 16:44:01,308:INFO:Initializing predict_model()
2024-05-29 16:44:01,308:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001ABC10EFDF0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001AC02CC9120>)
2024-05-29 16:44:01,308:INFO:Checking exceptions
2024-05-29 16:44:01,308:INFO:Preloading libraries
2024-05-29 16:44:04,927:INFO:Creating Dashboard logs
2024-05-29 16:44:04,931:INFO:Model: Light Gradient Boosting Machine
2024-05-29 16:44:05,019:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 8002, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-05-29 16:44:06,973:INFO:Creating Dashboard logs
2024-05-29 16:44:06,978:INFO:Model: Gradient Boosting Classifier
2024-05-29 16:44:07,069:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 8002, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-29 16:44:09,001:INFO:Creating Dashboard logs
2024-05-29 16:44:09,005:INFO:Model: Random Forest Classifier
2024-05-29 16:44:09,095:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 8002, 'verbose': 0, 'warm_start': False}
2024-05-29 16:44:11,023:INFO:Creating Dashboard logs
2024-05-29 16:44:11,027:INFO:Model: Ada Boost Classifier
2024-05-29 16:44:11,115:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 8002}
2024-05-29 16:44:12,977:INFO:Creating Dashboard logs
2024-05-29 16:44:12,982:INFO:Model: Extra Trees Classifier
2024-05-29 16:44:13,072:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 8002, 'verbose': 0, 'warm_start': False}
2024-05-29 16:44:14,971:INFO:Creating Dashboard logs
2024-05-29 16:44:14,975:INFO:Model: Logistic Regression
2024-05-29 16:44:15,064:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 8002, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-05-29 16:44:17,109:INFO:Creating Dashboard logs
2024-05-29 16:44:17,113:INFO:Model: Ridge Classifier
2024-05-29 16:44:17,202:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 8002, 'solver': 'auto', 'tol': 0.0001}
2024-05-29 16:44:19,074:INFO:Creating Dashboard logs
2024-05-29 16:44:19,079:INFO:Model: Linear Discriminant Analysis
2024-05-29 16:44:19,166:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-05-29 16:44:21,044:INFO:Creating Dashboard logs
2024-05-29 16:44:21,048:INFO:Model: SVM - Linear Kernel
2024-05-29 16:44:21,136:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 8002, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-29 16:44:23,041:INFO:Creating Dashboard logs
2024-05-29 16:44:23,045:INFO:Model: K Neighbors Classifier
2024-05-29 16:44:23,137:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2024-05-29 16:44:25,057:INFO:Creating Dashboard logs
2024-05-29 16:44:25,061:INFO:Model: Decision Tree Classifier
2024-05-29 16:44:25,149:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 8002, 'splitter': 'best'}
2024-05-29 16:44:27,078:INFO:Creating Dashboard logs
2024-05-29 16:44:27,084:INFO:Model: Quadratic Discriminant Analysis
2024-05-29 16:44:27,179:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2024-05-29 16:44:29,070:INFO:Creating Dashboard logs
2024-05-29 16:44:29,074:INFO:Model: Naive Bayes
2024-05-29 16:44:29,166:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-05-29 16:44:31,240:INFO:Creating Dashboard logs
2024-05-29 16:44:31,245:INFO:Model: Dummy Classifier
2024-05-29 16:44:31,340:INFO:Logged params: {'constant': None, 'random_state': 8002, 'strategy': 'prior'}
2024-05-29 16:44:33,339:INFO:_master_model_container: 15
2024-05-29 16:44:33,339:INFO:_display_container: 2
2024-05-29 16:44:33,340:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-29 16:44:33,342:INFO:compare_models() successfully completed......................................
2024-05-29 17:33:37,943:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-29 17:33:37,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-29 17:33:37,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-29 17:33:37,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-29 17:39:20,246:INFO:PyCaret ClassificationExperiment
2024-05-29 17:39:20,246:INFO:Logging name: codex
2024-05-29 17:39:20,246:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-29 17:39:20,246:INFO:version 3.3.2
2024-05-29 17:39:20,246:INFO:Initializing setup()
2024-05-29 17:39:20,246:INFO:self.USI: 94ce
2024-05-29 17:39:20,246:INFO:self._variable_keys: {'html_param', 'y_train', 'y', 'exp_name_log', 'fold_groups_param', 'n_jobs_param', 'target_param', 'pipeline', 'idx', 'y_test', 'gpu_param', 'seed', 'X', 'fold_generator', 'data', 'is_multiclass', 'X_train', 'exp_id', 'fix_imbalance', '_ml_usecase', 'logging_param', 'memory', 'gpu_n_jobs_param', 'fold_shuffle_param', 'X_test', '_available_plots', 'log_plots_param', 'USI'}
2024-05-29 17:39:20,246:INFO:Checking environment
2024-05-29 17:39:20,247:INFO:python_version: 3.10.13
2024-05-29 17:39:20,247:INFO:python_build: ('main', 'Sep 11 2023 13:24:38')
2024-05-29 17:39:20,247:INFO:machine: AMD64
2024-05-29 17:39:20,247:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-29 17:39:20,247:INFO:Memory: svmem(total=34267656192, available=15005114368, percent=56.2, used=19262541824, free=15005114368)
2024-05-29 17:39:20,247:INFO:Physical Core: 8
2024-05-29 17:39:20,247:INFO:Logical Core: 16
2024-05-29 17:39:20,247:INFO:Checking libraries
2024-05-29 17:39:20,247:INFO:System:
2024-05-29 17:39:20,247:INFO:    python: 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]
2024-05-29 17:39:20,247:INFO:executable: c:\Users\Adm\.conda\envs\python310\python.exe
2024-05-29 17:39:20,248:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-29 17:39:20,248:INFO:PyCaret required dependencies:
2024-05-29 17:39:20,285:INFO:                 pip: 23.3
2024-05-29 17:39:20,285:INFO:          setuptools: 68.0.0
2024-05-29 17:39:20,285:INFO:             pycaret: 3.3.2
2024-05-29 17:39:20,286:INFO:             IPython: 8.24.0
2024-05-29 17:39:20,286:INFO:          ipywidgets: 8.1.2
2024-05-29 17:39:20,286:INFO:                tqdm: 4.66.4
2024-05-29 17:39:20,286:INFO:               numpy: 1.26.4
2024-05-29 17:39:20,286:INFO:              pandas: 2.1.4
2024-05-29 17:39:20,286:INFO:              jinja2: 3.1.4
2024-05-29 17:39:20,286:INFO:               scipy: 1.11.4
2024-05-29 17:39:20,286:INFO:              joblib: 1.3.2
2024-05-29 17:39:20,286:INFO:             sklearn: 1.4.2
2024-05-29 17:39:20,286:INFO:                pyod: 1.1.3
2024-05-29 17:39:20,286:INFO:            imblearn: 0.12.2
2024-05-29 17:39:20,286:INFO:   category_encoders: 2.6.3
2024-05-29 17:39:20,287:INFO:            lightgbm: 4.3.0
2024-05-29 17:39:20,287:INFO:               numba: 0.59.1
2024-05-29 17:39:20,287:INFO:            requests: 2.32.2
2024-05-29 17:39:20,287:INFO:          matplotlib: 3.7.5
2024-05-29 17:39:20,287:INFO:          scikitplot: 0.3.7
2024-05-29 17:39:20,287:INFO:         yellowbrick: 1.5
2024-05-29 17:39:20,287:INFO:              plotly: 5.22.0
2024-05-29 17:39:20,287:INFO:    plotly-resampler: Not installed
2024-05-29 17:39:20,287:INFO:             kaleido: 0.2.1
2024-05-29 17:39:20,287:INFO:           schemdraw: 0.15
2024-05-29 17:39:20,288:INFO:         statsmodels: 0.14.2
2024-05-29 17:39:20,288:INFO:              sktime: 0.26.0
2024-05-29 17:39:20,288:INFO:               tbats: 1.1.3
2024-05-29 17:39:20,288:INFO:            pmdarima: 2.0.4
2024-05-29 17:39:20,288:INFO:              psutil: 5.9.0
2024-05-29 17:39:20,288:INFO:          markupsafe: 2.1.5
2024-05-29 17:39:20,288:INFO:             pickle5: Not installed
2024-05-29 17:39:20,288:INFO:         cloudpickle: 3.0.0
2024-05-29 17:39:20,288:INFO:         deprecation: 2.1.0
2024-05-29 17:39:20,288:INFO:              xxhash: 3.4.1
2024-05-29 17:39:20,288:INFO:           wurlitzer: Not installed
2024-05-29 17:39:20,288:INFO:PyCaret optional dependencies:
2024-05-29 17:39:20,313:INFO:                shap: Not installed
2024-05-29 17:39:20,313:INFO:           interpret: Not installed
2024-05-29 17:39:20,313:INFO:                umap: Not installed
2024-05-29 17:39:20,313:INFO:     ydata_profiling: Not installed
2024-05-29 17:39:20,313:INFO:  explainerdashboard: Not installed
2024-05-29 17:39:20,314:INFO:             autoviz: Not installed
2024-05-29 17:39:20,314:INFO:           fairlearn: Not installed
2024-05-29 17:39:20,314:INFO:          deepchecks: Not installed
2024-05-29 17:39:20,314:INFO:             xgboost: 2.0.3
2024-05-29 17:39:20,314:INFO:            catboost: Not installed
2024-05-29 17:39:20,314:INFO:              kmodes: Not installed
2024-05-29 17:39:20,314:INFO:             mlxtend: Not installed
2024-05-29 17:39:20,314:INFO:       statsforecast: Not installed
2024-05-29 17:39:20,314:INFO:        tune_sklearn: Not installed
2024-05-29 17:39:20,314:INFO:                 ray: Not installed
2024-05-29 17:39:20,314:INFO:            hyperopt: 0.2.7
2024-05-29 17:39:20,314:INFO:              optuna: Not installed
2024-05-29 17:39:20,315:INFO:               skopt: Not installed
2024-05-29 17:39:20,315:INFO:              mlflow: 2.13.0
2024-05-29 17:39:20,315:INFO:              gradio: Not installed
2024-05-29 17:39:20,315:INFO:             fastapi: Not installed
2024-05-29 17:39:20,315:INFO:             uvicorn: Not installed
2024-05-29 17:39:20,315:INFO:              m2cgen: Not installed
2024-05-29 17:39:20,315:INFO:           evidently: Not installed
2024-05-29 17:39:20,315:INFO:               fugue: Not installed
2024-05-29 17:39:20,315:INFO:           streamlit: Not installed
2024-05-29 17:39:20,315:INFO:             prophet: Not installed
2024-05-29 17:39:20,315:INFO:None
2024-05-29 17:39:20,315:INFO:Set up data.
2024-05-29 17:39:20,344:INFO:Set up folding strategy.
2024-05-29 17:39:20,345:INFO:Set up train/test split.
2024-05-29 17:39:20,403:INFO:Set up index.
2024-05-29 17:39:20,405:INFO:Assigning column types.
2024-05-29 17:39:20,438:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-29 17:39:20,511:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 17:39:20,516:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 17:39:20,571:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 17:39:20,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 17:39:20,647:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-29 17:39:20,649:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 17:39:20,694:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 17:39:20,699:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 17:39:20,699:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-29 17:39:20,774:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 17:39:20,818:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 17:39:20,825:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 17:39:20,899:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-29 17:39:20,944:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 17:39:20,948:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 17:39:20,949:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-29 17:39:21,067:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 17:39:21,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 17:39:21,191:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 17:39:21,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 17:39:21,234:INFO:Finished creating preprocessing pipeline.
2024-05-29 17:39:21,235:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2024-05-29 17:39:21,235:INFO:Creating final display dataframe.
2024-05-29 17:39:21,443:INFO:Setup _display_container:                    Description        Value
0                   Session id         7886
1                       Target       target
2                  Target type       Binary
3          Original data shape  (90000, 18)
4       Transformed data shape  (90000, 18)
5  Transformed train set shape  (72000, 18)
6   Transformed test set shape  (18000, 18)
7             Numeric features           17
2024-05-29 17:39:21,592:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 17:39:21,597:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 17:39:21,717:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-29 17:39:21,721:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-29 17:39:21,723:INFO:Logging experiment in loggers
2024-05-29 17:39:22,121:INFO:SubProcess save_model() called ==================================
2024-05-29 17:39:22,122:INFO:Initializing save_model()
2024-05-29 17:39:22,122:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), model_name=C:\Users\Adm\AppData\Local\Temp\tmp_t71vwzv\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-29 17:39:22,122:INFO:Adding model into prep_pipe
2024-05-29 17:39:22,122:WARNING:Only Model saved as it was a pipeline.
2024-05-29 17:39:22,127:INFO:C:\Users\Adm\AppData\Local\Temp\tmp_t71vwzv\Transformation Pipeline.pkl saved in current working directory
2024-05-29 17:39:22,128:INFO:Pipeline(memory=FastMemory(location=C:\Users\Adm\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2024-05-29 17:39:22,128:INFO:save_model() successfully completed......................................
2024-05-29 17:39:23,819:INFO:SubProcess save_model() end ==================================
2024-05-29 17:39:23,844:INFO:setup() successfully completed in 1.52s...............
2024-05-29 17:39:23,845:INFO:Initializing compare_models()
2024-05-29 17:39:23,845:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E640CDA1A0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E640CDA1A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-29 17:39:23,845:INFO:Checking exceptions
2024-05-29 17:39:23,874:INFO:Preparing display monitor
2024-05-29 17:39:23,907:INFO:Initializing Logistic Regression
2024-05-29 17:39:23,907:INFO:Total runtime is 0.0 minutes
2024-05-29 17:39:23,913:INFO:SubProcess create_model() called ==================================
2024-05-29 17:39:23,913:INFO:Initializing create_model()
2024-05-29 17:39:23,913:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E640CDA1A0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6406FAA40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 17:39:23,914:INFO:Checking exceptions
2024-05-29 17:39:23,914:INFO:Importing libraries
2024-05-29 17:39:23,914:INFO:Copying training dataset
2024-05-29 17:39:23,964:INFO:Defining folds
2024-05-29 17:39:23,964:INFO:Declaring metric variables
2024-05-29 17:39:23,971:INFO:Importing untrained model
2024-05-29 17:39:23,980:INFO:Logistic Regression Imported successfully
2024-05-29 17:39:23,993:INFO:Starting cross validation
2024-05-29 17:39:23,995:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 17:39:31,014:INFO:Calculating mean and std
2024-05-29 17:39:31,017:INFO:Creating metrics dataframe
2024-05-29 17:39:31,020:INFO:Uploading results into container
2024-05-29 17:39:31,021:INFO:Uploading model into container now
2024-05-29 17:39:31,022:INFO:_master_model_container: 1
2024-05-29 17:39:31,023:INFO:_display_container: 2
2024-05-29 17:39:31,024:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7886, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-29 17:39:31,024:INFO:create_model() successfully completed......................................
2024-05-29 17:39:32,601:INFO:SubProcess create_model() end ==================================
2024-05-29 17:39:32,601:INFO:Creating metrics dataframe
2024-05-29 17:39:32,609:INFO:Initializing K Neighbors Classifier
2024-05-29 17:39:32,610:INFO:Total runtime is 0.14504774808883666 minutes
2024-05-29 17:39:32,614:INFO:SubProcess create_model() called ==================================
2024-05-29 17:39:32,614:INFO:Initializing create_model()
2024-05-29 17:39:32,615:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E640CDA1A0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6406FAA40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 17:39:32,615:INFO:Checking exceptions
2024-05-29 17:39:32,615:INFO:Importing libraries
2024-05-29 17:39:32,615:INFO:Copying training dataset
2024-05-29 17:39:32,663:INFO:Defining folds
2024-05-29 17:39:32,663:INFO:Declaring metric variables
2024-05-29 17:39:32,668:INFO:Importing untrained model
2024-05-29 17:39:32,673:INFO:K Neighbors Classifier Imported successfully
2024-05-29 17:39:32,682:INFO:Starting cross validation
2024-05-29 17:39:32,683:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 17:39:46,220:INFO:Calculating mean and std
2024-05-29 17:39:46,222:INFO:Creating metrics dataframe
2024-05-29 17:39:46,224:INFO:Uploading results into container
2024-05-29 17:39:46,225:INFO:Uploading model into container now
2024-05-29 17:39:46,226:INFO:_master_model_container: 2
2024-05-29 17:39:46,226:INFO:_display_container: 2
2024-05-29 17:39:46,226:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-29 17:39:46,227:INFO:create_model() successfully completed......................................
2024-05-29 17:39:47,830:INFO:SubProcess create_model() end ==================================
2024-05-29 17:39:47,830:INFO:Creating metrics dataframe
2024-05-29 17:39:47,840:INFO:Initializing Naive Bayes
2024-05-29 17:39:47,840:INFO:Total runtime is 0.398886219660441 minutes
2024-05-29 17:39:47,846:INFO:SubProcess create_model() called ==================================
2024-05-29 17:39:47,846:INFO:Initializing create_model()
2024-05-29 17:39:47,846:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E640CDA1A0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6406FAA40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 17:39:47,846:INFO:Checking exceptions
2024-05-29 17:39:47,847:INFO:Importing libraries
2024-05-29 17:39:47,847:INFO:Copying training dataset
2024-05-29 17:39:47,895:INFO:Defining folds
2024-05-29 17:39:47,896:INFO:Declaring metric variables
2024-05-29 17:39:47,901:INFO:Importing untrained model
2024-05-29 17:39:47,905:INFO:Naive Bayes Imported successfully
2024-05-29 17:39:47,915:INFO:Starting cross validation
2024-05-29 17:39:47,916:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 17:39:48,243:INFO:Calculating mean and std
2024-05-29 17:39:48,245:INFO:Creating metrics dataframe
2024-05-29 17:39:48,248:INFO:Uploading results into container
2024-05-29 17:39:48,249:INFO:Uploading model into container now
2024-05-29 17:39:48,250:INFO:_master_model_container: 3
2024-05-29 17:39:48,250:INFO:_display_container: 2
2024-05-29 17:39:48,250:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-29 17:39:48,251:INFO:create_model() successfully completed......................................
2024-05-29 17:39:49,935:INFO:SubProcess create_model() end ==================================
2024-05-29 17:39:49,935:INFO:Creating metrics dataframe
2024-05-29 17:39:49,946:INFO:Initializing Decision Tree Classifier
2024-05-29 17:39:49,946:INFO:Total runtime is 0.43397402366002397 minutes
2024-05-29 17:39:49,951:INFO:SubProcess create_model() called ==================================
2024-05-29 17:39:49,951:INFO:Initializing create_model()
2024-05-29 17:39:49,951:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E640CDA1A0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6406FAA40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 17:39:49,951:INFO:Checking exceptions
2024-05-29 17:39:49,951:INFO:Importing libraries
2024-05-29 17:39:49,952:INFO:Copying training dataset
2024-05-29 17:39:50,008:INFO:Defining folds
2024-05-29 17:39:50,009:INFO:Declaring metric variables
2024-05-29 17:39:50,017:INFO:Importing untrained model
2024-05-29 17:39:50,024:INFO:Decision Tree Classifier Imported successfully
2024-05-29 17:39:50,037:INFO:Starting cross validation
2024-05-29 17:39:50,038:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 17:39:50,713:INFO:Calculating mean and std
2024-05-29 17:39:50,715:INFO:Creating metrics dataframe
2024-05-29 17:39:50,718:INFO:Uploading results into container
2024-05-29 17:39:50,718:INFO:Uploading model into container now
2024-05-29 17:39:50,719:INFO:_master_model_container: 4
2024-05-29 17:39:50,719:INFO:_display_container: 2
2024-05-29 17:39:50,720:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7886, splitter='best')
2024-05-29 17:39:50,720:INFO:create_model() successfully completed......................................
2024-05-29 17:39:52,357:INFO:SubProcess create_model() end ==================================
2024-05-29 17:39:52,357:INFO:Creating metrics dataframe
2024-05-29 17:39:52,368:INFO:Initializing SVM - Linear Kernel
2024-05-29 17:39:52,369:INFO:Total runtime is 0.4743682344754537 minutes
2024-05-29 17:39:52,373:INFO:SubProcess create_model() called ==================================
2024-05-29 17:39:52,374:INFO:Initializing create_model()
2024-05-29 17:39:52,374:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E640CDA1A0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6406FAA40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 17:39:52,374:INFO:Checking exceptions
2024-05-29 17:39:52,374:INFO:Importing libraries
2024-05-29 17:39:52,374:INFO:Copying training dataset
2024-05-29 17:39:52,424:INFO:Defining folds
2024-05-29 17:39:52,424:INFO:Declaring metric variables
2024-05-29 17:39:52,429:INFO:Importing untrained model
2024-05-29 17:39:52,434:INFO:SVM - Linear Kernel Imported successfully
2024-05-29 17:39:52,444:INFO:Starting cross validation
2024-05-29 17:39:52,445:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 17:39:52,915:INFO:Calculating mean and std
2024-05-29 17:39:52,917:INFO:Creating metrics dataframe
2024-05-29 17:39:52,919:INFO:Uploading results into container
2024-05-29 17:39:52,920:INFO:Uploading model into container now
2024-05-29 17:39:52,921:INFO:_master_model_container: 5
2024-05-29 17:39:52,921:INFO:_display_container: 2
2024-05-29 17:39:52,921:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7886, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-29 17:39:52,922:INFO:create_model() successfully completed......................................
2024-05-29 17:39:54,552:INFO:SubProcess create_model() end ==================================
2024-05-29 17:39:54,552:INFO:Creating metrics dataframe
2024-05-29 17:39:54,563:INFO:Initializing Ridge Classifier
2024-05-29 17:39:54,563:INFO:Total runtime is 0.5109368443489074 minutes
2024-05-29 17:39:54,568:INFO:SubProcess create_model() called ==================================
2024-05-29 17:39:54,569:INFO:Initializing create_model()
2024-05-29 17:39:54,569:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E640CDA1A0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6406FAA40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 17:39:54,570:INFO:Checking exceptions
2024-05-29 17:39:54,570:INFO:Importing libraries
2024-05-29 17:39:54,570:INFO:Copying training dataset
2024-05-29 17:39:54,619:INFO:Defining folds
2024-05-29 17:39:54,619:INFO:Declaring metric variables
2024-05-29 17:39:54,625:INFO:Importing untrained model
2024-05-29 17:39:54,630:INFO:Ridge Classifier Imported successfully
2024-05-29 17:39:54,640:INFO:Starting cross validation
2024-05-29 17:39:54,642:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 17:39:54,932:INFO:Calculating mean and std
2024-05-29 17:39:54,934:INFO:Creating metrics dataframe
2024-05-29 17:39:54,937:INFO:Uploading results into container
2024-05-29 17:39:54,937:INFO:Uploading model into container now
2024-05-29 17:39:54,938:INFO:_master_model_container: 6
2024-05-29 17:39:54,938:INFO:_display_container: 2
2024-05-29 17:39:54,938:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7886, solver='auto',
                tol=0.0001)
2024-05-29 17:39:54,939:INFO:create_model() successfully completed......................................
2024-05-29 17:39:56,597:INFO:SubProcess create_model() end ==================================
2024-05-29 17:39:56,597:INFO:Creating metrics dataframe
2024-05-29 17:39:56,609:INFO:Initializing Random Forest Classifier
2024-05-29 17:39:56,610:INFO:Total runtime is 0.5450510104497273 minutes
2024-05-29 17:39:56,614:INFO:SubProcess create_model() called ==================================
2024-05-29 17:39:56,615:INFO:Initializing create_model()
2024-05-29 17:39:56,615:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E640CDA1A0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6406FAA40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 17:39:56,615:INFO:Checking exceptions
2024-05-29 17:39:56,615:INFO:Importing libraries
2024-05-29 17:39:56,616:INFO:Copying training dataset
2024-05-29 17:39:56,664:INFO:Defining folds
2024-05-29 17:39:56,664:INFO:Declaring metric variables
2024-05-29 17:39:56,669:INFO:Importing untrained model
2024-05-29 17:39:56,675:INFO:Random Forest Classifier Imported successfully
2024-05-29 17:39:56,685:INFO:Starting cross validation
2024-05-29 17:39:56,686:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 17:40:05,188:INFO:Calculating mean and std
2024-05-29 17:40:05,190:INFO:Creating metrics dataframe
2024-05-29 17:40:05,193:INFO:Uploading results into container
2024-05-29 17:40:05,194:INFO:Uploading model into container now
2024-05-29 17:40:05,195:INFO:_master_model_container: 7
2024-05-29 17:40:05,195:INFO:_display_container: 2
2024-05-29 17:40:05,196:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=7886, verbose=0,
                       warm_start=False)
2024-05-29 17:40:05,196:INFO:create_model() successfully completed......................................
2024-05-29 17:40:06,771:INFO:SubProcess create_model() end ==================================
2024-05-29 17:40:06,772:INFO:Creating metrics dataframe
2024-05-29 17:40:06,784:INFO:Initializing Quadratic Discriminant Analysis
2024-05-29 17:40:06,784:INFO:Total runtime is 0.7146160085995991 minutes
2024-05-29 17:40:06,789:INFO:SubProcess create_model() called ==================================
2024-05-29 17:40:06,789:INFO:Initializing create_model()
2024-05-29 17:40:06,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E640CDA1A0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6406FAA40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 17:40:06,789:INFO:Checking exceptions
2024-05-29 17:40:06,790:INFO:Importing libraries
2024-05-29 17:40:06,790:INFO:Copying training dataset
2024-05-29 17:40:06,842:INFO:Defining folds
2024-05-29 17:40:06,843:INFO:Declaring metric variables
2024-05-29 17:40:06,849:INFO:Importing untrained model
2024-05-29 17:40:06,854:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-29 17:40:06,864:INFO:Starting cross validation
2024-05-29 17:40:06,865:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 17:40:07,233:INFO:Calculating mean and std
2024-05-29 17:40:07,235:INFO:Creating metrics dataframe
2024-05-29 17:40:07,237:INFO:Uploading results into container
2024-05-29 17:40:07,238:INFO:Uploading model into container now
2024-05-29 17:40:07,238:INFO:_master_model_container: 8
2024-05-29 17:40:07,239:INFO:_display_container: 2
2024-05-29 17:40:07,239:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-29 17:40:07,239:INFO:create_model() successfully completed......................................
2024-05-29 17:40:08,880:INFO:SubProcess create_model() end ==================================
2024-05-29 17:40:08,880:INFO:Creating metrics dataframe
2024-05-29 17:40:08,893:INFO:Initializing Ada Boost Classifier
2024-05-29 17:40:08,893:INFO:Total runtime is 0.7497681697209675 minutes
2024-05-29 17:40:08,898:INFO:SubProcess create_model() called ==================================
2024-05-29 17:40:08,898:INFO:Initializing create_model()
2024-05-29 17:40:08,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E640CDA1A0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6406FAA40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 17:40:08,899:INFO:Checking exceptions
2024-05-29 17:40:08,899:INFO:Importing libraries
2024-05-29 17:40:08,899:INFO:Copying training dataset
2024-05-29 17:40:08,948:INFO:Defining folds
2024-05-29 17:40:08,948:INFO:Declaring metric variables
2024-05-29 17:40:08,953:INFO:Importing untrained model
2024-05-29 17:40:08,959:INFO:Ada Boost Classifier Imported successfully
2024-05-29 17:40:08,969:INFO:Starting cross validation
2024-05-29 17:40:08,970:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 17:40:09,029:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 17:40:09,045:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 17:40:09,062:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 17:40:09,079:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 17:40:09,100:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 17:40:09,125:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 17:40:09,144:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 17:40:09,165:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 17:40:09,185:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 17:40:09,211:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-29 17:40:12,118:INFO:Calculating mean and std
2024-05-29 17:40:12,120:INFO:Creating metrics dataframe
2024-05-29 17:40:12,122:INFO:Uploading results into container
2024-05-29 17:40:12,123:INFO:Uploading model into container now
2024-05-29 17:40:12,123:INFO:_master_model_container: 9
2024-05-29 17:40:12,124:INFO:_display_container: 2
2024-05-29 17:40:12,124:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=7886)
2024-05-29 17:40:12,124:INFO:create_model() successfully completed......................................
2024-05-29 17:40:13,680:INFO:SubProcess create_model() end ==================================
2024-05-29 17:40:13,680:INFO:Creating metrics dataframe
2024-05-29 17:40:13,694:INFO:Initializing Gradient Boosting Classifier
2024-05-29 17:40:13,695:INFO:Total runtime is 0.8298025528589883 minutes
2024-05-29 17:40:13,700:INFO:SubProcess create_model() called ==================================
2024-05-29 17:40:13,700:INFO:Initializing create_model()
2024-05-29 17:40:13,701:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E640CDA1A0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6406FAA40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 17:40:13,701:INFO:Checking exceptions
2024-05-29 17:40:13,701:INFO:Importing libraries
2024-05-29 17:40:13,701:INFO:Copying training dataset
2024-05-29 17:40:13,750:INFO:Defining folds
2024-05-29 17:40:13,750:INFO:Declaring metric variables
2024-05-29 17:40:13,755:INFO:Importing untrained model
2024-05-29 17:40:13,762:INFO:Gradient Boosting Classifier Imported successfully
2024-05-29 17:40:13,771:INFO:Starting cross validation
2024-05-29 17:40:13,771:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 17:40:23,220:INFO:Calculating mean and std
2024-05-29 17:40:23,222:INFO:Creating metrics dataframe
2024-05-29 17:40:23,224:INFO:Uploading results into container
2024-05-29 17:40:23,225:INFO:Uploading model into container now
2024-05-29 17:40:23,225:INFO:_master_model_container: 10
2024-05-29 17:40:23,226:INFO:_display_container: 2
2024-05-29 17:40:23,226:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7886, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-29 17:40:23,227:INFO:create_model() successfully completed......................................
2024-05-29 17:40:24,799:INFO:SubProcess create_model() end ==================================
2024-05-29 17:40:24,799:INFO:Creating metrics dataframe
2024-05-29 17:40:24,814:INFO:Initializing Linear Discriminant Analysis
2024-05-29 17:40:24,814:INFO:Total runtime is 1.0151068329811095 minutes
2024-05-29 17:40:24,819:INFO:SubProcess create_model() called ==================================
2024-05-29 17:40:24,819:INFO:Initializing create_model()
2024-05-29 17:40:24,819:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E640CDA1A0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6406FAA40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 17:40:24,819:INFO:Checking exceptions
2024-05-29 17:40:24,820:INFO:Importing libraries
2024-05-29 17:40:24,820:INFO:Copying training dataset
2024-05-29 17:40:24,867:INFO:Defining folds
2024-05-29 17:40:24,867:INFO:Declaring metric variables
2024-05-29 17:40:24,873:INFO:Importing untrained model
2024-05-29 17:40:24,878:INFO:Linear Discriminant Analysis Imported successfully
2024-05-29 17:40:24,888:INFO:Starting cross validation
2024-05-29 17:40:24,889:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 17:40:25,218:INFO:Calculating mean and std
2024-05-29 17:40:25,220:INFO:Creating metrics dataframe
2024-05-29 17:40:25,223:INFO:Uploading results into container
2024-05-29 17:40:25,223:INFO:Uploading model into container now
2024-05-29 17:40:25,224:INFO:_master_model_container: 11
2024-05-29 17:40:25,224:INFO:_display_container: 2
2024-05-29 17:40:25,224:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-29 17:40:25,225:INFO:create_model() successfully completed......................................
2024-05-29 17:40:26,919:INFO:SubProcess create_model() end ==================================
2024-05-29 17:40:26,919:INFO:Creating metrics dataframe
2024-05-29 17:40:26,933:INFO:Initializing Extra Trees Classifier
2024-05-29 17:40:26,934:INFO:Total runtime is 1.0504480044047035 minutes
2024-05-29 17:40:26,939:INFO:SubProcess create_model() called ==================================
2024-05-29 17:40:26,939:INFO:Initializing create_model()
2024-05-29 17:40:26,940:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E640CDA1A0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6406FAA40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 17:40:26,940:INFO:Checking exceptions
2024-05-29 17:40:26,940:INFO:Importing libraries
2024-05-29 17:40:26,940:INFO:Copying training dataset
2024-05-29 17:40:26,988:INFO:Defining folds
2024-05-29 17:40:26,988:INFO:Declaring metric variables
2024-05-29 17:40:26,994:INFO:Importing untrained model
2024-05-29 17:40:26,999:INFO:Extra Trees Classifier Imported successfully
2024-05-29 17:40:27,010:INFO:Starting cross validation
2024-05-29 17:40:27,011:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 17:40:35,660:INFO:Calculating mean and std
2024-05-29 17:40:35,663:INFO:Creating metrics dataframe
2024-05-29 17:40:35,666:INFO:Uploading results into container
2024-05-29 17:40:35,667:INFO:Uploading model into container now
2024-05-29 17:40:35,668:INFO:_master_model_container: 12
2024-05-29 17:40:35,668:INFO:_display_container: 2
2024-05-29 17:40:35,669:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=7886, verbose=0,
                     warm_start=False)
2024-05-29 17:40:35,669:INFO:create_model() successfully completed......................................
2024-05-29 17:40:37,260:INFO:SubProcess create_model() end ==================================
2024-05-29 17:40:37,260:INFO:Creating metrics dataframe
2024-05-29 17:40:37,275:INFO:Initializing Extreme Gradient Boosting
2024-05-29 17:40:37,276:INFO:Total runtime is 1.2228024641672768 minutes
2024-05-29 17:40:37,280:INFO:SubProcess create_model() called ==================================
2024-05-29 17:40:37,280:INFO:Initializing create_model()
2024-05-29 17:40:37,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E640CDA1A0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6406FAA40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 17:40:37,281:INFO:Checking exceptions
2024-05-29 17:40:37,281:INFO:Importing libraries
2024-05-29 17:40:37,281:INFO:Copying training dataset
2024-05-29 17:40:37,332:INFO:Defining folds
2024-05-29 17:40:37,333:INFO:Declaring metric variables
2024-05-29 17:40:37,338:INFO:Importing untrained model
2024-05-29 17:40:37,345:INFO:Extreme Gradient Boosting Imported successfully
2024-05-29 17:40:37,355:INFO:Starting cross validation
2024-05-29 17:40:37,356:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 17:40:38,930:INFO:Calculating mean and std
2024-05-29 17:40:38,932:INFO:Creating metrics dataframe
2024-05-29 17:40:38,935:INFO:Uploading results into container
2024-05-29 17:40:38,936:INFO:Uploading model into container now
2024-05-29 17:40:38,937:INFO:_master_model_container: 13
2024-05-29 17:40:38,937:INFO:_display_container: 2
2024-05-29 17:40:38,938:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-29 17:40:38,938:INFO:create_model() successfully completed......................................
2024-05-29 17:40:40,544:INFO:SubProcess create_model() end ==================================
2024-05-29 17:40:40,544:INFO:Creating metrics dataframe
2024-05-29 17:40:40,560:INFO:Initializing Light Gradient Boosting Machine
2024-05-29 17:40:40,561:INFO:Total runtime is 1.2775701681772866 minutes
2024-05-29 17:40:40,566:INFO:SubProcess create_model() called ==================================
2024-05-29 17:40:40,566:INFO:Initializing create_model()
2024-05-29 17:40:40,566:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E640CDA1A0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6406FAA40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 17:40:40,567:INFO:Checking exceptions
2024-05-29 17:40:40,567:INFO:Importing libraries
2024-05-29 17:40:40,567:INFO:Copying training dataset
2024-05-29 17:40:40,615:INFO:Defining folds
2024-05-29 17:40:40,615:INFO:Declaring metric variables
2024-05-29 17:40:40,620:INFO:Importing untrained model
2024-05-29 17:40:40,627:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-29 17:40:40,637:INFO:Starting cross validation
2024-05-29 17:40:40,639:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 17:40:43,234:INFO:Calculating mean and std
2024-05-29 17:40:43,236:INFO:Creating metrics dataframe
2024-05-29 17:40:43,239:INFO:Uploading results into container
2024-05-29 17:40:43,240:INFO:Uploading model into container now
2024-05-29 17:40:43,241:INFO:_master_model_container: 14
2024-05-29 17:40:43,241:INFO:_display_container: 2
2024-05-29 17:40:43,242:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7886, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-29 17:40:43,242:INFO:create_model() successfully completed......................................
2024-05-29 17:40:44,802:INFO:SubProcess create_model() end ==================================
2024-05-29 17:40:44,802:INFO:Creating metrics dataframe
2024-05-29 17:40:44,818:INFO:Initializing Dummy Classifier
2024-05-29 17:40:44,818:INFO:Total runtime is 1.348518613974253 minutes
2024-05-29 17:40:44,824:INFO:SubProcess create_model() called ==================================
2024-05-29 17:40:44,824:INFO:Initializing create_model()
2024-05-29 17:40:44,825:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E640CDA1A0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6406FAA40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 17:40:44,825:INFO:Checking exceptions
2024-05-29 17:40:44,825:INFO:Importing libraries
2024-05-29 17:40:44,825:INFO:Copying training dataset
2024-05-29 17:40:44,888:INFO:Defining folds
2024-05-29 17:40:44,888:INFO:Declaring metric variables
2024-05-29 17:40:44,895:INFO:Importing untrained model
2024-05-29 17:40:44,901:INFO:Dummy Classifier Imported successfully
2024-05-29 17:40:44,913:INFO:Starting cross validation
2024-05-29 17:40:44,914:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-29 17:40:44,998:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 17:40:45,016:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 17:40:45,036:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 17:40:45,050:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 17:40:45,066:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 17:40:45,089:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 17:40:45,101:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 17:40:45,126:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 17:40:45,134:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 17:40:45,154:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-29 17:40:45,172:INFO:Calculating mean and std
2024-05-29 17:40:45,174:INFO:Creating metrics dataframe
2024-05-29 17:40:45,177:INFO:Uploading results into container
2024-05-29 17:40:45,178:INFO:Uploading model into container now
2024-05-29 17:40:45,178:INFO:_master_model_container: 15
2024-05-29 17:40:45,179:INFO:_display_container: 2
2024-05-29 17:40:45,179:INFO:DummyClassifier(constant=None, random_state=7886, strategy='prior')
2024-05-29 17:40:45,179:INFO:create_model() successfully completed......................................
2024-05-29 17:40:46,846:INFO:SubProcess create_model() end ==================================
2024-05-29 17:40:46,847:INFO:Creating metrics dataframe
2024-05-29 17:40:46,867:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-29 17:40:46,879:INFO:Initializing create_model()
2024-05-29 17:40:46,880:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E640CDA1A0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-29 17:40:46,880:INFO:Checking exceptions
2024-05-29 17:40:46,882:INFO:Importing libraries
2024-05-29 17:40:46,883:INFO:Copying training dataset
2024-05-29 17:40:46,930:INFO:Defining folds
2024-05-29 17:40:46,930:INFO:Declaring metric variables
2024-05-29 17:40:46,931:INFO:Importing untrained model
2024-05-29 17:40:46,931:INFO:Declaring custom model
2024-05-29 17:40:46,933:INFO:Extreme Gradient Boosting Imported successfully
2024-05-29 17:40:46,934:INFO:Cross validation set to False
2024-05-29 17:40:46,934:INFO:Fitting Model
2024-05-29 17:40:47,217:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-29 17:40:47,217:INFO:create_model() successfully completed......................................
2024-05-29 17:40:48,883:INFO:Creating Dashboard logs
2024-05-29 17:40:48,889:INFO:Model: Extreme Gradient Boosting
2024-05-29 17:40:48,991:INFO:Logged params: {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 7886, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2024-05-29 17:40:49,279:INFO:Initializing predict_model()
2024-05-29 17:40:49,279:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E640CDA1A0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E688AB0790>)
2024-05-29 17:40:49,279:INFO:Checking exceptions
2024-05-29 17:40:49,279:INFO:Preloading libraries
2024-05-29 17:40:51,132:WARNING:c:\Users\Adm\.conda\envs\python310\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2024-05-29 17:40:54,663:INFO:Creating Dashboard logs
2024-05-29 17:40:54,668:INFO:Model: Light Gradient Boosting Machine
2024-05-29 17:40:54,757:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 7886, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-05-29 17:40:56,672:INFO:Creating Dashboard logs
2024-05-29 17:40:56,676:INFO:Model: Gradient Boosting Classifier
2024-05-29 17:40:56,765:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 7886, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-29 17:40:58,654:INFO:Creating Dashboard logs
2024-05-29 17:40:58,658:INFO:Model: Random Forest Classifier
2024-05-29 17:40:58,747:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 7886, 'verbose': 0, 'warm_start': False}
2024-05-29 17:41:00,647:INFO:Creating Dashboard logs
2024-05-29 17:41:00,652:INFO:Model: Ada Boost Classifier
2024-05-29 17:41:00,741:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 7886}
2024-05-29 17:41:02,607:INFO:Creating Dashboard logs
2024-05-29 17:41:02,612:INFO:Model: Extra Trees Classifier
2024-05-29 17:41:02,703:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 7886, 'verbose': 0, 'warm_start': False}
2024-05-29 17:41:04,601:INFO:Creating Dashboard logs
2024-05-29 17:41:04,606:INFO:Model: Logistic Regression
2024-05-29 17:41:04,696:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 7886, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-05-29 17:41:06,589:INFO:Creating Dashboard logs
2024-05-29 17:41:06,593:INFO:Model: SVM - Linear Kernel
2024-05-29 17:41:06,683:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 7886, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-29 17:41:08,599:INFO:Creating Dashboard logs
2024-05-29 17:41:08,603:INFO:Model: Ridge Classifier
2024-05-29 17:41:08,694:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 7886, 'solver': 'auto', 'tol': 0.0001}
2024-05-29 17:41:10,549:INFO:Creating Dashboard logs
2024-05-29 17:41:10,554:INFO:Model: Linear Discriminant Analysis
2024-05-29 17:41:10,643:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-05-29 17:41:12,505:INFO:Creating Dashboard logs
2024-05-29 17:41:12,510:INFO:Model: K Neighbors Classifier
2024-05-29 17:41:12,602:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2024-05-29 17:41:14,530:INFO:Creating Dashboard logs
2024-05-29 17:41:14,535:INFO:Model: Decision Tree Classifier
2024-05-29 17:41:14,626:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 7886, 'splitter': 'best'}
2024-05-29 17:41:16,514:INFO:Creating Dashboard logs
2024-05-29 17:41:16,518:INFO:Model: Quadratic Discriminant Analysis
2024-05-29 17:41:16,610:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2024-05-29 17:41:18,514:INFO:Creating Dashboard logs
2024-05-29 17:41:18,519:INFO:Model: Naive Bayes
2024-05-29 17:41:18,609:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-05-29 17:41:20,492:INFO:Creating Dashboard logs
2024-05-29 17:41:20,496:INFO:Model: Dummy Classifier
2024-05-29 17:41:20,587:INFO:Logged params: {'constant': None, 'random_state': 7886, 'strategy': 'prior'}
2024-05-29 17:41:22,468:INFO:_master_model_container: 15
2024-05-29 17:41:22,468:INFO:_display_container: 2
2024-05-29 17:41:22,470:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-29 17:41:22,470:INFO:compare_models() successfully completed......................................
